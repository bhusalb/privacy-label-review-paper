Authors,Title,keywords,Abstract,Year of Publication,Publication Venue,Article Link,Bib,Source
"Zhu, Ying and Xu, Bin and Shi, Xinghua and Wang, Yu",A Survey of Social-Based Routing in Delay Tolerant Networks: Positive and Negative Social Effects,Fault tolerant networks;Social network services;Routing;Relays;Routing protocols;Delays;DTN routing;Social-based approaches;Social graphs;Social network analysis;Delay tolerant networks,"Delay tolerant networks (DTNs) may lack continuous network connectivity. Routing in DTNs is thus challenging since it must handle network partitioning, long delays, and dynamic topology in such networks. In recent years, social-based approaches, which attempt to exploit social behaviors of DTN nodes to make better routing decision, have drawn tremendous interests in DTN routing design. In this article, we summarize the social properties in DTNs, and provide a survey of recent social-based DTN routing approaches. To improve routing performance, these methods either take advantages of positive social characteristics such as community and friendship to assist packet forwarding or consider negative social characteristics such as selfishness. We conclude by discussing some open issues and challenges in social-based approaches regarding the design of DTN routing protocols.",2013,IEEE Communications Surveys & Tutorials,,"{'month': 'First', 'issn': '1553-877X', 'doi': '10.1109/SURV.2012.032612.00004', 'keywords': 'Fault tolerant networks;Social network services;Routing;Relays;Routing protocols;Delays;DTN routing;Social-based approaches;Social graphs;Social network analysis;Delay tolerant networks', 'abstract': 'Delay tolerant networks (DTNs) may lack continuous network connectivity. Routing in DTNs is thus challenging since it must handle network partitioning, long delays, and dynamic topology in such networks. In recent years, social-based approaches, which attempt to exploit social behaviors of DTN nodes to make better routing decision, have drawn tremendous interests in DTN routing design. In this article, we summarize the social properties in DTNs, and provide a survey of recent social-based DTN routing approaches. To improve routing performance, these methods either take advantages of positive social characteristics such as community and friendship to assist packet forwarding or consider negative social characteristics such as selfishness. We conclude by discussing some open issues and challenges in social-based approaches regarding the design of DTN routing protocols.', 'pages': '387-401', 'number': '1', 'volume': '15', 'year': '2013', 'title': 'A Survey of Social-Based Routing in Delay Tolerant Networks: Positive and Negative Social Effects', 'journal': 'IEEE Communications Surveys & Tutorials', 'author': 'Zhu, Ying and Xu, Bin and Shi, Xinghua and Wang, Yu', 'ENTRYTYPE': 'article', 'ID': '6177189'}",IEEE Xplore
"Al-Rubaie, Mohammad and Chang, J. Morris",Privacy-Preserving Machine Learning: Threats and Solutions,Data models;Image reconstruction;Computational modeling;Training;Predictive models;Feature extraction;Testing,"For privacy concerns to be addressed adequately in today's machine-learning (ML) systems, the knowledge gap between the ML and privacy communities must be bridged. This article aims to provide an introduction to the intersection of both fields with special emphasis on the techniques used to protect the data.",2019,IEEE Security & Privacy,,"{'month': 'March', 'issn': '1558-4046', 'doi': '10.1109/MSEC.2018.2888775', 'keywords': 'Data models;Image reconstruction;Computational modeling;Training;Predictive models;Feature extraction;Testing', 'abstract': ""For privacy concerns to be addressed adequately in today's machine-learning (ML) systems, the knowledge gap between the ML and privacy communities must be bridged. This article aims to provide an introduction to the intersection of both fields with special emphasis on the techniques used to protect the data."", 'pages': '49-58', 'number': '2', 'volume': '17', 'year': '2019', 'title': 'Privacy-Preserving Machine Learning: Threats and Solutions', 'journal': 'IEEE Security & Privacy', 'author': 'Al-Rubaie, Mohammad and Chang, J. Morris', 'ENTRYTYPE': 'article', 'ID': '8677282'}",IEEE Xplore
"Emami-Naeini, Pardis and Agarwal, Yuvraj and Faith Cranor, Lorrie and Hibshi, Hanan",Ask the Experts: What Should Be on an IoT Privacy and Security Label?,Security;Privacy;Interviews;Government;Industries;Prototypes;Companies;Internet of Things (IoT);Privacy and Security;Label;Expert Elicitation;Delphi,"Information about the privacy and security of Internet of Things (IoT) devices is not readily available to consumers who want to consider it before making purchase decisions. While legislators have proposed adding succinct, consumer accessible, labels, they do not provide guidance on the content of these labels. In this paper, we report on the results of a series of interviews and surveys with privacy and security experts, as well as consumers, where we explore and test the design space of the content to include on an IoT privacy and security label. We conduct an expert elicitation study by following a three-round Delphi process with 22 privacy and security experts to identify the factors that experts believed are important for consumers when comparing the privacy and security of IoT devices to inform their purchase decisions. Based on how critical experts believed each factor is in conveying risk to consumers, we distributed these factors across two layers-a primary layer to display on the product package itself or prominently on a website, and a secondary layer available online through a web link or a QR code. We report on the experts' rationale and arguments used to support their choice of factors. Moreover, to study how consumers would perceive the privacy and security information specified by experts, we conducted a series of semi-structured interviews with 15 participants, who had purchased at least one IoT device (smart home device or wearable). Based on the results of our expert elicitation and consumer studies, we propose a prototype privacy and security label to help consumers make more informed IoT-related purchase decisions.",2020,2020 IEEE Symposium on Security and Privacy (SP),,"{'month': 'May', 'issn': '2375-1207', 'doi': '10.1109/SP40000.2020.00043', 'keywords': 'Security;Privacy;Interviews;Government;Industries;Prototypes;Companies;Internet of Things (IoT);Privacy and Security;Label;Expert Elicitation;Delphi', 'abstract': ""Information about the privacy and security of Internet of Things (IoT) devices is not readily available to consumers who want to consider it before making purchase decisions. While legislators have proposed adding succinct, consumer accessible, labels, they do not provide guidance on the content of these labels. In this paper, we report on the results of a series of interviews and surveys with privacy and security experts, as well as consumers, where we explore and test the design space of the content to include on an IoT privacy and security label. We conduct an expert elicitation study by following a three-round Delphi process with 22 privacy and security experts to identify the factors that experts believed are important for consumers when comparing the privacy and security of IoT devices to inform their purchase decisions. Based on how critical experts believed each factor is in conveying risk to consumers, we distributed these factors across two layers-a primary layer to display on the product package itself or prominently on a website, and a secondary layer available online through a web link or a QR code. We report on the experts' rationale and arguments used to support their choice of factors. Moreover, to study how consumers would perceive the privacy and security information specified by experts, we conducted a series of semi-structured interviews with 15 participants, who had purchased at least one IoT device (smart home device or wearable). Based on the results of our expert elicitation and consumer studies, we propose a prototype privacy and security label to help consumers make more informed IoT-related purchase decisions."", 'pages': '447-464', 'number': '', 'volume': '', 'year': '2020', 'title': 'Ask the Experts: What Should Be on an IoT Privacy and Security Label?', 'booktitle': '2020 IEEE Symposium on Security and Privacy (SP)', 'author': 'Emami-Naeini, Pardis and Agarwal, Yuvraj and Faith Cranor, Lorrie and Hibshi, Hanan', 'ENTRYTYPE': 'inproceedings', 'ID': '9152770'}",IEEE Xplore
"Wang, Xiaofan and Wang, Lei and Li, Yujun and Gai, Keke",Privacy-Aware Efficient Fine-Grained Data Access Control in Internet of Medical Things Based Fog Computing,Access control;Edge computing;Cloud computing;Servers;Privacy;Internet of Medical Things;fog computing;privacy-aware;fine-grained data access control;privacy time optimization,"The recent development of cloud computing has empowered the Internet-based services, which enable users to gain a broad scope of access to their applications, such as Internet of Medical Things (IoMT). Considering the efficiency performance, the privacy protection is often kept at a lower level in order to ensure the application can offer a higher level performance. However, this mechanism also causes a serious concern of privacy hazards due to the information over collections operated by apps/applications. Addressing this privacy issue, this paper proposes an approach that is designed to provide high-level privacy protection without lowering down the efficiency in cloud/fog computing (especially in biological systems of IoMT). The proposed model is called fog-based access control model. The fine-grained data access control is combined with the implementation of fog computing in the proposed approach. Our simulation experiment has shown that our approach could offer high-level privacy protection within a shortened execution time, thus it can be useful for IoMT-based applications.",2018,IEEE Access,,"{'month': '', 'issn': '2169-3536', 'doi': '10.1109/ACCESS.2018.2856896', 'keywords': 'Access control;Edge computing;Cloud computing;Servers;Privacy;Internet of Medical Things;fog computing;privacy-aware;fine-grained data access control;privacy time optimization', 'abstract': 'The recent development of cloud computing has empowered the Internet-based services, which enable users to gain a broad scope of access to their applications, such as Internet of Medical Things (IoMT). Considering the efficiency performance, the privacy protection is often kept at a lower level in order to ensure the application can offer a higher level performance. However, this mechanism also causes a serious concern of privacy hazards due to the information over collections operated by apps/applications. Addressing this privacy issue, this paper proposes an approach that is designed to provide high-level privacy protection without lowering down the efficiency in cloud/fog computing (especially in biological systems of IoMT). The proposed model is called fog-based access control model. The fine-grained data access control is combined with the implementation of fog computing in the proposed approach. Our simulation experiment has shown that our approach could offer high-level privacy protection within a shortened execution time, thus it can be useful for IoMT-based applications.', 'pages': '47657-47665', 'number': '', 'volume': '6', 'year': '2018', 'title': 'Privacy-Aware Efficient Fine-Grained Data Access Control in Internet of Medical Things Based Fog Computing', 'journal': 'IEEE Access', 'author': 'Wang, Xiaofan and Wang, Lei and Li, Yujun and Gai, Keke', 'ENTRYTYPE': 'article', 'ID': '8412491'}",IEEE Xplore
"Li, Kaiyang and Luo, Guangchun and Ye, Yang and Li, Wei and Ji, Shihao and Cai, Zhipeng",Adversarial Privacy-Preserving Graph Embedding Against Inference Attack,Privacy;Internet of Things;Social networking (online);Topology;Inference algorithms;Differential privacy;Network topology;Adversarial learning;data privacy;graph embedding;inference attack,"Recently, the surge in popularity of the Internet of Things (IoT), mobile devices, social media, etc., has opened up a large source for graph data. Graph embedding has been proved extremely useful to learn low-dimensional feature representations from graph-structured data. These feature representations can be used for a variety of prediction tasks from node classification to link prediction. However, the existing graph embedding methods do not consider users' privacy to prevent inference attacks. That is, adversaries can infer users' sensitive information by analyzing node representations learned from graph embedding algorithms. In this article, we propose adversarial privacy graph embedding (APGE), a graph adversarial training framework that integrates the disentangling and purging mechanisms to remove users' private information from learned node representations. The proposed method preserves the structural information and utility attributes of a graph while concealing users' private attributes from inference attacks. Extensive experiments on real-world graph data sets demonstrate the superior performance of APGE compared to the state-of-the-arts. Our source code can be found at https://github.com/KaiyangLi1992/Privacy-Preserving-Social-Network-Embedding.",2021,IEEE Internet of Things Journal,,"{'month': 'April', 'issn': '2327-4662', 'doi': '10.1109/JIOT.2020.3036583', 'keywords': 'Privacy;Internet of Things;Social networking (online);Topology;Inference algorithms;Differential privacy;Network topology;Adversarial learning;data privacy;graph embedding;inference attack', 'abstract': ""Recently, the surge in popularity of the Internet of Things (IoT), mobile devices, social media, etc., has opened up a large source for graph data. Graph embedding has been proved extremely useful to learn low-dimensional feature representations from graph-structured data. These feature representations can be used for a variety of prediction tasks from node classification to link prediction. However, the existing graph embedding methods do not consider users' privacy to prevent inference attacks. That is, adversaries can infer users' sensitive information by analyzing node representations learned from graph embedding algorithms. In this article, we propose adversarial privacy graph embedding (APGE), a graph adversarial training framework that integrates the disentangling and purging mechanisms to remove users' private information from learned node representations. The proposed method preserves the structural information and utility attributes of a graph while concealing users' private attributes from inference attacks. Extensive experiments on real-world graph data sets demonstrate the superior performance of APGE compared to the state-of-the-arts. Our source code can be found at https://github.com/KaiyangLi1992/Privacy-Preserving-Social-Network-Embedding."", 'pages': '6904-6915', 'number': '8', 'volume': '8', 'year': '2021', 'title': 'Adversarial Privacy-Preserving Graph Embedding Against Inference Attack', 'journal': 'IEEE Internet of Things Journal', 'author': 'Li, Kaiyang and Luo, Guangchun and Ye, Yang and Li, Wei and Ji, Shihao and Cai, Zhipeng', 'ENTRYTYPE': 'article', 'ID': '9250489'}",IEEE Xplore
"Kung, S.Y.",Compressive Privacy: From Information\/Estimation Theory to Machine Learning [Lecture Notes],Privacy;Data privacy;Entropy;Covariance matrices;Cloud computing;Big data,"Most of our daily activities are now moving online in the big data era, with more than 25 billion devices already connected to the Internet, to possibly over a trillion in a decade. However, big data also bears a connotation of “big brother” when personal information (such as sales transactions) is being ubiquitously collected, stored, and circulated around the Internet, often without the data owner's knowledge. Consequently, a new paradigm known as online privacy or Internet privacy is becoming a major concern regarding the privacy of personal and sensitive data.",2017,IEEE Signal Processing Magazine,,"{'month': 'Jan', 'issn': '1558-0792', 'doi': '10.1109/MSP.2016.2616720', 'keywords': 'Privacy;Data privacy;Entropy;Covariance matrices;Cloud computing;Big data', 'abstract': ""Most of our daily activities are now moving online in the big data era, with more than 25 billion devices already connected to the Internet, to possibly over a trillion in a decade. However, big data also bears a connotation of “big brother” when personal information (such as sales transactions) is being ubiquitously collected, stored, and circulated around the Internet, often without the data owner's knowledge. Consequently, a new paradigm known as online privacy or Internet privacy is becoming a major concern regarding the privacy of personal and sensitive data."", 'pages': '94-112', 'number': '1', 'volume': '34', 'year': '2017', 'title': 'Compressive Privacy: From Information\\/Estimation Theory to Machine Learning [Lecture Notes]', 'journal': 'IEEE Signal Processing Magazine', 'author': 'Kung, S.Y.', 'ENTRYTYPE': 'article', 'ID': '7815484'}",IEEE Xplore
"Benton, Kevin and Camp, L. Jean and Garg, Vaibhav",Studying the effectiveness of android application permissions requests,Privacy;Software;Facebook;Smart phones;Visualization;Androids;Humanoid robots,"Popular platforms including Android and Facebook have adopted a permissions-based model. Under this model applications (apps) are required to declare specific access to user information required for functionality. We conducted two user studies on Amazon's Mechanical Turk to test the efficacy of these permissions requests on the Android platform. We found permissions were ineffective, even with the addition of an additional text warning. Conversely, we found that an app's download count had a strong effect on app installations. In order to determine if it was a failure of our text-based warning, we ran a second experiment with a previously proven visual indicator.",2013,2013 IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops),,"{'month': 'March', 'issn': '', 'doi': '10.1109/PerComW.2013.6529497', 'keywords': 'Privacy;Software;Facebook;Smart phones;Visualization;Androids;Humanoid robots', 'abstract': ""Popular platforms including Android and Facebook have adopted a permissions-based model. Under this model applications (apps) are required to declare specific access to user information required for functionality. We conducted two user studies on Amazon's Mechanical Turk to test the efficacy of these permissions requests on the Android platform. We found permissions were ineffective, even with the addition of an additional text warning. Conversely, we found that an app's download count had a strong effect on app installations. In order to determine if it was a failure of our text-based warning, we ran a second experiment with a previously proven visual indicator."", 'pages': '291-296', 'number': '', 'volume': '', 'year': '2013', 'title': 'Studying the effectiveness of android application permissions requests', 'booktitle': '2013 IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops)', 'author': 'Benton, Kevin and Camp, L. Jean and Garg, Vaibhav', 'ENTRYTYPE': 'inproceedings', 'ID': '6529497'}",IEEE Xplore
"Ahn, G.-J. and Ko, M. and Shehab, M.",Privacy-Enhanced User-Centric Identity Management,Identity management systems;Privacy;Digital control;Technology management;Protection;Web services;Communications Society;Authentication;Prototypes;User interfaces,"User-centric identity management approaches have received significant attention for managing private and critical identity attributes from the user's perspective. User-centric identity management allows users to control their own digital identities. Users are allowed to select their credentials when responding to an authentication or attribute requester and it gives users more rights and responsibility over their identity information. However, current user-centric approaches mainly focus on interoperable architectures between existing identity management systems and privacy issues have not been considered in depth. In this paper, we propose a category-based privacy preference approach to enhance the privacy of user-centric identity management systems. In addition, we present our proof- of-concept prototype of our approach in the Identity Metasystem.",2009,2009 IEEE International Conference on Communications,,"{'month': 'June', 'issn': '1938-1883', 'doi': '10.1109/ICC.2009.5199363', 'keywords': 'Identity management systems;Privacy;Digital control;Technology management;Protection;Web services;Communications Society;Authentication;Prototypes;User interfaces', 'abstract': ""User-centric identity management approaches have received significant attention for managing private and critical identity attributes from the user's perspective. User-centric identity management allows users to control their own digital identities. Users are allowed to select their credentials when responding to an authentication or attribute requester and it gives users more rights and responsibility over their identity information. However, current user-centric approaches mainly focus on interoperable architectures between existing identity management systems and privacy issues have not been considered in depth. In this paper, we propose a category-based privacy preference approach to enhance the privacy of user-centric identity management systems. In addition, we present our proof- of-concept prototype of our approach in the Identity Metasystem."", 'pages': '1-5', 'number': '', 'volume': '', 'year': '2009', 'title': 'Privacy-Enhanced User-Centric Identity Management', 'booktitle': '2009 IEEE International Conference on Communications', 'author': 'Ahn, G.-J. and Ko, M. and Shehab, M.', 'ENTRYTYPE': 'inproceedings', 'ID': '5199363'}",IEEE Xplore
"Zavvos, Efstathios and Gerding, Enrico H. and Yazdanpanah, Vahid and Maple, Carsten and Stein, Sebastian and schraefel, m.c.",Privacy and Trust in the Internet of Vehicles,Privacy;Internet of Things;Vehicular ad hoc networks;Data privacy;Safety;Security;Peer-to-peer computing;Privacy;trust;Internet of Vehicles;IoV;IoT;connected vehicles,"The Internet of Vehicles aims to fundamentally improve transportation by connecting vehicles, drivers, passengers, and service providers together. Several new services such as parking space identification, platooning and intersection control—to name just a few—are expected to improve traffic congestion, reduce pollution, and improve the efficiency, safety and logistics of transportation. Proposed end-user services, however, make extensive use of private information with little consideration for the impact on users and third parties (those individuals whose information is indirectly involved). This article provides the first comprehensive overview of privacy and trust issues in the Internet of Vehicles at the service level. Various concerns over privacy are formalised into four basic categories: personal information privacy, multi-party privacy, trust, and consent to share information. To help analyse services and to facilitate future research, the main relevant end-user services are taxonomised according to voluntary and involuntary information they require and produce. Finally, this work identifies several open research problems and highlights general approaches to address them. These especially relate to measuring the trade-off between privacy and service functionality, automated consent negotiation, trust towards the IoV and its individual services, and identifying and resolving multi-party privacy conflicts.",2022,IEEE Transactions on Intelligent Transportation Systems,,"{'month': 'Aug', 'issn': '1558-0016', 'doi': '10.1109/TITS.2021.3121125', 'keywords': 'Privacy;Internet of Things;Vehicular ad hoc networks;Data privacy;Safety;Security;Peer-to-peer computing;Privacy;trust;Internet of Vehicles;IoV;IoT;connected vehicles', 'abstract': 'The Internet of Vehicles aims to fundamentally improve transportation by connecting vehicles, drivers, passengers, and service providers together. Several new services such as parking space identification, platooning and intersection control—to name just a few—are expected to improve traffic congestion, reduce pollution, and improve the efficiency, safety and logistics of transportation. Proposed end-user services, however, make extensive use of private information with little consideration for the impact on users and third parties (those individuals whose information is indirectly involved). This article provides the first comprehensive overview of privacy and trust issues in the Internet of Vehicles at the service level. Various concerns over privacy are formalised into four basic categories: personal information privacy, multi-party privacy, trust, and consent to share information. To help analyse services and to facilitate future research, the main relevant end-user services are taxonomised according to voluntary and involuntary information they require and produce. Finally, this work identifies several open research problems and highlights general approaches to address them. These especially relate to measuring the trade-off between privacy and service functionality, automated consent negotiation, trust towards the IoV and its individual services, and identifying and resolving multi-party privacy conflicts.', 'pages': '10126-10141', 'number': '8', 'volume': '23', 'year': '2022', 'title': 'Privacy and Trust in the Internet of Vehicles', 'journal': 'IEEE Transactions on Intelligent Transportation Systems', 'author': 'Zavvos, Efstathios and Gerding, Enrico H. and Yazdanpanah, Vahid and Maple, Carsten and Stein, Sebastian and schraefel, m.c.', 'ENTRYTYPE': 'article', 'ID': '9590550'}",IEEE Xplore
"Wang, Ziyuan",Security and Privacy Issues within the Cloud Computing,Cloud computing;Privacy;Access control;Data privacy;Servers;Computer architecture;Cloud Computing;Security issues;Privacy issues;Security solutions;Privacy solutions,"Cloud Computing has been regarded as evolutionary paradigm recently. It has much strength, such as large storage, ubiquitous network access, cost effective and so on. However it also faces security and privacy concerns. In this paper, we discussed several major security and privacy issues. And we also proposed four effective methods to handle such issues. According to the features of issues, we investigated the feasible solutions and finally found four methods. Such methods can be applied to the generalized Cloud Computing. This paper is original that we consider the characteristics of Cloud Computing adequately, so the methods are well functioned and can be developed further to solve other problems.",2011,2011 International Conference on Computational and Information Sciences,,"{'month': 'Oct', 'issn': '', 'doi': '10.1109/ICCIS.2011.247', 'keywords': 'Cloud computing;Privacy;Access control;Data privacy;Servers;Computer architecture;Cloud Computing;Security issues;Privacy issues;Security solutions;Privacy solutions', 'abstract': 'Cloud Computing has been regarded as evolutionary paradigm recently. It has much strength, such as large storage, ubiquitous network access, cost effective and so on. However it also faces security and privacy concerns. In this paper, we discussed several major security and privacy issues. And we also proposed four effective methods to handle such issues. According to the features of issues, we investigated the feasible solutions and finally found four methods. Such methods can be applied to the generalized Cloud Computing. This paper is original that we consider the characteristics of Cloud Computing adequately, so the methods are well functioned and can be developed further to solve other problems.', 'pages': '175-178', 'number': '', 'volume': '', 'year': '2011', 'title': 'Security and Privacy Issues within the Cloud Computing', 'booktitle': '2011 International Conference on Computational and Information Sciences', 'author': 'Wang, Ziyuan', 'ENTRYTYPE': 'inproceedings', 'ID': '6086163'}",IEEE Xplore
"Zhang, Hongli and Zhou, Zhigang and Ye, Lin and Du, Xiaojiang",Towards Privacy Preserving Publishing of Set-Valued Data on Hybrid Cloud,Cloud computing;Data privacy;Publishing;Security;Privacy;Measurement;Outsourcing;Cloud computing;differential privacy;data partition;data privacy;hybrid cloud;set-valued data,"Storage as a service has become an important paradigm in cloud computing for its great flexibility and economic savings. However, the development is hampered by data privacy concerns: data owners no longer physically possess the storage of their data. In this work, we study the issue of privacy-preserving set-valued data publishing. Existing data privacy-preserving techniques (such as encryption, suppression, generalization) are not applicable in many real scenes, since they would incur large overhead for data query or high information loss. Motivated by this observation, we present a suite of new techniques that make privacy-aware set-valued data publishing feasible on hybrid cloud. On data publishing phase, we propose a data partition technique, named extended quasi-identifierpartitioning (EQI-partitioning), which disassociates record terms that participate in identifying combinations. This way the cloud server cannot associate with high probability a record with rare term combinations. We prove the privacy guarantee of our mechanism. On data querying phase, we adopt interactive differential privacy strategy to resist privacy breaches from statistical queries. We finally evaluate its performance using real-life data sets on our cloud test-bed. Our extensive experiments demonstrate the validity and practicality of the proposed scheme.",2018,IEEE Transactions on Cloud Computing,,"{'month': 'April', 'issn': '2168-7161', 'doi': '10.1109/TCC.2015.2430316', 'keywords': 'Cloud computing;Data privacy;Publishing;Security;Privacy;Measurement;Outsourcing;Cloud computing;differential privacy;data partition;data privacy;hybrid cloud;set-valued data', 'abstract': 'Storage as a service has become an important paradigm in cloud computing for its great flexibility and economic savings. However, the development is hampered by data privacy concerns: data owners no longer physically possess the storage of their data. In this work, we study the issue of privacy-preserving set-valued data publishing. Existing data privacy-preserving techniques (such as encryption, suppression, generalization) are not applicable in many real scenes, since they would incur large overhead for data query or high information loss. Motivated by this observation, we present a suite of new techniques that make privacy-aware set-valued data publishing feasible on hybrid cloud. On data publishing phase, we propose a data partition technique, named extended quasi-identifierpartitioning (EQI-partitioning), which disassociates record terms that participate in identifying combinations. This way the cloud server cannot associate with high probability a record with rare term combinations. We prove the privacy guarantee of our mechanism. On data querying phase, we adopt interactive differential privacy strategy to resist privacy breaches from statistical queries. We finally evaluate its performance using real-life data sets on our cloud test-bed. Our extensive experiments demonstrate the validity and practicality of the proposed scheme.', 'pages': '316-329', 'number': '2', 'volume': '6', 'year': '2018', 'title': 'Towards Privacy Preserving Publishing of Set-Valued Data on Hybrid Cloud', 'journal': 'IEEE Transactions on Cloud Computing', 'author': 'Zhang, Hongli and Zhou, Zhigang and Ye, Lin and Du, Xiaojiang', 'ENTRYTYPE': 'article', 'ID': '7103035'}",IEEE Xplore
"Dave, Ishan Rajendrakumar and Chen, Chen and Shah, Mubarak",SPAct: Self-supervised Privacy Preservation for Action Recognition,Training;Privacy;Data privacy;Visualization;Computer vision;Protocols;Self-supervised learning;Action and event recognition; Privacy and federated learning; Self-& semi-& meta- Video analysis and understanding,"Visual private information leakage is an emerging key is-sue for the fast growing applications of video understanding like activity recognition. Existing approaches for mitigating privacy leakage in action recognition require privacy labels along with the action labels from the video dataset. However, annotating frames of video dataset for privacy la-bels is not feasible. Recent developments of self-supervised learning (SSL) have unleashed the untapped potential of the unlabeled data. For the first time, we present a novel training framework which removes privacy information from in-put video in a self-supervised manner without requiring pri-vacy labels. Our training framework consists of three main components: anonymization function, self-supervised pri-vacy removal branch, and action recognition branch. We train our framework using a minimax optimization strategy to minimize the action recognition cost function and max-imize the privacy cost function through a contrastive self-supervised loss. Employing existing protocols of known-action and privacy attributes, our framework achieves a competitive action-privacy trade-off to the existing state-of-the-art supervised methods. In addition, we introduce a new protocol to evaluate the generalization of learned the anonymization function to novel-action and privacy at-tributes and show that our self-supervised framework out-performs existing supervised methods. Code available at: https://github.com/DAVEISHAN/SPAct",2022,2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),,"{'month': 'June', 'issn': '2575-7075', 'doi': '10.1109/CVPR52688.2022.01953', 'keywords': 'Training;Privacy;Data privacy;Visualization;Computer vision;Protocols;Self-supervised learning;Action and event recognition; Privacy and federated learning; Self-& semi-& meta- Video analysis and understanding', 'abstract': 'Visual private information leakage is an emerging key is-sue for the fast growing applications of video understanding like activity recognition. Existing approaches for mitigating privacy leakage in action recognition require privacy labels along with the action labels from the video dataset. However, annotating frames of video dataset for privacy la-bels is not feasible. Recent developments of self-supervised learning (SSL) have unleashed the untapped potential of the unlabeled data. For the first time, we present a novel training framework which removes privacy information from in-put video in a self-supervised manner without requiring pri-vacy labels. Our training framework consists of three main components: anonymization function, self-supervised pri-vacy removal branch, and action recognition branch. We train our framework using a minimax optimization strategy to minimize the action recognition cost function and max-imize the privacy cost function through a contrastive self-supervised loss. Employing existing protocols of known-action and privacy attributes, our framework achieves a competitive action-privacy trade-off to the existing state-of-the-art supervised methods. In addition, we introduce a new protocol to evaluate the generalization of learned the anonymization function to novel-action and privacy at-tributes and show that our self-supervised framework out-performs existing supervised methods. Code available at: https://github.com/DAVEISHAN/SPAct', 'pages': '20132-20141', 'number': '', 'volume': '', 'year': '2022', 'title': 'SPAct: Self-supervised Privacy Preservation for Action Recognition', 'booktitle': '2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)', 'author': 'Dave, Ishan Rajendrakumar and Chen, Chen and Shah, Mubarak', 'ENTRYTYPE': 'inproceedings', 'ID': '9879004'}",IEEE Xplore
"Morgner, Philipp and Mai, Christoph and Koschate-Fischer, Nicole and Freiling, Felix and Benenson, Zinaida",Security Update Labels: Establishing Economic Incentives for Security Patching of IoT Consumer Products,Security;Privacy;Consumer products;Internet of Things;Labeling;Economics;Testing,"With the expansion of the Internet of Things (IoT), the number of security incidents due to insecure and misconfigured IoT devices is increasing. Especially on the consumer market, manufacturers focus on new features and early releases at the expense of a comprehensive security strategy. Hence, experts have started calling for regulation of the IoT consumer market, while policymakers are seeking for suitable regulatory approaches. We investigate how manufacturers can be incentivized to increase sustainable security efforts for IoT products. We propose mandatory security update labels that inform consumers during buying decisions about the willingness of the manufacturer to provide security updates in the future. Mandatory means that the labels explicitly state when security updates are not guaranteed. We conducted a user study with more than 1,400 participants to assess the importance of security update labels for the consumer choice by means of a conjoint analysis. The results show that the availability of security updates (until which date the updates are guaranteed) accounts for 8% to 35% impact on overall consumers' choice, depending on the perceived security risk of the product category. For products with a high perceived security risk, this availability is twice as important as other high-ranked product attributes. Moreover, provisioning time for security updates (how quickly the product will be patched after a vulnerability is discovered) additionally accounts for 7% to 25% impact on consumers' choices. The proposed labels are intuitively understood by consumers, do not require product assessments by third parties before release, and have a potential to incentivize manufacturers to provide sustainable security support.",2020,2020 IEEE Symposium on Security and Privacy (SP),,"{'month': 'May', 'issn': '2375-1207', 'doi': '10.1109/SP40000.2020.00021', 'keywords': 'Security;Privacy;Consumer products;Internet of Things;Labeling;Economics;Testing', 'abstract': ""With the expansion of the Internet of Things (IoT), the number of security incidents due to insecure and misconfigured IoT devices is increasing. Especially on the consumer market, manufacturers focus on new features and early releases at the expense of a comprehensive security strategy. Hence, experts have started calling for regulation of the IoT consumer market, while policymakers are seeking for suitable regulatory approaches. We investigate how manufacturers can be incentivized to increase sustainable security efforts for IoT products. We propose mandatory security update labels that inform consumers during buying decisions about the willingness of the manufacturer to provide security updates in the future. Mandatory means that the labels explicitly state when security updates are not guaranteed. We conducted a user study with more than 1,400 participants to assess the importance of security update labels for the consumer choice by means of a conjoint analysis. The results show that the availability of security updates (until which date the updates are guaranteed) accounts for 8% to 35% impact on overall consumers' choice, depending on the perceived security risk of the product category. For products with a high perceived security risk, this availability is twice as important as other high-ranked product attributes. Moreover, provisioning time for security updates (how quickly the product will be patched after a vulnerability is discovered) additionally accounts for 7% to 25% impact on consumers' choices. The proposed labels are intuitively understood by consumers, do not require product assessments by third parties before release, and have a potential to incentivize manufacturers to provide sustainable security support."", 'pages': '429-446', 'number': '', 'volume': '', 'year': '2020', 'title': 'Security Update Labels: Establishing Economic Incentives for Security Patching of IoT Consumer Products', 'booktitle': '2020 IEEE Symposium on Security and Privacy (SP)', 'author': 'Morgner, Philipp and Mai, Christoph and Koschate-Fischer, Nicole and Freiling, Felix and Benenson, Zinaida', 'ENTRYTYPE': 'inproceedings', 'ID': '9152783'}",IEEE Xplore
"Emami-Naeini, Pardis and Dheenadhayalan, Janarth and Agarwal, Yuvraj and Cranor, Lorrie Faith",Which Privacy and Security Attributes Most Impact Consumers’ Risk Perception and Willingness to Purchase IoT Devices?,Privacy;Atmospheric measurements;Particle measurements;Security;Internet of Things;Usability;Smart devices;Internet of Things (IoT);Privacy and Security;Label;Risk Perception;Willingness to Purchase,"In prior work, researchers proposed an Internet of Things (IoT) security and privacy label akin to a food nutrition label, based on input from experts. We conducted a survey with 1,371 Mechanical Turk (MTurk) participants to test the effectiveness of each of the privacy and security attribute-value pairs proposed in that prior work along two key dimensions: ability to convey risk to consumers and impact on their willingness to purchase an IoT device. We found that the values intended to communicate increased risk were generally perceived that way by participants. For example, we found that consumers perceived more risk when a label conveyed that data would be sold to third parties than when it would not be sold at all, and that consumers were more willing to purchase devices when they knew that their data would not be retained or shared with others. However, participants’ risk perception did not always align with their willingness to purchase, sometimes due to usability concerns. Based on our findings, we propose actionable recommendations on how to more effectively present privacy and security attributes on an IoT label to better communicate risk to consumers.",2021,2021 IEEE Symposium on Security and Privacy (SP),,"{'month': 'May', 'issn': '2375-1207', 'doi': '10.1109/SP40001.2021.00112', 'keywords': 'Privacy;Atmospheric measurements;Particle measurements;Security;Internet of Things;Usability;Smart devices;Internet of Things (IoT);Privacy and Security;Label;Risk Perception;Willingness to Purchase', 'abstract': 'In prior work, researchers proposed an Internet of Things (IoT) security and privacy label akin to a food nutrition label, based on input from experts. We conducted a survey with 1,371 Mechanical Turk (MTurk) participants to test the effectiveness of each of the privacy and security attribute-value pairs proposed in that prior work along two key dimensions: ability to convey risk to consumers and impact on their willingness to purchase an IoT device. We found that the values intended to communicate increased risk were generally perceived that way by participants. For example, we found that consumers perceived more risk when a label conveyed that data would be sold to third parties than when it would not be sold at all, and that consumers were more willing to purchase devices when they knew that their data would not be retained or shared with others. However, participants’ risk perception did not always align with their willingness to purchase, sometimes due to usability concerns. Based on our findings, we propose actionable recommendations on how to more effectively present privacy and security attributes on an IoT label to better communicate risk to consumers.', 'pages': '519-536', 'number': '', 'volume': '', 'year': '2021', 'title': 'Which Privacy and Security Attributes Most Impact Consumers’ Risk Perception and Willingness to Purchase IoT Devices?', 'booktitle': '2021 IEEE Symposium on Security and Privacy (SP)', 'author': 'Emami-Naeini, Pardis and Dheenadhayalan, Janarth and Agarwal, Yuvraj and Cranor, Lorrie Faith', 'ENTRYTYPE': 'inproceedings', 'ID': '9519463'}",IEEE Xplore
"Moncrieff, Simon and Venkatesh, Svetha and West, Geoff",Dynamic Privacy in a Smart House Environment,Data privacy;Surveillance;Biomedical monitoring;Data encapsulation;Space technology;Domestic safety;Aging;Smart homes;Pervasive computing;Linear feedback control systems,"A smart house can be regarded as a surveillance environment in which the person being observed carries out activities that range from intimate to more public. What can be observed depends on the activity, the person observing (e.g. a carer) and policy. In assisted living smart house environments, a single privacy policy, applied throughout, would be either too invasive for an occupant, or too restrictive for an observer, due to the conflicting goals of surveillance and private environments. Hence, we propose a dynamic method for altering the level of privacy in the environment based on the context, the situation within the environment, encompassing factors relevant to ensuring the occupant's safety and privacy. The context is mapped to an appropriate level of privacy, which is implemented by controlling access to data sources (e.g. video) using data hiding techniques. The aim of this work is to decrease the invasiveness of the technology, while retaining the purpose of the system.",2007,2007 IEEE International Conference on Multimedia and Expo,,"{'month': 'July', 'issn': '1945-788X', 'doi': '10.1109/ICME.2007.4285080', 'keywords': 'Data privacy;Surveillance;Biomedical monitoring;Data encapsulation;Space technology;Domestic safety;Aging;Smart homes;Pervasive computing;Linear feedback control systems', 'abstract': ""A smart house can be regarded as a surveillance environment in which the person being observed carries out activities that range from intimate to more public. What can be observed depends on the activity, the person observing (e.g. a carer) and policy. In assisted living smart house environments, a single privacy policy, applied throughout, would be either too invasive for an occupant, or too restrictive for an observer, due to the conflicting goals of surveillance and private environments. Hence, we propose a dynamic method for altering the level of privacy in the environment based on the context, the situation within the environment, encompassing factors relevant to ensuring the occupant's safety and privacy. The context is mapped to an appropriate level of privacy, which is implemented by controlling access to data sources (e.g. video) using data hiding techniques. The aim of this work is to decrease the invasiveness of the technology, while retaining the purpose of the system."", 'pages': '2034-2037', 'number': '', 'volume': '', 'year': '2007', 'title': 'Dynamic Privacy in a Smart House Environment', 'booktitle': '2007 IEEE International Conference on Multimedia and Expo', 'author': 'Moncrieff, Simon and Venkatesh, Svetha and West, Geoff', 'ENTRYTYPE': 'inproceedings', 'ID': '4285080'}",IEEE Xplore
"Ding, Xiaofeng and Fang, Hongbiao and Zhang, Zhilin and Choo, Kim-Kwang Raymond and Jin, Hai",Privacy-Preserving Feature Extraction via Adversarial Training,Privacy;Feature extraction;Deep learning;Training;Task analysis;Cloud computing;Data models;Deep learning;adversarial training;privacy protection,"Deep learning is increasingly popular, partly due to its widespread application potential, such as in civilian, government and military domains. Given the exacting computational requirements, cloud computing has been utilized to host user data and model. However, such an approach has potential privacy implications. Therefore, in this paper, we propose a method to protect user’s privacy in the inference phase of deep learning workflow. Specifically, we use an intermediate layer to separate the entire neural network into two parts, which are respectively deployed on the user device and the cloud server. The encoder, deployed on the user device, is used for raw data transformation, which removes the need for users to upload raw data to the cloud directly. However, we also demonstrate there exists potential for privacy leakage in the intermediate features of the neural network through two concrete experiments. In other words, the encoder on its own does not provide adequate privacy protection. Therefore, we also propose an approach to achieve Privacy-preserving Feature Extraction based on Adversarial Training (P-FEAT), where the goal of privacy attacking tasks and the goal of target tasks are adversarial in terms of sensitive attributes. By imposing privacy constraints during the feature extraction, we can reduce the contribution of the extracted features to the privacy leakage. In this way, privacy protection capability of the encoder can be further strengthened. We then demonstrate the effectiveness of P-FEAT using a large number of experiments, whose findings show that P-FEAT can significantly reduce the threats of privacy attacking tasks while maintaining high accuracy of the target tasks.",2022,IEEE Transactions on Knowledge and Data Engineering,,"{'month': 'April', 'issn': '1558-2191', 'doi': '10.1109/TKDE.2020.2997604', 'keywords': 'Privacy;Feature extraction;Deep learning;Training;Task analysis;Cloud computing;Data models;Deep learning;adversarial training;privacy protection', 'abstract': 'Deep learning is increasingly popular, partly due to its widespread application potential, such as in civilian, government and military domains. Given the exacting computational requirements, cloud computing has been utilized to host user data and model. However, such an approach has potential privacy implications. Therefore, in this paper, we propose a method to protect user’s privacy in the inference phase of deep learning workflow. Specifically, we use an intermediate layer to separate the entire neural network into two parts, which are respectively deployed on the user device and the cloud server. The encoder, deployed on the user device, is used for raw data transformation, which removes the need for users to upload raw data to the cloud directly. However, we also demonstrate there exists potential for privacy leakage in the intermediate features of the neural network through two concrete experiments. In other words, the encoder on its own does not provide adequate privacy protection. Therefore, we also propose an approach to achieve Privacy-preserving Feature Extraction based on Adversarial Training (P-FEAT), where the goal of privacy attacking tasks and the goal of target tasks are adversarial in terms of sensitive attributes. By imposing privacy constraints during the feature extraction, we can reduce the contribution of the extracted features to the privacy leakage. In this way, privacy protection capability of the encoder can be further strengthened. We then demonstrate the effectiveness of P-FEAT using a large number of experiments, whose findings show that P-FEAT can significantly reduce the threats of privacy attacking tasks while maintaining high accuracy of the target tasks.', 'pages': '1967-1979', 'number': '4', 'volume': '34', 'year': '2022', 'title': 'Privacy-Preserving Feature Extraction via Adversarial Training', 'journal': 'IEEE Transactions on Knowledge and Data Engineering', 'author': 'Ding, Xiaofeng and Fang, Hongbiao and Zhang, Zhilin and Choo, Kim-Kwang Raymond and Jin, Hai', 'ENTRYTYPE': 'article', 'ID': '9099993'}",IEEE Xplore
"Chanyaswad, Thee and Chang, J. Morris and Kung, S. Y.",A compressive multi-kernel method for privacy-preserving machine learning,Kernel;Privacy;Data privacy;Learning systems;Signal to noise ratio;Neural networks;Encoding,"As the analytic tools become more powerful, and more data are generated on a daily basis, the issue of data privacy arises. This leads to the study of the design of privacy-preserving machine learning algorithms. Given two objectives, namely, utility maximization and privacy-loss minimization, this work is based on two previously non-intersecting regimes - Compressive Privacy and multi-kernel method. Compressive Privacy is a privacy framework that employs utility-preserving lossy-encoding scheme to protect the privacy of the data, while multi-kernel method is a kernel-based machine learning regime that explores the idea of using multiple kernels for building better predictors. In relation to the neural-network architecture, multi-kernel method can be described as a two-hidden-layered network with its width proportional to the number of kernels. The compressive multi-kernel method proposed consists of two stages - the compression stage and the multi-kernel stage. The compression stage follows the Compressive Privacy paradigm to provide the desired privacy protection. Each kernel matrix is compressed with a lossy projection matrix derived from the Discriminant Component Analysis (DCA). The multikernel stage uses the signal-to-noise ratio (SNR) score of each kernel to non-uniformly combine multiple compressive kernels. The proposed method is evaluated on two mobile-sensing datasets - MHEALTH and HAR - where activity recognition is defined as utility and person identification is defined as privacy. The results show that the compression regime is successful in privacy preservation as the privacy classification accuracies are almost at the random-guess level in all experiments. On the other hand, the novel SNR-based multi-kernel shows utility classification accuracy improvement upon the state-of-the-art in both datasets. These results indicate a promising direction for research in privacy-preserving machine learning.",2017,2017 International Joint Conference on Neural Networks (IJCNN),,"{'month': 'May', 'issn': '2161-4407', 'doi': '10.1109/IJCNN.2017.7966371', 'keywords': 'Kernel;Privacy;Data privacy;Learning systems;Signal to noise ratio;Neural networks;Encoding', 'abstract': 'As the analytic tools become more powerful, and more data are generated on a daily basis, the issue of data privacy arises. This leads to the study of the design of privacy-preserving machine learning algorithms. Given two objectives, namely, utility maximization and privacy-loss minimization, this work is based on two previously non-intersecting regimes - Compressive Privacy and multi-kernel method. Compressive Privacy is a privacy framework that employs utility-preserving lossy-encoding scheme to protect the privacy of the data, while multi-kernel method is a kernel-based machine learning regime that explores the idea of using multiple kernels for building better predictors. In relation to the neural-network architecture, multi-kernel method can be described as a two-hidden-layered network with its width proportional to the number of kernels. The compressive multi-kernel method proposed consists of two stages - the compression stage and the multi-kernel stage. The compression stage follows the Compressive Privacy paradigm to provide the desired privacy protection. Each kernel matrix is compressed with a lossy projection matrix derived from the Discriminant Component Analysis (DCA). The multikernel stage uses the signal-to-noise ratio (SNR) score of each kernel to non-uniformly combine multiple compressive kernels. The proposed method is evaluated on two mobile-sensing datasets - MHEALTH and HAR - where activity recognition is defined as utility and person identification is defined as privacy. The results show that the compression regime is successful in privacy preservation as the privacy classification accuracies are almost at the random-guess level in all experiments. On the other hand, the novel SNR-based multi-kernel shows utility classification accuracy improvement upon the state-of-the-art in both datasets. These results indicate a promising direction for research in privacy-preserving machine learning.', 'pages': '4079-4086', 'number': '', 'volume': '', 'year': '2017', 'title': 'A compressive multi-kernel method for privacy-preserving machine learning', 'booktitle': '2017 International Joint Conference on Neural Networks (IJCNN)', 'author': 'Chanyaswad, Thee and Chang, J. Morris and Kung, S. Y.', 'ENTRYTYPE': 'inproceedings', 'ID': '7966371'}",IEEE Xplore
"Shehab, Mohamed and Touati, Hakim",Semi-Supervised Policy Recommendation for Online Social Networks,Privacy;Vectors;Tin;Labeling;Facebook;Supervised learning;Semi-Supervised Learning;Graph-based Propagation;Policy Recommendation;Active Learning,"Fine grain policy settings in social network sites is becoming a very important requirement for managing user's privacy. Incorrect privacy policy settings can easily lead to leaks in private and personal information. At the same time, being too restrictive would reduce the benefits of online social networks. This is further complicated with the growing adoption of social networks and with the rapid growth in information uploading and sharing. The problem of facilitating policy settings has attracted numerous access control, and human computer interaction researchers. The solutions proposed range from usable interfaces for policy settings to automated policy settings. We propose a fine grained policy recommendation system that is based on an iterative semi-supervised learning approach that uses the social graph propagation properties. Active learning and social graph properties were used to detect the most informative instances to be labeled as training sets. We implemented and tested our approach using real Facebook dataset. We compared our proposed approach to supervised learning and random walk approaches. Our proposed approaches provided high accuracy and precision when compared to the other approaches.",2012,2012 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,,"{'month': 'Aug', 'issn': '', 'doi': '10.1109/ASONAM.2012.66', 'keywords': 'Privacy;Vectors;Tin;Labeling;Facebook;Supervised learning;Semi-Supervised Learning;Graph-based Propagation;Policy Recommendation;Active Learning', 'abstract': ""Fine grain policy settings in social network sites is becoming a very important requirement for managing user's privacy. Incorrect privacy policy settings can easily lead to leaks in private and personal information. At the same time, being too restrictive would reduce the benefits of online social networks. This is further complicated with the growing adoption of social networks and with the rapid growth in information uploading and sharing. The problem of facilitating policy settings has attracted numerous access control, and human computer interaction researchers. The solutions proposed range from usable interfaces for policy settings to automated policy settings. We propose a fine grained policy recommendation system that is based on an iterative semi-supervised learning approach that uses the social graph propagation properties. Active learning and social graph properties were used to detect the most informative instances to be labeled as training sets. We implemented and tested our approach using real Facebook dataset. We compared our proposed approach to supervised learning and random walk approaches. Our proposed approaches provided high accuracy and precision when compared to the other approaches."", 'pages': '360-367', 'number': '', 'volume': '', 'year': '2012', 'title': 'Semi-Supervised Policy Recommendation for Online Social Networks', 'booktitle': '2012 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining', 'author': 'Shehab, Mohamed and Touati, Hakim', 'ENTRYTYPE': 'inproceedings', 'ID': '6425738'}",IEEE Xplore
"Du, Wei and Li, Ang and Zhou, Pan and Niu, Ben and Wu, Dapeng",PrivacyEye: A Privacy-Preserving and Computationally Efficient Deep Learning-Based Mobile Video Analytics System,Feature extraction;Data mining;Task analysis;Color;Servers;Histograms;Privacy;Privacy protection;efficient mobile computing;deep learning;video analytics,"Large volumes of video data recorded by the increasing mobile devices and embedded sensors can be leveraged to answer queries of our lives, physical world and our evolving society. Especially, the rapid development of convolutional neural networks (CNNs) in the past few years offers the great advantage for multiple tasks in video analysis. However, adopting running CNNs directly on mobile devices and embedded sensors for video analytics brings heavy burden due to their limited capacity, especially for learning a large volume of data. A promising approach is to outsource the computation-intensive part of CNN to cloud. However, the reveal of data to cloud may cause privacy leakage. In addition, the cloud-assisted approach may also bring some communication efficiency challenges for large volume of data. To address both privacy and efficiency issues, we design a privacy-preserving and computationally efficient framework for mobile video analytics. To protect the private information, we split the CNN model into two subnetworks, and first part is used as a feature extractor deployed in the mobile side and the second part is utilized as a classifier deployed in the cloud side. A specific-designed adversarial training process is adopted in order to extract features for normal task classification while hiding the features for sensitive task. In addition, to improve video process efficiency, we design a two-stage framework. The first stage is to extract key frames and necessary intermediate frames, while skipping redundant ones. The second stage is to extract the features of key frames by CNN-based feature extractor but apply optical-flow-based feature propagation algorithm to obtain the features of intermediate frames. Extensive experiments demonstrate our proposed system PrivacyEye can effectively protect private information while keep the accuracy of the normal tasks with less than 2 percent drop, and it saves up to 82.9 percent execution time and 78.8 percent energy consumption.",2022,IEEE Transactions on Mobile Computing,,"{'month': 'Sep.', 'issn': '1558-0660', 'doi': '10.1109/TMC.2021.3050458', 'keywords': 'Feature extraction;Data mining;Task analysis;Color;Servers;Histograms;Privacy;Privacy protection;efficient mobile computing;deep learning;video analytics', 'abstract': 'Large volumes of video data recorded by the increasing mobile devices and embedded sensors can be leveraged to answer queries of our lives, physical world and our evolving society. Especially, the rapid development of convolutional neural networks (CNNs) in the past few years offers the great advantage for multiple tasks in video analysis. However, adopting running CNNs directly on mobile devices and embedded sensors for video analytics brings heavy burden due to their limited capacity, especially for learning a large volume of data. A promising approach is to outsource the computation-intensive part of CNN to cloud. However, the reveal of data to cloud may cause privacy leakage. In addition, the cloud-assisted approach may also bring some communication efficiency challenges for large volume of data. To address both privacy and efficiency issues, we design a privacy-preserving and computationally efficient framework for mobile video analytics. To protect the private information, we split the CNN model into two subnetworks, and first part is used as a feature extractor deployed in the mobile side and the second part is utilized as a classifier deployed in the cloud side. A specific-designed adversarial training process is adopted in order to extract features for normal task classification while hiding the features for sensitive task. In addition, to improve video process efficiency, we design a two-stage framework. The first stage is to extract key frames and necessary intermediate frames, while skipping redundant ones. The second stage is to extract the features of key frames by CNN-based feature extractor but apply optical-flow-based feature propagation algorithm to obtain the features of intermediate frames. Extensive experiments demonstrate our proposed system PrivacyEye can effectively protect private information while keep the accuracy of the normal tasks with less than 2 percent drop, and it saves up to 82.9 percent execution time and 78.8 percent energy consumption.', 'pages': '3263-3279', 'number': '9', 'volume': '21', 'year': '2022', 'title': 'PrivacyEye: A Privacy-Preserving and Computationally Efficient Deep Learning-Based Mobile Video Analytics System', 'journal': 'IEEE Transactions on Mobile Computing', 'author': 'Du, Wei and Li, Ang and Zhou, Pan and Niu, Ben and Wu, Dapeng', 'ENTRYTYPE': 'article', 'ID': '9319537'}",IEEE Xplore
"Barth, Susanne and Ionita, Dan and de Jong, Menno D. T. and Hartel, Pieter H. and Junger, Marianne",Privacy Rating: A User-Centered Approach for Visualizing Data Handling Practices of Online Services,Privacy;Data privacy;Data visualization;Media;Data collection;Usability;Online services;User centered design;Online privacy;privacy rating;privacy visualization;usability;user-centered design,"Background: Many countries mandate transparency and consent when personal data are handled by online services. However, most users do not read privacy policies or cannot understand them. An important challenge for technical communicators is empowering users to manage their online privacy responsibly. Literature review: Research suggests that privacy visualizations may alleviate this problem, but existing approaches are incomplete and under-researched. Research questions: 1. How can we design a privacy rating that optimally empowers users with different levels of knowledge about and awareness of online privacy? 2. How do users react to such a privacy rating, in terms of usability, perceived usefulness, and trust in online services? Methodology: We developed Privacy Rating, a tool for mapping and visualizing the privacy of online services. The tool was subjected to user research (N = 30) focusing on usability, perceived usefulness, and effects on trust. To establish the effects on trust, participants were exposed to a website with either a positive or a negative privacy rating. Results: The Privacy Rating appeared to be usable and useful for lay users, and it had a significant effect on users’ trust in the online service. Users indicated that they would like the visualization to become an established standard, preferably approved by an independent organization. Conclusions: The Privacy Rating is a user-friendly privacy visualization covering all relevant aspects of privacy. We aim to bring the tool to the market and make it a standard, ideally supported by an independent trustworthy organization.",2021,IEEE Transactions on Professional Communication,,"{'month': 'Dec', 'issn': '1558-1500', 'doi': '10.1109/TPC.2021.3110617', 'keywords': 'Privacy;Data privacy;Data visualization;Media;Data collection;Usability;Online services;User centered design;Online privacy;privacy rating;privacy visualization;usability;user-centered design', 'abstract': 'Background: Many countries mandate transparency and consent when personal data are handled by online services. However, most users do not read privacy policies or cannot understand them. An important challenge for technical communicators is empowering users to manage their online privacy responsibly. Literature review: Research suggests that privacy visualizations may alleviate this problem, but existing approaches are incomplete and under-researched. Research questions: 1. How can we design a privacy rating that optimally empowers users with different levels of knowledge about and awareness of online privacy? 2. How do users react to such a privacy rating, in terms of usability, perceived usefulness, and trust in online services? Methodology: We developed Privacy Rating, a tool for mapping and visualizing the privacy of online services. The tool was subjected to user research (N = 30) focusing on usability, perceived usefulness, and effects on trust. To establish the effects on trust, participants were exposed to a website with either a positive or a negative privacy rating. Results: The Privacy Rating appeared to be usable and useful for lay users, and it had a significant effect on users’ trust in the online service. Users indicated that they would like the visualization to become an established standard, preferably approved by an independent organization. Conclusions: The Privacy Rating is a user-friendly privacy visualization covering all relevant aspects of privacy. We aim to bring the tool to the market and make it a standard, ideally supported by an independent trustworthy organization.', 'pages': '354-373', 'number': '4', 'volume': '64', 'year': '2021', 'title': 'Privacy Rating: A User-Centered Approach for Visualizing Data Handling Practices of Online Services', 'journal': 'IEEE Transactions on Professional Communication', 'author': 'Barth, Susanne and Ionita, Dan and de Jong, Menno D. T. and Hartel, Pieter H. and Junger, Marianne', 'ENTRYTYPE': 'article', 'ID': '9612118'}",IEEE Xplore
"Mahler, Jeffrey and Hou, Brian and Niyaz, Sherdil and Pokorny, Florian T. and Chandra, Ramu and Goldberg, Ken",Privacy-preserving Grasp Planning in the Cloud,Planning;Robustness;Measurement;Solid modeling;Grippers;Privacy;Dispersion,"To support industrial automation, systems such as GraspIt! and Dex-Net 1.0 provide “Grasp Planning as a Service” (GPaaS). To assist manufacturers setting up automated assembly lines, users can send part geometry via the Internet to the service and receive a ranked set of robust grasp configurations. As industrial users may be reluctant to share proprietary details of product geometry with outside parties, this paper proposes a privacy-preserving approach awhere a masked version of the part boundary is uploaded, allowing proprietary aspects of the part geometry to remain confidential. One challenge is the tradeoff between grasp coverage and privacy: balancing the desire for a rich set of alternative grasps based on analysis of graspable surfaces (coverage) against the desire for privacy. We introduce a grasp coverage metric based on dispersion from motion planning, and plot its relationship with privacy (the fraction of the object surface that is masked). We implement the algorithm using Dex-Net 1.0 and present case studies of the privacy-coverage tradeoff on a set of 23 industrial parts. Results suggest that masking the part using the convex hull of the proprietary zone can provide grasp coverage with minor distortion to the object similarity metric used to accelerate grasp planning in Dex-Net 1.0. Code, data, and additional information can be found at http://berkeleyautomation.io/privacy_preserving_grasping.",2016,2016 IEEE International Conference on Automation Science and Engineering (CASE),,"{'month': 'Aug', 'issn': '2161-8089', 'doi': '10.1109/COASE.2016.7743442', 'keywords': 'Planning;Robustness;Measurement;Solid modeling;Grippers;Privacy;Dispersion', 'abstract': 'To support industrial automation, systems such as GraspIt! and Dex-Net 1.0 provide “Grasp Planning as a Service” (GPaaS). To assist manufacturers setting up automated assembly lines, users can send part geometry via the Internet to the service and receive a ranked set of robust grasp configurations. As industrial users may be reluctant to share proprietary details of product geometry with outside parties, this paper proposes a privacy-preserving approach awhere a masked version of the part boundary is uploaded, allowing proprietary aspects of the part geometry to remain confidential. One challenge is the tradeoff between grasp coverage and privacy: balancing the desire for a rich set of alternative grasps based on analysis of graspable surfaces (coverage) against the desire for privacy. We introduce a grasp coverage metric based on dispersion from motion planning, and plot its relationship with privacy (the fraction of the object surface that is masked). We implement the algorithm using Dex-Net 1.0 and present case studies of the privacy-coverage tradeoff on a set of 23 industrial parts. Results suggest that masking the part using the convex hull of the proprietary zone can provide grasp coverage with minor distortion to the object similarity metric used to accelerate grasp planning in Dex-Net 1.0. Code, data, and additional information can be found at http://berkeleyautomation.io/privacy_preserving_grasping.', 'pages': '468-475', 'number': '', 'volume': '', 'year': '2016', 'title': 'Privacy-preserving Grasp Planning in the Cloud', 'booktitle': '2016 IEEE International Conference on Automation Science and Engineering (CASE)', 'author': 'Mahler, Jeffrey and Hou, Brian and Niyaz, Sherdil and Pokorny, Florian T. and Chandra, Ramu and Goldberg, Ken', 'ENTRYTYPE': 'inproceedings', 'ID': '7743442'}",IEEE Xplore
"Jesus, Vitor and Pandit, Harshvardhan J.",Consent Receipts for a Usable and Auditable Web of Personal Data,Law;Privacy;General Data Protection Regulation;Companies;Europe;Usability;Technological innovation;Accountability;consent;GDPR;personal data;web;consent receipt,"Consenting on the Web, in the context of online privacy and data protection, is universally accepted as a difficult problem, mainly because of its cross-disciplinarity. For example, any approach to online Consenting needs to meet usability, legal, regulatory, technical, and business requirements. To date, effort has been predominantly focused on meeting compliance with regulations and automation, and less on the true re-empowerment of users with respect to their personal data. One approach that has not seen sufficient research is the use of ‘Consent Receipts’, which offer a new paradigm of recording interactions concerning consent and using them as proofs in future actions, similar to familiar use of a common shopping receipt. In addition to being a record, receipts encourage accountability in how technology handles consent and is beneficial for all involved stakeholders. For organisations, it assists with legal requirements for demonstration of valid consent, while for users it provides transparency and accountability by being a proof to be used against malpractices related to consent. Receipts also have uses in addition to those related to consent, such as for authorising the holder in exercising related rights. This paper analyses the requirements, uses, and benefits offered by Consent Receipts with an extensive and broad literature review. Since receipts are a novel concept, we identify properties and requirements, and then new mechanisms necessary for the Web to support receipts. We then demonstrate feasibility of receipts through proof-of-concepts in three common real-world use-cases: (a) acceptance of a privacy policy and its subsequent changes; (b) choices expressed via consent dialogues or cookie banners; and (c) verbal interactions with Amazon Alexa.",2022,IEEE Access,,"{'month': '', 'issn': '2169-3536', 'doi': '10.1109/ACCESS.2022.3157850', 'keywords': 'Law;Privacy;General Data Protection Regulation;Companies;Europe;Usability;Technological innovation;Accountability;consent;GDPR;personal data;web;consent receipt', 'abstract': 'Consenting on the Web, in the context of online privacy and data protection, is universally accepted as a difficult problem, mainly because of its cross-disciplinarity. For example, any approach to online Consenting needs to meet usability, legal, regulatory, technical, and business requirements. To date, effort has been predominantly focused on meeting compliance with regulations and automation, and less on the true re-empowerment of users with respect to their personal data. One approach that has not seen sufficient research is the use of ‘Consent Receipts’, which offer a new paradigm of recording interactions concerning consent and using them as proofs in future actions, similar to familiar use of a common shopping receipt. In addition to being a record, receipts encourage accountability in how technology handles consent and is beneficial for all involved stakeholders. For organisations, it assists with legal requirements for demonstration of valid consent, while for users it provides transparency and accountability by being a proof to be used against malpractices related to consent. Receipts also have uses in addition to those related to consent, such as for authorising the holder in exercising related rights. This paper analyses the requirements, uses, and benefits offered by Consent Receipts with an extensive and broad literature review. Since receipts are a novel concept, we identify properties and requirements, and then new mechanisms necessary for the Web to support receipts. We then demonstrate feasibility of receipts through proof-of-concepts in three common real-world use-cases: (a) acceptance of a privacy policy and its subsequent changes; (b) choices expressed via consent dialogues or cookie banners; and (c) verbal interactions with Amazon Alexa.', 'pages': '28545-28563', 'number': '', 'volume': '10', 'year': '2022', 'title': 'Consent Receipts for a Usable and Auditable Web of Personal Data', 'journal': 'IEEE Access', 'author': 'Jesus, Vitor and Pandit, Harshvardhan J.', 'ENTRYTYPE': 'article', 'ID': '9730898'}",IEEE Xplore
"Hsieh, I-Chung and Li, Cheng-Te",NetFense: Adversarial Defenses Against Privacy Attacks on Neural Networks for Graph Data,Data models;Data privacy;Privacy;Predictive models;Perturbation methods;Social networking (online);Optimization;Adversarial defense;privacy attack;privacy-protected graph perturbation;adversarial methods;attack and defense,"Recent advances in protecting node privacy on graph data and attacking graph neural networks (GNNs) gain much attention. The eye does not bring these two essential tasks together yet. Imagine an adversary can utilize the powerful GNNs to infer users’ private labels in a social network. How can we adversarially defend against such privacy attacks while maintaining the utility of perturbed graphs? In this work, we propose a novel research task, adversarial defenses against GNN-based privacy attacks, and present a graph perturbation-based approach, NetFense, to achieve the goal. NetFense can simultaneously keep graph data unnoticeability (i.e., having limited changes on the graph structure), maintain the prediction confidence of targeted label classification (i.e., preserving data utility), and reduce the prediction confidence of private label classification (i.e., protecting the privacy of nodes). Experiments conducted on single- and multiple-target perturbations using three real graph data exhibit that the perturbed graphs by NetFense can effectively maintain data utility (i.e., model unnoticeability) on targeted label classification and significantly decrease the prediction confidence of private label classification (i.e., privacy protection). Extensive studies also bring several insights, such as the flexibility of NetFense, preserving local neighborhoods in data unnoticeability, and better privacy protection for high-degree nodes.",2023,IEEE Transactions on Knowledge and Data Engineering,,"{'month': 'Jan', 'issn': '1558-2191', 'doi': '10.1109/TKDE.2021.3087515', 'keywords': 'Data models;Data privacy;Privacy;Predictive models;Perturbation methods;Social networking (online);Optimization;Adversarial defense;privacy attack;privacy-protected graph perturbation;adversarial methods;attack and defense', 'abstract': 'Recent advances in protecting node privacy on graph data and attacking graph neural networks (GNNs) gain much attention. The eye does not bring these two essential tasks together yet. Imagine an adversary can utilize the powerful GNNs to infer users’ private labels in a social network. How can we adversarially defend against such privacy attacks while maintaining the utility of perturbed graphs? In this work, we propose a novel research task, adversarial defenses against GNN-based privacy attacks, and present a graph perturbation-based approach, NetFense, to achieve the goal. NetFense can simultaneously keep graph data unnoticeability (i.e., having limited changes on the graph structure), maintain the prediction confidence of targeted label classification (i.e., preserving data utility), and reduce the prediction confidence of private label classification (i.e., protecting the privacy of nodes). Experiments conducted on single- and multiple-target perturbations using three real graph data exhibit that the perturbed graphs by NetFense can effectively maintain data utility (i.e., model unnoticeability) on targeted label classification and significantly decrease the prediction confidence of private label classification (i.e., privacy protection). Extensive studies also bring several insights, such as the flexibility of NetFense, preserving local neighborhoods in data unnoticeability, and better privacy protection for high-degree nodes.', 'pages': '796-809', 'number': '1', 'volume': '35', 'year': '2023', 'title': 'NetFense: Adversarial Defenses Against Privacy Attacks on Neural Networks for Graph Data', 'journal': 'IEEE Transactions on Knowledge and Data Engineering', 'author': 'Hsieh, I-Chung and Li, Cheng-Te', 'ENTRYTYPE': 'article', 'ID': '9448513'}",IEEE Xplore
"Perera, Charith and Barhamgi, Mahmoud and Vecchio, Massimo",Envisioning Tool Support for Designing Privacy-Aware Internet of Thing Applications,Privacy;Internet of Things;System-on-chip;Medical services;Software engineering;Mobile handsets;Human computer interaction,"The design and development process for Internet of Things (IoT) applications is more complicated than for desktop, mobile, or web applications. IoT applications require both software and hardware to work together across multiple different types of nodes (e.g., microcontrollers, system-on-chips, mobile phones, miniaturized single-board computers, and cloud platforms) with different capabilities under different conditions. IoT applications typically collect and analyze personal data that can be used to derive sensitive information about individuals. Without proper privacy protections in place, IoT applications could lead to serious privacy violations. Thus far, privacy concerns have not been explicitly considered in software engineering processes when designing and developing IoT applications, partly due to a lack of tools, technologies, and guidance. This article presents a research vision that argues the importance of developing a privacy-aware IoT application design tool to address the challenges mentioned above. This tool should not only transform IoT application designs into privacy-aware application designs, but also validate and verify them. First, we outline how this proposed tool should work in practice and its core functionalities. Then, we identify research challenges and potential directions for developing the proposed tool. We anticipate that this proposed tool will save many engineering hours which engineers would otherwise need to spend on developing privacy expertise and applying it. We also highlight the usefulness of this tool toward privacy education and privacy compliance.",2021,IEEE Internet of Things Magazine,,"{'month': 'March', 'issn': '2576-3199', 'doi': '10.1109/IOTM.0001.2000006', 'keywords': 'Privacy;Internet of Things;System-on-chip;Medical services;Software engineering;Mobile handsets;Human computer interaction', 'abstract': 'The design and development process for Internet of Things (IoT) applications is more complicated than for desktop, mobile, or web applications. IoT applications require both software and hardware to work together across multiple different types of nodes (e.g., microcontrollers, system-on-chips, mobile phones, miniaturized single-board computers, and cloud platforms) with different capabilities under different conditions. IoT applications typically collect and analyze personal data that can be used to derive sensitive information about individuals. Without proper privacy protections in place, IoT applications could lead to serious privacy violations. Thus far, privacy concerns have not been explicitly considered in software engineering processes when designing and developing IoT applications, partly due to a lack of tools, technologies, and guidance. This article presents a research vision that argues the importance of developing a privacy-aware IoT application design tool to address the challenges mentioned above. This tool should not only transform IoT application designs into privacy-aware application designs, but also validate and verify them. First, we outline how this proposed tool should work in practice and its core functionalities. Then, we identify research challenges and potential directions for developing the proposed tool. We anticipate that this proposed tool will save many engineering hours which engineers would otherwise need to spend on developing privacy expertise and applying it. We also highlight the usefulness of this tool toward privacy education and privacy compliance.', 'pages': '78-83', 'number': '1', 'volume': '4', 'year': '2021', 'title': 'Envisioning Tool Support for Designing Privacy-Aware Internet of Thing Applications', 'journal': 'IEEE Internet of Things Magazine', 'author': 'Perera, Charith and Barhamgi, Mahmoud and Vecchio, Massimo', 'ENTRYTYPE': 'article', 'ID': '9351837'}",IEEE Xplore
"Fukuda, Mei and Nakajima, Kazuki and Shudo, Kazuyuki",Estimating the Bot Population on Twitter via Random Walk Based Sampling,Social networking (online);Blogs;Statistics;Sociology;Directed graphs;Fake news;Estimation;Bot population;estimation;online social networks;random walk;sampling;social bots;Twitter,"The rise of social bots, which contribute to marketing, political intervention, and the spread of fake news, has been noted. Analysis methods for the characteristics of Twitter bots have been developed for third-party researchers who have access limitations to Twitter data. Here, we propose a method for estimating the bot population on Twitter based on a random walk. The proposed method addresses two major problems in estimating the bot population on Twitter based on a random walk. First, the maximum number of retrievable friends or followers of a user per query is limited. Second, there is a certain percentage of private users who do not publish personal content, e.g., friends, followers, and tweets. We conduct a simulation analysis using directed social graph datasets to validate whether the proposed estimator is effective on the real Twitter follow graph. Then, we present three different estimates of the bot population on Twitter using the proposed estimator based on the three sample sequences of 25,000 users collected in 2.5 weeks each. The three estimates consistently suggest that 8%–18% of Twitter users during April–June 2021 are bots.",2022,IEEE Access,,"{'month': '', 'issn': '2169-3536', 'doi': '10.1109/ACCESS.2022.3149887', 'keywords': 'Social networking (online);Blogs;Statistics;Sociology;Directed graphs;Fake news;Estimation;Bot population;estimation;online social networks;random walk;sampling;social bots;Twitter', 'abstract': 'The rise of social bots, which contribute to marketing, political intervention, and the spread of fake news, has been noted. Analysis methods for the characteristics of Twitter bots have been developed for third-party researchers who have access limitations to Twitter data. Here, we propose a method for estimating the bot population on Twitter based on a random walk. The proposed method addresses two major problems in estimating the bot population on Twitter based on a random walk. First, the maximum number of retrievable friends or followers of a user per query is limited. Second, there is a certain percentage of private users who do not publish personal content, e.g., friends, followers, and tweets. We conduct a simulation analysis using directed social graph datasets to validate whether the proposed estimator is effective on the real Twitter follow graph. Then, we present three different estimates of the bot population on Twitter using the proposed estimator based on the three sample sequences of 25,000 users collected in 2.5 weeks each. The three estimates consistently suggest that 8%–18% of Twitter users during April–June 2021 are bots.', 'pages': '17201-17211', 'number': '', 'volume': '10', 'year': '2022', 'title': 'Estimating the Bot Population on Twitter via Random Walk Based Sampling', 'journal': 'IEEE Access', 'author': 'Fukuda, Mei and Nakajima, Kazuki and Shudo, Kazuyuki', 'ENTRYTYPE': 'article', 'ID': '9706455'}",IEEE Xplore
"Gardner, Jack and Feng, Yuanyuan and Reiman, Kayla and Lin, Zhi and Jain, Akshath and Sadeh, Norman",Helping Mobile Application Developers Create Accurate Privacy Labels,Privacy;Data privacy;Codes;Static analysis;Data collection;Mobile applications;Behavioral sciences;Privacy labels;mobile applications;compliance;developers;Privacy Engineering,"In December, 2020, Apple began requiring developers to disclose their data collection and use practices to generate a “privacy label” for their application. The use of mobile application Software Development Kits (SDKs) and third-party libraries, coupled with a typical lack of expertise in privacy, makes it challenging for developers to accurately report their data collection and use practices. In this work we discuss the design and evaluation of a tool to help iOS developers generate privacy labels. The tool combines static code analysis to identify likely data collection and use practices with interactive functionality designed to prompt developers to elucidate analysis results and carefully reflect on their applications' data practices. We conducted semi-structured interviews with iOS developers as they used an initial version of the tool. We discuss how these results motivated us to develop an enhanced software tool, Privacy Label Wiz, that more closely resembles interactions developers reported to be most useful in our semi-structured interviews. We present findings from our interviews and the enhanced tool motivated by our study. We also outline future directions for software tools to better assist developers communicating their mobile app's data practices to different audiences.",2022,2022 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW),,"{'month': 'June', 'issn': '2768-0657', 'doi': '10.1109/EuroSPW55150.2022.00028', 'keywords': 'Privacy;Data privacy;Codes;Static analysis;Data collection;Mobile applications;Behavioral sciences;Privacy labels;mobile applications;compliance;developers;Privacy Engineering', 'abstract': ""In December, 2020, Apple began requiring developers to disclose their data collection and use practices to generate a “privacy label” for their application. The use of mobile application Software Development Kits (SDKs) and third-party libraries, coupled with a typical lack of expertise in privacy, makes it challenging for developers to accurately report their data collection and use practices. In this work we discuss the design and evaluation of a tool to help iOS developers generate privacy labels. The tool combines static code analysis to identify likely data collection and use practices with interactive functionality designed to prompt developers to elucidate analysis results and carefully reflect on their applications' data practices. We conducted semi-structured interviews with iOS developers as they used an initial version of the tool. We discuss how these results motivated us to develop an enhanced software tool, Privacy Label Wiz, that more closely resembles interactions developers reported to be most useful in our semi-structured interviews. We present findings from our interviews and the enhanced tool motivated by our study. We also outline future directions for software tools to better assist developers communicating their mobile app's data practices to different audiences."", 'pages': '212-230', 'number': '', 'volume': '', 'year': '2022', 'title': 'Helping Mobile Application Developers Create Accurate Privacy Labels', 'booktitle': '2022 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW)', 'author': 'Gardner, Jack and Feng, Yuanyuan and Reiman, Kayla and Lin, Zhi and Jain, Akshath and Sadeh, Norman', 'ENTRYTYPE': 'inproceedings', 'ID': '9799337'}",IEEE Xplore
"Jain, Akshath and Rodriguez, David and Alamo, Jose M. Del and Sadeh, Norman",ATLAS: Automatically Detecting Discrepancies Between Privacy Policies and Privacy Labels,Privacy;Data privacy;Regulators;Pipelines;Natural languages;Market research;Mobile applications;Natural Language Processing;Machine Learning;Transformers;Privacy Policies;Privacy Labels;iOS,"Privacy policies are long, complex documents that end-users seldom read. Privacy labels aim to ameliorate these issues by providing succinct summaries of salient data practices. In December 2020, Apple began requiring that app developers submit privacy labels describing their apps’ data practices. Yet, research suggests that app developers often struggle to do so. In this paper, we automatically identify possible discrepancies between mobile app privacy policies and their privacy labels. Such discrepancies could be indicators of potential privacy compliance issues. We introduce the Automated Privacy Label Analysis System (ATLAS). ATLAS includes three components: a pipeline to systematically retrieve iOS App Store listings and privacy policies; an ensemble-based classifier capable of predicting privacy labels from the text of privacy policies with 91.3% accuracy using state-of-the-art NLP techniques; and a discrepancy analysis mechanism that enables a large-scale privacy analysis of the iOS App Store. Our system has enabled us to analyze 354,725 iOS apps. We find several interesting trends. For example, only 40.3% of apps in the App Store provide easily accessible privacy policies, and only 29.6% of apps provide both accessible privacy policies and privacy labels. Among apps that provide both, 88.0% have at least one possible discrepancy between the text of their privacy policy and their privacy label, which could be indicative of a potential compliance issue. We find that, on average, apps have 5.32 such potential compliance issues. We hope that ATLAS will help app developers, researchers, regulators, and mobile app stores alike. For example, app developers could use our classifier to check for discrepancies between their privacy policies and privacy labels, and regulators could use our system to help review apps at scale for potential compliance issues.",2023,2023 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW),,"{'month': 'July', 'issn': '2768-0657', 'doi': '10.1109/EuroSPW59978.2023.00016', 'keywords': 'Privacy;Data privacy;Regulators;Pipelines;Natural languages;Market research;Mobile applications;Natural Language Processing;Machine Learning;Transformers;Privacy Policies;Privacy Labels;iOS', 'abstract': 'Privacy policies are long, complex documents that end-users seldom read. Privacy labels aim to ameliorate these issues by providing succinct summaries of salient data practices. In December 2020, Apple began requiring that app developers submit privacy labels describing their apps’ data practices. Yet, research suggests that app developers often struggle to do so. In this paper, we automatically identify possible discrepancies between mobile app privacy policies and their privacy labels. Such discrepancies could be indicators of potential privacy compliance issues. We introduce the Automated Privacy Label Analysis System (ATLAS). ATLAS includes three components: a pipeline to systematically retrieve iOS App Store listings and privacy policies; an ensemble-based classifier capable of predicting privacy labels from the text of privacy policies with 91.3% accuracy using state-of-the-art NLP techniques; and a discrepancy analysis mechanism that enables a large-scale privacy analysis of the iOS App Store. Our system has enabled us to analyze 354,725 iOS apps. We find several interesting trends. For example, only 40.3% of apps in the App Store provide easily accessible privacy policies, and only 29.6% of apps provide both accessible privacy policies and privacy labels. Among apps that provide both, 88.0% have at least one possible discrepancy between the text of their privacy policy and their privacy label, which could be indicative of a potential compliance issue. We find that, on average, apps have 5.32 such potential compliance issues. We hope that ATLAS will help app developers, researchers, regulators, and mobile app stores alike. For example, app developers could use our classifier to check for discrepancies between their privacy policies and privacy labels, and regulators could use our system to help review apps at scale for potential compliance issues.', 'pages': '94-107', 'number': '', 'volume': '', 'year': '2023', 'title': 'ATLAS: Automatically Detecting Discrepancies Between Privacy Policies and Privacy Labels', 'booktitle': '2023 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW)', 'author': 'Jain, Akshath and Rodriguez, David and Alamo, Jose M. Del and Sadeh, Norman', 'ENTRYTYPE': 'inproceedings', 'ID': '10190673'}",IEEE Xplore
"Nema, Preksha and Anthonysamy, Pauline and Taft, Nina and Peddinti, Sai Teia",Analyzing User Perspectives on Mobile App Privacy at Scale,Privacy;Data privacy;Systematics;Pain;Ecosystems;Sociology;Mobile applications;privacy;nlp;mobile apps;empirical,"In this paper we present a methodology to analyze users‘ con-cerns and perspectives about privacy at scale. We leverage NLP techniques to process millions of mobile app reviews and extract privacy concerns. Our methodology is composed of a binary clas-sifier that distinguishes between privacy and non-privacy related reviews. We use clustering to gather reviews that discuss similar privacy concerns, and employ summarization metrics to extract representative reviews to summarize each cluster. We apply our methods on 287M reviews for about 2M apps across the 29 cate-gories in Google Play to identify top privacy pain points in mobile apps. We identified approximately 440K privacy related reviews. We find that privacy related reviews occur in all 29 categories, with some issues arising across numerous app categories and other issues only surfacing in a small set of app categories. We show empirical evidence that confirms dominant privacy themes - concerns about apps requesting unnecessary permissions, collection of personal information, frustration with privacy controls, tracking and the selling of personal data. As far as we know, this is the first large scale analysis to confirm these findings based on hundreds of thousands of user inputs. We also observe some unexpected findings such as users warning each other not to install an app due to privacy issues, users uninstalling apps due to privacy reasons, as well as positive reviews that reward developers for privacy friendly apps. Finally we discuss the implications of our method and findings for developers and app stores.",2022,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),,"{'month': 'May', 'issn': '1558-1225', 'doi': '10.1145/3510003.3510079', 'keywords': 'Privacy;Data privacy;Systematics;Pain;Ecosystems;Sociology;Mobile applications;privacy;nlp;mobile apps;empirical', 'abstract': 'In this paper we present a methodology to analyze users‘ con-cerns and perspectives about privacy at scale. We leverage NLP techniques to process millions of mobile app reviews and extract privacy concerns. Our methodology is composed of a binary clas-sifier that distinguishes between privacy and non-privacy related reviews. We use clustering to gather reviews that discuss similar privacy concerns, and employ summarization metrics to extract representative reviews to summarize each cluster. We apply our methods on 287M reviews for about 2M apps across the 29 cate-gories in Google Play to identify top privacy pain points in mobile apps. We identified approximately 440K privacy related reviews. We find that privacy related reviews occur in all 29 categories, with some issues arising across numerous app categories and other issues only surfacing in a small set of app categories. We show empirical evidence that confirms dominant privacy themes - concerns about apps requesting unnecessary permissions, collection of personal information, frustration with privacy controls, tracking and the selling of personal data. As far as we know, this is the first large scale analysis to confirm these findings based on hundreds of thousands of user inputs. We also observe some unexpected findings such as users warning each other not to install an app due to privacy issues, users uninstalling apps due to privacy reasons, as well as positive reviews that reward developers for privacy friendly apps. Finally we discuss the implications of our method and findings for developers and app stores.', 'pages': '112-124', 'number': '', 'volume': '', 'year': '2022', 'title': 'Analyzing User Perspectives on Mobile App Privacy at Scale', 'booktitle': '2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)', 'author': 'Nema, Preksha and Anthonysamy, Pauline and Taft, Nina and Peddinti, Sai Teia', 'ENTRYTYPE': 'inproceedings', 'ID': '9794103'}",IEEE Xplore
"Ahn, Gail-Joon and Ko, Moonam",User-centric privacy management for federated identity management,Identity management systems;Privacy;Vehicles;Information management;Educational institutions;Informatics;Internet;Customer relationship management;Enterprise resource planning;Supply chain management,"We have witnessed that the Internet is now a prime vehicle for business, community, and personal interactions. The notion of identity is the important component of this vehicle. Identity management has been recently considered to be a viable solution for simplifying user management across enterprise applications. The network identity of each user is the global set of personal credentials and preferences constituting the various accounts. The prevalence of business alliances or coalitions necessitates the further evolution of identity management, named federated identity management (FIM). The main motivation of FIM is to facilitate the federation of identities among business partners emphasizing on ease of user management. In this paper, we propose systematic mechanisms to specify privacy preferences in FIM, attempting to help users facilitate preferences for managing their private information across domains.",2007,"2007 International Conference on Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom 2007)",,"{'month': 'Nov', 'issn': '', 'doi': '10.1109/COLCOM.2007.4553829', 'keywords': 'Identity management systems;Privacy;Vehicles;Information management;Educational institutions;Informatics;Internet;Customer relationship management;Enterprise resource planning;Supply chain management', 'abstract': 'We have witnessed that the Internet is now a prime vehicle for business, community, and personal interactions. The notion of identity is the important component of this vehicle. Identity management has been recently considered to be a viable solution for simplifying user management across enterprise applications. The network identity of each user is the global set of personal credentials and preferences constituting the various accounts. The prevalence of business alliances or coalitions necessitates the further evolution of identity management, named federated identity management (FIM). The main motivation of FIM is to facilitate the federation of identities among business partners emphasizing on ease of user management. In this paper, we propose systematic mechanisms to specify privacy preferences in FIM, attempting to help users facilitate preferences for managing their private information across domains.', 'pages': '187-195', 'number': '', 'volume': '', 'year': '2007', 'title': 'User-centric privacy management for federated identity management', 'booktitle': '2007 International Conference on Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom 2007)', 'author': 'Ahn, Gail-Joon and Ko, Moonam', 'ENTRYTYPE': 'inproceedings', 'ID': '4553829'}",IEEE Xplore
"Konings, Bastian and Piendl, David and Schaub, Florian and Weber, Michael",PrivacyJudge: Effective Privacy Controls for Online Published Information,Privacy;Servers;Control systems;Encryption;Publishing;Electronic mail;privacy;online privacy;information privacy;privacy signaling,"With the rise of online social networks, sharing of personal information online has become the rule for many people rather than the exception. However, users have only limited abilities to effectively control privacy of their posted information. Even gaining an overview of posted information is already a difficult task. We propose a privacy control system for personal information online. Privacy Judge allows fine-grained access control to posted information and provides a comprehensive overview of previously posted data. Thereby, Privacy Judge does not require cooperation of service providers, instead operation remains transparent to them. Thus effectively providing privacy protection against other users and service providers alike. Privacy Judge follows a hybrid approach combining cryptographic enforcement with social signaling to achieve privacy protection beyond technical enforcement boundaries by leveraging system trust as well as social trust mechanisms.",2011,"2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and 2011 IEEE Third International Conference on Social Computing",,"{'month': 'Oct', 'issn': '', 'doi': '10.1109/PASSAT/SocialCom.2011.86', 'keywords': 'Privacy;Servers;Control systems;Encryption;Publishing;Electronic mail;privacy;online privacy;information privacy;privacy signaling', 'abstract': 'With the rise of online social networks, sharing of personal information online has become the rule for many people rather than the exception. However, users have only limited abilities to effectively control privacy of their posted information. Even gaining an overview of posted information is already a difficult task. We propose a privacy control system for personal information online. Privacy Judge allows fine-grained access control to posted information and provides a comprehensive overview of previously posted data. Thereby, Privacy Judge does not require cooperation of service providers, instead operation remains transparent to them. Thus effectively providing privacy protection against other users and service providers alike. Privacy Judge follows a hybrid approach combining cryptographic enforcement with social signaling to achieve privacy protection beyond technical enforcement boundaries by leveraging system trust as well as social trust mechanisms.', 'pages': '935-941', 'number': '', 'volume': '', 'year': '2011', 'title': 'PrivacyJudge: Effective Privacy Controls for Online Published Information', 'booktitle': '2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and 2011 IEEE Third International Conference on Social Computing', 'author': 'Konings, Bastian and Piendl, David and Schaub, Florian and Weber, Michael', 'ENTRYTYPE': 'inproceedings', 'ID': '6113243'}",IEEE Xplore
"Chandramouli, R.",Privacy protection of enterprise information through inference analysis,Protection;Information analysis;Taxonomy;Data privacy;Labeling;Performance analysis;Logic programming;Computer security;NIST;Government,Ensuring that disclosure of information to outside entities is in conformance with the enterprise privacy policies is of utmost concern for all enterprises dealing with consumer information. The existing protection measures proposed for meeting this goal are inadequate. In this paper we present an approach in which the privacy label taxonomy is developed to classify information types in an enterprise by their privacy labels. Inference analysis is performed on the information types using a disjunctive logic programming technique to detect violations of privacy labeling semantics in various information types. The analysis also provides the technique to deal with such violations so as to achieve a violation-free privacy labeling scheme.,2005,Sixth IEEE International Workshop on Policies for Distributed Systems and Networks (POLICY'05),,"{'month': 'June', 'issn': '', 'doi': '10.1109/POLICY.2005.29', 'keywords': 'Protection;Information analysis;Taxonomy;Data privacy;Labeling;Performance analysis;Logic programming;Computer security;NIST;Government', 'abstract': 'Ensuring that disclosure of information to outside entities is in conformance with the enterprise privacy policies is of utmost concern for all enterprises dealing with consumer information. The existing protection measures proposed for meeting this goal are inadequate. In this paper we present an approach in which the privacy label taxonomy is developed to classify information types in an enterprise by their privacy labels. Inference analysis is performed on the information types using a disjunctive logic programming technique to detect violations of privacy labeling semantics in various information types. The analysis also provides the technique to deal with such violations so as to achieve a violation-free privacy labeling scheme.', 'pages': '47-56', 'number': '', 'volume': '', 'year': '2005', 'title': 'Privacy protection of enterprise information through inference analysis', 'booktitle': ""Sixth IEEE International Workshop on Policies for Distributed Systems and Networks (POLICY'05)"", 'author': 'Chandramouli, R.', 'ENTRYTYPE': 'inproceedings', 'ID': '1454302'}",IEEE Xplore
"Park, Jungheum and Chung, Hyunji and DeFranco, Joanna F.",Multilayered Diagnostics for Smart Cities,Smart cities;Education;Medical services;Computer crime,"The fields of health care, education, culture, and shopping can all be integrated into the core of a smart city to create an infrastructure that allows people to live more conveniently. We must think ahead about cybersecurity, as cyberattacks can threaten the lives of citizens.",2022,Computer,,"{'month': 'Feb', 'issn': '1558-0814', 'doi': '10.1109/MC.2021.3070325', 'keywords': 'Smart cities;Education;Medical services;Computer crime', 'abstract': 'The fields of health care, education, culture, and shopping can all be integrated into the core of a smart city to create an infrastructure that allows people to live more conveniently. We must think ahead about cybersecurity, as cyberattacks can threaten the lives of citizens.', 'pages': '14-22', 'number': '2', 'volume': '55', 'year': '2022', 'title': 'Multilayered Diagnostics for Smart Cities', 'journal': 'Computer', 'author': 'Park, Jungheum and Chung, Hyunji and DeFranco, Joanna F.', 'ENTRYTYPE': 'article', 'ID': '9714103'}",IEEE Xplore
"Rodriguez, David and Jain, Akshath and Alamo, Jose M. Del and Sadeh, Norman",Comparing Privacy Label Disclosures of Apps Published in both the App Store and Google Play Stores,Privacy;Data privacy;Regulators;Ecosystems;Focusing;Companies;Data collection;Privacy labels;iOS;Android;Compliance;Privacy;Personal data;Static analysis,"Apple and Android introduced privacy labels in 2020 and 2022 respectively as a way of providing consumers with succinct summaries of mobile apps’ more salient data practices. A number of apps are published in both stores, offering us the opportunity to compare their privacy label disclosures in the two app stores. This paper compares the data practices privacy labels are intended to capture in each store. It then proceeds to analyze the disclosures of 822 apps published in both app stores, focusing on possible discrepancies. This analysis reveals that privacy label disclosures of what is ostensibly the same mobile app can be quite different. We discuss the different possible reasons behind these differences, including the possibility that these discrepancies might be indicative of potential privacy compliance issues. In particular, focusing on data collection disclosures of five different data types (location, contact info, sensitive info, identifiers, and health & fitness) we find discrepancies between iOS and Google Play privacy label disclosures in 66.5% of the mobile apps we analyze.",2023,2023 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW),,"{'month': 'July', 'issn': '2768-0657', 'doi': '10.1109/EuroSPW59978.2023.00022', 'keywords': 'Privacy;Data privacy;Regulators;Ecosystems;Focusing;Companies;Data collection;Privacy labels;iOS;Android;Compliance;Privacy;Personal data;Static analysis', 'abstract': 'Apple and Android introduced privacy labels in 2020 and 2022 respectively as a way of providing consumers with succinct summaries of mobile apps’ more salient data practices. A number of apps are published in both stores, offering us the opportunity to compare their privacy label disclosures in the two app stores. This paper compares the data practices privacy labels are intended to capture in each store. It then proceeds to analyze the disclosures of 822 apps published in both app stores, focusing on possible discrepancies. This analysis reveals that privacy label disclosures of what is ostensibly the same mobile app can be quite different. We discuss the different possible reasons behind these differences, including the possibility that these discrepancies might be indicative of potential privacy compliance issues. In particular, focusing on data collection disclosures of five different data types (location, contact info, sensitive info, identifiers, and health & fitness) we find discrepancies between iOS and Google Play privacy label disclosures in 66.5% of the mobile apps we analyze.', 'pages': '150-157', 'number': '', 'volume': '', 'year': '2023', 'title': 'Comparing Privacy Label Disclosures of Apps Published in both the App Store and Google Play Stores', 'booktitle': '2023 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW)', 'author': 'Rodriguez, David and Jain, Akshath and Alamo, Jose M. Del and Sadeh, Norman', 'ENTRYTYPE': 'inproceedings', 'ID': '10190677'}",IEEE Xplore
"Li, Dong and Guo, Danhao and Han, Weili and Chen, Hao and Cao, Chang and Wang, Xiaoyang Sean",Camera-Recognizable and Human-Invisible Labelling for Privacy Protection,Privacy;Cameras;Mobile handsets;Access control;Prototypes;Data privacy;Invisible Labelling;Near Infrared;Smartphone;Privacy Protection;Access Control,"Modern mobile devices, especially smartphones, are widely equipped with cameras, which enable their owners to capture every memorable moment or scenery, such as parties with friends. However, significant privacy concerns are posed by the potential possibility of revealing a large amount of privacy contained by photos, e.g., portrait of a person. World Driven Access Control (WDAC) [1], which triggered by environment signs rather than user operations, provides a privacy access control mechanism for photographed objects (including people and other objects containing sensitive information). WDAC supports several policy label forms which either have impact on the normal appearance of objects or rely on sensors other than camera to sense policy labels. This paper proposes an approach of labelling with a Near Infrared (NIR) label which relies only on camera and has no influence on normal appearance of objects. When an object wears a NIR label, surrounding people are unaware of the existence of the labels. Meanwhile, we design and implement a policy label recognition and policy enforcement system based on Android. The system is able to recognize NIR labels binding to objects, and then enforce privacy policies, such as Gaussian Blur, on these objects to protect their privacy.",2016,2016 12th International Conference on Mobile Ad-Hoc and Sensor Networks (MSN),,"{'month': 'Dec', 'issn': '', 'doi': '10.1109/MSN.2016.066', 'keywords': 'Privacy;Cameras;Mobile handsets;Access control;Prototypes;Data privacy;Invisible Labelling;Near Infrared;Smartphone;Privacy Protection;Access Control', 'abstract': 'Modern mobile devices, especially smartphones, are widely equipped with cameras, which enable their owners to capture every memorable moment or scenery, such as parties with friends. However, significant privacy concerns are posed by the potential possibility of revealing a large amount of privacy contained by photos, e.g., portrait of a person. World Driven Access Control (WDAC) [1], which triggered by environment signs rather than user operations, provides a privacy access control mechanism for photographed objects (including people and other objects containing sensitive information). WDAC supports several policy label forms which either have impact on the normal appearance of objects or rely on sensors other than camera to sense policy labels. This paper proposes an approach of labelling with a Near Infrared (NIR) label which relies only on camera and has no influence on normal appearance of objects. When an object wears a NIR label, surrounding people are unaware of the existence of the labels. Meanwhile, we design and implement a policy label recognition and policy enforcement system based on Android. The system is able to recognize NIR labels binding to objects, and then enforce privacy policies, such as Gaussian Blur, on these objects to protect their privacy.', 'pages': '365-369', 'number': '', 'volume': '', 'year': '2016', 'title': 'Camera-Recognizable and Human-Invisible Labelling for Privacy Protection', 'booktitle': '2016 12th International Conference on Mobile Ad-Hoc and Sensor Networks (MSN)', 'author': 'Li, Dong and Guo, Danhao and Han, Weili and Chen, Hao and Cao, Chang and Wang, Xiaoyang Sean', 'ENTRYTYPE': 'inproceedings', 'ID': '7950260'}",IEEE Xplore
"Bagnulo, M. and Garcia-Martinez, A. and Azcorra, A.",An Architecture for Network Layer Privacy,Privacy;Protocols;Protection;Peer to peer computing;Internet;Performance analysis;Identity management systems;Random sequences;Communications Society;Information analysis,"We present an architecture for the provision of network layer privacy based on the SHIM6 multihoming protocol. In its basic form, the architecture prevents on-path eavesdroppers from using SHIM6 network layer information to correlate packets that belong to the same communication but use different locators. To achieve this, several extensions to the SHIM6 protocol and to the HBA (Hash Based Addresses) addressing model are defined. On its full-featured mode of operation, hosts can vary dynamically the addresses of the packets of on-going communications. Single-homed hosts can adopt the SHIM6 protocol with the privacy enhancements to benefit from this protection against information collectors.",2007,2007 IEEE International Conference on Communications,,"{'month': 'June', 'issn': '1938-1883', 'doi': '10.1109/ICC.2007.253', 'keywords': 'Privacy;Protocols;Protection;Peer to peer computing;Internet;Performance analysis;Identity management systems;Random sequences;Communications Society;Information analysis', 'abstract': 'We present an architecture for the provision of network layer privacy based on the SHIM6 multihoming protocol. In its basic form, the architecture prevents on-path eavesdroppers from using SHIM6 network layer information to correlate packets that belong to the same communication but use different locators. To achieve this, several extensions to the SHIM6 protocol and to the HBA (Hash Based Addresses) addressing model are defined. On its full-featured mode of operation, hosts can vary dynamically the addresses of the packets of on-going communications. Single-homed hosts can adopt the SHIM6 protocol with the privacy enhancements to benefit from this protection against information collectors.', 'pages': '1509-1514', 'number': '', 'volume': '', 'year': '2007', 'title': 'An Architecture for Network Layer Privacy', 'booktitle': '2007 IEEE International Conference on Communications', 'author': 'Bagnulo, M. and Garcia-Martinez, A. and Azcorra, A.', 'ENTRYTYPE': 'inproceedings', 'ID': '4288924'}",IEEE Xplore
"Lin, Tsung-Hsien and Lee, Ying-Shuo and Chang, Fu-Chieh and Chang, J. Morris and Wu, Pei-Yuan",Protecting Sensitive Attributes by Adversarial Training Through Class-Overlapping Techniques,Data privacy;Privacy;Training;Machine learning;Feature extraction;Cloud computing;Threat modeling;Privacy-preserving machine learning;adversarial training;generative adversarial network;class overlap;machine learning as a service;Wasserstein distance;data obfuscation,"In recent years, machine learning as a service (MLaaS) has brought considerable convenience to our daily lives. However, these services raise the issue of leaking users’ sensitive attributes, such as race, when provided through the cloud. The present work overcomes this issue by proposing an innovative privacy-preserving approach called privacy-preserving class overlap (PPCO), which incorporates both a Wasserstein generative adversarial network and the idea of class overlapping to obfuscate data for better resilience against the leakage of attribute-inference attacks(i.e., malicious inference on users’ sensitive attributes). Experiments show that the proposed method can be employed to enhance current state-of-the-art works and achieve superior privacy–utility trade-off. Furthermore, the proposed method is shown to be less susceptible to the influence of imbalanced classes in training data. Finally, we provide a theoretical analysis of the performance of our proposed method to give a flavour of the gap between theoretical and empirical performances.",2023,IEEE Transactions on Information Forensics and Security,,"{'month': '', 'issn': '1556-6021', 'doi': '10.1109/TIFS.2023.3236180', 'keywords': 'Data privacy;Privacy;Training;Machine learning;Feature extraction;Cloud computing;Threat modeling;Privacy-preserving machine learning;adversarial training;generative adversarial network;class overlap;machine learning as a service;Wasserstein distance;data obfuscation', 'abstract': 'In recent years, machine learning as a service (MLaaS) has brought considerable convenience to our daily lives. However, these services raise the issue of leaking users’ sensitive attributes, such as race, when provided through the cloud. The present work overcomes this issue by proposing an innovative privacy-preserving approach called privacy-preserving class overlap (PPCO), which incorporates both a Wasserstein generative adversarial network and the idea of class overlapping to obfuscate data for better resilience against the leakage of attribute-inference attacks(i.e., malicious inference on users’ sensitive attributes). Experiments show that the proposed method can be employed to enhance current state-of-the-art works and achieve superior privacy–utility trade-off. Furthermore, the proposed method is shown to be less susceptible to the influence of imbalanced classes in training data. Finally, we provide a theoretical analysis of the performance of our proposed method to give a flavour of the gap between theoretical and empirical performances.', 'pages': '1283-1294', 'number': '', 'volume': '18', 'year': '2023', 'title': 'Protecting Sensitive Attributes by Adversarial Training Through Class-Overlapping Techniques', 'journal': 'IEEE Transactions on Information Forensics and Security', 'author': 'Lin, Tsung-Hsien and Lee, Ying-Shuo and Chang, Fu-Chieh and Chang, J. Morris and Wu, Pei-Yuan', 'ENTRYTYPE': 'article', 'ID': '10015066'}",IEEE Xplore
"Chanyaswad, Thee and Al, Mert and Chang, J. Morris and Kung, S. Y.",Differential mutual information forward search for multi-kernel discriminant-component selection with an application to privacy-preserving classification,Kernel;Privacy;Measurement;Mutual information;Data privacy;Redundancy;Compressive Privacy;Differential Mutual Information (DMI);incremental forward search;Kernel Discriminant Component Analysis (KDCA);kernel selection;multi-kernel learning,"In machine learning, feature engineering has been a pivotal stage in building a high-quality predictor. Particularly, this work explores the multiple Kernel Discriminant Component Analysis (mKDCA) feature-map and its variants. However, seeking the right subset of kernels for mKDCA feature-map can be challenging. Therefore, we consider the problem of kernel selection, and propose an algorithm based on Differential Mutual Information (DMI) and incremental forward search. DMI serves as an effective metric for selecting kernels, as is theoretically supported by mutual information and Fisher's discriminant analysis. On the other hand, incremental forward search plays a role in removing redundancy among kernels. Finally, we illustrate the potential of the method via an application in privacy-aware classification, and show on three mobile-sensing datasets that selecting an effective set of kernels for mKDCA feature-maps can enhance the utility classification performance, while successfully preserve the data privacy. Specifically, the results show that the proposed DMI forward search method can perform better than the state-of-the-art, and, with much smaller computational cost, can perform as well as the optimal, yet computationally expensive, exhaustive search.",2017,2017 IEEE 27th International Workshop on Machine Learning for Signal Processing (MLSP),,"{'month': 'Sep.', 'issn': '', 'doi': '10.1109/MLSP.2017.8168177', 'keywords': 'Kernel;Privacy;Measurement;Mutual information;Data privacy;Redundancy;Compressive Privacy;Differential Mutual Information (DMI);incremental forward search;Kernel Discriminant Component Analysis (KDCA);kernel selection;multi-kernel learning', 'abstract': ""In machine learning, feature engineering has been a pivotal stage in building a high-quality predictor. Particularly, this work explores the multiple Kernel Discriminant Component Analysis (mKDCA) feature-map and its variants. However, seeking the right subset of kernels for mKDCA feature-map can be challenging. Therefore, we consider the problem of kernel selection, and propose an algorithm based on Differential Mutual Information (DMI) and incremental forward search. DMI serves as an effective metric for selecting kernels, as is theoretically supported by mutual information and Fisher's discriminant analysis. On the other hand, incremental forward search plays a role in removing redundancy among kernels. Finally, we illustrate the potential of the method via an application in privacy-aware classification, and show on three mobile-sensing datasets that selecting an effective set of kernels for mKDCA feature-maps can enhance the utility classification performance, while successfully preserve the data privacy. Specifically, the results show that the proposed DMI forward search method can perform better than the state-of-the-art, and, with much smaller computational cost, can perform as well as the optimal, yet computationally expensive, exhaustive search."", 'pages': '1-6', 'number': '', 'volume': '', 'year': '2017', 'title': 'Differential mutual information forward search for multi-kernel discriminant-component selection with an application to privacy-preserving classification', 'booktitle': '2017 IEEE 27th International Workshop on Machine Learning for Signal Processing (MLSP)', 'author': 'Chanyaswad, Thee and Al, Mert and Chang, J. Morris and Kung, S. Y.', 'ENTRYTYPE': 'inproceedings', 'ID': '8168177'}",IEEE Xplore
"Sexton, Julian and Chudnov, Andrey and Naumann, David A.",Spartan Jester: End-to-End Information Flow Control for Hybrid Android Applications,Androids;Humanoid robots;Java;Security;Tools;Monitoring;Lattices,"Web-based applications are attractive due to their portability. To leverage that, many mobile applications are hybrid, incorporating a web component that implements most of their functionality. While solutions for enforcing security exist for both mobile and web applications, enforcing and reasoning about the security of their combinations is difficult. We argue for a combination of static and dynamic analysis for assurance of end-to-end confidentiality in hybrid apps. We show how information flows in hybrid Android applications can be secured through use of SPARTA, a static analyzer for Android/Java, and JEST, a dynamic monitor for JavaScript, connected by a compatibility layer that translates policies and value representations. This paper reports on our preliminary investigation using a case study.",2017,2017 IEEE Security and Privacy Workshops (SPW),,"{'month': 'May', 'issn': '', 'doi': '10.1109/SPW.2017.15', 'keywords': 'Androids;Humanoid robots;Java;Security;Tools;Monitoring;Lattices', 'abstract': 'Web-based applications are attractive due to their portability. To leverage that, many mobile applications are hybrid, incorporating a web component that implements most of their functionality. While solutions for enforcing security exist for both mobile and web applications, enforcing and reasoning about the security of their combinations is difficult. We argue for a combination of static and dynamic analysis for assurance of end-to-end confidentiality in hybrid apps. We show how information flows in hybrid Android applications can be secured through use of SPARTA, a static analyzer for Android/Java, and JEST, a dynamic monitor for JavaScript, connected by a compatibility layer that translates policies and value representations. This paper reports on our preliminary investigation using a case study.', 'pages': '157-162', 'number': '', 'volume': '', 'year': '2017', 'title': 'Spartan Jester: End-to-End Information Flow Control for Hybrid Android Applications', 'booktitle': '2017 IEEE Security and Privacy Workshops (SPW)', 'author': 'Sexton, Julian and Chudnov, Andrey and Naumann, David A.', 'ENTRYTYPE': 'inproceedings', 'ID': '8227302'}",IEEE Xplore
"Liang, Jia and Xiao, Di and Huang, Hui and Li, Min",Multilevel Privacy Preservation Scheme Based on Compressed Sensing,Data privacy;Encryption;Privacy;Task analysis;Sensors;Internet of Things;Image reconstruction;Compressed sensing (CS);discriminant component analysis (DCA);multilevel encryption;privacy protection,"Although the extensive application of the Internet of Things brings great convenience, it raises the concern of privacy leakage in the processes of data acquisition, analyzing, and sharing as well. In this article, multilevel privacy protection via compressed sensing (CS) is proposed, which has the advantages of compressed sampling, protection of data privacy, and controllability of data access. At the data acquisition end, the CS technique suitable for a resource-constrained environment is employed to sample and encrypt signals with the assistance of discriminant component analysis. Then, the encrypted data will be transmitted to the cloud in time. On the cloud service, signals protected by CS rarely disclose private information to malicious attackers, and they will be accessed by two-class authorized entities. One is the semiauthorized user with low privilege who can only get the features from encrypted data for the subsequent inference; the other is the full-authorized user who is capable of reconstructing the original data. We demonstrate the scheme through two case studies of a face recognition system and a human activity recognition system and analyze its performance.",2023,IEEE Transactions on Industrial Informatics,,"{'month': 'June', 'issn': '1941-0050', 'doi': '10.1109/TII.2022.3209153', 'keywords': 'Data privacy;Encryption;Privacy;Task analysis;Sensors;Internet of Things;Image reconstruction;Compressed sensing (CS);discriminant component analysis (DCA);multilevel encryption;privacy protection', 'abstract': 'Although the extensive application of the Internet of Things brings great convenience, it raises the concern of privacy leakage in the processes of data acquisition, analyzing, and sharing as well. In this article, multilevel privacy protection via compressed sensing (CS) is proposed, which has the advantages of compressed sampling, protection of data privacy, and controllability of data access. At the data acquisition end, the CS technique suitable for a resource-constrained environment is employed to sample and encrypt signals with the assistance of discriminant component analysis. Then, the encrypted data will be transmitted to the cloud in time. On the cloud service, signals protected by CS rarely disclose private information to malicious attackers, and they will be accessed by two-class authorized entities. One is the semiauthorized user with low privilege who can only get the features from encrypted data for the subsequent inference; the other is the full-authorized user who is capable of reconstructing the original data. We demonstrate the scheme through two case studies of a face recognition system and a human activity recognition system and analyze its performance.', 'pages': '7435-7444', 'number': '6', 'volume': '19', 'year': '2023', 'title': 'Multilevel Privacy Preservation Scheme Based on Compressed Sensing', 'journal': 'IEEE Transactions on Industrial Informatics', 'author': 'Liang, Jia and Xiao, Di and Huang, Hui and Li, Min', 'ENTRYTYPE': 'article', 'ID': '9903332'}",IEEE Xplore
"Deng, Robert and Qiu, Ying and Zhou, Jianying and Bao, Feng",Protecting Location Information of Mobile Nodes in Mobile IPv6,Protection;Portable computers;Privacy;Monitoring;Standards organizations;Tunneling;Personal digital assistants;Mobile computing;Protocols;Internet;Security;Pricacy Location;Mobile IPv6,"Mobile IPv6 is an IP layer mobility protocol which allows mobile nodes to remain reachable while moving around in the Internet. In the current IETF Mobile IPv6 specifications (D. Johnson et al., 2004), when a mobile node roams, its location movement can be tracked by simply monitoring the IP addresses in IP packets. Recently, the issue of protecting location information in mobile IPv6 has received increasing attention, especially within the IETF and the 3GPP standard bodies. In this paper we propose a technique for hiding a mobile node's location movement information from eavesdroppers during route optimization and as well as from its correspondent node during reverse tunneling. The proposed technique is highly efficient and fully compatible with the base mobile IPv6 operation.",2006,2006 First International Conference on Communications and Networking in China,,"{'month': 'Oct', 'issn': '', 'doi': '10.1109/CHINACOM.2006.344648', 'keywords': 'Protection;Portable computers;Privacy;Monitoring;Standards organizations;Tunneling;Personal digital assistants;Mobile computing;Protocols;Internet;Security;Pricacy Location;Mobile IPv6', 'abstract': ""Mobile IPv6 is an IP layer mobility protocol which allows mobile nodes to remain reachable while moving around in the Internet. In the current IETF Mobile IPv6 specifications (D. Johnson et al., 2004), when a mobile node roams, its location movement can be tracked by simply monitoring the IP addresses in IP packets. Recently, the issue of protecting location information in mobile IPv6 has received increasing attention, especially within the IETF and the 3GPP standard bodies. In this paper we propose a technique for hiding a mobile node's location movement information from eavesdroppers during route optimization and as well as from its correspondent node during reverse tunneling. The proposed technique is highly efficient and fully compatible with the base mobile IPv6 operation."", 'pages': '1-7', 'number': '', 'volume': '', 'year': '2006', 'title': 'Protecting Location Information of Mobile Nodes in Mobile IPv6', 'booktitle': '2006 First International Conference on Communications and Networking in China', 'author': 'Deng, Robert and Qiu, Ying and Zhou, Jianying and Bao, Feng', 'ENTRYTYPE': 'inproceedings', 'ID': '4149901'}",IEEE Xplore
"Shen, Xicong and Liu, Ying",Distributed Differential Utility/Cost Analysis for Privacy Protection,Privacy;Data privacy;Optimization;Eigenvalues and eigenfunctions;Matrix decomposition;Distributed databases;Task analysis;Compressive privacy;distributed learning;differential utility/cost analysis;dimension reduction;diffusion,"In the era of Big Data, as vast amounts of data are collected and shared among collaborators or uploaded to the Internet, the attacks on data privacy become more and more serious. Compressive privacy (CP) is a kind of privacy-preserving dimension-reduced projection schemes such that the projected data can be well used for the intended utility task but not for malicious applications. Nevertheless, most of existing CP approaches belong to centralized processing, which are not applicable to the cases that data is dispersedly collected/stored at distributed nodes and cannot be centralized to one node for processing due to various reasons. To tackle this problem, we propose a distributed differential utility/cost analysis (dDUCA), in which each node in the network is only allowed to exchange and combine the compressive-and-lossy projection matrix with its one-hop neighbors. Using the projection matrix, the classification of the projected data is performed. Experiments on several datasets confirm the effectiveness of the proposed method in terms of both privacy protection and utility retention.",2019,IEEE Signal Processing Letters,,"{'month': 'Oct', 'issn': '1558-2361', 'doi': '10.1109/LSP.2019.2932915', 'keywords': 'Privacy;Data privacy;Optimization;Eigenvalues and eigenfunctions;Matrix decomposition;Distributed databases;Task analysis;Compressive privacy;distributed learning;differential utility/cost analysis;dimension reduction;diffusion', 'abstract': 'In the era of Big Data, as vast amounts of data are collected and shared among collaborators or uploaded to the Internet, the attacks on data privacy become more and more serious. Compressive privacy (CP) is a kind of privacy-preserving dimension-reduced projection schemes such that the projected data can be well used for the intended utility task but not for malicious applications. Nevertheless, most of existing CP approaches belong to centralized processing, which are not applicable to the cases that data is dispersedly collected/stored at distributed nodes and cannot be centralized to one node for processing due to various reasons. To tackle this problem, we propose a distributed differential utility/cost analysis (dDUCA), in which each node in the network is only allowed to exchange and combine the compressive-and-lossy projection matrix with its one-hop neighbors. Using the projection matrix, the classification of the projected data is performed. Experiments on several datasets confirm the effectiveness of the proposed method in terms of both privacy protection and utility retention.', 'pages': '1436-1440', 'number': '10', 'volume': '26', 'year': '2019', 'title': 'Distributed Differential Utility/Cost Analysis for Privacy Protection', 'journal': 'IEEE Signal Processing Letters', 'author': 'Shen, Xicong and Liu, Ying', 'ENTRYTYPE': 'article', 'ID': '8788609'}",IEEE Xplore
"Scoccia, Gian Luca and Autili, Marco and Stilo, Giovanni and Inverardi, Paola",An empirical study of privacy labels on the Apple iOS mobile app store,Data privacy;Privacy;Regulators;Decision making;Data collection;Mobile applications;Software engineering;iOS;Apps;Privacy,"Privacy labels provide an easy and recognizable overview of data collection practices adopted by mobile apps developers. Specifically, on the Apple App Store, privacy labels are displayed on each mobile app's page and summarize what data is collected by the app, how it is used, and for what purposes it is needed. Starting from the release of iOS version 14.3 developers are required to provide privacy labels for their applications. We conducted a large-scale empirical study, collecting and analyzing the privacy labels of 17, 312 apps published on the App Store, to understand and characterize how sensitive data is collected and shared. The results of our analysis highlight important criticalities about the collection and sharing of personal data for tracking purposes. In particular, on average free applications collect more sensitive data, the majority of data is collected in an unanonimyzed form, and a wide range of sensitive information are collected for tracking purposes. The analysis provides also evidence to support the decision-making of users, platform maintainers, and regulators. Furthermore, we repeated the data collection and analysis after seven months, following the introduction of additional run-time tracking controls by Apple. Comparing the two datasets, we observed that the newly introduced measures resulted in a statistically significant decrease in the number of apps that collect data for tracking purposes. At the same time, we observed a growth in overall data collection.",2022,2022 IEEE/ACM 9th International Conference on Mobile Software Engineering and Systems (MobileSoft),,"{'month': 'May', 'issn': '', 'doi': '10.1145/3524613.3527813', 'keywords': 'Data privacy;Privacy;Regulators;Decision making;Data collection;Mobile applications;Software engineering;iOS;Apps;Privacy', 'abstract': ""Privacy labels provide an easy and recognizable overview of data collection practices adopted by mobile apps developers. Specifically, on the Apple App Store, privacy labels are displayed on each mobile app's page and summarize what data is collected by the app, how it is used, and for what purposes it is needed. Starting from the release of iOS version 14.3 developers are required to provide privacy labels for their applications. We conducted a large-scale empirical study, collecting and analyzing the privacy labels of 17, 312 apps published on the App Store, to understand and characterize how sensitive data is collected and shared. The results of our analysis highlight important criticalities about the collection and sharing of personal data for tracking purposes. In particular, on average free applications collect more sensitive data, the majority of data is collected in an unanonimyzed form, and a wide range of sensitive information are collected for tracking purposes. The analysis provides also evidence to support the decision-making of users, platform maintainers, and regulators. Furthermore, we repeated the data collection and analysis after seven months, following the introduction of additional run-time tracking controls by Apple. Comparing the two datasets, we observed that the newly introduced measures resulted in a statistically significant decrease in the number of apps that collect data for tracking purposes. At the same time, we observed a growth in overall data collection."", 'pages': '114-124', 'number': '', 'volume': '', 'year': '2022', 'title': 'An empirical study of privacy labels on the Apple iOS mobile app store', 'booktitle': '2022 IEEE/ACM 9th International Conference on Mobile Software Engineering and Systems (MobileSoft)', 'author': 'Scoccia, Gian Luca and Autili, Marco and Stilo, Giovanni and Inverardi, Paola', 'ENTRYTYPE': 'inproceedings', 'ID': '9797333'}",IEEE Xplore
"Hume, Alethia and Ferreira, Nicolás and Cernuzzi, Luca",The design of a privacy dashboard for an academic environment based on participatory design,Privacy;Conferences;Art;Software;Law;Human computer interaction;Usability;privacy;dashboard;participatory design,"In today's world, characterized by the massive generation of data, a major problem related to data manipulation occurs when people's privacy is violated. To face this situation different regulations and solutions, to help users get in control over their data, emerged. However, many of the solutions require a certain level of knowledge in the field of privacy or offer unclear information that does not facilitate a real control of their data by the users. Added to this is the unfriendly user interface design as one of the factors that prevents users from managing their privacy settings effectively. Thus, in this work we explore the effect of the application of Participatory Design (PD) techniques in the implementation of privacy enhancing technologies. In particular, we focus on the use of PD for the design of a privacy dashboard that encourages the immersion of users with privacy issues and gives them greater control with a user interface according to usability criteria. The evaluation of the PD process, which has resulted in a high-fidelity prototype of the dashboard, shows encouraging results and greater user immersion in privacy management.",2021,2021 XLVII Latin American Computing Conference (CLEI),,"{'month': 'Oct', 'issn': '', 'doi': '10.1109/CLEI53233.2021.9640155', 'keywords': 'Privacy;Conferences;Art;Software;Law;Human computer interaction;Usability;privacy;dashboard;participatory design', 'abstract': ""In today's world, characterized by the massive generation of data, a major problem related to data manipulation occurs when people's privacy is violated. To face this situation different regulations and solutions, to help users get in control over their data, emerged. However, many of the solutions require a certain level of knowledge in the field of privacy or offer unclear information that does not facilitate a real control of their data by the users. Added to this is the unfriendly user interface design as one of the factors that prevents users from managing their privacy settings effectively. Thus, in this work we explore the effect of the application of Participatory Design (PD) techniques in the implementation of privacy enhancing technologies. In particular, we focus on the use of PD for the design of a privacy dashboard that encourages the immersion of users with privacy issues and gives them greater control with a user interface according to usability criteria. The evaluation of the PD process, which has resulted in a high-fidelity prototype of the dashboard, shows encouraging results and greater user immersion in privacy management."", 'pages': '1-10', 'number': '', 'volume': '', 'year': '2021', 'title': 'The design of a privacy dashboard for an academic environment based on participatory design', 'booktitle': '2021 XLVII Latin American Computing Conference (CLEI)', 'author': 'Hume, Alethia and Ferreira, Nicolás and Cernuzzi, Luca', 'ENTRYTYPE': 'inproceedings', 'ID': '9640155'}",IEEE Xplore
"Feltus, Christophe and Grandjean, Thierry and Aubert, Jocelyn and Khadraoui, Djamel",Towards a Standard-Based Security and Privacy of IoT System's Services,"Internet of Things;Security;Privacy;Monitoring;ISO Standards;IEC Standards;IoT security, IoT privacy, system's services, system assessment, system monitoring, standard-based","The Internet of Things (IoT) industry increases rapidly and becomes progressively more devoted to critical business services. IoT adoption generates two kinds of challenges: cybersecurity risks and privacy concerns. In order to generate a trust environment and provide confidence to IoT business services, LIST will partnered with private companies to implement an integrated framework and software tools for assessing and monitoring IoT system's service security and privacy. SPRINT assessment and monitoring foresees (1) an aggregated publicly available security and privacy integrated referential database dedicated to IoT services (SPRINT-REF), and (2), an IoT service-oriented assessment and monitoring methods based on this referential (SPRINT-METH). Compared to existing approaches, SPRINT-METH innovation is that it is service-oriented rather than device-oriented, as well as based recognized existing professional standards. Finally, the SPRINT toolbox (3) will include two assets: a software web service component aiming to assess the IoT system's service at the time of design, and an IoT Security Operations Centre to monitor IoT security and privacy at run time (SPRINT-TOOL).",2018,2018 International Conference on Computational Science and Computational Intelligence (CSCI),,"{'month': 'Dec', 'issn': '', 'doi': '10.1109/CSCI46756.2018.00201', 'keywords': ""Internet of Things;Security;Privacy;Monitoring;ISO Standards;IEC Standards;IoT security, IoT privacy, system's services, system assessment, system monitoring, standard-based"", 'abstract': ""The Internet of Things (IoT) industry increases rapidly and becomes progressively more devoted to critical business services. IoT adoption generates two kinds of challenges: cybersecurity risks and privacy concerns. In order to generate a trust environment and provide confidence to IoT business services, LIST will partnered with private companies to implement an integrated framework and software tools for assessing and monitoring IoT system's service security and privacy. SPRINT assessment and monitoring foresees (1) an aggregated publicly available security and privacy integrated referential database dedicated to IoT services (SPRINT-REF), and (2), an IoT service-oriented assessment and monitoring methods based on this referential (SPRINT-METH). Compared to existing approaches, SPRINT-METH innovation is that it is service-oriented rather than device-oriented, as well as based recognized existing professional standards. Finally, the SPRINT toolbox (3) will include two assets: a software web service component aiming to assess the IoT system's service at the time of design, and an IoT Security Operations Centre to monitor IoT security and privacy at run time (SPRINT-TOOL)."", 'pages': '1036-1039', 'number': '', 'volume': '', 'year': '2018', 'title': ""Towards a Standard-Based Security and Privacy of IoT System's Services"", 'booktitle': '2018 International Conference on Computational Science and Computational Intelligence (CSCI)', 'author': 'Feltus, Christophe and Grandjean, Thierry and Aubert, Jocelyn and Khadraoui, Djamel', 'ENTRYTYPE': 'inproceedings', 'ID': '8947691'}",IEEE Xplore
"Liu, Changchang and Lee, Wei-Han and Calo, Seraphin",Neuraltran: Optimal Data Transformation for Privacy-Preserving Machine Learning by Leveraging Neural Networks,Privacy;Data privacy;Task analysis;Mutual information;Neural networks;Markov processes;Optimization,"In this work, we develop a new data transformation technique to mediate privacy-preserving access to data while achieving machine learning (ML) tasks. Specifically, we first leverage mutual information in information theory to quantify the utility-providing information (corresponding to any ML task) and the privacy information (could be arbitrary information specified by the users). We further convert the optimization of utility-privacy tradeoff into training a novel neural network (named as NeuralTran) which consists of three modules: transformation module, utility module and privacy module. NeuralTran can be leveraged to automatically transform the input data to ensure that only utility-providing information is kept while the private information is removed. Through extensive experiments on real world datasets, we show the effectiveness of NeuralTran in balancing utility and privacy as well as its advantages over previous approaches.",2020,2020 50th Annual IEEE-IFIP International Conference on Dependable Systems and Networks-Supplemental Volume (DSN-S),,"{'month': 'June', 'issn': '', 'doi': '10.1109/DSN-S50200.2020.00018', 'keywords': 'Privacy;Data privacy;Task analysis;Mutual information;Neural networks;Markov processes;Optimization', 'abstract': 'In this work, we develop a new data transformation technique to mediate privacy-preserving access to data while achieving machine learning (ML) tasks. Specifically, we first leverage mutual information in information theory to quantify the utility-providing information (corresponding to any ML task) and the privacy information (could be arbitrary information specified by the users). We further convert the optimization of utility-privacy tradeoff into training a novel neural network (named as NeuralTran) which consists of three modules: transformation module, utility module and privacy module. NeuralTran can be leveraged to automatically transform the input data to ensure that only utility-providing information is kept while the private information is removed. Through extensive experiments on real world datasets, we show the effectiveness of NeuralTran in balancing utility and privacy as well as its advantages over previous approaches.', 'pages': '21-24', 'number': '', 'volume': '', 'year': '2020', 'title': 'Neuraltran: Optimal Data Transformation for Privacy-Preserving Machine Learning by Leveraging Neural Networks', 'booktitle': '2020 50th Annual IEEE-IFIP International Conference on Dependable Systems and Networks-Supplemental Volume (DSN-S)', 'author': 'Liu, Changchang and Lee, Wei-Han and Calo, Seraphin', 'ENTRYTYPE': 'inproceedings', 'ID': '9159143'}",IEEE Xplore
"Zhong, Haoti and Li, Hao and Squicciarini, Anna and Rajtmajer, Sarah and Miller, David",Toward Image Privacy Classification and Spatial Attribution of Private Content,Privacy;Training;Machine learning;Task analysis;Image color analysis;Feature extraction;Histograms,"Machine labeling of image content as private or public is a notoriously difficult problem, with the usual image processing challenges compounded by the highly personal, subjective, and contextual nature of access control decision making. In general, a user's privacy expectation for a given image is consequential to specific contents therein and the presence of sensitive content somewhere in the image is sufficient to warrant a private label. In this work, we extend the problem of determining a single privacy label for a given image to jointly inferring a privacy label and detecting the specific areas of sensitive content within a privately labeled image. We propose a stochastic spatial attribution model which exploits sophisticated (deep neural net derived) image features over randomly selected image patches, as well as image saliency quantification. We validate our detected private regions through extensive user study experiments. This effort to achieve spatial attribution of private image content helps to lay a foundation for warning mechanisms which may serve to aid both social media sites and their users.",2019,2019 IEEE International Conference on Big Data (Big Data),,"{'month': 'Dec', 'issn': '', 'doi': '10.1109/BigData47090.2019.9006510', 'keywords': 'Privacy;Training;Machine learning;Task analysis;Image color analysis;Feature extraction;Histograms', 'abstract': ""Machine labeling of image content as private or public is a notoriously difficult problem, with the usual image processing challenges compounded by the highly personal, subjective, and contextual nature of access control decision making. In general, a user's privacy expectation for a given image is consequential to specific contents therein and the presence of sensitive content somewhere in the image is sufficient to warrant a private label. In this work, we extend the problem of determining a single privacy label for a given image to jointly inferring a privacy label and detecting the specific areas of sensitive content within a privately labeled image. We propose a stochastic spatial attribution model which exploits sophisticated (deep neural net derived) image features over randomly selected image patches, as well as image saliency quantification. We validate our detected private regions through extensive user study experiments. This effort to achieve spatial attribution of private image content helps to lay a foundation for warning mechanisms which may serve to aid both social media sites and their users."", 'pages': '1351-1360', 'number': '', 'volume': '', 'year': '2019', 'title': 'Toward Image Privacy Classification and Spatial Attribution of Private Content', 'booktitle': '2019 IEEE International Conference on Big Data (Big Data)', 'author': 'Zhong, Haoti and Li, Hao and Squicciarini, Anna and Rajtmajer, Sarah and Miller, David', 'ENTRYTYPE': 'inproceedings', 'ID': '9006510'}",IEEE Xplore
"Ovi, Pretom Roy and Gangopadhyay, Aryya and Erbacher, Robert F. and Busart, Carl",Secure Federated Training: Detecting Compromised Nodes and Identifying the Type of Attacks,Training;Data privacy;Toxicology;Federated learning;Training data;Process control;Data models;data level poisoning;model level poisoning;federated training;adversarial attacks;identify attacks,"Federated learning (FL) allows a set of clients to collaboratively train a model without sharing private data. As a result, FL has limited control over the local data and corresponding training process. Therefore, it is susceptible to poisoning attacks in which malicious clients use malicious training data or local updates to poison the global model. In this work, we first studied the data level and model level poisoning attacks. We simulated model poisoning attacks by tampering the local model updates during each round of communication and data poisoning attacks by training a few clients on malicious data. And clients under such attacks carry faulty information to the server, poison the global model, and restrict it from convergence. Therefore, detecting clients under attacks as well as identifying the type of attacks are required to recover the clients from their malicious status. To address these issues, we proposed a way under federated framework that enables the detection of malicious clients and attack types while ensuring data privacy. Our clustering-based approach utilizes the neuron’s activations from the local models to identify the type of poisoning attacks. We also proposed to check the weight distribution of local model updates among the participating clients to detect malicious clients. Our experimental results validated the robustness of the proposed framework against the attacks mentioned above by successfully detecting the compromised clients and the attack types. Moreover, the global model trained on MNIST data couldn’t reach the optimal point even after 75 rounds because of malicious clients, whereas the proposed approach by detecting the malicious clients ensured convergence within only 30 rounds and 40 rounds in independent and identically distributed (IID) and non- independent and identically distributed (non-IID) setup respectively.",2022,2022 21st IEEE International Conference on Machine Learning and Applications (ICMLA),,"{'month': 'Dec', 'issn': '', 'doi': '10.1109/ICMLA55696.2022.00183', 'keywords': 'Training;Data privacy;Toxicology;Federated learning;Training data;Process control;Data models;data level poisoning;model level poisoning;federated training;adversarial attacks;identify attacks', 'abstract': 'Federated learning (FL) allows a set of clients to collaboratively train a model without sharing private data. As a result, FL has limited control over the local data and corresponding training process. Therefore, it is susceptible to poisoning attacks in which malicious clients use malicious training data or local updates to poison the global model. In this work, we first studied the data level and model level poisoning attacks. We simulated model poisoning attacks by tampering the local model updates during each round of communication and data poisoning attacks by training a few clients on malicious data. And clients under such attacks carry faulty information to the server, poison the global model, and restrict it from convergence. Therefore, detecting clients under attacks as well as identifying the type of attacks are required to recover the clients from their malicious status. To address these issues, we proposed a way under federated framework that enables the detection of malicious clients and attack types while ensuring data privacy. Our clustering-based approach utilizes the neuron’s activations from the local models to identify the type of poisoning attacks. We also proposed to check the weight distribution of local model updates among the participating clients to detect malicious clients. Our experimental results validated the robustness of the proposed framework against the attacks mentioned above by successfully detecting the compromised clients and the attack types. Moreover, the global model trained on MNIST data couldn’t reach the optimal point even after 75 rounds because of malicious clients, whereas the proposed approach by detecting the malicious clients ensured convergence within only 30 rounds and 40 rounds in independent and identically distributed (IID) and non- independent and identically distributed (non-IID) setup respectively.', 'pages': '1115-1120', 'number': '', 'volume': '', 'year': '2022', 'title': 'Secure Federated Training: Detecting Compromised Nodes and Identifying the Type of Attacks', 'booktitle': '2022 21st IEEE International Conference on Machine Learning and Applications (ICMLA)', 'author': 'Ovi, Pretom Roy and Gangopadhyay, Aryya and Erbacher, Robert F. and Busart, Carl', 'ENTRYTYPE': 'inproceedings', 'ID': '10069230'}",IEEE Xplore
"Daniels, Mark and Farkas, Csilla",Health data privacy: A case of undesired inferences,Privacy;Ontologies;Data privacy;Medical services;Prototypes;Databases;Resource description framework,"In this work, we investigate privacy violations that occur when non-confidential medical data is combined with domain ontologies to infer confidential data. We propose a framework to detect such privacy violations and to eliminate undesired inferences. Our inference channel removal is based on modifying data that contribute to an inference. We show that our method is sound and complete. Soundness means that we modify only data items that lead to undesired inferences. Completeness means that we detect all inferences leading to undesired data disclosures. Finally, we show that our approach preserves data availability by minimizing the number of data items to be modified. An important aspect of our approach is that it sets the foundation for creating patient-specific privacy policies; an emerging need in the healthcare domain.",2018,2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI),,"{'month': 'March', 'issn': '', 'doi': '10.1109/BHI.2018.8333426', 'keywords': 'Privacy;Ontologies;Data privacy;Medical services;Prototypes;Databases;Resource description framework', 'abstract': 'In this work, we investigate privacy violations that occur when non-confidential medical data is combined with domain ontologies to infer confidential data. We propose a framework to detect such privacy violations and to eliminate undesired inferences. Our inference channel removal is based on modifying data that contribute to an inference. We show that our method is sound and complete. Soundness means that we modify only data items that lead to undesired inferences. Completeness means that we detect all inferences leading to undesired data disclosures. Finally, we show that our approach preserves data availability by minimizing the number of data items to be modified. An important aspect of our approach is that it sets the foundation for creating patient-specific privacy policies; an emerging need in the healthcare domain.', 'pages': '291-294', 'number': '', 'volume': '', 'year': '2018', 'title': 'Health data privacy: A case of undesired inferences', 'booktitle': '2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI)', 'author': 'Daniels, Mark and Farkas, Csilla', 'ENTRYTYPE': 'inproceedings', 'ID': '8333426'}",IEEE Xplore
"Liu, Junlin and Lyu, Xinchen and Cui, Qimei and Tao, Xiaofeng",Similarity-Based Label Inference Attack Against Training and Inference of Split Learning,Training;Servers;Distance learning;Computer aided instruction;Artificial intelligence;Federated learning;Data models;Split learning;label privacy;similarity measurement;training and inference,"Split learning is a promising paradigm for privacy-preserving distributed learning. The learning model can be cut into multiple portions to be collaboratively trained at the participants by exchanging only the intermediate results at the cut layer. It is crucial to understand the security performance of split learning, particularly for various privacy-sensitive applications. This paper shows that the exchanged intermediate results, including the smashed data (i.e., extracted features from the raw data) and gradients during training and inference of split learning, can already reveal the private labels. We mathematically analyze the potential label leakages and propose the cosine and Euclidean similarity measurements for gradients and smashed data. The two similarity measurements are shown to be unified in Euclidean space. Leveraging the similarity metric, we design three label inference attacks to efficiently recover the private labels during both the training and inference phases. Experimental results validate that the proposed attacks can achieve close to 100% accuracy of label attacks. Furthermore, our proposed attacks can remain effective against various state-of-the-art defense mechanisms, including DP-SGD, label differential privacy, gradient compression, and Marvell.",2024,IEEE Transactions on Information Forensics and Security,,"{'month': '', 'issn': '1556-6021', 'doi': '10.1109/TIFS.2024.3356821', 'keywords': 'Training;Servers;Distance learning;Computer aided instruction;Artificial intelligence;Federated learning;Data models;Split learning;label privacy;similarity measurement;training and inference', 'abstract': 'Split learning is a promising paradigm for privacy-preserving distributed learning. The learning model can be cut into multiple portions to be collaboratively trained at the participants by exchanging only the intermediate results at the cut layer. It is crucial to understand the security performance of split learning, particularly for various privacy-sensitive applications. This paper shows that the exchanged intermediate results, including the smashed data (i.e., extracted features from the raw data) and gradients during training and inference of split learning, can already reveal the private labels. We mathematically analyze the potential label leakages and propose the cosine and Euclidean similarity measurements for gradients and smashed data. The two similarity measurements are shown to be unified in Euclidean space. Leveraging the similarity metric, we design three label inference attacks to efficiently recover the private labels during both the training and inference phases. Experimental results validate that the proposed attacks can achieve close to 100% accuracy of label attacks. Furthermore, our proposed attacks can remain effective against various state-of-the-art defense mechanisms, including DP-SGD, label differential privacy, gradient compression, and Marvell.', 'pages': '2881-2895', 'number': '', 'volume': '19', 'year': '2024', 'title': 'Similarity-Based Label Inference Attack Against Training and Inference of Split Learning', 'journal': 'IEEE Transactions on Information Forensics and Security', 'author': 'Liu, Junlin and Lyu, Xinchen and Cui, Qimei and Tao, Xiaofeng', 'ENTRYTYPE': 'article', 'ID': '10411061'}",IEEE Xplore
"Cleveland, Simon",In search of user privacy protection in ubiquitous computing,Privacy;Sensors;Data privacy;Mobile communication;Servers;Mobile handsets;Ubiquitous computing;privacy technologies;mobile privacy solutions;participatory sensing applications;social computing;ubiquitous computing,"Participatory applications provide users with value-added and reusable information; however, collection of this information comes at the expense of the participants' privacy. Preserving the mobile participants' privacy is a key concern of mobile computing. This paper outlines current participatory application system model, privacy weaknesses, and existing privacy enhancing technologies. Next, it proposes a study to address mobile privacy protection by educating participants of exploitable privacy areas of their participatory applications. The contribution of the paper is two-fold: it provides a review of the existing privacy weaknesses of PS applications and demonstrates that participants' wanting to know more about these weaknesses warrants further study.",2012,2012 IEEE 13th International Conference on Information Reuse & Integration (IRI),,"{'month': 'Aug', 'issn': '', 'doi': '10.1109/IRI.2012.6303077', 'keywords': 'Privacy;Sensors;Data privacy;Mobile communication;Servers;Mobile handsets;Ubiquitous computing;privacy technologies;mobile privacy solutions;participatory sensing applications;social computing;ubiquitous computing', 'abstract': ""Participatory applications provide users with value-added and reusable information; however, collection of this information comes at the expense of the participants' privacy. Preserving the mobile participants' privacy is a key concern of mobile computing. This paper outlines current participatory application system model, privacy weaknesses, and existing privacy enhancing technologies. Next, it proposes a study to address mobile privacy protection by educating participants of exploitable privacy areas of their participatory applications. The contribution of the paper is two-fold: it provides a review of the existing privacy weaknesses of PS applications and demonstrates that participants' wanting to know more about these weaknesses warrants further study."", 'pages': '694-699', 'number': '', 'volume': '', 'year': '2012', 'title': 'In search of user privacy protection in ubiquitous computing', 'booktitle': '2012 IEEE 13th International Conference on Information Reuse & Integration (IRI)', 'author': 'Cleveland, Simon', 'ENTRYTYPE': 'inproceedings', 'ID': '6303077'}",IEEE Xplore
"Essefi, Intidhar and Boussi Rahmouni, Hanen and Solomonides, Tony and Fethi Ladeb, Mohamed",HIPAA Controlled Patient Information Exchange and Traceability in Clinical Processes,Data privacy;Statistical analysis;Process control;Medical services;Privacy breach;Regulation;Telecommunications;Digital transformation;GDPR;Healthcare entities;HIPAA Privacy Rule;HL7-CDA standard;protection methods;security labels;sensitive data,"The digital transformation of healthcare processes is deeply changing the quality of healthcare services offered to the patient. Although it is often seen as highly beneficial, the move to digital connected health systems exposes both health providers and individuals to many risks ranging from privacy violations to medical identity usurpation Throughout this process of digitisation, it is essential that privacy protection and systemic compliance to personal data regulations such as HIPAA and GDPR are ensured by all healthcare stakeholders. This is essential to setup the boundaries and limitation imposed by the legislative framework with relation to the legitimate processing of sensitive data. In this paper, we are aiming to represent privacy and security controls as tags/labels to data elements highlighted in clinical processes and their automation as privacy protection filters to the data at user interface layers of the healthcare information system. As a data model we rely on the HL7-CDA standard for medical documents architecture thanks to its seamless and extensible data integration capabilities while exchanging EHR data.",2022,"2022 IEEE 9th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT)",,"{'month': 'May', 'issn': '', 'doi': '10.1109/SETIT54465.2022.9875865', 'keywords': 'Data privacy;Statistical analysis;Process control;Medical services;Privacy breach;Regulation;Telecommunications;Digital transformation;GDPR;Healthcare entities;HIPAA Privacy Rule;HL7-CDA standard;protection methods;security labels;sensitive data', 'abstract': 'The digital transformation of healthcare processes is deeply changing the quality of healthcare services offered to the patient. Although it is often seen as highly beneficial, the move to digital connected health systems exposes both health providers and individuals to many risks ranging from privacy violations to medical identity usurpation Throughout this process of digitisation, it is essential that privacy protection and systemic compliance to personal data regulations such as HIPAA and GDPR are ensured by all healthcare stakeholders. This is essential to setup the boundaries and limitation imposed by the legislative framework with relation to the legitimate processing of sensitive data. In this paper, we are aiming to represent privacy and security controls as tags/labels to data elements highlighted in clinical processes and their automation as privacy protection filters to the data at user interface layers of the healthcare information system. As a data model we rely on the HL7-CDA standard for medical documents architecture thanks to its seamless and extensible data integration capabilities while exchanging EHR data.', 'pages': '452-460', 'number': '', 'volume': '', 'year': '2022', 'title': 'HIPAA Controlled Patient Information Exchange and Traceability in Clinical Processes', 'booktitle': '2022 IEEE 9th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT)', 'author': 'Essefi, Intidhar and Boussi Rahmouni, Hanen and Solomonides, Tony and Fethi Ladeb, Mohamed', 'ENTRYTYPE': 'inproceedings', 'ID': '9875865'}",IEEE Xplore
"Ishikawa, Yuchi and Kondo, Masayoshi and Kataoka, Hirokatsu",Learnable Cube-based Video Encryption for Privacy-Preserving Action Recognition,Training;Privacy;Visualization;Computer architecture;Transformers;Data models;Encryption;Algorithms;Video recognition and understanding;Algorithms;Explainable;fair;accountable;privacy-preserving;ethical computer vision,"With the development of cloud services and machine learning, there has been an inevitable need to enhance privacy and security when serving video recognition models. Although existing image encryption methods can be used to address this issue, applying them frame by frame to videos is insufficient in two respects: model performance degradation and security strength. In this paper, we propose a novel encryption approach for privacy-preserving action recognition. It consists of two encrypting operations; Learnable Cube-based Video Encryption (LCVE) and ViT Scrambling. LCVE is video encryption based on spatio-temporal cubes, which has a large key space and can provide robust privacy protection. ViT Scrambling encrypts the Vision Transformer (ViT) model, which enables it to recognize the encrypted videos in the same manner as unencrypted videos without modifying the model architecture or fine-tuning on the encrypted data. We evaluate our method in an action recognition task with seven datasets containing a variety of action classes as well as motion and visual patterns. Empirical results demonstrate that LCVE combined with ViT Scrambling can preserve video privacy while recognizing action in encrypted videos as well as unencrypted videos. As a result, our approach outperforms existing privacy-preserving action recognition methods.",2024,2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV),,"{'month': 'Jan', 'issn': '2642-9381', 'doi': '10.1109/WACV57701.2024.00685', 'keywords': 'Training;Privacy;Visualization;Computer architecture;Transformers;Data models;Encryption;Algorithms;Video recognition and understanding;Algorithms;Explainable;fair;accountable;privacy-preserving;ethical computer vision', 'abstract': 'With the development of cloud services and machine learning, there has been an inevitable need to enhance privacy and security when serving video recognition models. Although existing image encryption methods can be used to address this issue, applying them frame by frame to videos is insufficient in two respects: model performance degradation and security strength. In this paper, we propose a novel encryption approach for privacy-preserving action recognition. It consists of two encrypting operations; Learnable Cube-based Video Encryption (LCVE) and ViT Scrambling. LCVE is video encryption based on spatio-temporal cubes, which has a large key space and can provide robust privacy protection. ViT Scrambling encrypts the Vision Transformer (ViT) model, which enables it to recognize the encrypted videos in the same manner as unencrypted videos without modifying the model architecture or fine-tuning on the encrypted data. We evaluate our method in an action recognition task with seven datasets containing a variety of action classes as well as motion and visual patterns. Empirical results demonstrate that LCVE combined with ViT Scrambling can preserve video privacy while recognizing action in encrypted videos as well as unencrypted videos. As a result, our approach outperforms existing privacy-preserving action recognition methods.', 'pages': '6988-6998', 'number': '', 'volume': '', 'year': '2024', 'title': 'Learnable Cube-based Video Encryption for Privacy-Preserving Action Recognition', 'booktitle': '2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)', 'author': 'Ishikawa, Yuchi and Kondo, Masayoshi and Kataoka, Hirokatsu', 'ENTRYTYPE': 'inproceedings', 'ID': '10483907'}",IEEE Xplore
"Ying Qiu and Jianying Zhou and Feng Bao and Deng, R.",Protocol for hiding movement of mobile nodes in mobile IPv6,Protocols;Testing;Monitoring;Internet;Privacy;Information security;Telecommunication traffic;Guidelines;Protection;Performance evaluation,,2005,"VTC-2005-Fall. 2005 IEEE 62nd Vehicular Technology Conference, 2005.",,"{'month': 'Sep.', 'issn': '1090-3038', 'doi': '10.1109/VETECF.2005.1558037', 'keywords': 'Protocols;Testing;Monitoring;Internet;Privacy;Information security;Telecommunication traffic;Guidelines;Protection;Performance evaluation', 'abstract': '', 'pages': '812-815', 'number': '', 'volume': '2', 'year': '2005', 'title': 'Protocol for hiding movement of mobile nodes in mobile IPv6', 'booktitle': 'VTC-2005-Fall. 2005 IEEE 62nd Vehicular Technology Conference, 2005.', 'author': 'Ying Qiu and Jianying Zhou and Feng Bao and Deng, R.', 'ENTRYTYPE': 'inproceedings', 'ID': '1558037'}",IEEE Xplore
"Tillmann, Arne and Kqiku, Lindrit and Reinhardt, Delphine and Weisser, Christoph and Säfken, Benjamin and Kneib, Thomas","Privacy Estimation on Twitter: Modelling the Effect of Latent Topics on Privacy by Integrating XGBoost, Topic and Generalized Additive Models",COVID-19;Privacy;Sentiment analysis;Additives;Social networking (online);Estimation;Mental health;Privacy;Tweets;Topic Model;Latent Dirichlet Allocation;Generalized Additive Model,"Securing their users’ privacy is a central duty of Online Social Networks (OSN), but the complex non-linear effects of social media content on privacy is not well understood. We propose a novel framework that integrates XGBoost, Latent Dirichlet Allocation (LDA) topic models and Generalized Additive Models (GAM) to perform statistical inference about the complex non-linear relationship between the topics and privacy of tweets. First, XGBoost is used to predict the privacy of tweets. Then, the predictions are improved by analyzing the classified tweets with LDA topic models. Finally, we model the nonlinear relationship between topics and privacy with GAMs by using (penalized) splines. Instead of being limited to predictive modeling, our approach enables us to model the non-linear relationship between latent topics and the privacy of tweets.",2022,"2022 IEEE Smartworld, Ubiquitous Intelligence & Computing, Scalable Computing & Communications, Digital Twin, Privacy Computing, Metaverse, Autonomous & Trusted Vehicles (SmartWorld/UIC/ScalCom/DigitalTwin/PriComp/Meta)",,"{'month': 'Dec', 'issn': '', 'doi': '10.1109/SmartWorld-UIC-ATC-ScalCom-DigitalTwin-PriComp-Metaverse56740.2022.00365', 'keywords': 'COVID-19;Privacy;Sentiment analysis;Additives;Social networking (online);Estimation;Mental health;Privacy;Tweets;Topic Model;Latent Dirichlet Allocation;Generalized Additive Model', 'abstract': 'Securing their users’ privacy is a central duty of Online Social Networks (OSN), but the complex non-linear effects of social media content on privacy is not well understood. We propose a novel framework that integrates XGBoost, Latent Dirichlet Allocation (LDA) topic models and Generalized Additive Models (GAM) to perform statistical inference about the complex non-linear relationship between the topics and privacy of tweets. First, XGBoost is used to predict the privacy of tweets. Then, the predictions are improved by analyzing the classified tweets with LDA topic models. Finally, we model the nonlinear relationship between topics and privacy with GAMs by using (penalized) splines. Instead of being limited to predictive modeling, our approach enables us to model the non-linear relationship between latent topics and the privacy of tweets.', 'pages': '2325-2332', 'number': '', 'volume': '', 'year': '2022', 'title': 'Privacy Estimation on Twitter: Modelling the Effect of Latent Topics on Privacy by Integrating XGBoost, Topic and Generalized Additive Models', 'booktitle': '2022 IEEE Smartworld, Ubiquitous Intelligence & Computing, Scalable Computing & Communications, Digital Twin, Privacy Computing, Metaverse, Autonomous & Trusted Vehicles (SmartWorld/UIC/ScalCom/DigitalTwin/PriComp/Meta)', 'author': 'Tillmann, Arne and Kqiku, Lindrit and Reinhardt, Delphine and Weisser, Christoph and Säfken, Benjamin and Kneib, Thomas', 'ENTRYTYPE': 'inproceedings', 'ID': '10189773'}",IEEE Xplore
"Klobucar, T. and Senicar, V. and Blazic, B.J.",Privacy issues of a smart space for learning,Space technology;Protection;Learning;Programmable logic arrays;Data privacy;Positron emission tomography;Web and internet services;Cryptography;Cryptographic protocols;Paper technology,"Personalized learning solutions typically involve learner profiles with sensitive information and activities that might breach learner's privacy, such as user profiling. In this paper we discuss privacy aspects of a smart space for learning that is being developed in the EU 1ST ELENA project. The paper presents threats and requirements, and describes several privacy-enhancing technology (PET) based solutions.",2004,"IEEE International Conference on Advanced Learning Technologies, 2004. Proceedings.",,"{'month': 'Aug', 'issn': '', 'doi': '10.1109/ICALT.2004.1357655', 'keywords': 'Space technology;Protection;Learning;Programmable logic arrays;Data privacy;Positron emission tomography;Web and internet services;Cryptography;Cryptographic protocols;Paper technology', 'abstract': ""Personalized learning solutions typically involve learner profiles with sensitive information and activities that might breach learner's privacy, such as user profiling. In this paper we discuss privacy aspects of a smart space for learning that is being developed in the EU 1ST ELENA project. The paper presents threats and requirements, and describes several privacy-enhancing technology (PET) based solutions."", 'pages': '780-782', 'number': '', 'volume': '', 'year': '2004', 'title': 'Privacy issues of a smart space for learning', 'booktitle': 'IEEE International Conference on Advanced Learning Technologies, 2004. Proceedings.', 'author': 'Klobucar, T. and Senicar, V. and Blazic, B.J.', 'ENTRYTYPE': 'inproceedings', 'ID': '1357655'}",IEEE Xplore
"Aycı, Gönül and Özgür, Arzucan and Şensoy, Murat and Yolum, Pınar",Can We Explain Privacy?,Privacy;Internet;Content management,"Web users want to protect their privacy while sharing content online. This can be done through automated privacy assistants that are capable of taking actions by detecting privacy violations and recommending privacy settings for content that the user intends to share. While these approaches are promising in terms of the accuracy of their privacy decisions, they lack the ability to explain to the end user why certain decisions are being made. In this work, we study how privacy assistants can be enhanced through explanations generated in the context of privacy decisions for the user content. We outline a methodology to create explanations of privacy decisions, discuss core challenges, and show example explanations that are generated by our approach.",2023,IEEE Internet Computing,,"{'month': 'July', 'issn': '1941-0131', 'doi': '10.1109/MIC.2023.3270768', 'keywords': 'Privacy;Internet;Content management', 'abstract': 'Web users want to protect their privacy while sharing content online. This can be done through automated privacy assistants that are capable of taking actions by detecting privacy violations and recommending privacy settings for content that the user intends to share. While these approaches are promising in terms of the accuracy of their privacy decisions, they lack the ability to explain to the end user why certain decisions are being made. In this work, we study how privacy assistants can be enhanced through explanations generated in the context of privacy decisions for the user content. We outline a methodology to create explanations of privacy decisions, discuss core challenges, and show example explanations that are generated by our approach.', 'pages': '75-80', 'number': '4', 'volume': '27', 'year': '2023', 'title': 'Can We Explain Privacy?', 'journal': 'IEEE Internet Computing', 'author': 'Aycı, Gönül and Özgür, Arzucan and Şensoy, Murat and Yolum, Pınar', 'ENTRYTYPE': 'article', 'ID': '10184288'}",IEEE Xplore
"Xie, Rongna and Fan, Xiaonan and Zhu, Jiayu and Shi, Guozhen and Lou, Jiapeng and Huang, Yuxin",Research on Label Based Data Flow Control Mechanism,Adaptation models;Redundancy;Process control;Cyberspace;Complex networks;Data science;Data models;complex network;label;data flow control;cross domain;lightweight,"Aiming at the problem of low evaluation efficiency caused by complex and large number of policies in the complex network, in view of the characteristics of a label are flexible, lightweight, and efficient policy matching, we propose a label-based data flow control mechanism. We build the system model and design the label description method around the operation of data. Our model covers a variety of control models based on roles, relationships and attributes, which can be adapted to more application scenarios. The label only includes the attribute rules necessary for flow control and allows users to customize it according to security requirements, so as to achieve the purposes of lightweight, fine-grained, and high flexibility. The label constraint rules are formulated and the corresponding algorithm for generating a visitor's permission set is proposed. The selection of the attribute rule type is added to the label, which makes the policy evaluation more efficient. Finally, performance analysis and use case analysis illustrate the availability and effectiveness of our mechanism.",2021,2021 IEEE Sixth International Conference on Data Science in Cyberspace (DSC),,"{'month': 'Oct', 'issn': '', 'doi': '10.1109/DSC53577.2021.00039', 'keywords': 'Adaptation models;Redundancy;Process control;Cyberspace;Complex networks;Data science;Data models;complex network;label;data flow control;cross domain;lightweight', 'abstract': ""Aiming at the problem of low evaluation efficiency caused by complex and large number of policies in the complex network, in view of the characteristics of a label are flexible, lightweight, and efficient policy matching, we propose a label-based data flow control mechanism. We build the system model and design the label description method around the operation of data. Our model covers a variety of control models based on roles, relationships and attributes, which can be adapted to more application scenarios. The label only includes the attribute rules necessary for flow control and allows users to customize it according to security requirements, so as to achieve the purposes of lightweight, fine-grained, and high flexibility. The label constraint rules are formulated and the corresponding algorithm for generating a visitor's permission set is proposed. The selection of the attribute rule type is added to the label, which makes the policy evaluation more efficient. Finally, performance analysis and use case analysis illustrate the availability and effectiveness of our mechanism."", 'pages': '233-239', 'number': '', 'volume': '', 'year': '2021', 'title': 'Research on Label Based Data Flow Control Mechanism', 'booktitle': '2021 IEEE Sixth International Conference on Data Science in Cyberspace (DSC)', 'author': 'Xie, Rongna and Fan, Xiaonan and Zhu, Jiayu and Shi, Guozhen and Lou, Jiapeng and Huang, Yuxin', 'ENTRYTYPE': 'inproceedings', 'ID': '9750507'}",IEEE Xplore
"Huang, Heyuan and Luo, Liwei and Zhang, Bingbing and Xie, Yankai and Zhang, Chi and Liu, Jianqing",A PATE-based Approach for Training Graph Neural Networks under Label Differential Privacy,Training;Differential privacy;Privacy;Noise reduction;Graph neural networks;Global communication;Standards;Graph Neural Networks;Differential Privacy;Label Differential Privacy,"As a standard solution to the problem of private deep learning, differential privacy (DP) is widely used in graph neural networks (GNNs) to protect sensitive information about the input graph data. However, most existing DP algorithms for GNNs protect the privacy of every attribute for each node. This results in the need for injecting a large amount of noise, making these methods significantly underperform their non-private counterparts. We argue that in some practical scenarios, node labels serve as the only or the most sensitive attribute, where label differential privacy, a more fine-grained notion of differential privacy that only protects the labels is more appropriate. To better capture these scenarios and improve the trade-off between data privacy and model accuracy, we propose a novel method of training GNNs under label differential privacy. Instead of naively adding noise to the node labels before training the GNN, our method follows the strategy of Private Aggregation of Teacher Ensembles (PATE) to generate differentially private node labels with both high accuracy and strong privacy guarantee. We also propose a label denoising module that takes advantage of the graph structure to further improve the accuracy of the trained model. Additionally, our method is model-agnostic, making it applicable to any GNN architecture. We evaluate its performance on two commonly used benchmark datasets and demonstrate its capability to learn high-performance models while ensuring privacy.",2023,GLOBECOM 2023 - 2023 IEEE Global Communications Conference,,"{'month': 'Dec', 'issn': '2576-6813', 'doi': '10.1109/GLOBECOM54140.2023.10437079', 'keywords': 'Training;Differential privacy;Privacy;Noise reduction;Graph neural networks;Global communication;Standards;Graph Neural Networks;Differential Privacy;Label Differential Privacy', 'abstract': 'As a standard solution to the problem of private deep learning, differential privacy (DP) is widely used in graph neural networks (GNNs) to protect sensitive information about the input graph data. However, most existing DP algorithms for GNNs protect the privacy of every attribute for each node. This results in the need for injecting a large amount of noise, making these methods significantly underperform their non-private counterparts. We argue that in some practical scenarios, node labels serve as the only or the most sensitive attribute, where label differential privacy, a more fine-grained notion of differential privacy that only protects the labels is more appropriate. To better capture these scenarios and improve the trade-off between data privacy and model accuracy, we propose a novel method of training GNNs under label differential privacy. Instead of naively adding noise to the node labels before training the GNN, our method follows the strategy of Private Aggregation of Teacher Ensembles (PATE) to generate differentially private node labels with both high accuracy and strong privacy guarantee. We also propose a label denoising module that takes advantage of the graph structure to further improve the accuracy of the trained model. Additionally, our method is model-agnostic, making it applicable to any GNN architecture. We evaluate its performance on two commonly used benchmark datasets and demonstrate its capability to learn high-performance models while ensuring privacy.', 'pages': '3427-3432', 'number': '', 'volume': '', 'year': '2023', 'title': 'A PATE-based Approach for Training Graph Neural Networks under Label Differential Privacy', 'booktitle': 'GLOBECOM 2023 - 2023 IEEE Global Communications Conference', 'author': 'Huang, Heyuan and Luo, Liwei and Zhang, Bingbing and Xie, Yankai and Zhang, Chi and Liu, Jianqing', 'ENTRYTYPE': 'inproceedings', 'ID': '10437079'}",IEEE Xplore
"Al, Mert and Yagli, Semih and Kung, Sun-Yuan",Privacy Enhancing Machine Learning via Removal of Unwanted Dependencies,Data privacy;Data models;Privacy;Predictive models;Kernel;Correlation;Training;Adversarial learning;data privacy;dimension reduction;Kernel methods;representation learning,"The rapid rise of IoT and Big Data has facilitated copious data-driven applications to enhance our quality of life. However, the omnipresent and all-encompassing nature of the data collection can generate privacy concerns. Hence, there is a strong need to develop techniques that ensure the data serve only the intended purposes, giving users control over the information they share. To this end, this article studies new variants of supervised and adversarial learning methods, which remove the sensitive information in the data before they are sent out for a particular application. The explored methods optimize privacy-preserving feature mappings and predictive models simultaneously in an end-to-end fashion. Additionally, the models are built with an emphasis on placing little computational burden on the user side so that the data can be desensitized on device in a cheap manner. Experimental results on mobile sensing and face datasets demonstrate that our models can successfully maintain the utility performances of predictive models while causing sensitive predictions to perform poorly.",2023,IEEE Transactions on Neural Networks and Learning Systems,,"{'month': 'June', 'issn': '2162-2388', 'doi': '10.1109/TNNLS.2021.3110831', 'keywords': 'Data privacy;Data models;Privacy;Predictive models;Kernel;Correlation;Training;Adversarial learning;data privacy;dimension reduction;Kernel methods;representation learning', 'abstract': 'The rapid rise of IoT and Big Data has facilitated copious data-driven applications to enhance our quality of life. However, the omnipresent and all-encompassing nature of the data collection can generate privacy concerns. Hence, there is a strong need to develop techniques that ensure the data serve only the intended purposes, giving users control over the information they share. To this end, this article studies new variants of supervised and adversarial learning methods, which remove the sensitive information in the data before they are sent out for a particular application. The explored methods optimize privacy-preserving feature mappings and predictive models simultaneously in an end-to-end fashion. Additionally, the models are built with an emphasis on placing little computational burden on the user side so that the data can be desensitized on device in a cheap manner. Experimental results on mobile sensing and face datasets demonstrate that our models can successfully maintain the utility performances of predictive models while causing sensitive predictions to perform poorly.', 'pages': '3019-3033', 'number': '6', 'volume': '34', 'year': '2023', 'title': 'Privacy Enhancing Machine Learning via Removal of Unwanted Dependencies', 'journal': 'IEEE Transactions on Neural Networks and Learning Systems', 'author': 'Al, Mert and Yagli, Semih and Kung, Sun-Yuan', 'ENTRYTYPE': 'article', 'ID': '9540030'}",IEEE Xplore
"Baranouskaya, Darya and Cavallaro, Andrea",Human-interpretable and deep features for image privacy classification,Deep learning;Privacy;Data privacy;Annotations;Decision making;Image representation;Task analysis,"Privacy is a complex, subjective and contextual concept that is difficult to define. Therefore, the annotation of images to train privacy classifiers is a challenging task. In this paper, we analyse privacy classification datasets and the properties of controversial images that are annotated with contrasting privacy labels by different assessors. We discuss suitable features for image privacy classification and propose eight privacy-specific and human-interpretable features. These features increase the performance of deep learning models and, on their own, improve the image representation for privacy classification compared with much higher dimensional deep features.",2023,2023 IEEE International Conference on Image Processing (ICIP),,"{'month': 'Oct', 'issn': '', 'doi': '10.1109/ICIP49359.2023.10222833', 'keywords': 'Deep learning;Privacy;Data privacy;Annotations;Decision making;Image representation;Task analysis', 'abstract': 'Privacy is a complex, subjective and contextual concept that is difficult to define. Therefore, the annotation of images to train privacy classifiers is a challenging task. In this paper, we analyse privacy classification datasets and the properties of controversial images that are annotated with contrasting privacy labels by different assessors. We discuss suitable features for image privacy classification and propose eight privacy-specific and human-interpretable features. These features increase the performance of deep learning models and, on their own, improve the image representation for privacy classification compared with much higher dimensional deep features.', 'pages': '3489-3492', 'number': '', 'volume': '', 'year': '2023', 'title': 'Human-interpretable and deep features for image privacy classification', 'booktitle': '2023 IEEE International Conference on Image Processing (ICIP)', 'author': 'Baranouskaya, Darya and Cavallaro, Andrea', 'ENTRYTYPE': 'inproceedings', 'ID': '10222833'}",IEEE Xplore
"Kozachok, Alexander V. and Kopylov, Sergey",Estimation of Watermark Embedding Capacity with Line Space Shifting,Analytical models;Data privacy;Simulation;Estimation;Watermarking;Robustness;Encoding;robust watermark;data loss prevention text document;mathematical modelling;approximation;least squares method,"The article describes an analytical model of the maximum achievable embedding capacity evaluation for robust watermark based on the approach to information embedding in text data by line space shifting. The developed model allows to boundary values assessment of information amount that may contain a watermark embedded into text data printed. In the developing process of an analytical model, the dependence of maximum achievable embedding capacity on the lines amount of a text document and the used watermark embedding parameters was established. The relationship between the parameters of a text document and the lines number per page of a text document is mathematically described. Mathematical calculations of the obtained expressions and the corresponding experimental researches are conducted. The evaluation of obtained simulation results correspondence to the parameters of texts printed on paper is implemented. The simulation results are analyzed and a linear dependence of the results is established. The obtained values are approximated and analytical expressions that allow one to quantify the maximum achievable embedding capacity of the developed robust watermark depending on the embedding parameters used are received. The degree of contradictions between the following parameters of robust watermarks: embedding capacity, extractability and robustness is estimated. The relationship between the maximum achievable embedding capacity and the accuracy of the extraction of the developed watermark is determined. Quantitative estimates of the influence of the size of the watermark on the final extraction accuracy of embedded information are given. The further research directions are determined.",2020,2020 Ivannikov Memorial Workshop (IVMEM),,"{'month': 'Sep.', 'issn': '', 'doi': '10.1109/IVMEM51402.2020.00011', 'keywords': 'Analytical models;Data privacy;Simulation;Estimation;Watermarking;Robustness;Encoding;robust watermark;data loss prevention text document;mathematical modelling;approximation;least squares method', 'abstract': 'The article describes an analytical model of the maximum achievable embedding capacity evaluation for robust watermark based on the approach to information embedding in text data by line space shifting. The developed model allows to boundary values assessment of information amount that may contain a watermark embedded into text data printed. In the developing process of an analytical model, the dependence of maximum achievable embedding capacity on the lines amount of a text document and the used watermark embedding parameters was established. The relationship between the parameters of a text document and the lines number per page of a text document is mathematically described. Mathematical calculations of the obtained expressions and the corresponding experimental researches are conducted. The evaluation of obtained simulation results correspondence to the parameters of texts printed on paper is implemented. The simulation results are analyzed and a linear dependence of the results is established. The obtained values are approximated and analytical expressions that allow one to quantify the maximum achievable embedding capacity of the developed robust watermark depending on the embedding parameters used are received. The degree of contradictions between the following parameters of robust watermarks: embedding capacity, extractability and robustness is estimated. The relationship between the maximum achievable embedding capacity and the accuracy of the extraction of the developed watermark is determined. Quantitative estimates of the influence of the size of the watermark on the final extraction accuracy of embedded information are given. The further research directions are determined.', 'pages': '29-34', 'number': '', 'volume': '', 'year': '2020', 'title': 'Estimation of Watermark Embedding Capacity with Line Space Shifting', 'booktitle': '2020 Ivannikov Memorial Workshop (IVMEM)', 'author': 'Kozachok, Alexander V. and Kopylov, Sergey', 'ENTRYTYPE': 'inproceedings', 'ID': '9357049'}",IEEE Xplore
"Klobucar, T.",Privacy and data protection in technology-enhanced professional learning,Data privacy;Protection;Electronic learning;Space technology;Employment;Information security;Management training;Educational institutions;Environmental management;Human resource management,"Privacy provision and data protection are basic requirements for professional learning, especially when personalized systems are used that adapt to sensitive learner personal data. In this paper we discuss important topics that need to be investigated before technology-enhanced professional learning is introduced in corporate settings. Although the paper is focused on privacy and personal data protection, specific issues such as digital rights management are also briefly described. As an example of introducing privacy-enhancing technologies into learning environments we give a Smart Space for Learning that has been developed in the context of the ELENA1 project. Future research issues related to privacy and data protection in professional learning, one of the topics of the PROLEARN network of excellence in professional learning, are presented as well.",2006,Advanced Int'l Conference on Telecommunications and Int'l Conference on Internet and Web Applications and Services (AICT-ICIW'06),,"{'month': 'Feb', 'issn': '', 'doi': '10.1109/AICT-ICIW.2006.151', 'keywords': 'Data privacy;Protection;Electronic learning;Space technology;Employment;Information security;Management training;Educational institutions;Environmental management;Human resource management', 'abstract': 'Privacy provision and data protection are basic requirements for professional learning, especially when personalized systems are used that adapt to sensitive learner personal data. In this paper we discuss important topics that need to be investigated before technology-enhanced professional learning is introduced in corporate settings. Although the paper is focused on privacy and personal data protection, specific issues such as digital rights management are also briefly described. As an example of introducing privacy-enhancing technologies into learning environments we give a Smart Space for Learning that has been developed in the context of the ELENA1 project. Future research issues related to privacy and data protection in professional learning, one of the topics of the PROLEARN network of excellence in professional learning, are presented as well.', 'pages': '14-14', 'number': '', 'volume': '', 'year': '2006', 'title': 'Privacy and data protection in technology-enhanced professional learning', 'booktitle': ""Advanced Int'l Conference on Telecommunications and Int'l Conference on Internet and Web Applications and Services (AICT-ICIW'06)"", 'author': 'Klobucar, T.', 'ENTRYTYPE': 'inproceedings', 'ID': '1602146'}",IEEE Xplore
"Alfaro, Luis Alfredo and Hanh Le, Thi My and Choi, Hyung Rim and Cho, Min Je and Kim, Chae Soo",A Framework for Tracking Reliable Data in the Cloud for Port Logistics,Security;Cloud computing;Logistics;Ports (Computers);Data models;Servers;Computational modeling;Accountability;Cloud Computing;Tracking System;Service Level Agreement;Access Control;Framework;Authentication;Real-Time,"The accountability of private data authority is the main issue that owners always concern and look for the good way to solve it, particularly in the cloud computing services era nowadays. On-demand service of cloud computing allows users to access the data anytime, anywhere from any sources but such access need to be in limitation. Cloud computing presents a level of risk because fundamental services are often outsourced to a Third Party Agreement or well known as Cloud Service Providers. In this paper, the authors provide literature review, present a layered framework for Tracking Reliable Data in the Cloud to control the data usage, others unauthorized access and make certain that the Service License Agreement which is signed between Cloud Service Providers and data owners is trespassing the rights or not.",2014,2014 IEEE Fourth International Conference on Big Data and Cloud Computing,,"{'month': 'Dec', 'issn': '', 'doi': '10.1109/BDCloud.2014.90', 'keywords': 'Security;Cloud computing;Logistics;Ports (Computers);Data models;Servers;Computational modeling;Accountability;Cloud Computing;Tracking System;Service Level Agreement;Access Control;Framework;Authentication;Real-Time', 'abstract': 'The accountability of private data authority is the main issue that owners always concern and look for the good way to solve it, particularly in the cloud computing services era nowadays. On-demand service of cloud computing allows users to access the data anytime, anywhere from any sources but such access need to be in limitation. Cloud computing presents a level of risk because fundamental services are often outsourced to a Third Party Agreement or well known as Cloud Service Providers. In this paper, the authors provide literature review, present a layered framework for Tracking Reliable Data in the Cloud to control the data usage, others unauthorized access and make certain that the Service License Agreement which is signed between Cloud Service Providers and data owners is trespassing the rights or not.', 'pages': '257-264', 'number': '', 'volume': '', 'year': '2014', 'title': 'A Framework for Tracking Reliable Data in the Cloud for Port Logistics', 'booktitle': '2014 IEEE Fourth International Conference on Big Data and Cloud Computing', 'author': 'Alfaro, Luis Alfredo and Hanh Le, Thi My and Choi, Hyung Rim and Cho, Min Je and Kim, Chae Soo', 'ENTRYTYPE': 'inproceedings', 'ID': '7034795'}",IEEE Xplore
"Hu, Yuchuan and Guo, Bin and Dai, Cheng and Zheng, Qin and Weng, Fangpeng and Li, Zhongwei",A Fine-grained Multi-label Privacy Detection Model for Unstructured Data Based on BERT Pre-training,Data privacy;Privacy;Correlation;Bit error rate;Information sharing;Training data;Feature extraction;privacy detection;BERT pretraining;multi-label classification;label correlation,"At present, a major bottleneck in the development of artificial intelligence is the difficulty of training data collection. Data holders are reluctant to share data because of concerns that sharing data may reveal private information. In order to solve this problem, this paper proposes a fine-grained multi-tag privacy detection model for unstructured data based on BERT pre-training. The model extracts the feature representation at the sentence level through BERT, and then allocates the weight to each sentence through the attention mechanism at the document level to obtain the feature representation of the document. Finally, combined with the calculation results of tag relevance based on GCN network, the result of multi-tag classification of unstructured text is obtained. This model achieves good results in the data set used in this paper.",2022,"2022 IEEE 24th Int Conf on High Performance Computing & Communications; 8th Int Conf on Data Science & Systems; 20th Int Conf on Smart City; 8th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)",,"{'month': 'Dec', 'issn': '', 'doi': '10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00126', 'keywords': 'Data privacy;Privacy;Correlation;Bit error rate;Information sharing;Training data;Feature extraction;privacy detection;BERT pretraining;multi-label classification;label correlation', 'abstract': 'At present, a major bottleneck in the development of artificial intelligence is the difficulty of training data collection. Data holders are reluctant to share data because of concerns that sharing data may reveal private information. In order to solve this problem, this paper proposes a fine-grained multi-tag privacy detection model for unstructured data based on BERT pre-training. The model extracts the feature representation at the sentence level through BERT, and then allocates the weight to each sentence through the attention mechanism at the document level to obtain the feature representation of the document. Finally, combined with the calculation results of tag relevance based on GCN network, the result of multi-tag classification of unstructured text is obtained. This model achieves good results in the data set used in this paper.', 'pages': '755-760', 'number': '', 'volume': '', 'year': '2022', 'title': 'A Fine-grained Multi-label Privacy Detection Model for Unstructured Data Based on BERT Pre-training', 'booktitle': '2022 IEEE 24th Int Conf on High Performance Computing & Communications; 8th Int Conf on Data Science & Systems; 20th Int Conf on Smart City; 8th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)', 'author': 'Hu, Yuchuan and Guo, Bin and Dai, Cheng and Zheng, Qin and Weng, Fangpeng and Li, Zhongwei', 'ENTRYTYPE': 'inproceedings', 'ID': '10074755'}",IEEE Xplore
"Rodriguez, David and Del Alamo, Jose M. and Fernández-Aller, Celia and Sadeh, Norman",Sharing is Not Always Caring: Delving Into Personal Data Transfer Compliance in Android Apps,Data privacy;Libraries;Data transfer;Privacy;Codes;Regulation;Ecosystems;Androids;Android;compliance assessment;data protection;data transfer;dynamic analysis;GDPR;large language model;personal data;privacy policy;third-party,"In an era marked by ubiquitous reliance on mobile applications for nearly every need, the opacity of apps’ behavior poses significant threats to their users’ privacy. Although major data protection regulations require apps to disclose their data practices transparently, previous studies have pointed out difficulties in doing so. To further delve into this issue, this article describes an automated method to capture data-sharing practices in Android apps and assess their proper disclosure according to the EU General Data Protection Regulation. We applied the method to 9,000 random Android apps, unveiling an uncomfortable reality: over 80% of Android applications that transfer personal data off device potentially fail to meet GDPR transparency requirements. We further investigate the role of third-party libraries, shedding light on the source of this problem and pointing towards measures to address it.",2024,IEEE Access,,"{'month': '', 'issn': '2169-3536', 'doi': '10.1109/ACCESS.2024.3349425', 'keywords': 'Data privacy;Libraries;Data transfer;Privacy;Codes;Regulation;Ecosystems;Androids;Android;compliance assessment;data protection;data transfer;dynamic analysis;GDPR;large language model;personal data;privacy policy;third-party', 'abstract': 'In an era marked by ubiquitous reliance on mobile applications for nearly every need, the opacity of apps’ behavior poses significant threats to their users’ privacy. Although major data protection regulations require apps to disclose their data practices transparently, previous studies have pointed out difficulties in doing so. To further delve into this issue, this article describes an automated method to capture data-sharing practices in Android apps and assess their proper disclosure according to the EU General Data Protection Regulation. We applied the method to 9,000 random Android apps, unveiling an uncomfortable reality: over 80% of Android applications that transfer personal data off device potentially fail to meet GDPR transparency requirements. We further investigate the role of third-party libraries, shedding light on the source of this problem and pointing towards measures to address it.', 'pages': '5256-5269', 'number': '', 'volume': '12', 'year': '2024', 'title': 'Sharing is Not Always Caring: Delving Into Personal Data Transfer Compliance in Android Apps', 'journal': 'IEEE Access', 'author': 'Rodriguez, David and Del Alamo, Jose M. and Fernández-Aller, Celia and Sadeh, Norman', 'ENTRYTYPE': 'article', 'ID': '10379677'}",IEEE Xplore
Ronglei Hu and Ping Zeng and Lei Ju and Wei Sun,The application scheme of dynamic data protection in SaaS based on DIFC,Data models;Writing;SaaS cloud;multi-tenant;decentralized information flow control;access control;data security,"Data security concerns are one of obstacles to adopt cloud computing on a large scale. Especially users cannot control the behavior of SaaS applications how to use their data in SaaS cloud. It is hard to verify whether the security protocols have been performed or not. In addition, the service model of single instance multi-tenant causes the threat of data leakage between tenants who share the same application instance. A universality dynamic data protection scheme in SaaS cloud services is proposed in the paper. This scheme focus on how to use decentralized information flow control (DIFC) model to prevent cloud programs revealing users' private data and stop the data leakage between tenants. A project application example is given, and its security is analyzed. The scheme has the advantage that the security policy can be set by the user independent. It can realize distributed authorization, and can be made of a small number of trusted codes to implement the strategy execution. This made the code monitoring easier.",2016,2016 2nd IEEE International Conference on Computer and Communications (ICCC),,"{'month': 'Oct', 'issn': '', 'doi': '10.1109/CompComm.2016.7924667', 'keywords': 'Data models;Writing;SaaS cloud;multi-tenant;decentralized information flow control;access control;data security', 'abstract': ""Data security concerns are one of obstacles to adopt cloud computing on a large scale. Especially users cannot control the behavior of SaaS applications how to use their data in SaaS cloud. It is hard to verify whether the security protocols have been performed or not. In addition, the service model of single instance multi-tenant causes the threat of data leakage between tenants who share the same application instance. A universality dynamic data protection scheme in SaaS cloud services is proposed in the paper. This scheme focus on how to use decentralized information flow control (DIFC) model to prevent cloud programs revealing users' private data and stop the data leakage between tenants. A project application example is given, and its security is analyzed. The scheme has the advantage that the security policy can be set by the user independent. It can realize distributed authorization, and can be made of a small number of trusted codes to implement the strategy execution. This made the code monitoring easier."", 'pages': '69-74', 'number': '', 'volume': '', 'year': '2016', 'title': 'The application scheme of dynamic data protection in SaaS based on DIFC', 'booktitle': '2016 2nd IEEE International Conference on Computer and Communications (ICCC)', 'author': 'Ronglei Hu and Ping Zeng and Lei Ju and Wei Sun', 'ENTRYTYPE': 'inproceedings', 'ID': '7924667'}",IEEE Xplore
"Abahmane, Omar and Logrippo, Luigi",Granularity based flow control,Access control;Noise;Availability;Permission;Computational modeling;Data models;Information flow;flow control;granularity;security models,"Many models, methods, techniques, and systems have been developed to preserve the integrity of data and guarantee an acceptable level of security over networks. Protection from illegitimate data access and control of information flow are two main goals. This paper presents new techniques that address two main issues: information protection at various levels of granularity and data flow control We first investigate challenges and limits of established access control models regarding flow control. We then introduce a new flow control model based on granularity, the GBFC. GBFC is capable of guaranteeing flow control under reasonable assumptions. In addition, it offers advantages such as adaptability, full control, reliability and compatibility amongst others. Essentially, in GBFC classified information at suitable levels of granularity is accessible through references and information flow control is applied on the references. We also introduce the concepts of views for information access and Noise Injection that represent building blocks for the Granularity Based Flow Control. With noise injection, a document can be transformed into different views to erase or replace protected information and this transformation can be made almost undetectable to the unauthorized reader. Therefore, inference can be made much more difficult with this method. The GBFC model is intended to complement, rather than replace, existing access control methods.",2014,"2014 Twelfth Annual International Conference on Privacy, Security and Trust",,"{'month': 'July', 'issn': '', 'doi': '10.1109/PST.2014.6890945', 'keywords': 'Access control;Noise;Availability;Permission;Computational modeling;Data models;Information flow;flow control;granularity;security models', 'abstract': 'Many models, methods, techniques, and systems have been developed to preserve the integrity of data and guarantee an acceptable level of security over networks. Protection from illegitimate data access and control of information flow are two main goals. This paper presents new techniques that address two main issues: information protection at various levels of granularity and data flow control We first investigate challenges and limits of established access control models regarding flow control. We then introduce a new flow control model based on granularity, the GBFC. GBFC is capable of guaranteeing flow control under reasonable assumptions. In addition, it offers advantages such as adaptability, full control, reliability and compatibility amongst others. Essentially, in GBFC classified information at suitable levels of granularity is accessible through references and information flow control is applied on the references. We also introduce the concepts of views for information access and Noise Injection that represent building blocks for the Granularity Based Flow Control. With noise injection, a document can be transformed into different views to erase or replace protected information and this transformation can be made almost undetectable to the unauthorized reader. Therefore, inference can be made much more difficult with this method. The GBFC model is intended to complement, rather than replace, existing access control methods.', 'pages': '239-248', 'number': '', 'volume': '', 'year': '2014', 'title': 'Granularity based flow control', 'booktitle': '2014 Twelfth Annual International Conference on Privacy, Security and Trust', 'author': 'Abahmane, Omar and Logrippo, Luigi', 'ENTRYTYPE': 'inproceedings', 'ID': '6890945'}",IEEE Xplore
"Jain, Vijayanta and Ghanavati, Sepideh and Peddinti, Sai Teja and McMillan, Collin",Towards Fine-Grained Localization of Privacy Behaviors,Location awareness;Privacy;Statistical analysis;Source coding;Software;Behavioral sciences;Faces;privacy labels;privacy-behavior;Android applications;machine learning,"Privacy labels help developers communicate their application’s privacy behaviors (i.e., how and why an application uses personal information) to users. But, studies show that developers face several challenges in creating them and the resultant labels are often inconsistent with their application’s privacy behaviors. In this paper, we create a novel methodology called fine-grained localization of privacy behaviors to locate individual statements in source code which encode privacy behaviors and predict their privacy labels. We design and develop an attention-based multi-head encoder model which creates individual representations of multiple methods and uses attention to identify relevant statements that implement privacy behaviors. These statements are then used to predict privacy labels for the application’s source code and can help developers write privacy statements that can be used as notices. Our quantitative analysis shows that our approach can achieve high accuracy in identifying privacy labels, with the lowest accuracy of 91.41% and the highest of 98.45%. We also evaluate the efficacy of our approach with six software professionals from our university. The results demonstrate that our approach reduces the time and mental effort required by developers to create high-quality privacy statements and can finely localize statements in methods that implement privacy behaviors.",2023,2023 IEEE 8th European Symposium on Security and Privacy (EuroS&P),,"{'month': 'July', 'issn': '', 'doi': '10.1109/EuroSP57164.2023.00024', 'keywords': 'Location awareness;Privacy;Statistical analysis;Source coding;Software;Behavioral sciences;Faces;privacy labels;privacy-behavior;Android applications;machine learning', 'abstract': 'Privacy labels help developers communicate their application’s privacy behaviors (i.e., how and why an application uses personal information) to users. But, studies show that developers face several challenges in creating them and the resultant labels are often inconsistent with their application’s privacy behaviors. In this paper, we create a novel methodology called fine-grained localization of privacy behaviors to locate individual statements in source code which encode privacy behaviors and predict their privacy labels. We design and develop an attention-based multi-head encoder model which creates individual representations of multiple methods and uses attention to identify relevant statements that implement privacy behaviors. These statements are then used to predict privacy labels for the application’s source code and can help developers write privacy statements that can be used as notices. Our quantitative analysis shows that our approach can achieve high accuracy in identifying privacy labels, with the lowest accuracy of 91.41% and the highest of 98.45%. We also evaluate the efficacy of our approach with six software professionals from our university. The results demonstrate that our approach reduces the time and mental effort required by developers to create high-quality privacy statements and can finely localize statements in methods that implement privacy behaviors.', 'pages': '258-277', 'number': '', 'volume': '', 'year': '2023', 'title': 'Towards Fine-Grained Localization of Privacy Behaviors', 'booktitle': '2023 IEEE 8th European Symposium on Security and Privacy (EuroS&P)', 'author': 'Jain, Vijayanta and Ghanavati, Sepideh and Peddinti, Sai Teja and McMillan, Collin', 'ENTRYTYPE': 'inproceedings', 'ID': '10190504'}",IEEE Xplore
"Chai, Di and Wang, Leye and Yang, Liu and Zhang, Junxue and Chen, Kai and Yang, Qiang",A Survey for Federated Learning Evaluations: Goals and Measures,Data models;Surveys;Security;Training;Data privacy;Computational modeling;Privacy;Efficiency;evaluation;introduction and survey;performance measures;security and privacy protection,"Evaluation is a systematic approach to assessing how well a system achieves its intended purpose. Federated learning (FL) is a novel paradigm for privacy-preserving machine learning that allows multiple parties to collaboratively train models without sharing sensitive data. However, evaluating FL is challenging due to its interdisciplinary nature and diverse goals, such as utility, efficiency, and security. In this survey, we first review the major evaluation goals adopted in the existing studies and then explore the evaluation metrics used for each goal. We also introduce FedEval, an open-source platform that provides a standardized and comprehensive evaluation framework for FL algorithms in terms of their utility, efficiency, and security. Finally, we discuss several challenges and future research directions for FL evaluation.",2024,IEEE Transactions on Knowledge and Data Engineering,,"{'month': '', 'issn': '1558-2191', 'doi': '10.1109/TKDE.2024.3382002', 'keywords': 'Data models;Surveys;Security;Training;Data privacy;Computational modeling;Privacy;Efficiency;evaluation;introduction and survey;performance measures;security and privacy protection', 'abstract': 'Evaluation is a systematic approach to assessing how well a system achieves its intended purpose. Federated learning (FL) is a novel paradigm for privacy-preserving machine learning that allows multiple parties to collaboratively train models without sharing sensitive data. However, evaluating FL is challenging due to its interdisciplinary nature and diverse goals, such as utility, efficiency, and security. In this survey, we first review the major evaluation goals adopted in the existing studies and then explore the evaluation metrics used for each goal. We also introduce FedEval, an open-source platform that provides a standardized and comprehensive evaluation framework for FL algorithms in terms of their utility, efficiency, and security. Finally, we discuss several challenges and future research directions for FL evaluation.', 'pages': '1-20', 'number': '', 'volume': '', 'year': '2024', 'title': 'A Survey for Federated Learning Evaluations: Goals and Measures', 'journal': 'IEEE Transactions on Knowledge and Data Engineering', 'author': 'Chai, Di and Wang, Leye and Yang, Liu and Zhang, Junxue and Chen, Kai and Yang, Qiang', 'ENTRYTYPE': 'article', 'ID': '10480259'}",IEEE Xplore
"Yin, Lihua and Wang, Simin and Sun, Zhe and Yang, Zhi and Zou, Yufu and Wei, Nan and He, Yuanyuan",Conditional GAN-Based Gradient Recovery Attack for Differentially Private Deep Image Processing,Deep learning;Differential privacy;Privacy;Image processing;Training data;Rendering (computer graphics);Data models,"It has been demonstrated that gradients of deep learning models, especially image processing models, can be exploited to memorize sensitive information from training data, rendering them vulnerable to gradient inversion attacks. Differential privacy, a provably secure privacy-preserving technique, has been widely adopted to protect gradients of deep learning models. In this paper, we propose a gradient recovery attack against differential privacy-preserving models. Adversaries can gather a small set of differential privacy perturbed and original gradients and leverage a cGAN network to train a gradient recovery model, which can recover the perturbed gradient to an approximately original state. Subsequently, the recovered gradient can be targeted by gradient inversion attacks, leading to further privacy leakage from the training data. Our experiments demonstrate that the proposed gradient recovery attack achieves promising results when using commonly used differential privacy budgets (from 1 to 7). When the privacy budget is 7, the recovered gradient and the original gradient have a similarity of 94-99% in gradient inversion attack.",2023,2023 IEEE Smart World Congress (SWC),,"{'month': 'Aug', 'issn': '', 'doi': '10.1109/SWC57546.2023.10449056', 'keywords': 'Deep learning;Differential privacy;Privacy;Image processing;Training data;Rendering (computer graphics);Data models', 'abstract': 'It has been demonstrated that gradients of deep learning models, especially image processing models, can be exploited to memorize sensitive information from training data, rendering them vulnerable to gradient inversion attacks. Differential privacy, a provably secure privacy-preserving technique, has been widely adopted to protect gradients of deep learning models. In this paper, we propose a gradient recovery attack against differential privacy-preserving models. Adversaries can gather a small set of differential privacy perturbed and original gradients and leverage a cGAN network to train a gradient recovery model, which can recover the perturbed gradient to an approximately original state. Subsequently, the recovered gradient can be targeted by gradient inversion attacks, leading to further privacy leakage from the training data. Our experiments demonstrate that the proposed gradient recovery attack achieves promising results when using commonly used differential privacy budgets (from 1 to 7). When the privacy budget is 7, the recovered gradient and the original gradient have a similarity of 94-99% in gradient inversion attack.', 'pages': '1-8', 'number': '', 'volume': '', 'year': '2023', 'title': 'Conditional GAN-Based Gradient Recovery Attack for Differentially Private Deep Image Processing', 'booktitle': '2023 IEEE Smart World Congress (SWC)', 'author': 'Yin, Lihua and Wang, Simin and Sun, Zhe and Yang, Zhi and Zou, Yufu and Wei, Nan and He, Yuanyuan', 'ENTRYTYPE': 'inproceedings', 'ID': '10449056'}",IEEE Xplore
"Schuler, Douglas and Day, Peter",Information Technology and the International Public Sphere,,"This chapter contains sections titled: Globalization, Networks and Knowledge, The Idea of the Public Sphere, Conclusion, Notes",2003,Shaping the Network Society: The New Role of Civil Society in Cyberspace,,"{'url': 'https://ieeexplore.ieee.org/document/6274920', 'isbn': '9780262283250', 'publisher': 'MIT Press', 'issn': '', 'doi': '', 'keywords': '', 'abstract': 'This chapter contains sections titled: Globalization, Networks and Knowledge, The Idea of the Public Sphere, Conclusion, Notes', 'pages': '229-251', 'number': '', 'volume': '', 'year': '2003', 'title': 'Information Technology and the International Public Sphere', 'booktitle': 'Shaping the Network Society: The New Role of Civil Society in Cyberspace', 'author': 'Schuler, Douglas and Day, Peter', 'ENTRYTYPE': 'inbook', 'ID': '6274920'}",IEEE Xplore
"Sun, Jingwei and Xu, Ziyue and Yang, Dong and Nath, Vishwesh and Li, Wenqi and Zhao, Can and Xu, Daguang and Chen, Yiran and Roth, Holger R.",Communication-Efficient Vertical Federated Learning with Limited Overlapping Samples,Computer vision;Costs;Codes;Federated learning;Semisupervised learning;Data models;Servers,"Federated learning is a popular collaborative learning approach that enables clients to train a global model without sharing their local data. Vertical federated learning (VFL) deals with scenarios in which the data on clients have different feature spaces but share some overlapping samples. Existing VFL approaches suffer from high communication costs and cannot deal efficiently with limited overlapping samples commonly seen in the real world. We propose a practical VFL framework called one-shot VFL that can solve the communication bottleneck and the problem of limited overlapping samples simultaneously based on semi-supervised learning. We also propose few-shot VFL to improve the accuracy further with just one more communication round between the server and the clients. In our proposed framework, the clients only need to communicate with the server once or only a few times. We evaluate the proposed VFL framework on both image and tabular datasets. Our methods can improve the accuracy by more than 46.5% and reduce the communication cost by more than 330× compared with state-of-the-art VFL methods when evaluated on CIFAR-10. Our code is available at https://nvidia.github.io/NVFlare/research/one-shot-vfl.",2023,2023 IEEE/CVF International Conference on Computer Vision (ICCV),,"{'month': 'Oct', 'issn': '2380-7504', 'doi': '10.1109/ICCV51070.2023.00480', 'keywords': 'Computer vision;Costs;Codes;Federated learning;Semisupervised learning;Data models;Servers', 'abstract': 'Federated learning is a popular collaborative learning approach that enables clients to train a global model without sharing their local data. Vertical federated learning (VFL) deals with scenarios in which the data on clients have different feature spaces but share some overlapping samples. Existing VFL approaches suffer from high communication costs and cannot deal efficiently with limited overlapping samples commonly seen in the real world. We propose a practical VFL framework called one-shot VFL that can solve the communication bottleneck and the problem of limited overlapping samples simultaneously based on semi-supervised learning. We also propose few-shot VFL to improve the accuracy further with just one more communication round between the server and the clients. In our proposed framework, the clients only need to communicate with the server once or only a few times. We evaluate the proposed VFL framework on both image and tabular datasets. Our methods can improve the accuracy by more than 46.5% and reduce the communication cost by more than 330× compared with state-of-the-art VFL methods when evaluated on CIFAR-10. Our code is available at https://nvidia.github.io/NVFlare/research/one-shot-vfl.', 'pages': '5180-5189', 'number': '', 'volume': '', 'year': '2023', 'title': 'Communication-Efficient Vertical Federated Learning with Limited Overlapping Samples', 'booktitle': '2023 IEEE/CVF International Conference on Computer Vision (ICCV)', 'author': 'Sun, Jingwei and Xu, Ziyue and Yang, Dong and Nath, Vishwesh and Li, Wenqi and Zhao, Can and Xu, Daguang and Chen, Yiran and Roth, Holger R.', 'ENTRYTYPE': 'inproceedings', 'ID': '10377189'}",IEEE Xplore
"Gupta, Sanonda Datta",Developing A Privacy Risk Analysis Framework for Heterogeneous IoT Network,Privacy;Data privacy;User interfaces;Regulation;Real-time systems;Internet of Things;Risk analysis;IoT;Privacy Requirements;Inconsistency Analysis;Privacy Notice,"The Internet of Things (IoT) collects a massive amount of data that raises several privacy concerns, such as inconsistency between an IoT device’s requirements and its privacy policy or non-compliance with different privacy regulations. Additionally, due to IoT devices’ inadequate user interface, providing a detailed and real-time notification is one of the significant privacy challenges in the IoT. To address these challenges, this thesis proposes a privacy risk analysis framework called Protected Heterogeneous IoT Network (PHIN). PHIN has the following two goals. First, it aims at identifying privacy risks from four perspectives: i) magnitude of the inconsistency between an IoT device and its privacy policy, ii) inference risk of PII, iii) non-compliance with multiple privacy regulations, and iv) incompatibility between users’ privacy preferences and the device’s default privacy settings. Second, PHIN provides users with a detailed two-layered privacy risk report associated with installing a new IoT device. The thesis aims to evaluate the framework by assessing its functionalities in a real heterogeneous IoT network as well as conducting several user studies.",2022,2022 IEEE 30th International Requirements Engineering Conference (RE),,"{'month': 'Aug', 'issn': '2332-6441', 'doi': '10.1109/RE54965.2022.00025', 'keywords': 'Privacy;Data privacy;User interfaces;Regulation;Real-time systems;Internet of Things;Risk analysis;IoT;Privacy Requirements;Inconsistency Analysis;Privacy Notice', 'abstract': 'The Internet of Things (IoT) collects a massive amount of data that raises several privacy concerns, such as inconsistency between an IoT device’s requirements and its privacy policy or non-compliance with different privacy regulations. Additionally, due to IoT devices’ inadequate user interface, providing a detailed and real-time notification is one of the significant privacy challenges in the IoT. To address these challenges, this thesis proposes a privacy risk analysis framework called Protected Heterogeneous IoT Network (PHIN). PHIN has the following two goals. First, it aims at identifying privacy risks from four perspectives: i) magnitude of the inconsistency between an IoT device and its privacy policy, ii) inference risk of PII, iii) non-compliance with multiple privacy regulations, and iv) incompatibility between users’ privacy preferences and the device’s default privacy settings. Second, PHIN provides users with a detailed two-layered privacy risk report associated with installing a new IoT device. The thesis aims to evaluate the framework by assessing its functionalities in a real heterogeneous IoT network as well as conducting several user studies.', 'pages': '207-212', 'number': '', 'volume': '', 'year': '2022', 'title': 'Developing A Privacy Risk Analysis Framework for Heterogeneous IoT Network', 'booktitle': '2022 IEEE 30th International Requirements Engineering Conference (RE)', 'author': 'Gupta, Sanonda Datta', 'ENTRYTYPE': 'inproceedings', 'ID': '9920026'}",IEEE Xplore
"Benzel, Terry and Holz, Thorsten",Selected Papers From the 2021 IEEE Symposium on Security and Privacy,,"In an effort to bring a portion of symposia to a broader audience, the IEEE Security & Privacy editorial board dedicates special issues to present selected papers. The contributions in this issue are from the IEEE Symposium on Security and Privacy. Since 1980, this event has been the premier forum for presenting developments in computer security and electronic privacy as well as bringing together researchers and practitioners in the field.",2022,IEEE Security & Privacy,,"{'month': 'March', 'issn': '1558-4046', 'doi': '10.1109/MSEC.2022.3142463', 'keywords': '', 'abstract': 'In an effort to bring a portion of symposia to a broader audience, the IEEE Security & Privacy editorial board dedicates special issues to present selected papers. The contributions in this issue are from the IEEE Symposium on Security and Privacy. Since 1980, this event has been the premier forum for presenting developments in computer security and electronic privacy as well as bringing together researchers and practitioners in the field.', 'pages': '8-9', 'number': '2', 'volume': '20', 'year': '2022', 'title': 'Selected Papers From the 2021 IEEE Symposium on Security and Privacy', 'journal': 'IEEE Security & Privacy', 'author': 'Benzel, Terry and Holz, Thorsten', 'ENTRYTYPE': 'article', 'ID': '9740706'}",IEEE Xplore
,Computer Highlights Society Magazines,,"The IEEE Computer Society’s lineup of 12 peer-reviewed technical magazines covers cutting-edge topics ranging from software design and computer graphics to Internet computing and security, from scientific applications and machine intelligence to visualization and microchip design. Here are highlights from recent issues.",2022,Computer,,"{'month': 'Sep.', 'issn': '1558-0814', 'doi': '10.1109/MC.2022.3169575', 'keywords': '', 'abstract': 'The IEEE Computer Society’s lineup of 12 peer-reviewed technical magazines covers cutting-edge topics ranging from software design and computer graphics to Internet computing and security, from scientific applications and machine intelligence to visualization and microchip design. Here are highlights from recent issues.', 'pages': '6-8', 'number': '9', 'volume': '55', 'year': '2022', 'title': 'Computer Highlights Society Magazines', 'journal': 'Computer', 'author': '', 'ENTRYTYPE': 'article', 'ID': '9869600'}",IEEE Xplore
Taki Eddine Toufik Djaidja and Bouziane Brik and Abdelwahab Boualouache and Sidi Mohammed Senouci and Yacine Ghamri-Doudane,"Federated learning for 5G and beyond, a blessing and a curse- an experimental study on intrusion detection systems","Federated learning, Deep learning, IDS, NON-IID, 5G and beyond","5G's service providers now leverage Deep Learning (DL) to automate their network slice management, provisioning, and security. To this end, each slice owner contributes data to feed a common dataset used to train centralized learning models. However, this method raises privacy considerations that prevent its usage. Therefore, Federated learning (FL), a collaborative approach that ensures data privacy, is being investigated while striving toward the same performance as centralized learning. As 5G and beyond services are so diverse, the local slice's data is not intended to reflect the entire data distribution. Thus, local data of slices are Non-Independently and non-Identically distributed (Non-IID), posing a challenge for FL-based models. In this paper, we investigate the use of FL to secure network slices and detect potential attacks. For that purpose, we first propose an architecture for deploying intrusion detection systems (IDSs) in 5G and beyond networks. Next, we thoroughly evaluate the latest state-of-art FL algorithms, including FedAvg, FedProx, FedPer, and SCAFFOLD, in the context of Independently and Identically Distributed (IID) and Non-IID data distributions. We compare these FL models to centralized and local DL models. We find that SCAFFOLD outperforms all the other FL algorithms and ensures a stable learning loss convergence, a promising finding that strengthens the case for leveraging FL in IDS development. Nevertheless, none of the FL models could achieve the centralized model's performance in Non-IID scenarios.",2024,Computers & Security,https://www.sciencedirect.com/science/article/pii/S0167404824000087,"{'abstract': ""5G's service providers now leverage Deep Learning (DL) to automate their network slice management, provisioning, and security. To this end, each slice owner contributes data to feed a common dataset used to train centralized learning models. However, this method raises privacy considerations that prevent its usage. Therefore, Federated learning (FL), a collaborative approach that ensures data privacy, is being investigated while striving toward the same performance as centralized learning. As 5G and beyond services are so diverse, the local slice's data is not intended to reflect the entire data distribution. Thus, local data of slices are Non-Independently and non-Identically distributed (Non-IID), posing a challenge for FL-based models. In this paper, we investigate the use of FL to secure network slices and detect potential attacks. For that purpose, we first propose an architecture for deploying intrusion detection systems (IDSs) in 5G and beyond networks. Next, we thoroughly evaluate the latest state-of-art FL algorithms, including FedAvg, FedProx, FedPer, and SCAFFOLD, in the context of Independently and Identically Distributed (IID) and Non-IID data distributions. We compare these FL models to centralized and local DL models. We find that SCAFFOLD outperforms all the other FL algorithms and ensures a stable learning loss convergence, a promising finding that strengthens the case for leveraging FL in IDS development. Nevertheless, none of the FL models could achieve the centralized model's performance in Non-IID scenarios."", 'keywords': 'Federated learning, Deep learning, IDS, NON-IID, 5G and beyond', 'author': 'Taki Eddine Toufik Djaidja and Bouziane Brik and Abdelwahab Boualouache and Sidi Mohammed Senouci and Yacine Ghamri-Doudane', 'url': 'https://www.sciencedirect.com/science/article/pii/S0167404824000087', 'doi': 'https://doi.org/10.1016/j.cose.2024.103707', 'issn': '0167-4048', 'year': '2024', 'pages': '103707', 'volume': '139', 'journal': 'Computers & Security', 'title': 'Federated learning for 5G and beyond, a blessing and a curse- an experimental study on intrusion detection systems', 'ENTRYTYPE': 'article', 'ID': 'DJAIDJA2024103707'}",ScienceDirect
Nineta Polemi,Chapter 6 - Conclusions and the Way Forward,"Maritime cloud, Ports critical information infrastructures, Supply chain services","This chapter captures the main research results from the European Projects—CYSM, MEDUSA, and MITIGATE—on risk assessment methodologies for ports' infrastructures and their supply chains.",2018,Port Cybersecurity,https://www.sciencedirect.com/science/article/pii/B978012811818400006X,"{'abstract': ""This chapter captures the main research results from the European Projects—CYSM, MEDUSA, and MITIGATE—on risk assessment methodologies for ports' infrastructures and their supply chains."", 'keywords': 'Maritime cloud, Ports critical information infrastructures, Supply chain services', 'author': 'Nineta Polemi', 'url': 'https://www.sciencedirect.com/science/article/pii/B978012811818400006X', 'doi': 'https://doi.org/10.1016/B978-0-12-811818-4.00006-X', 'isbn': '978-0-12-811818-4', 'year': '2018', 'pages': '125-134', 'publisher': 'Elsevier', 'booktitle': 'Port Cybersecurity', 'editor': 'Nineta Polemi', 'title': 'Chapter 6 - Conclusions and the Way Forward', 'ENTRYTYPE': 'incollection', 'ID': 'POLEMI2018125'}",ScienceDirect
Xiao Chen and Thomas Navidi and Ram Rajagopal,Energy resource control via privacy preserving data,"Smart meter, Privacy, Optimization, Battery storage","Although the frequent monitoring of smart meters enables granular control over energy resources, it also increases the risk of leakage of private information such as income, home occupancy, and power consumption behavior that can be inferred from the data by an adversary. We propose a method of releasing modified smart meter data so specific private attributes are obscured while the utility of the data for use in an energy resource controller is preserved. The method privatizes data by injecting noise conditioned on the private attribute through a linear filter learned via a minimax optimization. The optimization contains the loss function of a classifier for the private attribute, which we maximize, and the energy resource controller’s objective formulated as a canonical form optimization, which we minimize. We perform our experiment on an aggregated dataset of household consumption with solar generation and another from the Commission for Energy Regulation (CER) that contains household smart meter data with sensitive attributes such as income and home occupancy. We demonstrate on the CER data that our method is able to reduce the ability of an adversary to classify a binary income label to that of random guessing while maintaining an objective value for an energy storage controller within 10% of optimal.",2020,Electric Power Systems Research,https://www.sciencedirect.com/science/article/pii/S0378779620305228,"{'abstract': 'Although the frequent monitoring of smart meters enables granular control over energy resources, it also increases the risk of leakage of private information such as income, home occupancy, and power consumption behavior that can be inferred from the data by an adversary. We propose a method of releasing modified smart meter data so specific private attributes are obscured while the utility of the data for use in an energy resource controller is preserved. The method privatizes data by injecting noise conditioned on the private attribute through a linear filter learned via a minimax optimization. The optimization contains the loss function of a classifier for the private attribute, which we maximize, and the energy resource controller’s objective formulated as a canonical form optimization, which we minimize. We perform our experiment on an aggregated dataset of household consumption with solar generation and another from the Commission for Energy Regulation (CER) that contains household smart meter data with sensitive attributes such as income and home occupancy. We demonstrate on the CER data that our method is able to reduce the ability of an adversary to classify a binary income label to that of random guessing while maintaining an objective value for an energy storage controller within 10% of optimal.', 'keywords': 'Smart meter, Privacy, Optimization, Battery storage', 'author': 'Xiao Chen and Thomas Navidi and Ram Rajagopal', 'url': 'https://www.sciencedirect.com/science/article/pii/S0378779620305228', 'doi': 'https://doi.org/10.1016/j.epsr.2020.106719', 'issn': '0378-7796', 'year': '2020', 'pages': '106719', 'volume': '189', 'journal': 'Electric Power Systems Research', 'title': 'Energy resource control via privacy preserving data', 'ENTRYTYPE': 'article', 'ID': 'CHEN2020106719'}",ScienceDirect
Jan {De Clercq} and Guido Grillenmeier,7 - IIS Authentication,,"Publisher Summary
The chapter focuses on the authentication methods supported in Internet Information Services (IIS) 6.0. It explores some radical changes that Microsoft has made to its Web server in Windows Server 2003 and their impact on the overall security quality of the IIS Web server. Windows Server 2003 is Microsoft's first enterprise operating system (OS) that carries the label “secure by default.” But Internet Information Services (IIS) is now an optional service and is not installed by default on a Windows Server 2003 installation. In a Windows Server 2003 domain, administrators can even prevent the installation of IIS 6.0 using the GPO setting “Prevent IIS installation” that is located in the Computer Configuration\Administrative Templates\Windows Components Internet Information Server GPO container. Perhaps the most fundamental change that makes IIS 6.0 more secure by default is its brand-new architecture. The key characteristic of this architecture is isolation. IIS 6.0 supports an operation mode that is known as worker process isolation mode (WPIM), which enables different Web sites and their worker processes) that are running on the same physical server to operate completely independent of one another. The chapter details the three HTTP authentication processes that are supported by Microsoft's Web server: basic and digest authentication and certificate-based authentication based on the secure sockets layer (SSL) and transport layer security (TLS) protocols. This explanation also includes the implication of Kerberos and NTLM protocols into the IIS authentication exchange and configuration; and the passport- based authentication.",2007,Microsoft Windows Security Fundamentals,https://www.sciencedirect.com/science/article/pii/B9781555583408500113,"{'abstract': ""Publisher Summary\nThe chapter focuses on the authentication methods supported in Internet Information Services (IIS) 6.0. It explores some radical changes that Microsoft has made to its Web server in Windows Server 2003 and their impact on the overall security quality of the IIS Web server. Windows Server 2003 is Microsoft's first enterprise operating system (OS) that carries the label “secure by default.” But Internet Information Services (IIS) is now an optional service and is not installed by default on a Windows Server 2003 installation. In a Windows Server 2003 domain, administrators can even prevent the installation of IIS 6.0 using the GPO setting “Prevent IIS installation” that is located in the Computer Configuration\\Administrative Templates\\Windows Components Internet Information Server GPO container. Perhaps the most fundamental change that makes IIS 6.0 more secure by default is its brand-new architecture. The key characteristic of this architecture is isolation. IIS 6.0 supports an operation mode that is known as worker process isolation mode (WPIM), which enables different Web sites and their worker processes) that are running on the same physical server to operate completely independent of one another. The chapter details the three HTTP authentication processes that are supported by Microsoft's Web server: basic and digest authentication and certificate-based authentication based on the secure sockets layer (SSL) and transport layer security (TLS) protocols. This explanation also includes the implication of Kerberos and NTLM protocols into the IIS authentication exchange and configuration; and the passport- based authentication."", 'author': 'Jan {De Clercq} and Guido Grillenmeier', 'url': 'https://www.sciencedirect.com/science/article/pii/B9781555583408500113', 'doi': 'https://doi.org/10.1016/B978-155558340-8/50011-3', 'isbn': '978-1-55558-340-8', 'year': '2007', 'pages': '409-476', 'address': 'Burlington', 'publisher': 'Digital Press', 'booktitle': 'Microsoft Windows Security Fundamentals', 'editor': 'Jan {De Clercq} and Guido Grillenmeier', 'title': '7 - IIS Authentication', 'ENTRYTYPE': 'incollection', 'ID': 'DECLERCQ2007409'}",ScienceDirect
Guang Yang and Juan Cao and Zhineng Chen and Junbo Guo and Jintao Li,Graph-based neural networks for explainable image privacy inference,"Image privacy protection, Graph neural networks, Image classification","With the development of social media and smartphones, people share their daily lives via a large number of images, but the convince also raises a problem of privacy leakage. Therefore, effective methods are needed to infer the privacy risk of images and identify images that may disclose privacy. Several works have tried to solve this problem with deep learning models. However, we know little about how the models infer the privacy label of an image, thus it is not easy to understand why the image may disclose privacy. Inspired by recent research on graph neural networks, we introduce prior knowledge to the deep models to make the inference more explainable. We propose the Graph-based neural networks for Image Privacy (GIP) to infer the privacy risk of images. The GIP mainly focuses on objects in an image, and the knowledge graph is extracted from the objects in the dataset without reliance on extra knowledge. Experimental results show that the GIP achieves higher performance compared with the object-based methods and comparable performance even compared with the multi-modal fusion method. The results show that the introduction of the knowledge graph not only makes the deep model more explainable but also makes better use of the information of objects provided by the images. Combing the knowledge graph with deep learning is a promising way to help protect image privacy that is worth exploring.",2020,Pattern Recognition,https://www.sciencedirect.com/science/article/pii/S0031320320301631,"{'abstract': 'With the development of social media and smartphones, people share their daily lives via a large number of images, but the convince also raises a problem of privacy leakage. Therefore, effective methods are needed to infer the privacy risk of images and identify images that may disclose privacy. Several works have tried to solve this problem with deep learning models. However, we know little about how the models infer the privacy label of an image, thus it is not easy to understand why the image may disclose privacy. Inspired by recent research on graph neural networks, we introduce prior knowledge to the deep models to make the inference more explainable. We propose the Graph-based neural networks for Image Privacy (GIP) to infer the privacy risk of images. The GIP mainly focuses on objects in an image, and the knowledge graph is extracted from the objects in the dataset without reliance on extra knowledge. Experimental results show that the GIP achieves higher performance compared with the object-based methods and comparable performance even compared with the multi-modal fusion method. The results show that the introduction of the knowledge graph not only makes the deep model more explainable but also makes better use of the information of objects provided by the images. Combing the knowledge graph with deep learning is a promising way to help protect image privacy that is worth exploring.', 'keywords': 'Image privacy protection, Graph neural networks, Image classification', 'author': 'Guang Yang and Juan Cao and Zhineng Chen and Junbo Guo and Jintao Li', 'url': 'https://www.sciencedirect.com/science/article/pii/S0031320320301631', 'doi': 'https://doi.org/10.1016/j.patcog.2020.107360', 'issn': '0031-3203', 'year': '2020', 'pages': '107360', 'volume': '105', 'journal': 'Pattern Recognition', 'title': 'Graph-based neural networks for explainable image privacy inference', 'ENTRYTYPE': 'article', 'ID': 'YANG2020107360'}",ScienceDirect
Sonal Allana and Shailey Chawla,ChildShield: A rating system for assessing privacy and security of internet of toys,"Internet of Toys (IoToys), Smart toys, Privacy, Security, Consumer awareness, IoT, Label","The wave of IoT has spread across the toy market providing designers opportunities for bringing innovation into children’s play in the form of toys that can adapt, connect and communicate referred to as Internet of Toys (IoToys). Research and media reports have underscored the potential misuse by threat actors for surveillance, theft of children’s personal information, opening a covert channel of communication with children and influencing their thoughts and actions. Currently there is a lack of standard labelling system for internet safety of toys that makes it difficult for parents to make the right choice while purchasing. Consumer awareness is critical in this area because of the vulnerability of children, who are the ultimate users. This research identifies the factors affecting privacy and security of IoToys and proposes a methodology for evaluation of toys based on these factors. ChildShield, a privacy and security label, has been recommended as a communication tool between toy manufacturers and consumers.",2021,Telematics and Informatics,https://www.sciencedirect.com/science/article/pii/S0736585320301362,"{'abstract': 'The wave of IoT has spread across the toy market providing designers opportunities for bringing innovation into children’s play in the form of toys that can adapt, connect and communicate referred to as Internet of Toys (IoToys). Research and media reports have underscored the potential misuse by threat actors for surveillance, theft of children’s personal information, opening a covert channel of communication with children and influencing their thoughts and actions. Currently there is a lack of standard labelling system for internet safety of toys that makes it difficult for parents to make the right choice while purchasing. Consumer awareness is critical in this area because of the vulnerability of children, who are the ultimate users. This research identifies the factors affecting privacy and security of IoToys and proposes a methodology for evaluation of toys based on these factors. ChildShield, a privacy and security label, has been recommended as a communication tool between toy manufacturers and consumers.', 'keywords': 'Internet of Toys (IoToys), Smart toys, Privacy, Security, Consumer awareness, IoT, Label', 'author': 'Sonal Allana and Shailey Chawla', 'url': 'https://www.sciencedirect.com/science/article/pii/S0736585320301362', 'doi': 'https://doi.org/10.1016/j.tele.2020.101477', 'issn': '0736-5853', 'year': '2021', 'pages': '101477', 'volume': '56', 'journal': 'Telematics and Informatics', 'title': 'ChildShield: A rating system for assessing privacy and security of internet of toys', 'ENTRYTYPE': 'article', 'ID': 'ALLANA2021101477'}",ScienceDirect
Eali Stephen {Neal Joshua} and Debnath Bhattacharyya and N. Thirupathi Rao,Chapter 18 - Managing information security risk and Internet of Things (IoT) impact on challenges of medicinal problems with complex settings: a complete systematic approach,"Big data, Complex systems, Electronic health records, Healthcare, Hetrogeneous data, Information security","In healthcare, big volumes of heterogeneous medical information have become available in numerous healthcare organizations. This information might be a permitting resource for acquiring knowledge for boosting treatment, lowering misuse. The outrage as well as complexity of these dataset current wonderful obstacles in reviews and also subsequential apps to a sensible scientific setting. Within this chapter, we will certainly discover the crossway of healthcare and also significant data. While the trend is actually modifying for healthcare big data records, analytics as additional associations find out how to harness big data as well as implement the ideal commercial infrastructure for producing actionable insights from a hoard of new sources; some suppliers may still be actually wondering exactly how large data can actually benefit all of them. Real-time Electronic Health Records analytics likewise assisted a Texas healthcare facility cut readmissions by 5% through relying on almost 30 information factors consisted of in the client's graph. This is just one of the very first would-be research studies to display how comprehensive records in EHRs could be used in real time to automatically identify as well as target clients at the greatest threat of readmission early in their preliminary hospitalization when there is actually a great deal that could be carried out to improve and collaborate their care; therefore, individuals will definitely do well when they leave behind the health center. Meanwhile, the Kaiser Permanente unit has been working to refine its own readmission protocols in order to better recognize readmissions that are actually avoidable and which are not, an important distinction for value-based compensations. In healthcare, big volumes of various clinical records have actually ended up being offered in a variety of medical care associations. The healthcare industry is massive, and there are large amounts of data coming out of medical care. One way big information could reinvent healthcare is actually through boosting hospital premium as well as client protection in the Intensive Care Units. Populace health and wellness monitoring are a lot about protection, as it is regarding therapy, and also healthcare-significant records’ analytics gear up companies with the tools they need to have to be practical regarding their patients' requirements. As new innovations surface, and buyer need for command over individual welfare increases, it is going to be evermore important to know just how ideal to get through the huge compilations of records for medical care organizations, and exactly how to size your data to maintain it applicable.",2022,"Multi-Chaos, Fractal and Multi-Fractional Artificial Intelligence of Different Complex Systems",https://www.sciencedirect.com/science/article/pii/B9780323900324000079,"{'abstract': ""In healthcare, big volumes of heterogeneous medical information have become available in numerous healthcare organizations. This information might be a permitting resource for acquiring knowledge for boosting treatment, lowering misuse. The outrage as well as complexity of these dataset current wonderful obstacles in reviews and also subsequential apps to a sensible scientific setting. Within this chapter, we will certainly discover the crossway of healthcare and also significant data. While the trend is actually modifying for healthcare big data records, analytics as additional associations find out how to harness big data as well as implement the ideal commercial infrastructure for producing actionable insights from a hoard of new sources; some suppliers may still be actually wondering exactly how large data can actually benefit all of them. Real-time Electronic Health Records analytics likewise assisted a Texas healthcare facility cut readmissions by 5% through relying on almost 30 information factors consisted of in the client's graph. This is just one of the very first would-be research studies to display how comprehensive records in EHRs could be used in real time to automatically identify as well as target clients at the greatest threat of readmission early in their preliminary hospitalization when there is actually a great deal that could be carried out to improve and collaborate their care; therefore, individuals will definitely do well when they leave behind the health center. Meanwhile, the Kaiser Permanente unit has been working to refine its own readmission protocols in order to better recognize readmissions that are actually avoidable and which are not, an important distinction for value-based compensations. In healthcare, big volumes of various clinical records have actually ended up being offered in a variety of medical care associations. The healthcare industry is massive, and there are large amounts of data coming out of medical care. One way big information could reinvent healthcare is actually through boosting hospital premium as well as client protection in the Intensive Care Units. Populace health and wellness monitoring are a lot about protection, as it is regarding therapy, and also healthcare-significant records’ analytics gear up companies with the tools they need to have to be practical regarding their patients' requirements. As new innovations surface, and buyer need for command over individual welfare increases, it is going to be evermore important to know just how ideal to get through the huge compilations of records for medical care organizations, and exactly how to size your data to maintain it applicable."", 'keywords': 'Big data, Complex systems, Electronic health records, Healthcare, Hetrogeneous data, Information security', 'author': 'Eali Stephen {Neal Joshua} and Debnath Bhattacharyya and N. Thirupathi Rao', 'url': 'https://www.sciencedirect.com/science/article/pii/B9780323900324000079', 'doi': 'https://doi.org/10.1016/B978-0-323-90032-4.00007-9', 'isbn': '978-0-323-90032-4', 'year': '2022', 'pages': '291-310', 'publisher': 'Academic Press', 'booktitle': 'Multi-Chaos, Fractal and Multi-Fractional Artificial Intelligence of Different Complex Systems', 'editor': 'Yeliz Karaca and Dumitru Baleanu and Yu-Dong Zhang and Osvaldo Gervasi and Majaz Moonis', 'title': 'Chapter 18 - Managing information security risk and Internet of Things (IoT) impact on challenges of medicinal problems with complex settings: a complete systematic approach', 'ENTRYTYPE': 'incollection', 'ID': 'NEALJOSHUA2022291'}",ScienceDirect
Sonal Allana,Improving the scalability of a rating system for assessing safety of Internet of Toys,"Children, IoToy, Privacy, Security, Consumer label, Manufacturers","Scalability is an important feature for the long term adoption of a rating system that determines the privacy and security of Internet of Toys (IoToys). As technology evolves and innovations are introduced in the IoToy market, the rating system must be capable of including the impact of new factors in the overall safety of the toy. Similarly obsolete factors should be easily removable. The rating system should also account for the difference in the weightage of individual factors. This research enhances the ChildShield rating system proposed by Allana & Chawla (2021) to reflect these additional features. The corresponding consumer label is expanded to include a secondary layer to present supplementary details to the consumer during purchase and use. A case study of grading an IoToy with the enhanced system is conducted in collaboration with a manufacturer and the steps for rating and labelling of IoToys using self-evaluation and guided modes are proposed.",2023,Computer Standards & Interfaces,https://www.sciencedirect.com/science/article/pii/S0920548922000228,"{'abstract': 'Scalability is an important feature for the long term adoption of a rating system that determines the privacy and security of Internet of Toys (IoToys). As technology evolves and innovations are introduced in the IoToy market, the rating system must be capable of including the impact of new factors in the overall safety of the toy. Similarly obsolete factors should be easily removable. The rating system should also account for the difference in the weightage of individual factors. This research enhances the ChildShield rating system proposed by Allana & Chawla (2021) to reflect these additional features. The corresponding consumer label is expanded to include a secondary layer to present supplementary details to the consumer during purchase and use. A case study of grading an IoToy with the enhanced system is conducted in collaboration with a manufacturer and the steps for rating and labelling of IoToys using self-evaluation and guided modes are proposed.', 'keywords': 'Children, IoToy, Privacy, Security, Consumer label, Manufacturers', 'author': 'Sonal Allana', 'url': 'https://www.sciencedirect.com/science/article/pii/S0920548922000228', 'doi': 'https://doi.org/10.1016/j.csi.2022.103645', 'issn': '0920-5489', 'year': '2023', 'pages': '103645', 'volume': '83', 'journal': 'Computer Standards & Interfaces', 'title': 'Improving the scalability of a rating system for assessing safety of Internet of Toys', 'ENTRYTYPE': 'article', 'ID': 'ALLANA2023103645'}",ScienceDirect
Bhavani Thuraisingham,Privacy constraint processing in a privacy-enhanced database management system,"DBMS, Database, Data management, Privacy, Data-mining, Inference, Architecture",This paper views the privacy problem as a form of inference problem. It first provides an overview of the privacy problem and then introduces the notion of privacy constraints. Next it describes architecture for a privacy-enhanced database management system and discusses algorithms for privacy constraint processing. A note on privacy constraints processing and release control are given next. Finally some directions for future research on privacy are stated.,2005,Data & Knowledge Engineering,https://www.sciencedirect.com/science/article/pii/S0169023X05000297,"{'abstract': 'This paper views the privacy problem as a form of inference problem. It first provides an overview of the privacy problem and then introduces the notion of privacy constraints. Next it describes architecture for a privacy-enhanced database management system and discusses algorithms for privacy constraint processing. A note on privacy constraints processing and release control are given next. Finally some directions for future research on privacy are stated.', 'keywords': 'DBMS, Database, Data management, Privacy, Data-mining, Inference, Architecture', 'author': 'Bhavani Thuraisingham', 'url': 'https://www.sciencedirect.com/science/article/pii/S0169023X05000297', 'doi': 'https://doi.org/10.1016/j.datak.2005.03.001', 'issn': '0169-023X', 'year': '2005', 'pages': '159-188', 'number': '2', 'volume': '55', 'journal': 'Data & Knowledge Engineering', 'title': 'Privacy constraint processing in a privacy-enhanced database management system', 'ENTRYTYPE': 'article', 'ID': 'THURAISINGHAM2005159'}",ScienceDirect
Xiao Bai and Xiang Wang and Xianglong Liu and Qiang Liu and Jingkuan Song and Nicu Sebe and Been Kim,Explainable deep learning for efficient and robust pattern recognition: A survey of recent developments,"Explainable deep learning, Network compression and acceleration, Adversarial robustness, Stability in deep learning","Deep learning has recently achieved great success in many visual recognition tasks. However, the deep neural networks (DNNs) are often perceived as black-boxes, making their decision less understandable to humans and prohibiting their usage in safety-critical applications. This guest editorial introduces the thirty papers accepted for the Special Issue on Explainable Deep Learning for Efficient and Robust Pattern Recognition. They are grouped into three main categories: explainable deep learning methods, efficient deep learning via model compression and acceleration, as well as robustness and stability in deep learning. For each of the three topics, a survey of the representative works and latest developments is presented, followed by the brief introduction of the accepted papers belonging to this topic. The special issue should be of high relevance to the reader interested in explainable deep learning methods for efficient and robust pattern recognition applications and it helps promoting the future research directions in this field.",2021,Pattern Recognition,https://www.sciencedirect.com/science/article/pii/S0031320321002892,"{'abstract': 'Deep learning has recently achieved great success in many visual recognition tasks. However, the deep neural networks (DNNs) are often perceived as black-boxes, making their decision less understandable to humans and prohibiting their usage in safety-critical applications. This guest editorial introduces the thirty papers accepted for the Special Issue on Explainable Deep Learning for Efficient and Robust Pattern Recognition. They are grouped into three main categories: explainable deep learning methods, efficient deep learning via model compression and acceleration, as well as robustness and stability in deep learning. For each of the three topics, a survey of the representative works and latest developments is presented, followed by the brief introduction of the accepted papers belonging to this topic. The special issue should be of high relevance to the reader interested in explainable deep learning methods for efficient and robust pattern recognition applications and it helps promoting the future research directions in this field.', 'keywords': 'Explainable deep learning, Network compression and acceleration, Adversarial robustness, Stability in deep learning', 'author': 'Xiao Bai and Xiang Wang and Xianglong Liu and Qiang Liu and Jingkuan Song and Nicu Sebe and Been Kim', 'url': 'https://www.sciencedirect.com/science/article/pii/S0031320321002892', 'doi': 'https://doi.org/10.1016/j.patcog.2021.108102', 'issn': '0031-3203', 'year': '2021', 'pages': '108102', 'volume': '120', 'journal': 'Pattern Recognition', 'title': 'Explainable deep learning for efficient and robust pattern recognition: A survey of recent developments', 'ENTRYTYPE': 'article', 'ID': 'BAI2021108102'}",ScienceDirect
Lihao Nan and Dacheng Tao,Variational approach for privacy funnel optimization on continuous data,"Privacy, Data security, Representation Learning","Here we consider a common data encryption problem encountered by users who want to disclose some data to gain utility but preserve their private information. Specifically, we consider the inference attack, in which an adversary conducts inference on the disclosed data to gain information about users’ private data. Following privacy funnel (Makhdoumi et al., 2014), assuming that the original data X is transformed into Z before disclosing and the log loss is used for both privacy and utility metrics, then the problem can be modeled as finding a mapping X→Z that maximizes mutual information between X and Z subject to a constraint that the mutual information between Z and private data S is smaller than a predefined threshold ϵ. In contrast to the original study (Makhdoumi et al., 2014), which only focused on discrete data, we consider the more general and practical setting of continuous and high-dimensional disclosed data (e.g., image data). Most previous work on privacy-preserving representation learning is based on adversarial learning or generative adversarial networks, which has been shown to suffer from the vanishing gradient problem, and it is experimentally difficult to eliminate the relationship with private data Y when Z is constrained to retain more information about X. Here we propose a simple but effective variational approach that does not rely on adversarial training. Our experimental results show that our approach is stable and outperforms previous methods in terms of both downstream task accuracy and mutual information estimation.",2020,Journal of Parallel and Distributed Computing,https://www.sciencedirect.com/science/article/pii/S0743731519300899,"{'abstract': 'Here we consider a common data encryption problem encountered by users who want to disclose some data to gain utility but preserve their private information. Specifically, we consider the inference attack, in which an adversary conducts inference on the disclosed data to gain information about users’ private data. Following privacy funnel (Makhdoumi et\xa0al., 2014), assuming that the original data X is transformed into Z before disclosing and the log loss is used for both privacy and utility metrics, then the problem can be modeled as finding a mapping X→Z that maximizes mutual information between X and Z subject to a constraint that the mutual information between Z and private data S is smaller than a predefined threshold ϵ. In contrast to the original study (Makhdoumi et\xa0al., 2014), which only focused on discrete data, we consider the more general and practical setting of continuous and high-dimensional disclosed data (e.g., image data). Most previous work on privacy-preserving representation learning is based on adversarial learning or generative adversarial networks, which has been shown to suffer from the vanishing gradient problem, and it is experimentally difficult to eliminate the relationship with private data Y when Z is constrained to retain more information about X. Here we propose a simple but effective variational approach that does not rely on adversarial training. Our experimental results show that our approach is stable and outperforms previous methods in terms of both downstream task accuracy and mutual information estimation.', 'keywords': 'Privacy, Data security, Representation Learning', 'author': 'Lihao Nan and Dacheng Tao', 'url': 'https://www.sciencedirect.com/science/article/pii/S0743731519300899', 'doi': 'https://doi.org/10.1016/j.jpdc.2019.09.010', 'issn': '0743-7315', 'year': '2020', 'pages': '17-25', 'volume': '137', 'journal': 'Journal of Parallel and Distributed Computing', 'title': 'Variational approach for privacy funnel optimization on continuous data', 'ENTRYTYPE': 'article', 'ID': 'NAN202017'}",ScienceDirect
Guangxi Lu and Zuobin Xiong and Ruinian Li and Nael Mohammad and Yingshu Li and Wei Li,DEFEAT: A decentralized federated learning against gradient attacks,"Federated learning, Peer to peer network, Privacy protection","As one of the most promising machine learning frameworks emerging in recent years, Federated learning (FL) has received lots of attention. The main idea of centralized FL is to train a global model by aggregating local model parameters and maintain the private data of users locally. However, recent studies have shown that traditional centralized federated learning is vulnerable to various attacks, such as gradient attacks, where a malicious server collects local model gradients and uses them to recover the private data stored on the client. In this paper, we propose a decentralized federated learning against aTtacks (DEFEAT) framework and use it to defend the gradient attack. The decentralized structure adopted by this paper uses a peer-to-peer network to transmit, aggregate, and update local models. In DEFEAT, the participating clients only need to communicate with their single-hop neighbors to learn the global model, in which the model accuracy and communication cost during the training process of DEFEAT are well balanced. Through a series of experiments and detailed case studies on real datasets, we evaluate the excellent model performance of DEFEAT and the privacy preservation capability against gradient attacks.",2023,High-Confidence Computing,https://www.sciencedirect.com/science/article/pii/S2667295223000260,"{'abstract': 'As one of the most promising machine learning frameworks emerging in recent years, Federated learning (FL) has received lots of attention. The main idea of centralized FL is to train a global model by aggregating local model parameters and maintain the private data of users locally. However, recent studies have shown that traditional centralized federated learning is vulnerable to various attacks, such as gradient attacks, where a malicious server collects local model gradients and uses them to recover the private data stored on the client. In this paper, we propose a decentralized federated learning against aTtacks (DEFEAT) framework and use it to defend the gradient attack. The decentralized structure adopted by this paper uses a peer-to-peer network to transmit, aggregate, and update local models. In DEFEAT, the participating clients only need to communicate with their single-hop neighbors to learn the global model, in which the model accuracy and communication cost during the training process of DEFEAT are well balanced. Through a series of experiments and detailed case studies on real datasets, we evaluate the excellent model performance of DEFEAT and the privacy preservation capability against gradient attacks.', 'keywords': 'Federated learning, Peer to peer network, Privacy protection', 'author': 'Guangxi Lu and Zuobin Xiong and Ruinian Li and Nael Mohammad and Yingshu Li and Wei Li', 'url': 'https://www.sciencedirect.com/science/article/pii/S2667295223000260', 'doi': 'https://doi.org/10.1016/j.hcc.2023.100128', 'issn': '2667-2952', 'year': '2023', 'pages': '100128', 'number': '3', 'volume': '3', 'journal': 'High-Confidence Computing', 'title': 'DEFEAT: A decentralized federated learning against gradient attacks', 'ENTRYTYPE': 'article', 'ID': 'LU2023100128'}",ScienceDirect
Christopher Choy and Ellie Young and Megan Li and Lorrie Faith Cranor and Jon M. Peha,Consumer-driven design and evaluation of broadband labels,"Broadband labels, Broadband policy, Product labels, Survey study, Broadband access, Digital divide","This study examines the content and layout of the proposed broadband consumer disclosure labels mandated by the U.S. Federal Communications Commission (FCC). Our large-scale user study identifies key consumer preferences and comprehension factors through a two-phase survey of 2500 broadband internet consumers. Findings reveal strong support for broadband labels, but dissatisfaction with the FCC's proposed labels from 2016. Participants generally struggled to use the label for cost computations and plan comparisons. Technical terms confused participants, but providing participants with brief education made the terms useable. Participants desired additional information, including reliability, speed measures for both periods when performance is “normal” and periods when performance is much worse than normal, quality-of-experience ratings, and detailed network management practices. This feedback informed our improved label designs that outperformed the 2016 labels in comprehension and preference. Overall, consumers valued clear pricing and performance details, comprehensive information, and an easy-to-understand format for plan comparison. Requiring broadband service providers to deposit machine-readable plan information in a publicly accessible database would enable third parties to further customize how information is presented to meet these consumer needs. Our work additionally highlights the need for user studies of labels to ensure they meet consumer demands.",2024,Telecommunications Policy,https://www.sciencedirect.com/science/article/pii/S0308596124000144,"{'abstract': ""This study examines the content and layout of the proposed broadband consumer disclosure labels mandated by the U.S. Federal Communications Commission (FCC). Our large-scale user study identifies key consumer preferences and comprehension factors through a two-phase survey of 2500 broadband internet consumers. Findings reveal strong support for broadband labels, but dissatisfaction with the FCC's proposed labels from 2016. Participants generally struggled to use the label for cost computations and plan comparisons. Technical terms confused participants, but providing participants with brief education made the terms useable. Participants desired additional information, including reliability, speed measures for both periods when performance is “normal” and periods when performance is much worse than normal, quality-of-experience ratings, and detailed network management practices. This feedback informed our improved label designs that outperformed the 2016 labels in comprehension and preference. Overall, consumers valued clear pricing and performance details, comprehensive information, and an easy-to-understand format for plan comparison. Requiring broadband service providers to deposit machine-readable plan information in a publicly accessible database would enable third parties to further customize how information is presented to meet these consumer needs. Our work additionally highlights the need for user studies of labels to ensure they meet consumer demands."", 'keywords': 'Broadband labels, Broadband policy, Product labels, Survey study, Broadband access, Digital divide', 'author': 'Christopher Choy and Ellie Young and Megan Li and Lorrie Faith Cranor and Jon M. Peha', 'url': 'https://www.sciencedirect.com/science/article/pii/S0308596124000144', 'doi': 'https://doi.org/10.1016/j.telpol.2024.102717', 'issn': '0308-5961', 'year': '2024', 'pages': '102717', 'number': '5', 'volume': '48', 'journal': 'Telecommunications Policy', 'title': 'Consumer-driven design and evaluation of broadband labels', 'ENTRYTYPE': 'article', 'ID': 'CHOY2024102717'}",ScienceDirect
Anna Squicciarini and Sushama Karumanchi and Dan Lin and Nicole DeSisto,Identifying hidden social circles for advanced privacy configuration,"Privacy, Social groups, Access control, Social networks, Cliques, Policies","With the dramatic increase of users on social network websites, the needs to assist users to manage their large number of contacts as well as providing privacy protection become more and more evident. Unfortunately, limited tools are available to address such needs and reduce users' workload on managing their social relationships. To tackle this issue, we propose an approach to facilitate online social network users to group their contacts into social circles with common interests. Further, we leverage the social group practice to automate the privacy setting process for users who add new contacts or upload new data items. We evaluate our approach using real-world data collected through a user study. The study also includes an analysis of the properties that are most critical for privacy related decisions.",2014,Computers & Security,https://www.sciencedirect.com/science/article/pii/S0167404813001107,"{'abstract': ""With the dramatic increase of users on social network websites, the needs to assist users to manage their large number of contacts as well as providing privacy protection become more and more evident. Unfortunately, limited tools are available to address such needs and reduce users' workload on managing their social relationships. To tackle this issue, we propose an approach to facilitate online social network users to group their contacts into social circles with common interests. Further, we leverage the social group practice to automate the privacy setting process for users who add new contacts or upload new data items. We evaluate our approach using real-world data collected through a user study. The study also includes an analysis of the properties that are most critical for privacy related decisions."", 'keywords': 'Privacy, Social groups, Access control, Social networks, Cliques, Policies', 'author': 'Anna Squicciarini and Sushama Karumanchi and Dan Lin and Nicole DeSisto', 'url': 'https://www.sciencedirect.com/science/article/pii/S0167404813001107', 'doi': 'https://doi.org/10.1016/j.cose.2013.07.007', 'issn': '0167-4048', 'note': '8th IEEE International Conference on Collaborative Computing: Networking, Applications and Worksharing', 'year': '2014', 'pages': '40-51', 'volume': '41', 'journal': 'Computers & Security', 'title': 'Identifying hidden social circles for advanced privacy configuration', 'ENTRYTYPE': 'article', 'ID': 'SQUICCIARINI201440'}",ScienceDirect
John Sterlicchi,Truste Outlines Online Privacy Symbols,,,2001,Computer Fraud & Security,https://www.sciencedirect.com/science/article/pii/S1361372301008120,"{'author': 'John Sterlicchi', 'url': 'https://www.sciencedirect.com/science/article/pii/S1361372301008120', 'doi': 'https://doi.org/10.1016/S1361-3723(01)00812-0', 'issn': '1361-3723', 'year': '2001', 'pages': '6', 'number': '8', 'volume': '2001', 'journal': 'Computer Fraud & Security', 'title': 'Truste Outlines Online Privacy Symbols', 'ENTRYTYPE': 'article', 'ID': 'STERLICCHI20016'}",ScienceDirect
Jinchun Choi and Afsah Anwar and Abdulrahman Alabduljabbar and Hisham Alasmary and Jeffrey Spaulding and An Wang and Songqing Chen and DaeHun Nyang and Amro Awad and David Mohaisen,Understanding Internet of Things malware by analyzing endpoints in their static artifacts,"Internet of Things, Endpoints, Malware","The lack of security measures among the Internet of Things (IoT) devices and their persistent online connection gives adversaries a prime opportunity to target them or even abuse them as intermediary targets in larger attacks such as distributed denial-of-service (DDoS) campaigns. In this paper, we analyze IoT malware and focus on the endpoints reachable on the public Internet, that play an essential part in the IoT malware ecosystem. Namely, we analyze endpoints acting as dropzones and their targets to gain insights into the underlying dynamics in this ecosystem, such as the affinity between the dropzones and their target IP addresses, and the different patterns among endpoints. Towards this goal, we reverse-engineer 2423 IoT malware samples and extract strings from them to obtain IP addresses. We further gather information about these endpoints from public Internet-wide scanners, such as Shodan and Censys. Our results, through analysis and visualization expose clear patterns of affinity between sources and targets of attacks, attack exposure by Internet infrastructure, and clear depiction of the ecosystem of IoT malware as a whole, only utilizing static artifacts. Our investigation from four different perspectives provides profound insights into the role of endpoints in IoT malware attacks, which deepens our understanding of IoT malware ecosystems and can assist future defenses.",2022,Computer Networks,https://www.sciencedirect.com/science/article/pii/S1389128622000056,"{'abstract': 'The lack of security measures among the Internet of Things (IoT) devices and their persistent online connection gives adversaries a prime opportunity to target them or even abuse them as intermediary targets in larger attacks such as distributed denial-of-service (DDoS) campaigns. In this paper, we analyze IoT malware and focus on the endpoints reachable on the public Internet, that play an essential part in the IoT malware ecosystem. Namely, we analyze endpoints acting as dropzones and their targets to gain insights into the underlying dynamics in this ecosystem, such as the affinity between the dropzones and their target IP addresses, and the different patterns among endpoints. Towards this goal, we reverse-engineer 2423 IoT malware samples and extract strings from them to obtain IP addresses. We further gather information about these endpoints from public Internet-wide scanners, such as Shodan and Censys. Our results, through analysis and visualization expose clear patterns of affinity between sources and targets of attacks, attack exposure by Internet infrastructure, and clear depiction of the ecosystem of IoT malware as a whole, only utilizing static artifacts. Our investigation from four different perspectives provides profound insights into the role of endpoints in IoT malware attacks, which deepens our understanding of IoT malware ecosystems and can assist future defenses.', 'keywords': 'Internet of Things, Endpoints, Malware', 'author': 'Jinchun Choi and Afsah Anwar and Abdulrahman Alabduljabbar and Hisham Alasmary and Jeffrey Spaulding and An Wang and Songqing Chen and DaeHun Nyang and Amro Awad and David Mohaisen', 'url': 'https://www.sciencedirect.com/science/article/pii/S1389128622000056', 'doi': 'https://doi.org/10.1016/j.comnet.2022.108768', 'issn': '1389-1286', 'year': '2022', 'pages': '108768', 'volume': '206', 'journal': 'Computer Networks', 'title': 'Understanding Internet of Things malware by analyzing endpoints in their static artifacts', 'ENTRYTYPE': 'article', 'ID': 'CHOI2022108768'}",ScienceDirect
Max {von Grafenstein} and Timo Jakobi and Gunnar Stevens,Effective data protection by design through interdisciplinary research methods: The example of effective purpose specification by applying user-Centred UX-design methods,"Data protection by design, Effective purpose specification, GDPR, UXD, HCI","While the recent discussion on Art. 25 GDPR often considers the approach of data protection by design as an innovative idea, the notion of making data protection law more effective through requiring the data controller to implement the legal norms into the processing design is almost as old as the data protection debate. However, there is another, more recent shift in establishing the data protection by design approach through law, which is not yet understood to its fullest extent in the debate. Art. 25 GDPR requires the controller to not only implement the legal norms into the processing design but to do so in an effective manner. By explicitly declaring the effectiveness of the protection measures to be the legally required result, the legislator inevitably raises the question of which methods can be used to test and assure such efficacy. In our opinion, extending the legal compatibility assessment to the real effects of the required measures opens this approach to interdisciplinary methodologies. In this paper, we first summarise the current state of research on the methodology established in Art. 25 sect. 1 GDPR, and pinpoint some of the challenges of incorporating interdisciplinary research methodologies. On this premise, we present an empirical research methodology and first findings which offer one approach to answering the question on how to specify processing purposes effectively. Lastly, we discuss the implications of these findings for the legal interpretation of Art. 25 GDPR and related provisions, especially with respect to a more effective implementation of transparency and consent, and provide an outlook on possible next research steps.",2022,Computer Law & Security Review,https://www.sciencedirect.com/science/article/pii/S026736492200067X,"{'abstract': 'While the recent discussion on Art. 25 GDPR often considers the approach of data protection by design as an innovative idea, the notion of making data protection law more effective through requiring the data controller to implement the legal norms into the processing design is almost as old as the data protection debate. However, there is another, more recent shift in establishing the data protection by design approach through law, which is not yet understood to its fullest extent in the debate. Art. 25 GDPR requires the controller to not only implement the legal norms into the processing design but to do so in an effective manner. By explicitly declaring the effectiveness of the protection measures to be the legally required result, the legislator inevitably raises the question of which methods can be used to test and assure such efficacy. In our opinion, extending the legal compatibility assessment to the real effects of the required measures opens this approach to interdisciplinary methodologies. In this paper, we first summarise the current state of research on the methodology established in Art. 25 sect. 1 GDPR, and pinpoint some of the challenges of incorporating interdisciplinary research methodologies. On this premise, we present an empirical research methodology and first findings which offer one approach to answering the question on how to specify processing purposes effectively. Lastly, we discuss the implications of these findings for the legal interpretation of Art. 25 GDPR and related provisions, especially with respect to a more effective implementation of transparency and consent, and provide an outlook on possible next research steps.', 'keywords': 'Data protection by design, Effective purpose specification, GDPR, UXD, HCI', 'author': 'Max {von Grafenstein} and Timo Jakobi and Gunnar Stevens', 'url': 'https://www.sciencedirect.com/science/article/pii/S026736492200067X', 'doi': 'https://doi.org/10.1016/j.clsr.2022.105722', 'issn': '0267-3649', 'year': '2022', 'pages': '105722', 'volume': '46', 'journal': 'Computer Law & Security Review', 'title': 'Effective data protection by design through interdisciplinary research methods: The example of effective purpose specification by applying user-Centred UX-design methods', 'ENTRYTYPE': 'article', 'ID': 'VONGRAFENSTEIN2022105722'}",ScienceDirect
Nili Steinfeld,“I agree to the terms and conditions”: (How) do users read privacy policies online? An eye-tracking experiment,"Privacy, Computer-mediated communication, Privacy policies, Eye tracking, Experiment, Decision making","Privacy policies are widely used by online service providers to regulate the use of personal data they collect, but users often skip on reading them and are unaware of the way information about them is being treated, and how they can control the ways in which that information is collected, stored or shared. Eye tracking methodology was used to test if a default presentation of a policy encourages reading it, and how the document is being read by users. Results show that when a privacy policy is presented by default, participants tend to read it quite carefully, while when given the option to sign their agreement without reading the policy, most participants skip the policy altogether. Surprisingly, participants who actively choose to read the policy spend significantly less time and effort on reading it than participants in the default condition. Finally, default policy presentation was significantly related to understanding user rights and restrictions on the use of personal data.",2016,Computers in Human Behavior,https://www.sciencedirect.com/science/article/pii/S0747563215301692,"{'abstract': 'Privacy policies are widely used by online service providers to regulate the use of personal data they collect, but users often skip on reading them and are unaware of the way information about them is being treated, and how they can control the ways in which that information is collected, stored or shared. Eye tracking methodology was used to test if a default presentation of a policy encourages reading it, and how the document is being read by users. Results show that when a privacy policy is presented by default, participants tend to read it quite carefully, while when given the option to sign their agreement without reading the policy, most participants skip the policy altogether. Surprisingly, participants who actively choose to read the policy spend significantly less time and effort on reading it than participants in the default condition. Finally, default policy presentation was significantly related to understanding user rights and restrictions on the use of personal data.', 'keywords': 'Privacy, Computer-mediated communication, Privacy policies, Eye tracking, Experiment, Decision making', 'author': 'Nili Steinfeld', 'url': 'https://www.sciencedirect.com/science/article/pii/S0747563215301692', 'doi': 'https://doi.org/10.1016/j.chb.2015.09.038', 'issn': '0747-5632', 'year': '2016', 'pages': '992-1000', 'volume': '55', 'journal': 'Computers in Human Behavior', 'title': '“I agree to the terms and conditions”: (How) do users read privacy policies online? An eye-tracking experiment', 'ENTRYTYPE': 'article', 'ID': 'STEINFELD2016992'}",ScienceDirect
Renpeng Zou and Xixiang Lv and Jingsong Zhao,SPChain: Blockchain-based medical data sharing and privacy-preserving eHealth system,"Blockchain, Electronic medical record, Privacy, Data sharing, Reputation system","The sharing of electronic medical records (EMRs) has great positive significance for research on disease and epidemic prevention. Recently, blockchain-based eHealth systems have achieved great success in terms of EMRs sharing and management, but there still remain some challenges. Permissioned blockchain-based solutions provide high throughput and scalability, but may suffer from rollback attacks and lead to privacy leakage. Designs based on the public blockchain, on the other hand, are more open and secure, but sacrifice scalability and have no incentives for medical institutions to join into the systems. Moreover, data retrieval in blockchain-based eHealth systems is inefficient because of the basic blockchain structure. To solve the above problems, we propose a blockchain-based medical data sharing and privacy-preserving eHealth system named SPChain. To achieve quick retrieval, we devise special keyblocks and microblocks for patients to store their EMRs. A reputation system is also constructed to motivate medical institutions to participate in SPChain. By using proxy re-encryption schemes, SPChain achieves medical data sharing for patients in a privacy-preserving manner. To evaluate SPChain, we leverage the distribution of miners in the real world to test the system’s performance and ability to resist mentioned attacks. The results show that SPChain can achieve high throughput (220 TPS) with low storage overhead. Compared with the existing schemes, SPChain achieves lower time complexity in terms of data retrieving, and can resist proposed blockchain attacks as well as SPChain attacks.",2021,Information Processing & Management,https://www.sciencedirect.com/science/article/pii/S0306457321001011,"{'abstract': 'The sharing of electronic medical records (EMRs) has great positive significance for research on disease and epidemic prevention. Recently, blockchain-based eHealth systems have achieved great success in terms of EMRs sharing and management, but there still remain some challenges. Permissioned blockchain-based solutions provide high throughput and scalability, but may suffer from rollback attacks and lead to privacy leakage. Designs based on the public blockchain, on the other hand, are more open and secure, but sacrifice scalability and have no incentives for medical institutions to join into the systems. Moreover, data retrieval in blockchain-based eHealth systems is inefficient because of the basic blockchain structure. To solve the above problems, we propose a blockchain-based medical data sharing and privacy-preserving eHealth system named SPChain. To achieve quick retrieval, we devise special keyblocks and microblocks for patients to store their EMRs. A reputation system is also constructed to motivate medical institutions to participate in SPChain. By using proxy re-encryption schemes, SPChain achieves medical data sharing for patients in a privacy-preserving manner. To evaluate SPChain, we leverage the distribution of miners in the real world to test the system’s performance and ability to resist mentioned attacks. The results show that SPChain can achieve high throughput (220 TPS) with low storage overhead. Compared with the existing schemes, SPChain achieves lower time complexity in terms of data retrieving, and can resist proposed blockchain attacks as well as SPChain attacks.', 'keywords': 'Blockchain, Electronic medical record, Privacy, Data sharing, Reputation system', 'author': 'Renpeng Zou and Xixiang Lv and Jingsong Zhao', 'url': 'https://www.sciencedirect.com/science/article/pii/S0306457321001011', 'doi': 'https://doi.org/10.1016/j.ipm.2021.102604', 'issn': '0306-4573', 'year': '2021', 'pages': '102604', 'number': '4', 'volume': '58', 'journal': 'Information Processing & Management', 'title': 'SPChain: Blockchain-based medical data sharing and privacy-preserving eHealth system', 'ENTRYTYPE': 'article', 'ID': 'ZOU2021102604'}",ScienceDirect
Samrat Acharya and Robert Mieth and Ramesh Karri and Yury Dvorkin,False data injection attacks on data markets for electric vehicle charging stations,"Data markets, Demand forecasts, Electric vehicle charging stations, Kullback-Leibler divergence, Machine learning, Quantile linear regression","Modern societies use machine learning techniques to support complex decision-making processes (e.g., renewable energy and power demand forecasting in energy systems). Data fuels these techniques, so the quality of the data fed into them determines the accuracy of the results. While the amount of data is increasing with the adoption of internet-of-things, most of it is still private. Availability of data limits the application of machine learning. Scientists and industry pioneers are proposing a model that relies on the economics of data markets, where private data can be traded for a price. Cybersecurity analyses of such markets are lacking. In this context, our study makes two contributions. First, it designs a data market for electric vehicle charging stations, which aims to improve the accuracy of electric vehicle charging demand forecasts. Accurate demand forecasts are essential for sustainable operations of the electric vehicle - charging station - power grid ecosystem, which, in turn, facilitates the electrification and decarbonization of the transportation sector. On the other hand, erroneous demand forecasts caused by malicious cyberattacks impose operational challenges to the ecosystem. Thus, the second contribution of our study is to examine the feasibility of false data injection attacks on the data market for electric vehicle charging stations and to propose a defense mechanism against such attacks. We illustrate our results using data from electric vehicle charging stations in Manhattan, New York. We demonstrate that the data market improves forecasting accuracy of charging stations and reduces the effectiveness of false data injection attacks. The purpose of this work is not only to inform electric vehicle charging stations about the economic benefits of data markets, but to promote cyber awareness among data market pioneers and stakeholders.",2022,Advances in Applied Energy,https://www.sciencedirect.com/science/article/pii/S2666792422000166,"{'abstract': 'Modern societies use machine learning techniques to support complex decision-making processes (e.g., renewable energy and power demand forecasting in energy systems). Data fuels these techniques, so the quality of the data fed into them determines the accuracy of the results. While the amount of data is increasing with the adoption of internet-of-things, most of it is still private. Availability of data limits the application of machine learning. Scientists and industry pioneers are proposing a model that relies on the economics of data markets, where private data can be traded for a price. Cybersecurity analyses of such markets are lacking. In this context, our study makes two contributions. First, it designs a data market for electric vehicle charging stations, which aims to improve the accuracy of electric vehicle charging demand forecasts. Accurate demand forecasts are essential for sustainable operations of the electric vehicle - charging station - power grid ecosystem, which, in turn, facilitates the electrification and decarbonization of the transportation sector. On the other hand, erroneous demand forecasts caused by malicious cyberattacks impose operational challenges to the ecosystem. Thus, the second contribution of our study is to examine the feasibility of false data injection attacks on the data market for electric vehicle charging stations and to propose a defense mechanism against such attacks. We illustrate our results using data from electric vehicle charging stations in Manhattan, New York. We demonstrate that the data market improves forecasting accuracy of charging stations and reduces the effectiveness of false data injection attacks. The purpose of this work is not only to inform electric vehicle charging stations about the economic benefits of data markets, but to promote cyber awareness among data market pioneers and stakeholders.', 'keywords': 'Data markets, Demand forecasts, Electric vehicle charging stations, Kullback-Leibler divergence, Machine learning, Quantile linear regression', 'author': 'Samrat Acharya and Robert Mieth and Ramesh Karri and Yury Dvorkin', 'url': 'https://www.sciencedirect.com/science/article/pii/S2666792422000166', 'doi': 'https://doi.org/10.1016/j.adapen.2022.100098', 'issn': '2666-7924', 'year': '2022', 'pages': '100098', 'volume': '7', 'journal': 'Advances in Applied Energy', 'title': 'False data injection attacks on data markets for electric vehicle charging stations', 'ENTRYTYPE': 'article', 'ID': 'ACHARYA2022100098'}",ScienceDirect
Kyle J McKibbin and Mahsa Shabani,Building a better mobile app marketplace: A legal and governance toolkit for app mediated genomics research,"Mhealth, Research ethics, Data protection, Genomics, Platforms","Due to ongoing developments in mobile health research and consumer genomics services, genomics mobile applications are set to become an increasingly important tool for biomedical researchers, offering to generate new insights into human health and shake up traditional research methods. However, as with other areas of mobile health research, current data governance and legal frameworks have failed to keep pace with these technological developments, generating ethical concerns and potential harms for research participants. Here, we explore the specific roles and responsibilities of the two major mobile platform providers, IOS and Android, in mediating genomics research on their platforms. This mobile platform duopoly and their respective app marketplaces play a significant role in the governance and design of app mediated research studies through the provision of technical infrastructure and contractual guidelines for developers. However, these platforms are not clearly regulated by the General Data Protection Regulation in this regard and are likely to have divergent and sometimes conflicting interests with researchers and research participants.  Two regulatory proposals, the Digital Services Act and Digital Markets Act, are set to introduce new obligations and oversight for mobile platforms. These laws are targeted more toward consumer protection and competition concerns, but they also offer new opportunities for promoting better data governance on platforms. Taking advantage of these legislative proposals, we offer a governance and legal toolkit for researchers, advocacy groups, national authorities, and platform providers interested in building a better app marketplace for genomics research.",2022,Computer Law & Security Review,https://www.sciencedirect.com/science/article/pii/S0267364922000541,"{'abstract': 'Due to ongoing developments in mobile health research and consumer genomics services, genomics mobile applications are set to become an increasingly important tool for biomedical researchers, offering to generate new insights into human health and shake up traditional research methods. However, as with other areas of mobile health research, current data governance\xa0and legal frameworks have failed to keep pace with these technological developments, generating ethical\xa0concerns and potential harms for research participants. Here, we explore the specific roles and responsibilities of the two major mobile platform providers, IOS and Android, in mediating genomics research on their platforms. This mobile platform duopoly and their respective app marketplaces play a significant role in the\xa0governance and design of app mediated research studies through the provision of technical infrastructure and contractual guidelines for developers. However, these platforms are not clearly regulated by the General Data Protection Regulation in this regard and are likely to have divergent and sometimes conflicting interests with researchers and research participants. \xa0Two regulatory proposals, the Digital Services Act and Digital Markets Act, are set to introduce new obligations and oversight for mobile platforms. These laws are targeted more toward consumer protection and competition concerns, but they also offer new opportunities for promoting better data governance on platforms. Taking advantage of these legislative proposals, we offer a governance\xa0and legal toolkit for researchers, advocacy groups, national authorities, and platform providers interested in building a better app marketplace for genomics research.', 'keywords': 'Mhealth, Research ethics, Data protection, Genomics, Platforms', 'author': 'Kyle J McKibbin and Mahsa Shabani', 'url': 'https://www.sciencedirect.com/science/article/pii/S0267364922000541', 'doi': 'https://doi.org/10.1016/j.clsr.2022.105707', 'issn': '0267-3649', 'year': '2022', 'pages': '105707', 'volume': '46', 'journal': 'Computer Law & Security Review', 'title': 'Building a better mobile app marketplace: A legal and governance toolkit for app mediated genomics research', 'ENTRYTYPE': 'article', 'ID': 'MCKIBBIN2022105707'}",ScienceDirect
Bing-Zhe He and Chien-Ming Chen and Yi-Ping Su and Hung-Min Sun,A defence scheme against Identity Theft Attack based on multiple social networks,"Identity Theft Attack, Social networks, Multi-dimensional social network","Recently, on-line social networking sites become more and more popular. People like to share their personal information such as their name, birthday and photos on these public sites. However, personal information could be misused by attackers. One kind of attacks called Identity Theft Attack is addressed in on-line social networking sites. After collecting the personal information of a victim, the attacker can create a fake identity to impersonate this victim and cheat the victim’s friends in order to destroy the trust relationships on the on-line social networking sites. In this paper, we propose a scheme to protect users from Identity Theft Attacks. In our work, users’ personal information can be still kept public. It means that this scheme does not violate the nature of the social networks. Compared with previous works, the proposed scheme incurs less overhead for users. Experimental results also demonstrate the practicality of the proposed scheme.",2014,Expert Systems with Applications,https://www.sciencedirect.com/science/article/pii/S0957417413007860,"{'abstract': 'Recently, on-line social networking sites become more and more popular. People like to share their personal information such as their name, birthday and photos on these public sites. However, personal information could be misused by attackers. One kind of attacks called Identity Theft Attack is addressed in on-line social networking sites. After collecting the personal information of a victim, the attacker can create a fake identity to impersonate this victim and cheat the victim’s friends in order to destroy the trust relationships on the on-line social networking sites. In this paper, we propose a scheme to protect users from Identity Theft Attacks. In our work, users’ personal information can be still kept public. It means that this scheme does not violate the nature of the social networks. Compared with previous works, the proposed scheme incurs less overhead for users. Experimental results also demonstrate the practicality of the proposed scheme.', 'keywords': 'Identity Theft Attack, Social networks, Multi-dimensional social network', 'author': 'Bing-Zhe He and Chien-Ming Chen and Yi-Ping Su and Hung-Min Sun', 'url': 'https://www.sciencedirect.com/science/article/pii/S0957417413007860', 'doi': 'https://doi.org/10.1016/j.eswa.2013.09.032', 'issn': '0957-4174', 'year': '2014', 'pages': '2345-2352', 'number': '5', 'volume': '41', 'journal': 'Expert Systems with Applications', 'title': 'A defence scheme against Identity Theft Attack based on multiple social networks', 'ENTRYTYPE': 'article', 'ID': 'HE20142345'}",ScienceDirect
Yuzhen Peng and Adam Rysanek and Zoltán Nagy and Arno Schlüter,Using machine learning techniques for occupancy-prediction-based cooling control in office buildings,"Machine learning, Occupant behavior, Building control, Smart buildings, Energy savings","Heating, ventilation, and air-conditioning (HVAC) are among the major energy demand in the buildings sector globally. Improving the energy efficiency of such systems is a critical objective for mitigating greenhouse gas emissions and transitioning towards renewable sources of energy supply. The interest of this paper is to explore means to increase the efficiency of HVAC systems in accommodating occupants’ behavior in real time. For instance, rooms in office buildings are not always occupied by occupants during scheduled HVAC service periods. This offers an opportunity to reduce unnecessary energy demands of HVAC systems associated with occupants’ behavior. An in-depth analysis of occupants’ stochastic behavior within an office building is conducted in this paper. A demand-driven control strategy is proposed that automatically responds to occupants’ energy-related behavior for reducing energy consumption and maintains room temperature for occupants with similar performances as a static cooling. In this control strategy, two types of machine learning methods – unsupervised and supervised learning – are applied to learn occupants’ behavior in two learning processes. The occupancy-related information learned by the algorithms is used by a set of specified rules to infer real-time room setpoints for controlling the office's space cooling system. This learning-based approach intends to reduce the need for human intervention in the cooling system’s control. The proposed strategy was applied to control the cooling system of the office building under real-world conditions. Eleven case study office spaces were selected, representing three typical office uses: single person offices, multi-person offices, and meeting rooms. The experimental results report between 7% and 52% energy savings as compared to the conventionally-scheduled cooling systems.",2018,Applied Energy,https://www.sciencedirect.com/science/article/pii/S0306261917317129,"{'abstract': ""Heating, ventilation, and air-conditioning (HVAC) are among the major energy demand in the buildings sector globally. Improving the energy efficiency of such systems is a critical objective for mitigating greenhouse gas emissions and transitioning towards renewable sources of energy supply. The interest of this paper is to explore means to increase the efficiency of HVAC systems in accommodating occupants’ behavior in real time. For instance, rooms in office buildings are not always occupied by occupants during scheduled HVAC service periods. This offers an opportunity to reduce unnecessary energy demands of HVAC systems associated with occupants’ behavior. An in-depth analysis of occupants’ stochastic behavior within an office building is conducted in this paper. A demand-driven control strategy is proposed that automatically responds to occupants’ energy-related behavior for reducing energy consumption and maintains room temperature for occupants with similar performances as a static cooling. In this control strategy, two types of machine learning methods – unsupervised and supervised learning – are applied to learn occupants’ behavior in two learning processes. The occupancy-related information learned by the algorithms is used by a set of specified rules to infer real-time room setpoints for controlling the office's space cooling system. This learning-based approach intends to reduce the need for human intervention in the cooling system’s control. The proposed strategy was applied to control the cooling system of the office building under real-world conditions. Eleven case study office spaces were selected, representing three typical office uses: single person offices, multi-person offices, and meeting rooms. The experimental results report between 7% and 52% energy savings as compared to the conventionally-scheduled cooling systems."", 'keywords': 'Machine learning, Occupant behavior, Building control, Smart buildings, Energy savings', 'author': 'Yuzhen Peng and Adam Rysanek and Zoltán Nagy and Arno Schlüter', 'url': 'https://www.sciencedirect.com/science/article/pii/S0306261917317129', 'doi': 'https://doi.org/10.1016/j.apenergy.2017.12.002', 'issn': '0306-2619', 'year': '2018', 'pages': '1343-1358', 'volume': '211', 'journal': 'Applied Energy', 'title': 'Using machine learning techniques for occupancy-prediction-based cooling control in office buildings', 'ENTRYTYPE': 'article', 'ID': 'PENG20181343'}",ScienceDirect
Valentin Rupp and Max {von Grafenstein},Clarifying “personal data” and the role of anonymisation in data protection law: Including and excluding data from the scope of the GDPR (more clearly) through refining the concept of data protection,"Data protection, Privacy, GDPR, Personal data, About element, Purpose element, Result element, Anonymisation, Risk-based approach, Risks to rights","In a data-driven society, the collection and processing of data is essential to the operation of existing technologies and the development of new ones. Data protection law protects individuals against risks associated with the processing of “personal data”. However, despite an intensive legal debate, there is still considerable uncertainty as to when data is personal data and when it is not. The reason for this is that data such as technical data or geo-location data usually is not “personal” per se but only when it is used for a specific purpose and in a specific way, or to be more precise, when the data processing causes a specific risk to a fundamental right of an individual. In our paper, we demonstrate that by focusing on these risks when assessing the scope of application, the question whether data falls into the scope of the General Data Protection Regulation (GDPR) or not becomes much clearer. The about, purpose, and result elements, introduced by the Art. 29 Working Party, thereby turn out to be a powerful set of analytical tools to determine which rights are specifically affected by data processing and, thus, to what extent a data subject is identified or identifiable in the processing context. While the about element addresses different risks to the right to privacy, the purpose element specifically reveals risks to the autonomy status of an individual. Finally, the result element focuses on the negative effect data processing can have on any other fundamental rights of the individual. On this basis, it is also possible to define more precisely the legal requirements for anonymising personal data. First of all, we illustrate that anonymisation mainly affects the about element and can do little “against” the purpose and result element. At least, however, by assessing which sphere of privacy is specifically concerned, it is possible to more precisely define when an individual is identified in a dataset and, thus, what the requirements for anonymization are.",2024,Computer Law & Security Review,https://www.sciencedirect.com/science/article/pii/S0267364923001425,"{'abstract': 'In a data-driven society, the collection and processing of data is essential to the operation of existing technologies and the development of new ones. Data protection law protects individuals against risks associated with the processing of “personal data”. However, despite an intensive legal debate, there is still considerable uncertainty as to when data is personal data and when it is not. The reason for this is that data such as technical data or geo-location data usually is not “personal” per se but only when it is used for a specific purpose and in a specific way, or to be more precise, when the data processing causes a specific risk to a fundamental right of an individual. In our paper, we demonstrate that by focusing on these risks when assessing the scope of application, the question whether data falls into the scope of the General Data Protection Regulation (GDPR) or not becomes much clearer. The about, purpose, and result elements, introduced by the Art. 29 Working Party, thereby turn out to be a powerful set of analytical tools to determine which rights are specifically affected by data processing and, thus, to what extent a data subject is identified or identifiable in the processing context. While the about element addresses different risks to the right to privacy, the purpose element specifically reveals risks to the autonomy status of an individual. Finally, the result element focuses on the negative effect data processing can have on any other fundamental rights of the individual. On this basis, it is also possible to define more precisely the legal requirements for anonymising personal data. First of all, we illustrate that anonymisation mainly affects the about element and can do little “against” the purpose and result element. At least, however, by assessing which sphere of privacy is specifically concerned, it is possible to more precisely define when an individual is identified in a dataset and, thus, what the requirements for anonymization are.', 'keywords': 'Data protection, Privacy, GDPR, Personal data, About element, Purpose element, Result element, Anonymisation, Risk-based approach, Risks to rights', 'author': 'Valentin Rupp and Max {von Grafenstein}', 'url': 'https://www.sciencedirect.com/science/article/pii/S0267364923001425', 'doi': 'https://doi.org/10.1016/j.clsr.2023.105932', 'issn': '0267-3649', 'year': '2024', 'pages': '105932', 'volume': '52', 'journal': 'Computer Law & Security Review', 'title': 'Clarifying “personal data” and the role of anonymisation in data protection law: Including and excluding data from the scope of the GDPR (more clearly) through refining the concept of data protection', 'ENTRYTYPE': 'article', 'ID': 'RUPP2024105932'}",ScienceDirect
Michelle Walterscheid and Nicole Huijts and Iris {van Sintemaartensdijk},Nudging purchase intention towards more secure domestic IoT: The effect of label features and psychological mechanisms,"Domestic IoT, Labels, Security","The domestic Internet of Things market is flooded with unsecure devices and yet, the demand rises. This study aimed to find ways for labels to nudge consumers into purchasing safer devices. Two studies were conducted, one with a Dutch student sample (N = 193) and one with a UK population sample (N = 278). Multiple labels were presented to participants to test potential effects of security degree (high vs. low), framing (positive vs. negative) and label type (grade format vs. informative format), in interaction with initial attitude towards smart devices and trust in the label, on purchase intention. Furthermore, we investigated the antecedents of trust in the label. Findings for both studies indicated significant positive effects of high security degree, positive framing, initial attitude and trust in the label on purchase intention. Both studies find that the positive effect of security degree on purchase intention was stronger when initial attitude was higher and when trust in the label was higher. The informative label was both more trusted and more preferred, so therefore recommended to be used. Overall, security information is effective in steering people towards purchasing safer IoT, and higher trust in the label increases the effectiveness of the label.",2024,Computers in Human Behavior Reports,https://www.sciencedirect.com/science/article/pii/S2451958824000198,"{'abstract': 'The domestic Internet of Things market is flooded with unsecure devices and yet, the demand rises. This study aimed to find ways for labels to nudge consumers into purchasing safer devices. Two studies were conducted, one with a Dutch student sample (N\xa0=\xa0193) and one with a UK population sample (N\xa0=\xa0278). Multiple labels were presented to participants to test potential effects of security degree (high vs. low), framing (positive vs. negative) and label type (grade format vs. informative format), in interaction with initial attitude towards smart devices and trust in the label, on purchase intention. Furthermore, we investigated the antecedents of trust in the label. Findings for both studies indicated significant positive effects of high security degree, positive framing, initial attitude and trust in the label on purchase intention. Both studies find that the positive effect of security degree on purchase intention was stronger when initial attitude was higher and when trust in the label was higher. The informative label was both more trusted and more preferred, so therefore recommended to be used. Overall, security information is effective in steering people towards purchasing safer IoT, and higher trust in the label increases the effectiveness of the label.', 'keywords': 'Domestic IoT, Labels, Security', 'author': 'Michelle Walterscheid and Nicole Huijts and Iris {van Sintemaartensdijk}', 'url': 'https://www.sciencedirect.com/science/article/pii/S2451958824000198', 'doi': 'https://doi.org/10.1016/j.chbr.2024.100386', 'issn': '2451-9588', 'year': '2024', 'pages': '100386', 'volume': '14', 'journal': 'Computers in Human Behavior Reports', 'title': 'Nudging purchase intention towards more secure domestic IoT: The effect of label features and psychological mechanisms', 'ENTRYTYPE': 'article', 'ID': 'WALTERSCHEID2024100386'}",ScienceDirect
Julian Jang-Jaccard and Surya Nepal,A survey of emerging threats in cybersecurity,"Cybersecurity, Malware, Emerging technology trends, Emerging cyber threats, Cyber attacks and countermeasures","The exponential growth of the Internet interconnections has led to a significant growth of cyber attack incidents often with disastrous and grievous consequences. Malware is the primary choice of weapon to carry out malicious intents in the cyberspace, either by exploitation into existing vulnerabilities or utilization of unique characteristics of emerging technologies. The development of more innovative and effective malware defense mechanisms has been regarded as an urgent requirement in the cybersecurity community. To assist in achieving this goal, we first present an overview of the most exploited vulnerabilities in existing hardware, software, and network layers. This is followed by critiques of existing state-of-the-art mitigation techniques as why they do or don't work. We then discuss new attack patterns in emerging technologies such as social media, cloud computing, smartphone technology, and critical infrastructure. Finally, we describe our speculative observations on future research directions.",2014,Journal of Computer and System Sciences,https://www.sciencedirect.com/science/article/pii/S0022000014000178,"{'abstract': ""The exponential growth of the Internet interconnections has led to a significant growth of cyber attack incidents often with disastrous and grievous consequences. Malware is the primary choice of weapon to carry out malicious intents in the cyberspace, either by exploitation into existing vulnerabilities or utilization of unique characteristics of emerging technologies. The development of more innovative and effective malware defense mechanisms has been regarded as an urgent requirement in the cybersecurity community. To assist in achieving this goal, we first present an overview of the most exploited vulnerabilities in existing hardware, software, and network layers. This is followed by critiques of existing state-of-the-art mitigation techniques as why they do or don't work. We then discuss new attack patterns in emerging technologies such as social media, cloud computing, smartphone technology, and critical infrastructure. Finally, we describe our speculative observations on future research directions."", 'keywords': 'Cybersecurity, Malware, Emerging technology trends, Emerging cyber threats, Cyber attacks and countermeasures', 'author': 'Julian Jang-Jaccard and Surya Nepal', 'url': 'https://www.sciencedirect.com/science/article/pii/S0022000014000178', 'doi': 'https://doi.org/10.1016/j.jcss.2014.02.005', 'issn': '0022-0000', 'note': 'Special Issue on Dependable and Secure Computing', 'year': '2014', 'pages': '973-993', 'number': '5', 'volume': '80', 'journal': 'Journal of Computer and System Sciences', 'title': 'A survey of emerging threats in cybersecurity', 'ENTRYTYPE': 'article', 'ID': 'JANGJACCARD2014973'}",ScienceDirect
Ruben Rios and Carmen Fernandez-Gago and Javier Lopez,Modelling privacy-aware trust negotiations,"Secure Software Engineering, Requirements Engineering, Goal-Oriented Modelling, Trust, Privacy, Policy","Trust negotiations are mechanisms that enable interaction between previously unknown users. After exchanging various pieces of potentially sensitive information, the participants of a negotiation can decide whether or not to trust one another. Therefore, trust negotiations bring about threats to personal privacy if not carefully considered. This paper presents a framework for representing trust negotiations in the early phases of the Software Development Life Cycle (SDLC). The framework can help software engineers to determine the most suitable policies for the system by detecting conflicts between privacy and trust requirements. More precisely, we extend the SI* modelling language and provide a set of predicates for defining trust and privacy policies and a set of rules for describing the dynamics of the system based on the established policies. The formal representation of the model facilitates its automatic verification. The framework has been validated in a distributed social network scenario for connecting drivers with potential passengers willing to share a journey.",2018,Computers & Security,https://www.sciencedirect.com/science/article/pii/S0167404817302043,"{'abstract': 'Trust negotiations are mechanisms that enable interaction between previously unknown users. After exchanging various pieces of potentially sensitive information, the participants of a negotiation can decide whether or not to trust one another. Therefore, trust negotiations bring about threats to personal privacy if not carefully considered. This paper presents a framework for representing trust negotiations in the early phases of the Software Development Life Cycle (SDLC). The framework can help software engineers to determine the most suitable policies for the system by detecting conflicts between privacy and trust requirements. More precisely, we extend the SI* modelling language and provide a set of predicates for defining trust and privacy policies and a set of rules for describing the dynamics of the system based on the established policies. The formal representation of the model facilitates its automatic verification. The framework has been validated in a distributed social network scenario for connecting drivers with potential passengers willing to share a journey.', 'keywords': 'Secure Software Engineering, Requirements Engineering, Goal-Oriented Modelling, Trust, Privacy, Policy', 'author': 'Ruben Rios and Carmen Fernandez-Gago and Javier Lopez', 'url': 'https://www.sciencedirect.com/science/article/pii/S0167404817302043', 'doi': 'https://doi.org/10.1016/j.cose.2017.09.015', 'issn': '0167-4048', 'year': '2018', 'pages': '773-789', 'volume': '77', 'journal': 'Computers & Security', 'title': 'Modelling privacy-aware trust negotiations', 'ENTRYTYPE': 'article', 'ID': 'RIOS2018773'}",ScienceDirect
David Finkelhor and Lisa Jones and Kimberly Mitchell,Teaching privacy: A flawed strategy for children’s online safety,"Online grooming, Cyberbullying, Hacking, Identity theft","Teaching young people about “privacy” has serious defects if the goal is to promote children’s online safety. This commentary points out some the key problems to programs and educational modules with this privacy orientation. Privacy is an abstract and complicated concept, whose norms are in flux, making it difficult to impart clear, relevant, consensus-based messages. We also know very little about how privacy concepts develop in childhood and at what age and in what sequence, making it hard to know what to teach and when. Privacy skills are not necessarily the most important ones for preventing most online harms, including the most serious ones, casting doubt on whether they should receive priority over other prevention skills. Research has also not clearly established connections between many privacy practices and reductions in harm. Most privacy messaging has not been evaluated for how well it is learned, applied and what forms of safety it enhances. As an alternative, the promotion of online safety is best organized, not around privacy, but around the specific harms that educators and children themselves are trying to prevent. The highest priority of these are sexual exploitation, peer bullying and harassment. Such educational safety programs are best built from the foundation of evidence-based programs related to parallel offline dangers.",2021,Child Abuse & Neglect,https://www.sciencedirect.com/science/article/pii/S014521342100137X,"{'abstract': 'Teaching young people about “privacy” has serious defects if the goal is to promote children’s online safety. This commentary points out some the key problems to programs and educational modules with this privacy orientation. Privacy is an abstract and complicated concept, whose norms are in flux, making it difficult to impart clear, relevant, consensus-based messages. We also know very little about how privacy concepts develop in childhood and at what age and in what sequence, making it hard to know what to teach and when. Privacy skills are not necessarily the most important ones for preventing most online harms, including the most serious ones, casting doubt on whether they should receive priority over other prevention skills. Research has also not clearly established connections between many privacy practices and reductions in harm. Most privacy messaging has not been evaluated for how well it is learned, applied and what forms of safety it enhances. As an alternative, the promotion of online safety is best organized, not around privacy, but around the specific harms that educators and children themselves are trying to prevent. The highest priority of these are sexual exploitation, peer bullying and harassment. Such educational safety programs are best built from the foundation of evidence-based programs related to parallel offline dangers.', 'keywords': 'Online grooming, Cyberbullying, Hacking, Identity theft', 'author': 'David Finkelhor and Lisa Jones and Kimberly Mitchell', 'url': 'https://www.sciencedirect.com/science/article/pii/S014521342100137X', 'doi': 'https://doi.org/10.1016/j.chiabu.2021.105064', 'issn': '0145-2134', 'year': '2021', 'pages': '105064', 'volume': '117', 'journal': 'Child Abuse & Neglect', 'title': 'Teaching privacy: A flawed strategy for children’s online safety', 'ENTRYTYPE': 'article', 'ID': 'FINKELHOR2021105064'}",ScienceDirect
Max {von Grafenstein} and Isabel Kiefaber and Julie Heumüller and Valentin Rupp and Paul Graßl and Otto Kolless and Zsófia Puzst,Privacy icons as a component of effective transparency and controls under the GDPR: effective data protection by design based on art. 25 GDPR,"Privacy icons, Data protection by design, Privacy by design, GDPR, Effective transparency, Effective controls, UX / UI design, legal design","Understandable privacy information builds trust with users and therefore provides an important competitive advantage for the provider. However, designing privacy information that is both truthful and easy for users to understand is challenging. There are many complex balancing decisions to be made, not only with respect to legal but also visual and user experience design issues. This is why designing understandable privacy information requires combining at least three disciplines that have had little to do with each other in current practice: law, visual design, and user experience design research. The challenges of combining all three disciplines actually culminate in the design and use of Privacy Icons, which are expected to make lengthy legal texts clear and easy to understand (see Art. 12 sect. 7 of the EU General Data Protection Regulation). However, that is much easier said than done. In this paper, we summarise our key learnings from a five years research process on how to design Privacy Icons as a component of effective transparency and user controls. We will provide examples of information and control architectures for privacy policies, forms of consent (especially in the form of cookie banners), privacy dashboards and consent agents in which Privacy Icons may be embedded, 2) a non-exhaustive set of more than 150 Privacy Icons, and above all 3) a concept and process model that can be used to implement the requirements of the GDPR in terms of transparency and user controls in an effective way, according to the data protection by design approach in Art. 25 sect. 1 GDPR. The paper will show that it is a rocky road to the stars and we still haven't arrived – but at least we know how to go.",2024,Computer Law & Security Review,https://www.sciencedirect.com/science/article/pii/S0267364923001346,"{'abstract': ""Understandable privacy information builds trust with users and therefore provides an important competitive advantage for the provider. However, designing privacy information that is both truthful and easy for users to understand is challenging. There are many complex balancing decisions to be made, not only with respect to legal but also visual and user experience design issues. This is why designing understandable privacy information requires combining at least three disciplines that have had little to do with each other in current practice: law, visual design, and user experience design research. The challenges of combining all three disciplines actually culminate in the design and use of Privacy Icons, which are expected to make lengthy legal texts clear and easy to understand (see Art. 12 sect. 7 of the EU General Data Protection Regulation). However, that is much easier said than done. In this paper, we summarise our key learnings from a five years research process on how to design Privacy Icons as a component of effective transparency and user controls. We will provide examples of information and control architectures for privacy policies, forms of consent (especially in the form of cookie banners), privacy dashboards and consent agents in which Privacy Icons may be embedded, 2) a non-exhaustive set of more than 150 Privacy Icons, and above all 3) a concept and process model that can be used to implement the requirements of the GDPR in terms of transparency and user controls in an effective way, according to the data protection by design approach in Art. 25 sect. 1 GDPR. The paper will show that it is a rocky road to the stars and we still haven't arrived – but at least we know how to go."", 'keywords': 'Privacy icons, Data protection by design, Privacy by design, GDPR, Effective transparency, Effective controls, UX / UI design, legal design', 'author': 'Max {von Grafenstein} and Isabel Kiefaber and Julie Heumüller and Valentin Rupp and Paul Graßl and Otto Kolless and Zsófia Puzst', 'url': 'https://www.sciencedirect.com/science/article/pii/S0267364923001346', 'doi': 'https://doi.org/10.1016/j.clsr.2023.105924', 'issn': '0267-3649', 'year': '2024', 'pages': '105924', 'volume': '52', 'journal': 'Computer Law & Security Review', 'title': 'Privacy icons as a component of effective transparency and controls under the GDPR: effective data protection by design based on art. 25 GDPR', 'ENTRYTYPE': 'article', 'ID': 'VONGRAFENSTEIN2024105924'}",ScienceDirect
Anna C. Squicciarini and Federica Paci and Elisa Bertino,Trust establishment in the formation of Virtual Organizations,"Trust negotiation, Virtual Organization, Semantic of trust","Virtual Organizations (VOs) represent a new collaboration paradigm in which the participating entities pool resources, services, and information to achieve a common goal. VOs represent an interesting approach for companies to achieve new and profitable business opportunities by being able to dynamically partner with others. Thus, choosing the appropriate VO partners is a crucial aspect. Ensuring trustworthiness of the members is also fundamental for making the best decisions. In this paper, we show how trust negotiation represents an effective means to select the best possible members during different stages in the VO lifecycle. We base our discussion on concrete application scenarios and illustrate the tools created by us that integrate trust negotiation with a VO Management toolkit.",2011,Computer Standards & Interfaces,https://www.sciencedirect.com/science/article/pii/S0920548910000310,"{'abstract': 'Virtual Organizations (VOs) represent a new collaboration paradigm in which the participating entities pool resources, services, and information to achieve a common goal. VOs represent an interesting approach for companies to achieve new and profitable business opportunities by being able to dynamically partner with others. Thus, choosing the appropriate VO partners is a crucial aspect. Ensuring trustworthiness of the members is also fundamental for making the best decisions. In this paper, we show how trust negotiation represents an effective means to select the best possible members during different stages in the VO lifecycle. We base our discussion on concrete application scenarios and illustrate the tools created by us that integrate trust negotiation with a VO Management toolkit.', 'keywords': 'Trust negotiation, Virtual Organization, Semantic of trust', 'author': 'Anna C. Squicciarini and Federica Paci and Elisa Bertino', 'url': 'https://www.sciencedirect.com/science/article/pii/S0920548910000310', 'doi': 'https://doi.org/10.1016/j.csi.2010.03.003', 'issn': '0920-5489', 'note': 'Special Issue: Secure Semantic Web', 'year': '2011', 'pages': '13-23', 'number': '1', 'volume': '33', 'journal': 'Computer Standards & Interfaces', 'title': 'Trust establishment in the formation of Virtual Organizations', 'ENTRYTYPE': 'article', 'ID': 'SQUICCIARINI201113'}",ScienceDirect
Md Mosarrof Hossen and Azad Ashraf and Mazhar Hasan and Molla E. Majid and Mohammad Nashbat and Saad Bin Abul Kashem and Ali K. Ansaruddin Kunju and Amith Khandakar and Sakib Mahmud and Muhammad E.H. Chowdhury,GCDN-Net: Garbage classifier deep neural network for recyclable urban waste management,"Waste Management, Recycling, Waste Classification, Multi-label Classification, Convolutional Neural Network (CNN), Deep Learning","The escalating waste volume due to urbanization and population growth has underscored the need for advanced waste sorting and recycling methods to ensure sustainable waste management. Deep learning models, adept at image recognition tasks, offer potential solutions for waste sorting applications. These models, trained on extensive waste image datasets, possess the ability to discern unique features of diverse waste types. Automating waste sorting hinges on robust deep learning models capable of accurately categorizing a wide range of waste types. In this study, a multi-stage machine learning approach is proposed to classify different waste categories using the “Garbage In, Garbage Out” (GIGO) dataset of 25,000 images. The novel Garbage Classifier Deep Neural Network (GCDN-Net) is introduced as a comprehensive solution, adept in both single-label and multi-label classification tasks. Single-label classification distinguishes between garbage and non-garbage images, while multi-label classification identifies distinct garbage categories within single or multiple images. The performance of GCDN-Net is rigorously evaluated and compared against state-of-the-art waste classification methods. Results demonstrate GCDN-Net's excellence, achieving 95.77% accuracy, 95.78% precision, 95.77% recall, 95.77% F1-score, and 95.54% specificity when classifying waste images, outperforming existing models in single-label classification. In multi-label classification, GCDN-Net attains an overall Mean Average Precision (mAP) of 0.69 and an F1-score of 75.01%. The reliability of network performance is affirmed through saliency map-based visualization generated by Score-CAM (class activation mapping). In conclusion, deep learning-based models exhibit efficacy in categorizing diverse waste types, paving the way for automated waste sorting and recycling systems that can mitigate costs and processing times.",2024,Waste Management,https://www.sciencedirect.com/science/article/pii/S0956053X23007511,"{'abstract': ""The escalating waste volume due to urbanization and population growth has underscored the need for advanced waste sorting and recycling methods to ensure sustainable waste management. Deep learning models, adept at image recognition tasks, offer potential solutions for waste sorting applications. These models, trained on extensive waste image datasets, possess the ability to discern unique features of diverse waste types. Automating waste sorting hinges on robust deep learning models capable of accurately categorizing a wide range of waste types. In this study, a multi-stage machine learning approach is proposed to classify different waste categories using the “Garbage In, Garbage Out” (GIGO) dataset of 25,000 images. The novel Garbage Classifier Deep Neural Network (GCDN-Net) is introduced as a comprehensive solution, adept in both single-label and multi-label classification tasks. Single-label classification distinguishes between garbage and non-garbage images, while multi-label classification identifies distinct garbage categories within single or multiple images. The performance of GCDN-Net is rigorously evaluated and compared against state-of-the-art waste classification methods. Results demonstrate GCDN-Net's excellence, achieving 95.77% accuracy, 95.78% precision, 95.77% recall, 95.77% F1-score, and 95.54% specificity when classifying waste images, outperforming existing models in single-label classification. In multi-label classification, GCDN-Net attains an overall Mean Average Precision (mAP) of 0.69 and an F1-score of 75.01%. The reliability of network performance is affirmed through saliency map-based visualization generated by Score-CAM (class activation mapping). In conclusion, deep learning-based models exhibit efficacy in categorizing diverse waste types, paving the way for automated waste sorting and recycling systems that can mitigate costs and processing times."", 'keywords': 'Waste Management, Recycling, Waste Classification, Multi-label Classification, Convolutional Neural Network (CNN), Deep Learning', 'author': 'Md Mosarrof Hossen and Azad Ashraf and Mazhar Hasan and Molla E. Majid and Mohammad Nashbat and Saad Bin Abul Kashem and Ali K. Ansaruddin Kunju and Amith Khandakar and Sakib Mahmud and Muhammad E.H. Chowdhury', 'url': 'https://www.sciencedirect.com/science/article/pii/S0956053X23007511', 'doi': 'https://doi.org/10.1016/j.wasman.2023.12.014', 'issn': '0956-053X', 'year': '2024', 'pages': '439-450', 'volume': '174', 'journal': 'Waste Management', 'title': 'GCDN-Net: Garbage classifier deep neural network for recyclable urban waste management', 'ENTRYTYPE': 'article', 'ID': 'HOSSEN2024439'}",ScienceDirect
,Digging deeper for evidence,,Researchers have found a way of making more auditable data available for forensics.,2008,Computer Fraud & Security,https://www.sciencedirect.com/science/article/pii/S1361372308700794,"{'abstract': 'Researchers have found a way of making more auditable data available for forensics.', 'url': 'https://www.sciencedirect.com/science/article/pii/S1361372308700794', 'doi': 'https://doi.org/10.1016/S1361-3723(08)70079-4', 'issn': '1361-3723', 'year': '2008', 'pages': '4', 'number': '5', 'volume': '2008', 'journal': 'Computer Fraud & Security', 'title': 'Digging deeper for evidence', 'ENTRYTYPE': 'article', 'ID': '20084'}",ScienceDirect
Cathy A. Simpson and Jalie A. Tucker,"Temporal sequencing of alcohol-related problems, problem recognition, and help-seeking episodes","Alcohol abuse, Help seeking, Developmental sequence","Little is known about temporal relations between the development of alcohol-related problems, self-recognition of problems, and help seeking from professional and lay sources. The sequencing of these events was investigated retrospectively using a community sample of male and female problem drinkers (N=101) who varied in their help-seeking histories [no assistance, Alcoholics Anonymous (AA)-only, or treatment-plus-AA] and current drinking status (resolved abstinent or nonresolved). The rank-order of events was similar across groups and gender. Problem recognition typically occurred early with the onset of pathological drinking and related psychosocial problems. Health problems and help seeking were late developments, if they occurred at all. Although the sequence order was similar across groups, the latency to help seeking varied; help seeking was more rapid among women, resolved participants, and participants who had sought help from both treatment and AA. The findings question conventional views that denial deters help seeking and suggest opportunities for screening and early intervention.",2002,Addictive Behaviors,https://www.sciencedirect.com/science/article/pii/S0306460301002003,"{'abstract': 'Little is known about temporal relations between the development of alcohol-related problems, self-recognition of problems, and help seeking from professional and lay sources. The sequencing of these events was investigated retrospectively using a community sample of male and female problem drinkers (N=101) who varied in their help-seeking histories [no assistance, Alcoholics Anonymous (AA)-only, or treatment-plus-AA] and current drinking status (resolved abstinent or nonresolved). The rank-order of events was similar across groups and gender. Problem recognition typically occurred early with the onset of pathological drinking and related psychosocial problems. Health problems and help seeking were late developments, if they occurred at all. Although the sequence order was similar across groups, the latency to help seeking varied; help seeking was more rapid among women, resolved participants, and participants who had sought help from both treatment and AA. The findings question conventional views that denial deters help seeking and suggest opportunities for screening and early intervention.', 'keywords': 'Alcohol abuse, Help seeking, Developmental sequence', 'author': 'Cathy A. Simpson and Jalie A. Tucker', 'url': 'https://www.sciencedirect.com/science/article/pii/S0306460301002003', 'doi': 'https://doi.org/10.1016/S0306-4603(01)00200-3', 'issn': '0306-4603', 'year': '2002', 'pages': '659-674', 'number': '5', 'volume': '27', 'journal': 'Addictive Behaviors', 'title': 'Temporal sequencing of alcohol-related problems, problem recognition, and help-seeking episodes', 'ENTRYTYPE': 'article', 'ID': 'SIMPSON2002659'}",ScienceDirect
Intidhar Essefi and Hanene Boussi Rahmouni and Mohamed Fethi Ladeb,Integrated privacy decision in BPMN clinical care pathways models using DMN,"BPMN, care pathways, Digital transformation, DMN, GDPR, HIPAA, protection methods, security labels, sensitive data","Personal data is highly affected by the witnessed digital transformation of healthcare processes. This process relies deeply on the connectivity and decentralization of healthcare systems and data repositories. In this context, value creation and quality enhancement are obviously leveraged, however both health providers and individuals could be exposed to many risks ranging from privacy violations to medical identity theft and personal harm. Hence, it is essential that healthcare stakeholders ensure privacy protection and systemic compliance to personal data regulations such as HIPPA (Health Insurance Portability and Accountability Act) and GDPR (General Data Protection Regulation). Taking clinical processes as a starting point is very important to highlight the personal data in use and to assess whether such usage is justifiable and subsequently allow privacy management decisions to be made. In this paper we combine BPMN (Business Process Model and Notation) and DMN (Decision Model and Notation) to model clinical care pathways as standard business processing constituting the hospital information system. Business process modelling presents a useful mean to model clinical care pathways. It allows a complete discovery of data processing scenarios. DMN (Decision Model and Notation) is implemented in BPMN models to present the rules that lead to a decision in easy-to-read tables which are executed directly by a decision engine. In addition, the integration of verifiable security labels of the manipulated data, we make sure compliance to legislation is ensured at the level of decision rules for each decision table of the DMN.",2022,Procedia Computer Science,https://www.sciencedirect.com/science/article/pii/S1877050921022663,"{'abstract': 'Personal data is highly affected by the witnessed digital transformation of healthcare processes. This process relies deeply on the connectivity and decentralization of healthcare systems and data repositories. In this context, value creation and quality enhancement are obviously leveraged, however both health providers and individuals could be exposed to many risks ranging from privacy violations to medical identity theft and personal harm. Hence, it is essential that healthcare stakeholders ensure privacy protection and systemic compliance to personal data regulations such as HIPPA (Health Insurance Portability and Accountability Act) and GDPR (General Data Protection Regulation). Taking clinical processes as a starting point is very important to highlight the personal data in use and to assess whether such usage is justifiable and subsequently allow privacy management decisions to be made. In this paper we combine BPMN (Business Process Model and Notation) and DMN (Decision Model and Notation) to model clinical care pathways as standard business processing constituting the hospital information system. Business process modelling presents a useful mean to model clinical care pathways. It allows a complete discovery of data processing scenarios. DMN (Decision Model and Notation) is implemented in BPMN models to present the rules that lead to a decision in easy-to-read tables which are executed directly by a decision engine. In addition, the integration of verifiable security labels of the manipulated data, we make sure compliance to legislation is ensured at the level of decision rules for each decision table of the DMN.', 'keywords': 'BPMN, care pathways, Digital transformation, DMN, GDPR, HIPAA, protection methods, security labels, sensitive data', 'author': 'Intidhar Essefi and Hanene Boussi Rahmouni and Mohamed Fethi Ladeb', 'url': 'https://www.sciencedirect.com/science/article/pii/S1877050921022663', 'doi': 'https://doi.org/10.1016/j.procs.2021.12.043', 'issn': '1877-0509', 'note': 'International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies 2021', 'year': '2022', 'pages': '509-516', 'volume': '196', 'journal': 'Procedia Computer Science', 'title': 'Integrated privacy decision in BPMN clinical care pathways models using DMN', 'ENTRYTYPE': 'article', 'ID': 'ESSEFI2022509'}",ScienceDirect
Mika Kortesniemi and Virginia Tsapaki and Annalisa Trianni and Paolo Russo and Ad Maas and Hans-Erik Källman and Marco Brambilla and John Damilakis,The European Federation of Organisations for Medical Physics (EFOMP) White Paper: Big data and deep learning in medical imaging and in relation to medical physics profession,,"Big data and deep learning will profoundly change various areas of professions and research in the future. This will also happen in medicine and medical imaging in particular. As medical physicists, we should pursue beyond the concept of technical quality to extend our methodology and competence towards measuring and optimising the diagnostic value in terms of how it is connected to care outcome. Functional implementation of such methodology requires data processing utilities starting from data collection and management and culminating in the data analysis methods. Data quality control and validation are prerequisites for the deep learning application in order to provide reliable further analysis, classification, interpretation, probabilistic and predictive modelling from the vast heterogeneous big data. Challenges in practical data analytics relate to both horizontal and longitudinal analysis aspects. Quantitative aspects of data validation, quality control, physically meaningful measures, parameter connections and system modelling for the future artificial intelligence (AI) methods are positioned firmly in the field of Medical Physics profession. It is our interest to ensure that our professional education, continuous training and competence will follow this significant global development.",2018,Physica Medica,https://www.sciencedirect.com/science/article/pii/S1120179718313152,"{'abstract': 'Big data and deep learning will profoundly change various areas of professions and research in the future. This will also happen in medicine and medical imaging in particular. As medical physicists, we should pursue beyond the concept of technical quality to extend our methodology and competence towards measuring and optimising the diagnostic value in terms of how it is connected to care outcome. Functional implementation of such methodology requires data processing utilities starting from data collection and management and culminating in the data analysis methods. Data quality control and validation are prerequisites for the deep learning application in order to provide reliable further analysis, classification, interpretation, probabilistic and predictive modelling from the vast heterogeneous big data. Challenges in practical data analytics relate to both horizontal and longitudinal analysis aspects. Quantitative aspects of data validation, quality control, physically meaningful measures, parameter connections and system modelling for the future artificial intelligence (AI) methods are positioned firmly in the field of Medical Physics profession. It is our interest to ensure that our professional education, continuous training and competence will follow this significant global development.', 'author': 'Mika Kortesniemi and Virginia Tsapaki and Annalisa Trianni and Paolo Russo and Ad Maas and Hans-Erik Källman and Marco Brambilla and John Damilakis', 'url': 'https://www.sciencedirect.com/science/article/pii/S1120179718313152', 'doi': 'https://doi.org/10.1016/j.ejmp.2018.11.005', 'issn': '1120-1797', 'year': '2018', 'pages': '90-93', 'volume': '56', 'journal': 'Physica Medica', 'title': 'The European Federation of Organisations for Medical Physics (EFOMP) White Paper: Big data and deep learning in medical imaging and in relation to medical physics profession', 'ENTRYTYPE': 'article', 'ID': 'KORTESNIEMI201890'}",ScienceDirect
Simone Fischer-Hbner and Stefan Berthold,Chapter 53 - Privacy-Enhancing Technologies,"Data minimization, Data subjects, Legal privacy, Legitimacy, Personal privacy, Privacy, Privacy-enhancing technologies, Purpose limitation, Purpose specification, Transparency","In our modern information age, recent technical developments and trends, such as mobile and pervasive computing, big data, cloud computing, and Web 2.0 applications, increasingly pose privacy dilemmas. Due to the low costs and technical advances of storage technologies, masses of personal data can easily be stored. Once disclosed, these data may be retained forever, often without the knowledge of the individuals concerned, and be removed with difficulty. Hence, it has become hard for individuals to manage and control their personal spheres. Both legal and technical means are needed to protect privacy and to (re-)establish the individuals' control. This chapter provides an overview to the area of Privacy-Enhancing Technologies (PETs), which help to protect privacy by technically enforcing legal privacy principles. It will start with defining the legal foundations of PETs, and will present a classification of PETs as well as a definition of traditional privacy properties that PETs are addressing and metrics for measuring the level of privacy that PETs are providing. Then, a selection of the most relevant PETs is presented.",2017,Computer and Information Security Handbook (Third Edition),https://www.sciencedirect.com/science/article/pii/B9780128038437000533,"{'abstract': ""In our modern information age, recent technical developments and trends, such as mobile and pervasive computing, big data, cloud computing, and Web 2.0 applications, increasingly pose privacy dilemmas. Due to the low costs and technical advances of storage technologies, masses of personal data can easily be stored. Once disclosed, these data may be retained forever, often without the knowledge of the individuals concerned, and be removed with difficulty. Hence, it has become hard for individuals to manage and control their personal spheres. Both legal and technical means are needed to protect privacy and to (re-)establish the individuals' control. This chapter provides an overview to the area of Privacy-Enhancing Technologies (PETs), which help to protect privacy by technically enforcing legal privacy principles. It will start with defining the legal foundations of PETs, and will present a classification of PETs as well as a definition of traditional privacy properties that PETs are addressing and metrics for measuring the level of privacy that PETs are providing. Then, a selection of the most relevant PETs is presented."", 'keywords': 'Data minimization, Data subjects, Legal privacy, Legitimacy, Personal privacy, Privacy, Privacy-enhancing technologies, Purpose limitation, Purpose specification, Transparency', 'author': 'Simone Fischer-Hbner and Stefan Berthold', 'url': 'https://www.sciencedirect.com/science/article/pii/B9780128038437000533', 'doi': 'https://doi.org/10.1016/B978-0-12-803843-7.00053-3', 'isbn': '978-0-12-803843-7', 'year': '2017', 'pages': '759-778', 'address': 'Boston', 'edition': 'Third Edition', 'publisher': 'Morgan Kaufmann', 'booktitle': 'Computer and Information Security Handbook (Third Edition)', 'editor': 'John R. Vacca', 'title': 'Chapter 53 - Privacy-Enhancing Technologies', 'ENTRYTYPE': 'incollection', 'ID': 'FISCHERHBNER2017759'}",ScienceDirect
Jean-Marc Dinant,2 - Law and technology convergence: electronic threats on personal data and electronic data protection on the Internet,,,2001,E-Commerce Law and Practice in Europe,https://www.sciencedirect.com/science/article/pii/B978185573580450015X,"{'author': 'Jean-Marc Dinant', 'url': 'https://www.sciencedirect.com/science/article/pii/B978185573580450015X', 'doi': 'https://doi.org/10.1016/B978-1-85573-580-4.50015-X', 'isbn': '978-1-85573-580-4', 'year': '2001', 'pages': '1-22', 'publisher': 'Woodhead Publishing', 'booktitle': 'E-Commerce Law and Practice in Europe', 'editor': 'Ian Walden and Julia Hörnle', 'title': '2 - Law and technology convergence: electronic threats on personal data and electronic data protection on the Internet', 'ENTRYTYPE': 'incollection', 'ID': 'DINANT20011'}",ScienceDirect
Muhammad Ahmad Nawaz {Ul Ghani} and Kun She and Muhammad Arslan Rauf and Masoud Alajmi and Yazeed Yasin Ghadi and Abdulmohsen Algarni,Securing synthetic faces: A GAN-blockchain approach to privacy-enhanced facial recognition,"Face recognition, GANs, Blockchain, Clustering, Privacy, Security","In recent years, facial recognition technology has become increasingly integrated into society, making privacy protection crucial. Previous techniques offered minimal secrecy safeguards through simple obscuration methods. This paper addresses the strict privacy requirements of face image data by developing a novel framework that synergistically integrates Generative Adversarial Networks (GANs), clustering algorithms, and Blockchain technology. The methodology proposes a cutting-edge Privacy-Preserving Self-Attention GAN (PPSA-GAN) to generate realistic synthetic facial imagery. An integrated mini-batch K-means clustering algorithm anonymizes these images into distinct groupings, maximizing privacy preservation. Blockchain integration complements the system by fortifying trust through decentralized ledgers for transparent yet secure data storage and auditing. Rigorous benchmarking on the CelebA dataset confirms the PPSA-GAN architecture’s state-of-the-art performance, attaining an impressive Inception Score of 13.99 and a Fréchet Inception Distance of 35.50. The mini-batch clustering forms 125 distinct clusters, effectively anonymizing facial attributes within the synthetic images. Blockchain integration further bolsters privacy assurances via tamper-proof historical records, showcasing precision, recall, F1-score, and accuracy values of 0.948, 0.938, 0.943, and 0.947, respectively. This multifunctional framework represents a novel contribution, fostering an ethical technological ecosystem that balances progress and privacy. Prospective deployment horizons encompass identity verification, surveillance infrastructure, and augmentation of medical image repositories, seeding an enlightening future for facial recognition domains.",2024,Journal of King Saud University - Computer and Information Sciences,https://www.sciencedirect.com/science/article/pii/S1319157824001253,"{'abstract': 'In recent years, facial recognition technology has become increasingly integrated into society, making privacy protection crucial. Previous techniques offered minimal secrecy safeguards through simple obscuration methods. This paper addresses the strict privacy requirements of face image data by developing a novel framework that synergistically integrates Generative Adversarial Networks (GANs), clustering algorithms, and Blockchain technology. The methodology proposes a cutting-edge Privacy-Preserving Self-Attention GAN (PPSA-GAN) to generate realistic synthetic facial imagery. An integrated mini-batch K-means clustering algorithm anonymizes these images into distinct groupings, maximizing privacy preservation. Blockchain integration complements the system by fortifying trust through decentralized ledgers for transparent yet secure data storage and auditing. Rigorous benchmarking on the CelebA dataset confirms the PPSA-GAN architecture’s state-of-the-art performance, attaining an impressive Inception Score of 13.99 and a Fréchet Inception Distance of 35.50. The mini-batch clustering forms 125 distinct clusters, effectively anonymizing facial attributes within the synthetic images. Blockchain integration further bolsters privacy assurances via tamper-proof historical records, showcasing precision, recall, F1-score, and accuracy values of 0.948, 0.938, 0.943, and 0.947, respectively. This multifunctional framework represents a novel contribution, fostering an ethical technological ecosystem that balances progress and privacy. Prospective deployment horizons encompass identity verification, surveillance infrastructure, and augmentation of medical image repositories, seeding an enlightening future for facial recognition domains.', 'keywords': 'Face recognition, GANs, Blockchain, Clustering, Privacy, Security', 'author': 'Muhammad Ahmad Nawaz {Ul Ghani} and Kun She and Muhammad Arslan Rauf and Masoud Alajmi and Yazeed Yasin Ghadi and Abdulmohsen Algarni', 'url': 'https://www.sciencedirect.com/science/article/pii/S1319157824001253', 'doi': 'https://doi.org/10.1016/j.jksuci.2024.102036', 'issn': '1319-1578', 'year': '2024', 'pages': '102036', 'number': '4', 'volume': '36', 'journal': 'Journal of King Saud University - Computer and Information Sciences', 'title': 'Securing synthetic faces: A GAN-blockchain approach to privacy-enhanced facial recognition', 'ENTRYTYPE': 'article', 'ID': 'ULGHANI2024102036'}",ScienceDirect
Borka Jerman-Blažič and Tomaž Klobučar,Privacy provision in e-learning standardized systems: status and improvements,"E-learning systems, Standardization, Learner profile, Privacy","Privacy is understood as a freedom from intrusion into the private life or affairs of an individual when that intrusion results from undue or illegal gathering and use of data about that individual. Appropriate use of technologies may provide privacy and data protection; however, these technologies require relevant attributes in the databases containing information that need protection. These are not obvious in the existing e-learning standard schemes. This paper discusses first the current e-learning standards regarding the schemes used for defining, storing and managing user profiles in e-learning standardized systems. Later, it gives an overview of the requirements for privacy provision and discusses the elements required in such systems. Comments and assessments of the existing solutions are given. An enhanced solution being developed within the ELENA project from the European IST 5th Framework Programme is described. The new solution is built up on the existing standards, but it introduces new features enabling better protection of sensitive data and more efficient management, enabling the users to decide about the relevant protection.",2005,Computer Standards & Interfaces,https://www.sciencedirect.com/science/article/pii/S0920548904001047,"{'abstract': 'Privacy is understood as a freedom from intrusion into the private life or affairs of an individual when that intrusion results from undue or illegal gathering and use of data about that individual. Appropriate use of technologies may provide privacy and data protection; however, these technologies require relevant attributes in the databases containing information that need protection. These are not obvious in the existing e-learning standard schemes. This paper discusses first the current e-learning standards regarding the schemes used for defining, storing and managing user profiles in e-learning standardized systems. Later, it gives an overview of the requirements for privacy provision and discusses the elements required in such systems. Comments and assessments of the existing solutions are given. An enhanced solution being developed within the ELENA project from the European IST 5th Framework Programme is described. The new solution is built up on the existing standards, but it introduces new features enabling better protection of sensitive data and more efficient management, enabling the users to decide about the relevant protection.', 'keywords': 'E-learning systems, Standardization, Learner profile, Privacy', 'author': 'Borka Jerman-Blažič and Tomaž Klobučar', 'url': 'https://www.sciencedirect.com/science/article/pii/S0920548904001047', 'doi': 'https://doi.org/10.1016/j.csi.2004.09.006', 'issn': '0920-5489', 'year': '2005', 'pages': '561-578', 'number': '6', 'volume': '27', 'journal': 'Computer Standards & Interfaces', 'title': 'Privacy provision in e-learning standardized systems: status and improvements', 'ENTRYTYPE': 'article', 'ID': 'JERMANBLAZIC2005561'}",ScienceDirect
Stella Ho and Youyang Qu and Bruce Gu and Longxiang Gao and Jianxin Li and Yong Xiang,DP-GAN: Differentially private consecutive data publishing using generative adversarial nets,"Continual data release, Differential privacy, Generative adversarial nets","In the era of big data, increasingly massive volumes of data is generated and published consecutively for both research and commercial purposes. The potential value of sensitive information also attracts interest from adversaries and thereby arises public concern. Current research mostly focuses on privacy-preserving data publishing in a statistic manner rather than taking the dynamics and correlation of context into consideration. Motivated by this, we propose a novel idea that combining differential privacy and generative adversarial nets. Generative adversarial nets and its extensions are used to generate a synthetic dataset with indistinguishable statistic features while differential privacy guarantees a trade-off between privacy protection and data utility. By employing a min-max game with three players, we devise a deep generative model, namely DP-GAN model, for synthetic data generation while fulfilling the privacy constraints in a differentially private manner. Extensive simulation results on a real-world dataset testify the superiority of the proposed model in terms of privacy protection, data utility, and efficiency.",2021,Journal of Network and Computer Applications,https://www.sciencedirect.com/science/article/pii/S1084804521000904,"{'abstract': 'In the era of big data, increasingly massive volumes of data is generated and published consecutively for both research and commercial purposes. The potential value of sensitive information also attracts interest from adversaries and thereby arises public concern. Current research mostly focuses on privacy-preserving data publishing in a statistic manner rather than taking the dynamics and correlation of context into consideration. Motivated by this, we propose a novel idea that combining differential privacy and generative adversarial nets. Generative adversarial nets and its extensions are used to generate a synthetic dataset with indistinguishable statistic features while differential privacy guarantees a trade-off between privacy protection and data utility. By employing a min-max game with three players, we devise a deep generative model, namely DP-GAN model, for synthetic data generation while fulfilling the privacy constraints in a differentially private manner. Extensive simulation results on a real-world dataset testify the superiority of the proposed model in terms of privacy protection, data utility, and efficiency.', 'keywords': 'Continual data release, Differential privacy, Generative adversarial nets', 'author': 'Stella Ho and Youyang Qu and Bruce Gu and Longxiang Gao and Jianxin Li and Yong Xiang', 'url': 'https://www.sciencedirect.com/science/article/pii/S1084804521000904', 'doi': 'https://doi.org/10.1016/j.jnca.2021.103066', 'issn': '1084-8045', 'year': '2021', 'pages': '103066', 'volume': '185', 'journal': 'Journal of Network and Computer Applications', 'title': 'DP-GAN: Differentially private consecutive data publishing using generative adversarial nets', 'ENTRYTYPE': 'article', 'ID': 'HO2021103066'}",ScienceDirect
Constantin Landers and Blanche Wies and Marcello Ienca,Chapter 16 - Ethical considerations of digital therapeutics for mental health,"Digital Therapeutics, Mental Health, Depression, Addiction, Privacy, Transparency, Autonomy, Clinical validation, HCP responsibility, Doctor responsibility","This chapter provides an overview of the ethical issues that arise when healthcare practitioners (HCPs) prescribe or recommend digital therapeutics, in particular for treating mental health and addiction issues. We show that the lack of adequate clinical validation and regulatory frameworks for digital therapeutics leaves HCPs with particularly high responsibility. We group ethical issues into those affecting patients directly, those arising for society, and HCPs’ new roles and responsibilities. We identify privacy, transparency, autonomy, lack of clinical validation, fairness, and equality, as well as HCP's changing responsibilities and roles as major ethical issues. We illustrate why these issues matter for patients and society, discuss how and where they occur in practice and provide suggestions on what HCPs can practically do about these issues. We argue that HCPs have high overall responsibility and should pay special attention to ethical issues when recommending digital therapeutics or using them with their patients.",2023,Digital Therapeutics for Mental Health and Addiction,https://www.sciencedirect.com/science/article/pii/B9780323900454000071,"{'abstract': ""This chapter provides an overview of the ethical issues that arise when healthcare practitioners (HCPs) prescribe or recommend digital therapeutics, in particular for treating mental health and addiction issues. We show that the lack of adequate clinical validation and regulatory frameworks for digital therapeutics leaves HCPs with particularly high responsibility. We group ethical issues into those affecting patients directly, those arising for society, and HCPs’ new roles and responsibilities. We identify privacy, transparency, autonomy, lack of clinical validation, fairness, and equality, as well as HCP's changing responsibilities and roles as major ethical issues. We illustrate why these issues matter for patients and society, discuss how and where they occur in practice and provide suggestions on what HCPs can practically do about these issues. We argue that HCPs have high overall responsibility and should pay special attention to ethical issues when recommending digital therapeutics or using them with their patients."", 'keywords': 'Digital Therapeutics, Mental Health, Depression, Addiction, Privacy, Transparency, Autonomy, Clinical validation, HCP responsibility, Doctor responsibility', 'author': 'Constantin Landers and Blanche Wies and Marcello Ienca', 'url': 'https://www.sciencedirect.com/science/article/pii/B9780323900454000071', 'doi': 'https://doi.org/10.1016/B978-0-323-90045-4.00007-1', 'isbn': '978-0-323-90045-4', 'year': '2023', 'pages': '205-217', 'publisher': 'Academic Press', 'booktitle': 'Digital Therapeutics for Mental Health and Addiction', 'editor': 'Nicholas Jacobson and Tobias Kowatsch and Lisa Marsch', 'title': 'Chapter 16 - Ethical considerations of digital therapeutics for mental health', 'ENTRYTYPE': 'incollection', 'ID': 'LANDERS2023205'}",ScienceDirect
Ruggero G. Pensa and Gianpiero {Di Blasi},A privacy self-assessment framework for online social networks,"Privacy measures, Online social networks, Active learning","During our digital social life, we share terabytes of information that can potentially reveal private facts and personality traits to unexpected strangers. Despite the research efforts aiming at providing efficient solutions for the anonymization of huge databases (including networked data), in online social networks the most powerful privacy protection “weapons” are the users themselves. However, most users are not aware of the risks derived by the indiscriminate disclosure of their personal data. Moreover, even when social networking platforms allow their participants to control the privacy level of every published item, adopting a correct privacy policy is often an annoying and frustrating task and many users prefer to adopt simple but extreme strategies such as “visible-to-all” (exposing themselves to the highest risk), or “hidden-to-all” (wasting the positive social and economic potential of social networking websites). In this paper we propose a theoretical framework to i) measure the privacy risk of the users and alert them whenever their privacy is compromised and ii) help the users customize semi-automatically their privacy settings by limiting the number of manual operations. By investigating the relationship between the privacy measure and privacy preferences of real Facebook users, we show the effectiveness of our framework.",2017,Expert Systems with Applications,https://www.sciencedirect.com/science/article/pii/S0957417417303767,"{'abstract': 'During our digital social life, we share terabytes of information that can potentially reveal private facts and personality traits to unexpected strangers. Despite the research efforts aiming at providing efficient solutions for the anonymization of huge databases (including networked data), in online social networks the most powerful privacy protection “weapons” are the users themselves. However, most users are not aware of the risks derived by the indiscriminate disclosure of their personal data. Moreover, even when social networking platforms allow their participants to control the privacy level of every published item, adopting a correct privacy policy is often an annoying and frustrating task and many users prefer to adopt simple but extreme strategies such as “visible-to-all” (exposing themselves to the highest risk), or “hidden-to-all” (wasting the positive social and economic potential of social networking websites). In this paper we propose a theoretical framework to i) measure the privacy risk of the users and alert them whenever their privacy is compromised and ii) help the users customize semi-automatically their privacy settings by limiting the number of manual operations. By investigating the relationship between the privacy measure and privacy preferences of real Facebook users, we show the effectiveness of our framework.', 'keywords': 'Privacy measures, Online social networks, Active learning', 'author': 'Ruggero G. Pensa and Gianpiero {Di Blasi}', 'url': 'https://www.sciencedirect.com/science/article/pii/S0957417417303767', 'doi': 'https://doi.org/10.1016/j.eswa.2017.05.054', 'issn': '0957-4174', 'year': '2017', 'pages': '18-31', 'volume': '86', 'journal': 'Expert Systems with Applications', 'title': 'A privacy self-assessment framework for online social networks', 'ENTRYTYPE': 'article', 'ID': 'PENSA201718'}",ScienceDirect
Simone Fischer-Hbner and Stefan Berthold,Chapter 43 - Privacy-Enhancing Technologies11Parts of this work were conducted within the scope of the PetWeb II project funded by the Norwegian Research Council (NFR) and the U-PrIM project funded by the Swedish Knowledge (KK) Foundation.,"privacy, privacy-enhancing technologies, personal privacy, legal privacy, legitimacy, purpose specification, purpose limitation, data minimization, transparency, data subjects","In our modern information age, recent technical developments and trends, such as mobile and pervasive computing, cloud computing, and Web 2.0 applications, increasingly pose privacy dilemmas. Due to the low costs and technical advances of storage technologies, masses of personal data can easily be stored. Once disclosed, these data may be retained forever, often without the knowledge of the individuals concerned, and be removed with difficulty. Hence, it has become hard for individuals to manage and control their personal spheres. Both legal and technical means are needed to protect privacy and to (re)establish the individuals’ control. This chapter provides an overview to the area of privacy-enhancing technologies (PETs), which help to protect privacy by technically enforcing legal privacy principles. It will start with defining the legal foundations of PETs and will present a classification of PETs as well as a definition of traditional privacy properties that PETs are addressing and metrics for measuring the level of privacy that PETs are providing. Then, a selection of the most relevant PETs is presented.",2013,Computer and Information Security Handbook (Second Edition),https://www.sciencedirect.com/science/article/pii/B978012394397200043X,"{'abstract': 'In our modern information age, recent technical developments and trends, such as mobile and pervasive computing, cloud computing, and Web 2.0 applications, increasingly pose privacy dilemmas. Due to the low costs and technical advances of storage technologies, masses of personal data can easily be stored. Once disclosed, these data may be retained forever, often without the knowledge of the individuals concerned, and be removed with difficulty. Hence, it has become hard for individuals to manage and control their personal spheres. Both legal and technical means are needed to protect privacy and to (re)establish the individuals’ control. This chapter provides an overview to the area of privacy-enhancing technologies (PETs), which help to protect privacy by technically enforcing legal privacy principles. It will start with defining the legal foundations of PETs and will present a classification of PETs as well as a definition of traditional privacy properties that PETs are addressing and metrics for measuring the level of privacy that PETs are providing. Then, a selection of the most relevant PETs is presented.', 'keywords': 'privacy, privacy-enhancing technologies, personal privacy, legal privacy, legitimacy, purpose specification, purpose limitation, data minimization, transparency, data subjects', 'author': 'Simone Fischer-Hbner and Stefan Berthold', 'url': 'https://www.sciencedirect.com/science/article/pii/B978012394397200043X', 'doi': 'https://doi.org/10.1016/B978-0-12-394397-2.00043-X', 'isbn': '978-0-12-394397-2', 'year': '2013', 'pages': '755-772', 'address': 'Boston', 'edition': 'Second Edition', 'publisher': 'Morgan Kaufmann', 'booktitle': 'Computer and Information Security Handbook (Second Edition)', 'editor': 'John R. Vacca', 'title': 'Chapter 43 - Privacy-Enhancing Technologies11Parts of this work were conducted within the scope of the PetWeb II project funded by the Norwegian Research Council (NFR) and the U-PrIM project funded by the Swedish Knowledge (KK) Foundation.', 'ENTRYTYPE': 'incollection', 'ID': 'FISCHERHBNER2013755'}",ScienceDirect
Gulshan Kumar and Rahul Saha and Mauro Conti and Tannishtha Devgun and Rekha Goyat and Joel J.P.C. Rodrigues,COUNT: Blockchain framework for resource accountability in e-healthcare,"Healthcare, Blockchain, Medical, IoT, Pandemic","The progress of sensor devices, digital communication, and computing techniques enhances the functionalities of e-healthcare, where the medical facilities are manageable based on the Internet. Now a days, e-healthcare not only helps in disease diagnosis, or tele-medicine, but also implies to general medical scope and medical resource management. Thus, Internet-of-Medical Thing (IoMT) becomes an umbrella term to connect e-healthcare, tele-medicine, and medical supply chain management. In the recent past, the outbreak of COVID-19 pandemic has shown the loopholes in the existing medical systems such as the mismanagement of medical resources and the unavailability of the basic requirements for patients. The medical infrastructure urges for the new frameworks to handle accountability and transparent governance in a medical emergency situation. This motivates us to address medical resource accountability in e-healthcare. In the present work, we introduce the first resource accountability framework to balance the demand–supply of medical facilities in an e-healthcare and IoMT ecosystem. Our solution is based on blockchain and we call it bloCkchained framework for resOUrce accouNTability (COUNT). We use a customized Proof of Vote (PoV) for consensus in COUNT. We call this consensus COUNT-PoV, which is another direction of novelty in our solution. The blocks in the proposed COUNT contain the resource requirements and their availability–production–supply status. Multiple stakeholders are involved in the process based on providing pre-attained credentials; thus, COUNT supports consortium blockchain. Existing literature shows a number of studies for blockchain-based frameworks for e-healthcare; however, those works do not address the accountability and transparency issues of medical e-governance and balancing the demand–supply of the medical facilities/resources. Therefore, our proposed COUNT is beneficial for e-healthcare and IoMTs. We use signcryption process to reduce the complexity of the cryptographic processes, which is an add-on to the contribution. We evaluate our proposed framework based on the Hyperledger Caliper benchmark test with latency, throughput, and resource consumption. Additionally, we also analyse the cost of the implementation. The comparative analysis of our consensus with other stake-based consensus protocols on the COUNT framework shows that our consensus, COUNT-PoV is efficient and suitable for the use of e-healthcare and IoMTs. Moreover, being a generic framework, COUNT is helpful for the e-governance of medical facilities, the vaccination process, and COVID passports.",2023,Computer Communications,https://www.sciencedirect.com/science/article/pii/S0140366423002505,"{'abstract': 'The progress of sensor devices, digital communication, and computing techniques enhances the functionalities of e-healthcare, where the medical facilities are manageable based on the Internet. Now a days, e-healthcare not only helps in disease diagnosis, or tele-medicine, but also implies to general medical scope and medical resource management. Thus, Internet-of-Medical Thing (IoMT) becomes an umbrella term to connect e-healthcare, tele-medicine, and medical supply chain management. In the recent past, the outbreak of COVID-19 pandemic has shown the loopholes in the existing medical systems such as the mismanagement of medical resources and the unavailability of the basic requirements for patients. The medical infrastructure urges for the new frameworks to handle accountability and transparent governance in a medical emergency situation. This motivates us to address medical resource accountability in e-healthcare. In the present work, we introduce the first resource accountability framework to balance the demand–supply of medical facilities in an e-healthcare and IoMT ecosystem. Our solution is based on blockchain and we call it bloCkchained framework for resOUrce accouNTability (COUNT). We use a customized Proof of Vote (PoV) for consensus in COUNT. We call this consensus COUNT-PoV, which is another direction of novelty in our solution. The blocks in the proposed COUNT contain the resource requirements and their availability–production–supply status. Multiple stakeholders are involved in the process based on providing pre-attained credentials; thus, COUNT supports consortium blockchain. Existing literature shows a number of studies for blockchain-based frameworks for e-healthcare; however, those works do not address the accountability and transparency issues of medical e-governance and balancing the demand–supply of the medical facilities/resources. Therefore, our proposed COUNT is beneficial for e-healthcare and IoMTs. We use signcryption process to reduce the complexity of the cryptographic processes, which is an add-on to the contribution. We evaluate our proposed framework based on the Hyperledger Caliper benchmark test with latency, throughput, and resource consumption. Additionally, we also analyse the cost of the implementation. The comparative analysis of our consensus with other stake-based consensus protocols on the COUNT framework shows that our consensus, COUNT-PoV is efficient and suitable for the use of e-healthcare and IoMTs. Moreover, being a generic framework, COUNT is helpful for the e-governance of medical facilities, the vaccination process, and COVID passports.', 'keywords': 'Healthcare, Blockchain, Medical, IoT, Pandemic', 'author': 'Gulshan Kumar and Rahul Saha and Mauro Conti and Tannishtha Devgun and Rekha Goyat and Joel J.P.C. Rodrigues', 'url': 'https://www.sciencedirect.com/science/article/pii/S0140366423002505', 'doi': 'https://doi.org/10.1016/j.comcom.2023.07.017', 'issn': '0140-3664', 'year': '2023', 'pages': '249-259', 'volume': '209', 'journal': 'Computer Communications', 'title': 'COUNT: Blockchain framework for resource accountability in e-healthcare', 'ENTRYTYPE': 'article', 'ID': 'KUMAR2023249'}",ScienceDirect
Yongming Zhang and Ruoyu Zhao and Yushu Zhang and Rushi Lan and Xiuli Chai,High-efficiency and visual-usability image encryption based on thumbnail preserving and chaotic system,"Visual usability, Image encryption, Privacy, Chaotic system","Privacy concerns may be caused after uploading images into image hosting platforms. For traditional image encryption, images with rich content and meaning are transformed into noise-like encrypted images without any visual information, which can protect privacy from infringement but at the expense of visual usability. Recently, thumbnail-preserving encryption (TPE) was proposed to balance privacy and usability by preserving the thumbnail unchanged after encrypting. On the other hand, a large number of pseudo-random functions with high computational complexity are utilized in the existing TPE schemes, which makes the encryption and decryption time too long. Motivated by this, we deeply analyze the characteristics of TPE and propose a scheme to organically combine TPE with chaotic systems, which reduces the encryption and decryption time exponentially besides ensuring security. The experiments show that the time cost is reduced dozens of times as well as relatively stable compared with the existing schemes. Meanwhile, encrypted images have high visual quality and can resist some commonly used attacks including differential attack and face detection and the balance between privacy and visual usability is achieved.",2022,Journal of King Saud University - Computer and Information Sciences,https://www.sciencedirect.com/science/article/pii/S1319157822001185,"{'abstract': 'Privacy concerns may be caused after uploading images into image hosting platforms. For traditional image encryption, images with rich content and meaning are transformed into noise-like encrypted images without any visual information, which can protect privacy from infringement but at the expense of visual usability. Recently, thumbnail-preserving encryption (TPE) was proposed to balance privacy and usability by preserving the thumbnail unchanged after encrypting. On the other hand, a large number of pseudo-random functions with high computational complexity are utilized in the existing TPE schemes, which makes the encryption and decryption time too long. Motivated by this, we deeply analyze the characteristics of TPE and propose a scheme to organically combine TPE with chaotic systems, which reduces the encryption and decryption time exponentially besides ensuring security. The experiments show that the time cost is reduced dozens of times as well as relatively stable compared with the existing schemes. Meanwhile, encrypted images have high visual quality and can resist some commonly used attacks including differential attack and face detection and the balance between privacy and visual usability is achieved.', 'keywords': 'Visual usability, Image encryption, Privacy, Chaotic system', 'author': 'Yongming Zhang and Ruoyu Zhao and Yushu Zhang and Rushi Lan and Xiuli Chai', 'url': 'https://www.sciencedirect.com/science/article/pii/S1319157822001185', 'doi': 'https://doi.org/10.1016/j.jksuci.2022.04.001', 'issn': '1319-1578', 'year': '2022', 'pages': '2993-3010', 'number': '6, Part A', 'volume': '34', 'journal': 'Journal of King Saud University - Computer and Information Sciences', 'title': 'High-efficiency and visual-usability image encryption based on thumbnail preserving and chaotic system', 'ENTRYTYPE': 'article', 'ID': 'ZHANG20222993'}",ScienceDirect
Harine Rajashree R and Sundarakantham K and Sivasankar E and Mercy Shalinie S,A hybrid deep learning framework for privacy preservation in edge computing,"Internet of things, Privacy preservation, Evolutionary algorithm, Adversarial training, Deep learning","The number of connected devices in our world is continuously increasing at a rapid rate. The Internet of Things(IoT) civilization has resulted in the generation of enormous amounts of data. Analytics on this data pays off in various sectors like health care, manufacturing, and transportation. However, the data generated in the IoT environment is often sensitive, and hence, the need to address the privacy concerns of the data owners. Existing approaches incur a huge computation cost and there is also a gap between privacy preservation and data utility. In this work, a genetic algorithm is coupled with a deep learning network based on adversarial training to build a utility-privacy balanced, low computation solution. The proposal aims to prevent inference of implicit privacy labels present in the data while maintaining data utility. The first part of the proposed work leverages an optimized encoder architecture to learn latent space representation of the input and the second part is the incorporation of adversary for training the framework to prevent unintended sensitive inference. Both parts are governed by a genetic algorithm to output a fitting encoder. Numerical results carried on a benchmark dataset exhibit the capability to protect sensitive data by keeping the accuracy level of the adversary within 23%, and producing a maximum inference accuracy of 95% for the intended task.",2023,Computers & Security,https://www.sciencedirect.com/science/article/pii/S0167404823001190,"{'abstract': 'The number of connected devices in our world is continuously increasing at a rapid rate. The Internet of Things(IoT) civilization has resulted in the generation of enormous amounts of data. Analytics on this data pays off in various sectors like health care, manufacturing, and transportation. However, the data generated in the IoT environment is often sensitive, and hence, the need to address the privacy concerns of the data owners. Existing approaches incur a huge computation cost and there is also a gap between privacy preservation and data utility. In this work, a genetic algorithm is coupled with a deep learning network based on adversarial training to build a utility-privacy balanced, low computation solution. The proposal aims to prevent inference of implicit privacy labels present in the data while maintaining data utility. The first part of the proposed work leverages an optimized encoder architecture to learn latent space representation of the input and the second part is the incorporation of adversary for training the framework to prevent unintended sensitive inference. Both parts are governed by a genetic algorithm to output a fitting encoder. Numerical results carried on a benchmark dataset exhibit the capability to protect sensitive data by keeping the accuracy level of the adversary within 23%, and producing a maximum inference accuracy of 95% for the intended task.', 'keywords': 'Internet of things, Privacy preservation, Evolutionary algorithm, Adversarial training, Deep learning', 'author': 'Harine Rajashree R and Sundarakantham K and Sivasankar E and Mercy Shalinie S', 'url': 'https://www.sciencedirect.com/science/article/pii/S0167404823001190', 'doi': 'https://doi.org/10.1016/j.cose.2023.103209', 'issn': '0167-4048', 'year': '2023', 'pages': '103209', 'volume': '129', 'journal': 'Computers & Security', 'title': 'A hybrid deep learning framework for privacy preservation in edge computing', 'ENTRYTYPE': 'article', 'ID': 'R2023103209'}",ScienceDirect
"Ayci, Gonul and Sensoy, Murat and Özgür, Arzucan and Yolum, Pinar",Uncertainty-Aware Personal Assistant for Making Personalized Privacy Decisions,,"Many software systems, such as online social networks, enable users to share information about themselves. Although the action of sharing is simple, it requires an elaborate thought process on privacy: what to share, with whom to share, and for what purposes. Thinking about these for each piece of content to be shared is tedious. Recent approaches to tackle this problem build personal assistants that can help users by learning what is private over time and recommending privacy labels such as private or public to individual content that a user considers sharing. However, privacy is inherently ambiguous and highly personal. Existing approaches to recommend privacy decisions do not address these aspects of privacy sufficiently. Ideally, a personal assistant should be able to adjust its recommendation based on a given user, considering that user's privacy understanding. Moreover, the personal assistant should be able to assess when its recommendation would be uncertain and let the user make the decision on her own. Accordingly, this article proposes a personal assistant that uses evidential deep learning to classify content based on its privacy label. An important characteristic of the personal assistant is that it can model its uncertainty in its decisions explicitly, determine that it does not know the answer, and delegate from making a recommendation when its uncertainty is high. By factoring in the user's own understanding of privacy, such as risk factors or own labels, the personal assistant can personalize its recommendations per user. We evaluate our proposed personal assistant using a well-known dataset. Our results show that our personal assistant can accurately identify uncertain cases, personalize them to its user's needs, and thus helps users preserve their privacy well.  © 2023 Association for Computing Machinery.",2023,ACM Transactions on Internet Technology,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152616569&doi=10.1145%2f3561820&partnerID=40&md5=0b7822b48b91d0c0c4e71f3526c61ad1,"{'note': 'All Open Access, Bronze Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': ""Many software systems, such as online social networks, enable users to share information about themselves. Although the action of sharing is simple, it requires an elaborate thought process on privacy: what to share, with whom to share, and for what purposes. Thinking about these for each piece of content to be shared is tedious. Recent approaches to tackle this problem build personal assistants that can help users by learning what is private over time and recommending privacy labels such as private or public to individual content that a user considers sharing. However, privacy is inherently ambiguous and highly personal. Existing approaches to recommend privacy decisions do not address these aspects of privacy sufficiently. Ideally, a personal assistant should be able to adjust its recommendation based on a given user, considering that user's privacy understanding. Moreover, the personal assistant should be able to assess when its recommendation would be uncertain and let the user make the decision on her own. Accordingly, this article proposes a personal assistant that uses evidential deep learning to classify content based on its privacy label. An important characteristic of the personal assistant is that it can model its uncertainty in its decisions explicitly, determine that it does not know the answer, and delegate from making a recommendation when its uncertainty is high. By factoring in the user's own understanding of privacy, such as risk factors or own labels, the personal assistant can personalize its recommendations per user. We evaluate our proposed personal assistant using a well-known dataset. Our results show that our personal assistant can accurately identify uncertain cases, personalize them to its user's needs, and thus helps users preserve their privacy well.  © 2023 Association for Computing Machinery."", 'affiliations': 'Bogazici University, Turkey; Amazon AlexaAI, United Kingdom; Utrecht University, Netherlands', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152616569&doi=10.1145%2f3561820&partnerID=40&md5=0b7822b48b91d0c0c4e71f3526c61ad1', 'doi': '10.1145/3561820', 'number': '1', 'volume': '23', 'journal': 'ACM Transactions on Internet Technology', 'year': '2023', 'title': 'Uncertainty-Aware Personal Assistant for Making Personalized Privacy Decisions', 'author': 'Ayci, Gonul and Sensoy, Murat and Özgür, Arzucan and Yolum, Pinar', 'ENTRYTYPE': 'article', 'ID': 'Ayci2023'}",Scopus
"Li, Yucheng and Chen, Deyuan and Li, Tianshi and Agarwal, Yuvraj and Cranor, Lorrie Faith and Hong, Jason I.",Understanding iOS Privacy Nutrition Labels: An Exploratory Large-Scale Analysis of App Store Data,,"Since December 2020, the Apple App Store has required all developers to create a privacy label when submitting new apps or app updates. However, there has not been a comprehensive study on how developers responded to this requirement. We present the first measurement study of Apple privacy nutrition labels to understand how apps on the U.S. App Store create and update privacy labels. We collected weekly snapshots of the privacy label and other metadata for all the 1.4 million apps on the U.S. App Store from April 2 to November 5, 2021. Our analysis showed that 51.6% of apps still do not have a privacy label as of November 5, 2021. Although 35.3% of old apps have created a privacy label, only 2.7% of old apps created a privacy label without app updates (i.e., voluntary adoption). Our findings suggest that inactive apps have little incentive to create privacy labels. © 2022 Owner/Author.",2022,Conference on Human Factors in Computing Systems - Proceedings,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129745137&doi=10.1145%2f3491101.3519739&partnerID=40&md5=37c324ea9363876cff045cf993e7fc6e,"{'note': 'All Open Access, Bronze Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': 'Since December 2020, the Apple App Store has required all developers to create a privacy label when submitting new apps or app updates. However, there has not been a comprehensive study on how developers responded to this requirement. We present the first measurement study of Apple privacy nutrition labels to understand how apps on the U.S. App Store create and update privacy labels. We collected weekly snapshots of the privacy label and other metadata for all the 1.4 million apps on the U.S. App Store from April 2 to November 5, 2021. Our analysis showed that 51.6% of apps still do not have a privacy label as of November 5, 2021. Although 35.3% of old apps have created a privacy label, only 2.7% of old apps created a privacy label without app updates (i.e., voluntary adoption). Our findings suggest that inactive apps have little incentive to create privacy labels. © 2022 Owner/Author.', 'affiliations': 'Carnegie Mellon University, Pittsburgh, PA, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129745137&doi=10.1145%2f3491101.3519739&partnerID=40&md5=37c324ea9363876cff045cf993e7fc6e', 'doi': '10.1145/3491101.3519739', 'journal': 'Conference on Human Factors in Computing Systems - Proceedings', 'year': '2022', 'title': 'Understanding iOS Privacy Nutrition Labels: An Exploratory Large-Scale Analysis of App Store Data', 'author': 'Li, Yucheng and Chen, Deyuan and Li, Tianshi and Agarwal, Yuvraj and Cranor, Lorrie Faith and Hong, Jason I.', 'ENTRYTYPE': 'conference', 'ID': 'Li2022'}",Scopus
"Binns, Reuben","Tracking on the Web, Mobile and the Internet of Things",,"""Tracking""is the collection of data about an individual's activity across multiple distinct contexts and the retention, use, or sharing of data derived from that activity outside the context in which it occurred. This monograph aims to introduce tracking on the web, smartphones, and the Internet of Things to an audience with little or no previous knowledge. It covers these topics primarily from the perspective of computer science and human-computer interaction, but also includes relevant law and policy aspects. Rather than a systematic literature review, it aims to provide an overarching narrative spanning this large research space. Section 1 introduces the concept of tracking. Section 2 provides a short history of the major developments of tracking on the web. Section 3 presents research covering the detection, measurement and analysis of web tracking technologies. Section 4 delves into the countermeasures against web tracking and mechanisms that have been proposed to allow users to control and limit tracking, as well as studies into end-user perspectives on tracking. Section 5 focuses on tracking on ""smart""devices including smartphones and the Internet of Things. Section 6 covers emerging issues affecting the future of tracking across these different platforms.  © 2022 R. Binns.",2022,Foundations and Trends in Web Science,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130865320&doi=10.1561%2f1800000029&partnerID=40&md5=33b68fa9bdd77eda7a06d751afc3e028,"{'note': 'All Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Review', 'language': 'English', 'publisher': 'Now Publishers Inc', 'abstract': '""Tracking""is the collection of data about an individual\'s activity across multiple distinct contexts and the retention, use, or sharing of data derived from that activity outside the context in which it occurred. This monograph aims to introduce tracking on the web, smartphones, and the Internet of Things to an audience with little or no previous knowledge. It covers these topics primarily from the perspective of computer science and human-computer interaction, but also includes relevant law and policy aspects. Rather than a systematic literature review, it aims to provide an overarching narrative spanning this large research space. Section 1 introduces the concept of tracking. Section 2 provides a short history of the major developments of tracking on the web. Section 3 presents research covering the detection, measurement and analysis of web tracking technologies. Section 4 delves into the countermeasures against web tracking and mechanisms that have been proposed to allow users to control and limit tracking, as well as studies into end-user perspectives on tracking. Section 5 focuses on tracking on ""smart""devices including smartphones and the Internet of Things. Section 6 covers emerging issues affecting the future of tracking across these different platforms.  © 2022 R. Binns.', 'affiliations': 'University of Oxford, United Kingdom', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130865320&doi=10.1561%2f1800000029&partnerID=40&md5=33b68fa9bdd77eda7a06d751afc3e028', 'doi': '10.1561/1800000029', 'pages': '1 – 113', 'number': '1-2', 'volume': '8', 'journal': 'Foundations and Trends in Web Science', 'year': '2022', 'title': 'Tracking on the Web, Mobile and the Internet of Things', 'author': 'Binns, Reuben', 'ENTRYTYPE': 'article', 'ID': 'Binns20221'}",Scopus
"Wang, Zixin and Huang, Danny Yuxing and Yao, Yaxing",Exploring Tenants’ Preferences of Privacy Negotiation in Airbnb,,"Literature suggests unmatched or conflicting privacy needs between users and bystanders in smart homes due to their different privacy concerns and priorities. A promising approach to mitigate such conflicts is through negotiation. Yet, it is unclear whether bystanders have privacy negotiation needs and, if so, what factors may influence their negotiation intention and how to better support the negotiation to achieve their privacy goals. In this paper, we investigate these questions in the context of Airbnb, a special case where tenants can be considered bystanders. We conducted a vignette study that varied across three categorical factors, including smart home device types, device location, and duration of stay, with 867 participants in the context of Airbnb. We further examined our participants’ preferences regarding with whom, when, how, and why they would like to negotiate their privacy. Our findings showed that device type remained the only factor that significantly influenced our participants’ negotiation intention. Additionally, we found our participants’ other preferences, such as contacting Airbnb hosts first to convey their privacy needs through asynchronous channels (e.g., messages and emails). We summarized design implications to fulfill tenants’ privacy negotiation needs. © USENIX Security 2023. All rights reserved.",2023,"32nd USENIX Security Symposium, USENIX Security 2023",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176114318&partnerID=40&md5=c039dfb62359e30d929c92de82d89cf7,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'USENIX Association', 'abstract': 'Literature suggests unmatched or conflicting privacy needs between users and bystanders in smart homes due to their different privacy concerns and priorities. A promising approach to mitigate such conflicts is through negotiation. Yet, it is unclear whether bystanders have privacy negotiation needs and, if so, what factors may influence their negotiation intention and how to better support the negotiation to achieve their privacy goals. In this paper, we investigate these questions in the context of Airbnb, a special case where tenants can be considered bystanders. We conducted a vignette study that varied across three categorical factors, including smart home device types, device location, and duration of stay, with 867 participants in the context of Airbnb. We further examined our participants’ preferences regarding with whom, when, how, and why they would like to negotiate their privacy. Our findings showed that device type remained the only factor that significantly influenced our participants’ negotiation intention. Additionally, we found our participants’ other preferences, such as contacting Airbnb hosts first to convey their privacy needs through asynchronous channels (e.g., messages and emails). We summarized design implications to fulfill tenants’ privacy negotiation needs. © USENIX Security 2023. All rights reserved.', 'affiliations': 'Zhejiang University, China; New York University, United States; University of Maryland, Baltimore, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176114318&partnerID=40&md5=c039dfb62359e30d929c92de82d89cf7', 'pages': '535 – 551', 'volume': '1', 'journal': '32nd USENIX Security Symposium, USENIX Security 2023', 'year': '2023', 'title': 'Exploring Tenants’ Preferences of Privacy Negotiation in Airbnb', 'author': 'Wang, Zixin and Huang, Danny Yuxing and Yao, Yaxing', 'ENTRYTYPE': 'conference', 'ID': 'Wang2023535'}",Scopus
"Paspatis, Ioannis and Tsohou, Aggeliki",Experiential Transformation in Privacy Behavior: A New Framework for Privacy Behavior Enhancement,,"Multiple studies have demonstrated that the conventional method of learning is suboptimal when our goal is to enhance individuals’ genuine privacy behavior. This study introduces a framework for transforming privacy behavior, with the objective of enhancing individuals’ privacy practices to a higher level of confidentiality. We performed an experiment on a limited number of people to validate the efficacy of our suggested transformation framework. This framework combined determining aspects of privacy behavior with experiential behavior modification methodologies such as neutral stimuli (e.g., cognitive behavioral transformation—CBTx), practical assessments and motivational interviews from other disciplines. While these methods have proven effective in fields like psychology and sociology, they have not yet been applied to the realm of Information Computer and Technology (ICT). In this study, we have effectively demonstrated the efficacy of the proposed framework through a five-phase experiment. The suggested framework has the potential to be advantageous for educational institutions, including both public and private schools as well as universities, to construct new frameworks or develop new methodologies regarding individuals’ privacy behavior transformation to a more protective one. Furthermore, our framework offers a conducive environment for further investigation into privacy behavior transformation methodologies. © 2024 by the authors.",2024,Journal of Cybersecurity and Privacy,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188942506&doi=10.3390%2fjcp4010005&partnerID=40&md5=d577a46dc279b86e6ba4766e7675f240,"{'note': 'All Open Access, Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Multidisciplinary Digital Publishing Institute (MDPI)', 'abstract': 'Multiple studies have demonstrated that the conventional method of learning is suboptimal when our goal is to enhance individuals’ genuine privacy behavior. This study introduces a framework for transforming privacy behavior, with the objective of enhancing individuals’ privacy practices to a higher level of confidentiality. We performed an experiment on a limited number of people to validate the efficacy of our suggested transformation framework. This framework combined determining aspects of privacy behavior with experiential behavior modification methodologies such as neutral stimuli (e.g., cognitive behavioral transformation—CBTx), practical assessments and motivational interviews from other disciplines. While these methods have proven effective in fields like psychology and sociology, they have not yet been applied to the realm of Information Computer and Technology (ICT). In this study, we have effectively demonstrated the efficacy of the proposed framework through a five-phase experiment. The suggested framework has the potential to be advantageous for educational institutions, including both public and private schools as well as universities, to construct new frameworks or develop new methodologies regarding individuals’ privacy behavior transformation to a more protective one. Furthermore, our framework offers a conducive environment for further investigation into privacy behavior transformation methodologies. © 2024 by the authors.', 'affiliations': 'Department of Informatics, Ionian University, Corfu, 49100, Greece', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188942506&doi=10.3390%2fjcp4010005&partnerID=40&md5=d577a46dc279b86e6ba4766e7675f240', 'doi': '10.3390/jcp4010005', 'pages': '76 – 104', 'number': '1', 'volume': '4', 'journal': 'Journal of Cybersecurity and Privacy', 'year': '2024', 'title': 'Experiential Transformation in Privacy Behavior: A New Framework for Privacy Behavior Enhancement', 'author': 'Paspatis, Ioannis and Tsohou, Aggeliki', 'ENTRYTYPE': 'article', 'ID': 'Paspatis202476'}",Scopus
"Haney, Julie M. and Furman, Susanne M.",Smart Home Device Loss of Support: Consumer Perspectives and Preferences,,"Unsupported smart home devices can pose serious safety and security issues for consumers. However, unpatched and vulnerable devices may remain connected because consumers may not be alerted that their devices are no longer supported or do not understand the implications of using unsupported devices. To investigate the consumer perspective on loss of manufacturer support, we conducted a survey of 412 smart home users. We discovered differences based on device category and provide insights into how user perspectives may relate to perceptions of smart home update importance, security, and privacy. Based on the results, we offer suggestions to guide the efforts of the smart home community to protect consumers from potentially harmful consequences of unsupported devices. © 2023, This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply.",2023,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171467412&doi=10.1007%2f978-3-031-35822-7_32&partnerID=40&md5=84455802f1c4dfabd8ba2148fdda44dc,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Springer Science and Business Media Deutschland GmbH', 'abstract': 'Unsupported smart home devices can pose serious safety and security issues for consumers. However, unpatched and vulnerable devices may remain connected because consumers may not be alerted that their devices are no longer supported or do not understand the implications of using unsupported devices. To investigate the consumer perspective on loss of manufacturer support, we conducted a survey of 412 smart home users. We discovered differences based on device category and provide insights into how user perspectives may relate to perceptions of smart home update importance, security, and privacy. Based on the results, we offer suggestions to guide the efforts of the smart home community to protect consumers from potentially harmful consequences of unsupported devices. © 2023, This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply.', 'affiliations': 'National Institute of Standards and Technology, Gaithersburg, 20899, MD, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171467412&doi=10.1007%2f978-3-031-35822-7_32&partnerID=40&md5=84455802f1c4dfabd8ba2148fdda44dc', 'doi': '10.1007/978-3-031-35822-7_32', 'pages': '492 – 510', 'volume': '14045 LNCS', 'journal': 'Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)', 'year': '2023', 'title': 'Smart Home Device Loss of\xa0Support: Consumer Perspectives and\xa0Preferences', 'author': 'Haney, Julie M. and Furman, Susanne M.', 'ENTRYTYPE': 'article', 'ID': 'Haney2023492'}",Scopus
"Balash, David G. and Ali, Mir Masood and Kodwani, Monica and Wu, Xiaoyuan and Kanich, Chris and Aviv, Adam J.",Poster: Longitudinal Measurement of the Adoption Dynamics in Apple's Privacy Label Ecosystem,,"This work reports on a large scale, longitudinal analysis of the adoption dynamics of privacy labels in the iOS App Store, measuring this first-of-its kind ecosystem as it reaches maturity over two and a half years after launching in December 2020. The motivation is to shed light on the factors affecting the shifts in privacy labels and provide insights into how and when an app's label changes. By collecting nearly weekly snapshots of over 1.6 million apps for over a year, we analyze the dynamics of privacy label adoption and the accuracy of reported labels. Our analysis of 74.5% of apps having labels after two years provides important context into this mature ecosystem where labels are becoming the standard. However, we find compelling evidence that labels may not fully capture behavior, as 28.9% of apps indicate no data collection and distributions differ between voluntary versus mandatory adoptions. Once set, labels rarely change but additions reflect more data collection. In addition to our measurement, we also plan to release a new (and growing) data set that can be used by future researchers. © 2023 Copyright held by the owner/author(s).",2023,CCS 2023 - Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179851303&doi=10.1145%2f3576915.3624383&partnerID=40&md5=b3ecb9478ea2cfe15d3d90a2f4b436c1,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery, Inc', 'abstract': ""This work reports on a large scale, longitudinal analysis of the adoption dynamics of privacy labels in the iOS App Store, measuring this first-of-its kind ecosystem as it reaches maturity over two and a half years after launching in December 2020. The motivation is to shed light on the factors affecting the shifts in privacy labels and provide insights into how and when an app's label changes. By collecting nearly weekly snapshots of over 1.6 million apps for over a year, we analyze the dynamics of privacy label adoption and the accuracy of reported labels. Our analysis of 74.5% of apps having labels after two years provides important context into this mature ecosystem where labels are becoming the standard. However, we find compelling evidence that labels may not fully capture behavior, as 28.9% of apps indicate no data collection and distributions differ between voluntary versus mandatory adoptions. Once set, labels rarely change but additions reflect more data collection. In addition to our measurement, we also plan to release a new (and growing) data set that can be used by future researchers. © 2023 Copyright held by the owner/author(s)."", 'affiliations': 'University of Richmond, United States; University of Illinois Chicago, United States; The George Washington University, United States; Carnegie Mellon University, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179851303&doi=10.1145%2f3576915.3624383&partnerID=40&md5=b3ecb9478ea2cfe15d3d90a2f4b436c1', 'doi': '10.1145/3576915.3624383', 'pages': '3600 – 3602', 'journal': 'CCS 2023 - Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security', 'year': '2023', 'title': ""Poster: Longitudinal Measurement of the Adoption Dynamics in Apple's Privacy Label Ecosystem"", 'author': 'Balash, David G. and Ali, Mir Masood and Kodwani, Monica and Wu, Xiaoyuan and Kanich, Chris and Aviv, Adam J.', 'ENTRYTYPE': 'conference', 'ID': 'Balash20233600'}",Scopus
"Wang, Yiwei and Hooi, Bryan and Liu, Yozen and Shah, Neil",Graph Explicit Neural Networks: Explicitly Encoding Graphs for Efficient and Accurate Inference,,"As the state-of-the-art graph learning models, the message passing based neural networks (MPNNs) implicitly use the graph topology as the ""pathways""to propagate node features. This implicit use of graph topology induces the MPNNs' over-reliance on (node) features and high inference latency, which hinders their large-scale applications in industrial contexts. To mitigate these weaknesses, we propose the Graph Explicit Neural Network (GENN) framework. GENN can be flexibly applied to various MPNNs and improves them by providing more efficient and accurate inference that is robust in feature-constrained settings. Specifically, we carefully incorporate recent developments in network embedding methods to efficiently prioritize the graph topology for inference. From this vantage, GENN explicitly encodes the topology as an important source of information to mitigate the reliance on node features. Moreover, by adopting knowledge distillation (KD) techniques, GENN takes an MPNN as the teacher to supervise the training for better effectiveness while avoiding the teacher's high inference latency. Empirical results show that our GENN infers dramatically faster than its MPNN teacher by 40x-78x. In terms of accuracy, GENN yields significant gains (more than 40%) for its MPNN teacher when the node features are limited based on our explicit encoding. Moreover, GENN outperforms the MPNN teacher even in feature-rich settings thanks to our KD design. © 2023 ACM.",2023,WSDM 2023 - Proceedings of the 16th ACM International Conference on Web Search and Data Mining,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149667274&doi=10.1145%2f3539597.3570388&partnerID=40&md5=8f0f959250eeac0ee1fcf13e39023ce3,"{'note': 'All Open Access, Bronze Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery, Inc', 'abstract': 'As the state-of-the-art graph learning models, the message passing based neural networks (MPNNs) implicitly use the graph topology as the ""pathways""to propagate node features. This implicit use of graph topology induces the MPNNs\' over-reliance on (node) features and high inference latency, which hinders their large-scale applications in industrial contexts. To mitigate these weaknesses, we propose the Graph Explicit Neural Network (GENN) framework. GENN can be flexibly applied to various MPNNs and improves them by providing more efficient and accurate inference that is robust in feature-constrained settings. Specifically, we carefully incorporate recent developments in network embedding methods to efficiently prioritize the graph topology for inference. From this vantage, GENN explicitly encodes the topology as an important source of information to mitigate the reliance on node features. Moreover, by adopting knowledge distillation (KD) techniques, GENN takes an MPNN as the teacher to supervise the training for better effectiveness while avoiding the teacher\'s high inference latency. Empirical results show that our GENN infers dramatically faster than its MPNN teacher by 40x-78x. In terms of accuracy, GENN yields significant gains (more than 40%) for its MPNN teacher when the node features are limited based on our explicit encoding. Moreover, GENN outperforms the MPNN teacher even in feature-rich settings thanks to our KD design. © 2023 ACM.', 'affiliations': 'National University of Singapore, Singapore, Singapore; Snap Inc., United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149667274&doi=10.1145%2f3539597.3570388&partnerID=40&md5=8f0f959250eeac0ee1fcf13e39023ce3', 'doi': '10.1145/3539597.3570388', 'pages': '348 – 356', 'journal': 'WSDM 2023 - Proceedings of the 16th ACM International Conference on Web Search and Data Mining', 'year': '2023', 'title': 'Graph Explicit Neural Networks: Explicitly Encoding Graphs for Efficient and Accurate Inference', 'author': 'Wang, Yiwei and Hooi, Bryan and Liu, Yozen and Shah, Neil', 'ENTRYTYPE': 'conference', 'ID': 'Wang2023348'}",Scopus
"Heid, Kris and Andrae, Vincent and Heider, Jens",Towards detecting device fingerprinting on iOS with API function hooking,,"Device fingerprinting is a technique that got popular at the end of the 90s by websites, to identify and track users. One of the biggest drivers behind such practices are advertising companies to identify users interests to personalize ads. From a user's perspective, this, of course, raises privacy concerns. While device fingerprinting and its detection has been extensively studied in the context of web browsing, little research has been conducted on device fingerprinting in mobile apps and especially iOS apps. In this paper, we capture the current state of device fingerprinting in iOS apps, and explore possible approaches for fingerprinting detection on mobile devices using static and dynamic app analysis techniques. Finally, we present a first heuristic approach for automatic behavior-based fingerprinting detection on iOS only using spatial and temporal context of relevant API-calls.  © 2023 Owner/Author.",2023,ACM International Conference Proceeding Series,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161441381&doi=10.1145%2f3590777.3590790&partnerID=40&md5=6d4fe96a26fed3643de83aba8d26f2cb,"{'note': 'All Open Access, Bronze Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': ""Device fingerprinting is a technique that got popular at the end of the 90s by websites, to identify and track users. One of the biggest drivers behind such practices are advertising companies to identify users interests to personalize ads. From a user's perspective, this, of course, raises privacy concerns. While device fingerprinting and its detection has been extensively studied in the context of web browsing, little research has been conducted on device fingerprinting in mobile apps and especially iOS apps. In this paper, we capture the current state of device fingerprinting in iOS apps, and explore possible approaches for fingerprinting detection on mobile devices using static and dynamic app analysis techniques. Finally, we present a first heuristic approach for automatic behavior-based fingerprinting detection on iOS only using spatial and temporal context of relevant API-calls.  © 2023 Owner/Author."", 'affiliations': 'Fraunhofer SIT, ATHENE - National Research Center for Applied Cybersecurity, Darmstadt, Germany', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161441381&doi=10.1145%2f3590777.3590790&partnerID=40&md5=6d4fe96a26fed3643de83aba8d26f2cb', 'doi': '10.1145/3590777.3590790', 'pages': '78 – 84', 'journal': 'ACM International Conference Proceeding Series', 'year': '2023', 'title': 'Towards detecting device fingerprinting on iOS with API function hooking', 'author': 'Heid, Kris and Andrae, Vincent and Heider, Jens', 'ENTRYTYPE': 'conference', 'ID': 'Heid202378'}",Scopus
"Park, Sunyup and Zimmer, Michael and Lenhart, Anna and Vitak, Jessica","“Nobody’s Happy”: Design Insights from Privacy-Conscious Smart Home Power Users on Enhancing Data Transparency, Visibility, and Control",,"As smart home technologies continue to grow in popularity and diversity, they raise important questions regarding ways to increase awareness about data collection practices and empower users to better manage data flows. In this paper, we share insights from 32 privacy-conscious smart home power users—individuals who have invested significant time, money, and technological prowess in customizing their smart home setup to maximize utility and meet privacy and security needs. We explore the drawbacks and limitations power users experience when balancing privacy goals with interoperability, customizability, and usability considerations, and we detail their design ideas to enhance and extend data transparency, visibility, and control. We conclude by discussing the importance of designing smart home technologies that both address these considerations and empower a wide range of users to make more informed decisions about whether and how to implement smart technologies in their homes, as well as the wider need for greater regulation of technologies that collect significant user data. © 2023 by The USENIX Association.All rights reserved.",2023,"Proceedings of the 19th Symposium on Usable Privacy and Security, SOUPS 2023",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174388613&partnerID=40&md5=2540a0263599130cd93c7098197ee56b,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'USENIX Association', 'abstract': 'As smart home technologies continue to grow in popularity and diversity, they raise important questions regarding ways to increase awareness about data collection practices and empower users to better manage data flows. In this paper, we share insights from 32 privacy-conscious smart home power users—individuals who have invested significant time, money, and technological prowess in customizing their smart home setup to maximize utility and meet privacy and security needs. We explore the drawbacks and limitations power users experience when balancing privacy goals with interoperability, customizability, and usability considerations, and we detail their design ideas to enhance and extend data transparency, visibility, and control. We conclude by discussing the importance of designing smart home technologies that both address these considerations and empower a wide range of users to make more informed decisions about whether and how to implement smart technologies in their homes, as well as the wider need for greater regulation of technologies that collect significant user data. © 2023 by The USENIX Association.All rights reserved.', 'affiliations': 'University of Maryland, College Park, United States; Marquette University, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174388613&partnerID=40&md5=2540a0263599130cd93c7098197ee56b', 'pages': '543 – 558', 'journal': 'Proceedings of the 19th Symposium on Usable Privacy and Security, SOUPS 2023', 'year': '2023', 'title': '“Nobody’s Happy”: Design Insights from Privacy-Conscious Smart Home Power Users on Enhancing Data Transparency, Visibility, and Control', 'author': 'Park, Sunyup and Zimmer, Michael and Lenhart, Anna and Vitak, Jessica', 'ENTRYTYPE': 'conference', 'ID': 'Park2023543'}",Scopus
"Xiao, Yue and Li, Zhengyi and Qin, Yue and Bai, Xiaolong and Guan, Jiale and Liao, Xiaojing and Xing, Luyi",Lalaine: Measuring and Characterizing Non-Compliance of Apple Privacy Labels,,"As a key supplement to privacy policies that are known to be lengthy and difficult to read, Apple has launched app privacy labels, which purportedly help users more easily understand an app's privacy practices. However, false and misleading privacy labels can dupe privacy-conscious consumers into downloading data-intensive apps, ultimately eroding the credibility and integrity of the labels. Although Apple releases requirements and guidelines for app developers to create privacy labels, little is known about whether and to what extent the privacy labels in the wild are correct and compliant, reflecting the actual data practices of iOS apps. This paper presents the first systematic study, based on our new methodology named Lalaine, to evaluate data-flow to privacy-label (flow-to-label) consistency. Lalaine analyzed the privacy labels and binaries of 5, 102 iOS apps, shedding light on the prevalence and seriousness of privacy-label noncompliance. We provide detailed case studies and analyze root causes for privacy label non-compliance that complements prior understandings. This has led to new insights for improving privacy-label design and compliance requirements, so app developers, platform stakeholders, and policy-makers can better achieve their privacy and accountability goals. Lalaine is thoroughly evaluated for its high effectiveness and efficiency. We are responsibly reporting the results to stakeholders. © 2023 32nd USENIX Security Symposium, USENIX Security 2023. All rights reserved.",2023,"32nd USENIX Security Symposium, USENIX Security 2023",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175981038&partnerID=40&md5=f6d48a1d88aeebf8316e3f218eff6b79,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'USENIX Association', 'abstract': ""As a key supplement to privacy policies that are known to be lengthy and difficult to read, Apple has launched app privacy labels, which purportedly help users more easily understand an app's privacy practices. However, false and misleading privacy labels can dupe privacy-conscious consumers into downloading data-intensive apps, ultimately eroding the credibility and integrity of the labels. Although Apple releases requirements and guidelines for app developers to create privacy labels, little is known about whether and to what extent the privacy labels in the wild are correct and compliant, reflecting the actual data practices of iOS apps. This paper presents the first systematic study, based on our new methodology named Lalaine, to evaluate data-flow to privacy-label (flow-to-label) consistency. Lalaine analyzed the privacy labels and binaries of 5, 102 iOS apps, shedding light on the prevalence and seriousness of privacy-label noncompliance. We provide detailed case studies and analyze root causes for privacy label non-compliance that complements prior understandings. This has led to new insights for improving privacy-label design and compliance requirements, so app developers, platform stakeholders, and policy-makers can better achieve their privacy and accountability goals. Lalaine is thoroughly evaluated for its high effectiveness and efficiency. We are responsibly reporting the results to stakeholders. © 2023 32nd USENIX Security Symposium, USENIX Security 2023. All rights reserved."", 'affiliations': 'Indiana University Bloomington, United States; Orion Security Lab, Alibaba Group', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175981038&partnerID=40&md5=f6d48a1d88aeebf8316e3f218eff6b79', 'pages': '1091 – 1108', 'volume': '2', 'journal': '32nd USENIX Security Symposium, USENIX Security 2023', 'year': '2023', 'title': 'Lalaine: Measuring and Characterizing Non-Compliance of Apple Privacy Labels', 'author': 'Xiao, Yue and Li, Zhengyi and Qin, Yue and Bai, Xiaolong and Guan, Jiale and Liao, Xiaojing and Xing, Luyi', 'ENTRYTYPE': 'conference', 'ID': 'Xiao20231091'}",Scopus
"Fox, Grace and Lynn, Theo and Rosati, Pierangelo",Enhancing consumer perceptions of privacy and trust: a GDPR label perspective,,"Purpose: The General Data Protection Regulation (GDPR) introduces significant data protection obligations on all organizations within the European Union (EU) and those transacting with EU citizens. This paper presents the GDPR privacy label and uses two empirical studies to examine the effectiveness of this approach in influencing consumers' privacy perceptions and related behavioral intentions. Design/methodology/approach: The paper tests the efficacy of two GDPR privacy label designs, a consent-based label and a static label. Study 1 examines the effects of each label on perceptions of risk, control and privacy. Study 2 investigates the influence of consumers' privacy perceptions on perceived trustworthiness and willingness to interact with the organization. Findings: The findings support the potential of GDPR privacy labels for positively influencing perceptions of risk, control, privacy and trustworthiness and enhancing consumers' willingness to transact and disclose data to online organizations. Practical implications: The findings are useful for organizations required to comply with the GDPR and present a solution to requirements for transparent communications and explicit consent. Originality/value: This study examines and demonstrates the efficacy of visualized privacy policies in impacting consumer privacy perceptions and behavioral intentions. © 2022, Grace Fox, Theo Lynn and Pierangelo Rosati.",2022,Information Technology and People,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129173240&doi=10.1108%2fITP-09-2021-0706&partnerID=40&md5=42e2ff945b8f75e7f45f443a11fb95f1,"{'note': 'All Open Access, Green Open Access, Hybrid Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Emerald Group Holdings Ltd.', 'abstract': ""Purpose: The General Data Protection Regulation (GDPR) introduces significant data protection obligations on all organizations within the European Union (EU) and those transacting with EU citizens. This paper presents the GDPR privacy label and uses two empirical studies to examine the effectiveness of this approach in influencing consumers' privacy perceptions and related behavioral intentions. Design/methodology/approach: The paper tests the efficacy of two GDPR privacy label designs, a consent-based label and a static label. Study 1 examines the effects of each label on perceptions of risk, control and privacy. Study 2 investigates the influence of consumers' privacy perceptions on perceived trustworthiness and willingness to interact with the organization. Findings: The findings support the potential of GDPR privacy labels for positively influencing perceptions of risk, control, privacy and trustworthiness and enhancing consumers' willingness to transact and disclose data to online organizations. Practical implications: The findings are useful for organizations required to comply with the GDPR and present a solution to requirements for transparent communications and explicit consent. Originality/value: This study examines and demonstrates the efficacy of visualized privacy policies in impacting consumer privacy perceptions and behavioral intentions. © 2022, Grace Fox, Theo Lynn and Pierangelo Rosati."", 'affiliations': 'Irish Institute of Digital Business, Dublin City University, Dublin, Ireland; Dublin City University Business School, Dublin, Ireland', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129173240&doi=10.1108%2fITP-09-2021-0706&partnerID=40&md5=42e2ff945b8f75e7f45f443a11fb95f1', 'doi': '10.1108/ITP-09-2021-0706', 'pages': '181 – 204', 'number': '8', 'volume': '35', 'journal': 'Information Technology and People', 'year': '2022', 'title': 'Enhancing consumer perceptions of privacy and trust: a GDPR label perspective', 'author': 'Fox, Grace and Lynn, Theo and Rosati, Pierangelo', 'ENTRYTYPE': 'article', 'ID': 'Fox2022181'}",Scopus
"McGuigan, Lee and West, Sarah Myers and Sivan-Sevilla, Ido and Parham, Patrick",The after party: Cynical resignation in Adtech's pivot to privacy,,"Digital advertising and technology companies are resigned to a new privacy imperative. They are bracing for a world where third-party tracking will be restricted by design or by law. Digital resignation typically refers to how companies cultivate a sense of powerlessness about privacy among internet users. Our paper looks through this optic from the other end of the lens: How is the digital advertising industry coping with the increasing salience of privacy? Recent developments have forced companies to implement “privacy-preserving” designs—or at least promise some semblance of privacy. Yet, the industry remains dependent on flows of data and means of identification to enable still-desired targeting, measurement, and optimization. Our paper analyzes this contradiction by looking at systems that aim to replicate existing functionalities while protecting user “privacy.” We call this a form of “cynical resignation” and characterize its key maneuvers as follows: (a) sanitizing surveillance; (b) party-hopping; and (c) sabotage. We argue that this “cynical resignation” to a privacy imperative represents a policy failure. In the absence of decisive interventions into the underlying business models of data capitalism, companies offer techno-solutionism and self-regulations that seem to conform to new laws and norms while reinforcing commitments to data-driven personalization. This may benefit the largest tech companies, since their privileged access to first-party data will make more companies reliant on them, and their computational power will be even more valuable in a world where modeling is used to compensate for the loss of third-party data and traditional methods of personal identification. © The Author(s) 2023.",2023,Big Data and Society,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174635432&doi=10.1177%2f20539517231203665&partnerID=40&md5=19d5b023015031db6f7bda7b7dbea654,"{'note': 'All Open Access, Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'SAGE Publications Ltd', 'abstract': 'Digital advertising and technology companies are resigned to a new privacy imperative. They are bracing for a world where third-party tracking will be restricted by design or by law. Digital resignation typically refers to how companies cultivate a sense of powerlessness about privacy among internet users. Our paper looks through this optic from the other end of the lens: How is the digital advertising industry coping with the increasing salience of privacy? Recent developments have forced companies to implement “privacy-preserving” designs—or at least promise some semblance of privacy. Yet, the industry remains dependent on flows of data and means of identification to enable still-desired targeting, measurement, and optimization. Our paper analyzes this contradiction by looking at systems that aim to replicate existing functionalities while protecting user “privacy.” We call this a form of “cynical resignation” and characterize its key maneuvers as follows: (a) sanitizing surveillance; (b) party-hopping; and (c) sabotage. We argue that this “cynical resignation” to a privacy imperative represents a policy failure. In the absence of decisive interventions into the underlying business models of data capitalism, companies offer techno-solutionism and self-regulations that seem to conform to new laws and norms while reinforcing commitments to data-driven personalization. This may benefit the largest tech companies, since their privileged access to first-party data will make more companies reliant on them, and their computational power will be even more valuable in a world where modeling is used to compensate for the loss of third-party data and traditional methods of personal identification. © The Author(s) 2023.', 'affiliations': 'Hussman School of Journalism and Media, University of North Carolina at Chapel Hill, Chapel Hill, NC, United States; AI Now Institute, New York, NY, United States; College of Information Studies, University of Maryland, College Park, MD, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174635432&doi=10.1177%2f20539517231203665&partnerID=40&md5=19d5b023015031db6f7bda7b7dbea654', 'doi': '10.1177/20539517231203665', 'number': '2', 'volume': '10', 'journal': 'Big Data and Society', 'year': '2023', 'title': ""The after party: Cynical resignation in Adtech's pivot to privacy"", 'author': 'McGuigan, Lee and West, Sarah Myers and Sivan-Sevilla, Ido and Parham, Patrick', 'ENTRYTYPE': 'article', 'ID': 'McGuigan2023'}",Scopus
"Barth, Susanne and Ionita, Dan and Hartel, Pieter",Understanding Online Privacy - A Systematic Review of Privacy Visualizations and Privacy by Design Guidelines,,"Privacy visualizations help users understand the privacy implications of using an online service. Privacy by Design guidelines provide generally accepted privacy standards for developers of online services. To obtain a comprehensive understanding of online privacy, we review established approaches, distill a unified list of 15 privacy attributes and rank them based on perceived importance by users and privacy experts. We then discuss similarities, explain notable differences, and examine trends in terms of the attributes covered. Finally, we show how our results provide a foundation for user-centric privacy visualizations, inspire best practices for developers, and give structure to privacy policies. © 2022 Association for Computing Machinery.",2022,ACM Computing Surveys,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140901513&doi=10.1145%2f3502288&partnerID=40&md5=35810c42a1e581352df3cba7f5453349,"{'note': 'All Open Access, Hybrid Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': 'Privacy visualizations help users understand the privacy implications of using an online service. Privacy by Design guidelines provide generally accepted privacy standards for developers of online services. To obtain a comprehensive understanding of online privacy, we review established approaches, distill a unified list of 15 privacy attributes and rank them based on perceived importance by users and privacy experts. We then discuss similarities, explain notable differences, and examine trends in terms of the attributes covered. Finally, we show how our results provide a foundation for user-centric privacy visualizations, inspire best practices for developers, and give structure to privacy policies. © 2022 Association for Computing Machinery.', 'affiliations': 'University of Twente, Drienerlolaan 5, Enschede, 7522 NB, Netherlands', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140901513&doi=10.1145%2f3502288&partnerID=40&md5=35810c42a1e581352df3cba7f5453349', 'doi': '10.1145/3502288', 'number': '3', 'volume': '55', 'journal': 'ACM Computing Surveys', 'year': '2022', 'title': 'Understanding Online Privacy - A Systematic Review of Privacy Visualizations and Privacy by Design Guidelines', 'author': 'Barth, Susanne and Ionita, Dan and Hartel, Pieter', 'ENTRYTYPE': 'article', 'ID': 'Barth2022'}",Scopus
"Deldari, Elmira and Thakkar, Parth and Yao, Yaxing",Users' Perceptions of Online Child Abuse Detection Mechanisms,,"Child sexual exploitation and abuse (CSEA) online has become a major safety issue for children to access the Internet. To combat CSEA, electronics services providers (ESP) have implemented various mechanisms to detect child sexual abuse materials (CSAM). However, these mechanisms, despite their capability to prevent the mass distribution of CSAM online, may raise significant privacy concerns among general users. In this paper, we conducted a semi-structured interview study with 23 participants to understand their privacy perceptions of two types of online CSAM detection mechanisms. Our results suggested that users were concerned about the transparency of the detection process, inappropriate access to users' data, and unclear boundaries of such mechanisms. Our results also highlight that, even though the majority of participants choose to sacrifice their privacy for societal benefits, they still have privacy concerns that need to be addressed. We discuss the design and policy implications for ESP to improve users' awareness of the data practices of these mechanisms, alleviate users' privacy concerns, and increase societal benefits. © 2023 Copyright held by the owner/author(s).",2024,Proceedings of the ACM on Human-Computer Interaction,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193265498&doi=10.1145%2f3637424&partnerID=40&md5=8b08fd7693e872aff43d713ca44bb680,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': ""Child sexual exploitation and abuse (CSEA) online has become a major safety issue for children to access the Internet. To combat CSEA, electronics services providers (ESP) have implemented various mechanisms to detect child sexual abuse materials (CSAM). However, these mechanisms, despite their capability to prevent the mass distribution of CSAM online, may raise significant privacy concerns among general users. In this paper, we conducted a semi-structured interview study with 23 participants to understand their privacy perceptions of two types of online CSAM detection mechanisms. Our results suggested that users were concerned about the transparency of the detection process, inappropriate access to users' data, and unclear boundaries of such mechanisms. Our results also highlight that, even though the majority of participants choose to sacrifice their privacy for societal benefits, they still have privacy concerns that need to be addressed. We discuss the design and policy implications for ESP to improve users' awareness of the data practices of these mechanisms, alleviate users' privacy concerns, and increase societal benefits. © 2023 Copyright held by the owner/author(s)."", 'affiliations': 'University of Maryland, Baltimore County, Baltimore, MD, United States; Virginia Tech, Blacksburg, VA, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193265498&doi=10.1145%2f3637424&partnerID=40&md5=8b08fd7693e872aff43d713ca44bb680', 'doi': '10.1145/3637424', 'number': 'CSCW1', 'volume': '8', 'journal': 'Proceedings of the ACM on Human-Computer Interaction', 'year': '2024', 'title': ""Users' Perceptions of Online Child Abuse Detection Mechanisms"", 'author': 'Deldari, Elmira and Thakkar, Parth and Yao, Yaxing', 'ENTRYTYPE': 'article', 'ID': 'Deldari2024'}",Scopus
"Palfinger, Gerald",OCScraper: Automated Analysis of the Fingerprintability of the iOS API,,"Tracking has allowed application providers to offer the vast majority of their applications for free as it allows them to target advertising. However, tracking has proven to be an invasion of user privacy. To counter this, operating system vendors have removed access to unique identifiers in their APIs. Nevertheless, applications can still combine other non-unique data from the device to create a unique fingerprint. Until now, it has not been well understood what kind of information is available to do so on iOS. This paper addresses this gap by introducing the OCScraper framework, a tool for automatically discovering fingerprintable information sources on iOS devices. OCScraper does this by systematically crawling the API of the operating system. In the process, it creates objects on which methods are called and properties are queried. In our evaluation, we show that OCScraper can successfully invoke a large number of methods and retrieve the majority of parameters. We discover hundreds of robust information sources that provide distinct bits of information which can be used to create a cross-application fingerprint. © 2023 by SCITEPRESS - Science and Technology Publications, Lda. Under CC license (CC BY-NC-ND 4.0).",2023,Proceedings of the International Conference on Security and Cryptography,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178570483&doi=10.5220%2f0012089600003555&partnerID=40&md5=1e34215976af1e4ad53ab3532172c826,"{'note': 'All Open Access, Hybrid Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Science and Technology Publications, Lda', 'abstract': 'Tracking has allowed application providers to offer the vast majority of their applications for free as it allows them to target advertising. However, tracking has proven to be an invasion of user privacy. To counter this, operating system vendors have removed access to unique identifiers in their APIs. Nevertheless, applications can still combine other non-unique data from the device to create a unique fingerprint. Until now, it has not been well understood what kind of information is available to do so on iOS. This paper addresses this gap by introducing the OCScraper framework, a tool for automatically discovering fingerprintable information sources on iOS devices. OCScraper does this by systematically crawling the API of the operating system. In the process, it creates objects on which methods are called and properties are queried. In our evaluation, we show that OCScraper can successfully invoke a large number of methods and retrieve the majority of parameters. We discover hundreds of robust information sources that provide distinct bits of information which can be used to create a cross-application fingerprint. © 2023 by SCITEPRESS - Science and Technology Publications, Lda. Under CC license (CC BY-NC-ND 4.0).', 'affiliations': 'A-SIT Secure Information Technology Center Austria, Seidlgasse 22 / Top 9, Vienna, 1030, Austria; Institute of Applied Information Processing and Communications (IAIK), Graz University of Technology, Inffeldgasse 16a, Graz, 8010, Austria', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178570483&doi=10.5220%2f0012089600003555&partnerID=40&md5=1e34215976af1e4ad53ab3532172c826', 'doi': '10.5220/0012089600003555', 'pages': '433 – 441', 'volume': '1', 'journal': 'Proceedings of the International Conference on Security and Cryptography', 'year': '2023', 'title': 'OCScraper: Automated Analysis of the Fingerprintability of the iOS API', 'author': 'Palfinger, Gerald', 'ENTRYTYPE': 'conference', 'ID': 'Palfinger2023433'}",Scopus
"Molesky, Monroe J.",COMMUNICATING CYBERSECURITY AND PRIVACY DESIGN ATTRIBUTES THROUGH PRIVACY LABELING OF CONSUMER ELECTRONIC MEDICAL DEVICES,,"The emergence of electronic medical devices has facilitated the integration of cybersecurity and privacy practices into the design of medical devices. An essential part of device design is the communication of the device principles to the consumers and providers that will utilize the device. The purpose of this research was to analyze the importance of health information privacy, propose a medical device privacy label and standards that can help fill these gaps for consumers, and evaluate the regulatory framework for which this proposal can be implemented. Privacy, both physical and informational, is a key pillar of American healthcare especially in our connected worlds. The threat to privacy from criminal actors and the impact that those actions of violating privacy can have on an individual's health are serious. Evaluating previous privacy labels, which lacked in applicability to the healthcare field, this research proposes a unique, standardized consumer privacy label for the FDA to implement, mirroring the design and success of the FDA nutrition label in educating consumers in healthy decision making. © 2022 by ASME",2022,"Proceedings of the 2022 Design of Medical Devices Conference, DMD 2022",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130221497&doi=10.1115%2fDMD2022-1045&partnerID=40&md5=4efff4359ea63f69343d9c07c323530e,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'American Society of Mechanical Engineers', 'abstract': ""The emergence of electronic medical devices has facilitated the integration of cybersecurity and privacy practices into the design of medical devices. An essential part of device design is the communication of the device principles to the consumers and providers that will utilize the device. The purpose of this research was to analyze the importance of health information privacy, propose a medical device privacy label and standards that can help fill these gaps for consumers, and evaluate the regulatory framework for which this proposal can be implemented. Privacy, both physical and informational, is a key pillar of American healthcare especially in our connected worlds. The threat to privacy from criminal actors and the impact that those actions of violating privacy can have on an individual's health are serious. Evaluating previous privacy labels, which lacked in applicability to the healthcare field, this research proposes a unique, standardized consumer privacy label for the FDA to implement, mirroring the design and success of the FDA nutrition label in educating consumers in healthy decision making. © 2022 by ASME"", 'affiliations': 'Department of Health Policy and Management, Milken Institute School of Public Health, The George Washington University, Washington, DC, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130221497&doi=10.1115%2fDMD2022-1045&partnerID=40&md5=4efff4359ea63f69343d9c07c323530e', 'doi': '10.1115/DMD2022-1045', 'journal': 'Proceedings of the 2022 Design of Medical Devices Conference, DMD 2022', 'year': '2022', 'title': 'COMMUNICATING CYBERSECURITY AND PRIVACY DESIGN ATTRIBUTES THROUGH PRIVACY LABELING OF CONSUMER ELECTRONIC MEDICAL DEVICES', 'author': 'Molesky, Monroe J.', 'ENTRYTYPE': 'conference', 'ID': 'Molesky2022'}",Scopus
"Khandelwal, Rishabh and Nayak, Asmit and Chung, Paul and Fawaz, Kassem",Comparing Privacy Labels of Applications in Android and iOS,,"The increasing concern for privacy protection in mobile apps has prompted the development of tools such as privacy labels to assist users in understanding the privacy practices of applications. Both Google and Apple have mandated developers to use privacy labels to increase transparency in data collection and sharing practices. These privacy labels provide detailed information about apps' data practices, including the types of data collected and the purposes associated with each data type. This offers a unique opportunity to understand apps' data practices at scale. In this study, we conduct a large-scale measurement study of privacy labels using apps from the Android Play Store (n=2.4M) and the Apple App Store (n=1.38M). We establish a common mapping between iOS and Android labels, enabling a direct comparison of disclosed practices and data types between the two platforms. By studying over 100K apps, we identify discrepancies and inconsistencies in self-reported privacy practices across platforms. Our findings reveal that at least 60% of all apps have different practices on the two platforms. Additionally, we explore factors contributing to these discrepancies and provide valuable insights for developers, users, and policymakers. Our analysis suggests that while privacy labels have the potential to provide useful information concisely, in their current state, it is not clear whether the information provided is accurate. Without robust consistency checks by the distribution platforms, privacy labels may not be as effective and can even create a false sense of security for users. Our study highlights the need for further research and improved mechanisms to ensure the accuracy and consistency of privacy labels.  © 2023 ACM.",2023,WPES 2023 - Proceedings of the 22nd Workshop on Privacy in the Electronic Society,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180008609&doi=10.1145%2f3603216.3624967&partnerID=40&md5=9e5a0d92f9d1bb51f01599a12bb5a945,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery, Inc', 'abstract': ""The increasing concern for privacy protection in mobile apps has prompted the development of tools such as privacy labels to assist users in understanding the privacy practices of applications. Both Google and Apple have mandated developers to use privacy labels to increase transparency in data collection and sharing practices. These privacy labels provide detailed information about apps' data practices, including the types of data collected and the purposes associated with each data type. This offers a unique opportunity to understand apps' data practices at scale. In this study, we conduct a large-scale measurement study of privacy labels using apps from the Android Play Store (n=2.4M) and the Apple App Store (n=1.38M). We establish a common mapping between iOS and Android labels, enabling a direct comparison of disclosed practices and data types between the two platforms. By studying over 100K apps, we identify discrepancies and inconsistencies in self-reported privacy practices across platforms. Our findings reveal that at least 60% of all apps have different practices on the two platforms. Additionally, we explore factors contributing to these discrepancies and provide valuable insights for developers, users, and policymakers. Our analysis suggests that while privacy labels have the potential to provide useful information concisely, in their current state, it is not clear whether the information provided is accurate. Without robust consistency checks by the distribution platforms, privacy labels may not be as effective and can even create a false sense of security for users. Our study highlights the need for further research and improved mechanisms to ensure the accuracy and consistency of privacy labels.  © 2023 ACM."", 'affiliations': 'University of Wisconsin-Madison, Madison, WI, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180008609&doi=10.1145%2f3603216.3624967&partnerID=40&md5=9e5a0d92f9d1bb51f01599a12bb5a945', 'doi': '10.1145/3603216.3624967', 'pages': '61 – 73', 'journal': 'WPES 2023 - Proceedings of the 22nd Workshop on Privacy in the Electronic Society', 'year': '2023', 'title': 'Comparing Privacy Labels of Applications in Android and iOS', 'author': 'Khandelwal, Rishabh and Nayak, Asmit and Chung, Paul and Fawaz, Kassem', 'ENTRYTYPE': 'conference', 'ID': 'Khandelwal202361'}",Scopus
"Fowler, Leah R. and Ulrich, Michael R.",Femtechnodystopia,,"Reproductive rights, as we have long understood them, are dead. But while history seems to be moving backward, technology moves relentlessly forward. “Femtech” products, a category of consumer technology addressing an array of “female” health needs, seem poised to fill gaps created by states and stakeholders eager to limit birth control and abortion access and to increase pregnancy surveillance and fetal rights. Period- and fertilitytracking applications could supplement or replace other contraception. Early digital alerts to missed periods can improve the chances of obtaining a legal abortion in states with evershrinking windows of availability or prompt behavioral changes that support the health of the fetus. However, more nefarious actors also have interests in these technologies and the intimate information they contain. In the wrong hands, these tools can effectuate increased reproductive control and criminalization. What happens next will depend on whether we can improve accuracy, limit foreseeable privacy risks, and raise consumer awareness. But the current legal and regulatory landscape makes achieving these goals difficult, and it is further complicated by political influence and a conservative Supreme Court. This Article assesses multiple solutions involving diverse stakeholders, concluding that a multifaceted approach is needed to keep femtech’s dystopian future from becoming a reality. © 2023, Stanford Law School. All rights reserved.",2023,Stanford Law Review,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172471310&partnerID=40&md5=214bdff6b892e9dad680c294899aa0d6,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Stanford Law School', 'abstract': 'Reproductive rights, as we have long understood them, are dead. But while history seems to be moving backward, technology moves relentlessly forward. “Femtech” products, a category of consumer technology addressing an array of “female” health needs, seem poised to fill gaps created by states and stakeholders eager to limit birth control and abortion access and to increase pregnancy surveillance and fetal rights. Period- and fertilitytracking applications could supplement or replace other contraception. Early digital alerts to missed periods can improve the chances of obtaining a legal abortion in states with evershrinking windows of availability or prompt behavioral changes that support the health of the fetus. However, more nefarious actors also have interests in these technologies and the intimate information they contain. In the wrong hands, these tools can effectuate increased reproductive control and criminalization. What happens next will depend on whether we can improve accuracy, limit foreseeable privacy risks, and raise consumer awareness. But the current legal and regulatory landscape makes achieving these goals difficult, and it is further complicated by political influence and a conservative Supreme Court. This Article assesses multiple solutions involving diverse stakeholders, concluding that a multifaceted approach is needed to keep femtech’s dystopian future from becoming a reality. © 2023, Stanford Law School. All rights reserved.', 'affiliations': 'University of Houston Law Center, United States; Boston University School of Law and Boston University School of Public Health, Solomon Center Distinguished Visiting Scholar, Yale Law School, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172471310&partnerID=40&md5=214bdff6b892e9dad680c294899aa0d6', 'pages': '1233 – 1313', 'number': '6', 'volume': '75', 'journal': 'Stanford Law Review', 'year': '2023', 'title': 'Femtechnodystopia', 'author': 'Fowler, Leah R. and Ulrich, Michael R.', 'ENTRYTYPE': 'article', 'ID': 'Fowler20231233'}",Scopus
"Balboni, Paolo and Francis, Kate Elizabeth",Data protection as a corporate social responsibility,,"This progressive book critically analyses the current state of data protection enforcement and proposes a new auditable framework of practical guidelines to contribute to a more sustainable data-driven future. In outlining the debates relating to current data protection structures, Paolo Balboni and Kate Elizabeth Francis argue that legislation alone cannot sufficiently protect individuals' fundamental rights and freedoms, and instead consider the pressing need for a more ethical approach to data protection. They present the Maastricht University Data Protection as a Corporate Social Responsibility Framework (UM-DPCSR Framework), outlining not only its features, but also how it can fill the gap left by the inadequacies of a merely legal approach to data protection. Balboni and Francis persuasively call on organisations wishing to contribute positively to society through data processing to adopt this framework and to commit to doing good with data or, at the very least, to avoid harming individuals by processing their data. Data Protection as a Corporate Social Responsibility will be a beneficial read for scholars and students with particular interest in corporate law and governance, human rights, internet and technology law, and privacy. It will also appeal to legal professionals, cybersecurity professionals, and sustainability specialists alike. © Paolo Balboni and Kate Elizabeth Francis 2023. All rights reserved.",2023,Data Protection as a Corporate Social Responsibility,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190259496&doi=10.4337%2f9781035314164&partnerID=40&md5=44033d45186c2f2fa8277ed68edd53c9,"{'note': 'All Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Book', 'language': 'English', 'publisher': 'Edward Elgar Publishing Ltd.', 'abstract': ""This progressive book critically analyses the current state of data protection enforcement and proposes a new auditable framework of practical guidelines to contribute to a more sustainable data-driven future. In outlining the debates relating to current data protection structures, Paolo Balboni and Kate Elizabeth Francis argue that legislation alone cannot sufficiently protect individuals' fundamental rights and freedoms, and instead consider the pressing need for a more ethical approach to data protection. They present the Maastricht University Data Protection as a Corporate Social Responsibility Framework (UM-DPCSR Framework), outlining not only its features, but also how it can fill the gap left by the inadequacies of a merely legal approach to data protection. Balboni and Francis persuasively call on organisations wishing to contribute positively to society through data processing to adopt this framework and to commit to doing good with data or, at the very least, to avoid harming individuals by processing their data. Data Protection as a Corporate Social Responsibility will be a beneficial read for scholars and students with particular interest in corporate law and governance, human rights, internet and technology law, and privacy. It will also appeal to legal professionals, cybersecurity professionals, and sustainability specialists alike. © Paolo Balboni and Kate Elizabeth Francis 2023. All rights reserved."", 'affiliations': 'Faculty of Law, Maastricht University, Netherlands', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190259496&doi=10.4337%2f9781035314164&partnerID=40&md5=44033d45186c2f2fa8277ed68edd53c9', 'doi': '10.4337/9781035314164', 'pages': '1 – 302', 'journal': 'Data Protection as a Corporate Social Responsibility', 'year': '2023', 'title': 'Data protection as a corporate social responsibility', 'author': 'Balboni, Paolo and Francis, Kate Elizabeth', 'ENTRYTYPE': 'book', 'ID': 'Balboni20231'}",Scopus
"Wu, Ruihan and Zhou, Jin Peng and Weiberger, Kilian Q. and Guo, Chuan",Does Label Differential Privacy Prevent Label Inference Attacks?,,"Label differential privacy (label-DP) is a popular framework for training private ML models on datasets with public features and sensitive private labels. Despite its rigorous privacy guarantee, it has been observed that in practice label-DP does not preclude label inference attacks (LIAs): Models trained with label-DP can be evaluated on the public training features to recover, with high accuracy, the very private labels that it was designed to protect. In this work, we argue that this phenomenon is not paradoxical and that label-DP is designed to limit the advantage of an LIA adversary compared to predicting training labels using the Bayes classifier. At label-DP ∊ = 0 this advantage is zero, hence the optimal attack is to predict according to the Bayes classifier and is independent of the training labels. Our bound shows the semantic protection conferred by label-DP and gives guidelines on how to choose ε to limit the threat of LIAs below a certain level. Finally, we empirically demonstrate that our result closely captures the behavior of simulated attacks on both synthetic and real world datasets. Copyright © 2023 by the author(s)",2023,Proceedings of Machine Learning Research,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165166110&partnerID=40&md5=07ff93ec40c241367a6485f948683423,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'ML Research Press', 'abstract': 'Label differential privacy (label-DP) is a popular framework for training private ML models on datasets with public features and sensitive private labels. Despite its rigorous privacy guarantee, it has been observed that in practice label-DP does not preclude label inference attacks (LIAs): Models trained with label-DP can be evaluated on the public training features to recover, with high accuracy, the very private labels that it was designed to protect. In this work, we argue that this phenomenon is not paradoxical and that label-DP is designed to limit the advantage of an LIA adversary compared to predicting training labels using the Bayes classifier. At label-DP ∊ = 0 this advantage is zero, hence the optimal attack is to predict according to the Bayes classifier and is independent of the training labels. Our bound shows the semantic protection conferred by label-DP and gives guidelines on how to choose ε to limit the threat of LIAs below a certain level. Finally, we empirically demonstrate that our result closely captures the behavior of simulated attacks on both synthetic and real world datasets. Copyright © 2023 by the author(s)', 'affiliations': 'Cornell University, United States; Meta AI, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165166110&partnerID=40&md5=07ff93ec40c241367a6485f948683423', 'pages': '4336 – 4347', 'volume': '206', 'journal': 'Proceedings of Machine Learning Research', 'year': '2023', 'title': 'Does Label Differential Privacy Prevent Label Inference Attacks?', 'author': 'Wu, Ruihan and Zhou, Jin Peng and Weiberger, Kilian Q. and Guo, Chuan', 'ENTRYTYPE': 'conference', 'ID': 'Wu20234336'}",Scopus
"Abraham, Melvin and Saeghe, Pejman and McGill, Mark and Khamis, Mohamed","Implications of XR on Privacy, Security and Behaviour: Insights from Experts",,"Extended-Reality (XR) devices are packed with sensors that allow tracking of users (e.g., behaviour, actions, eye-gaze) and their surroundings (e.g., people, places, objects). As a consequence, XR devices pose significant risks to privacy, security, and our ability to understand and influence the behaviour of users - risks that will be amplified by ever-increasing adoption. This necessitates addressing these concerns before XR becomes ubiquitous. We conducted three focus groups with thirteen XR experts from industry and academia interested in XR, security, and privacy, to investigate current and emerging issues relating to security, privacy, and influencing behaviour. We identified issues such as virtual threats leading to physical harm, missing opting-out methods, and amplifying bias through perceptual filters. From the results we establish a collection of prescient challenges relating to security, privacy and behavioural manipulation within XR and present recommendations working towards developing future XR devices that better support security and privacy by default.  © 2022 ACM.",2022,ACM International Conference Proceeding Series,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140913602&doi=10.1145%2f3546155.3546691&partnerID=40&md5=d95ad598d1ee997bea1ba767e2b66ee8,"{'note': 'All Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': 'Extended-Reality (XR) devices are packed with sensors that allow tracking of users (e.g., behaviour, actions, eye-gaze) and their surroundings (e.g., people, places, objects). As a consequence, XR devices pose significant risks to privacy, security, and our ability to understand and influence the behaviour of users - risks that will be amplified by ever-increasing adoption. This necessitates addressing these concerns before XR becomes ubiquitous. We conducted three focus groups with thirteen XR experts from industry and academia interested in XR, security, and privacy, to investigate current and emerging issues relating to security, privacy, and influencing behaviour. We identified issues such as virtual threats leading to physical harm, missing opting-out methods, and amplifying bias through perceptual filters. From the results we establish a collection of prescient challenges relating to security, privacy and behavioural manipulation within XR and present recommendations working towards developing future XR devices that better support security and privacy by default.  © 2022 ACM.', 'affiliations': 'School of Computer Science, University of Glasgow, United Kingdom', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140913602&doi=10.1145%2f3546155.3546691&partnerID=40&md5=d95ad598d1ee997bea1ba767e2b66ee8', 'doi': '10.1145/3546155.3546691', 'journal': 'ACM International Conference Proceeding Series', 'year': '2022', 'title': 'Implications of XR on Privacy, Security and Behaviour: Insights from Experts', 'author': 'Abraham, Melvin and Saeghe, Pejman and McGill, Mark and Khamis, Mohamed', 'ENTRYTYPE': 'conference', 'ID': 'Abraham2022'}",Scopus
"Heinrich, Matthew and Gerhart, Natalie",Privacy Education Effectiveness: Does It Matter?,,"Mobile devices are a constantly used item in a college student’s life. Students depend on them for entertainment, academics, and socializing with their friends. While they continually use them, they perhaps do not understand the impact of their use on their privacy or that the devices can be used to track them and collect their personal information. This study utilizes the Antecedent, Privacy Concern, Outcome (APCO) model, combined with the Fogg Behavior Model (FBM) to determine (1) the factors that comprise privacy concerns on a mobile device; (2) whether individuals use privacy-protective behaviors, and (3) whether education on privacy issues regarding mobile devices will increase their use of privacy-enhancing technology (PET). A longitudinal study was conducted to test whether privacy protection education increases the use of PET. While students express concern for their privacy when using mobile devices and express an intent to use additional PET, their behavior using mobile device protections does not change, even after an educational intervention. Perceived privacy control does not change their privacy concern and habit and trust outweigh the impact of privacy concern. Theoretical and practical implications are provided © 2023 by the Information Systems & Computing Academic Professionals, Inc. (ISCAP)",2023,Journal of Information Systems Education,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148573344&partnerID=40&md5=3cb54f59538a3af52effca059ffe3a04,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'ISCAP- Information Systems and Computing Academic Professionals', 'abstract': 'Mobile devices are a constantly used item in a college student’s life. Students depend on them for entertainment, academics, and socializing with their friends. While they continually use them, they perhaps do not understand the impact of their use on their privacy or that the devices can be used to track them and collect their personal information. This study utilizes the Antecedent, Privacy Concern, Outcome (APCO) model, combined with the Fogg Behavior Model (FBM) to determine (1) the factors that comprise privacy concerns on a mobile device; (2) whether individuals use privacy-protective behaviors, and (3) whether education on privacy issues regarding mobile devices will increase their use of privacy-enhancing technology (PET). A longitudinal study was conducted to test whether privacy protection education increases the use of PET. While students express concern for their privacy when using mobile devices and express an intent to use additional PET, their behavior using mobile device protections does not change, even after an educational intervention. Perceived privacy control does not change their privacy concern and habit and trust outweigh the impact of privacy concern. Theoretical and practical implications are provided © 2023 by the Information Systems & Computing Academic Professionals, Inc. (ISCAP)', 'affiliations': 'Department of Mathematics, Analytics, and Technology, Rockhurst University, Kansas City, 64110, MO, United States; Department of Business Intelligence and Analytics, Creighton University, Omaha, 68178, NE, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148573344&partnerID=40&md5=3cb54f59538a3af52effca059ffe3a04', 'pages': '49 – 69', 'number': '1', 'volume': '34', 'journal': 'Journal of Information Systems Education', 'year': '2023', 'title': 'Privacy Education Effectiveness: Does It Matter?', 'author': 'Heinrich, Matthew and Gerhart, Natalie', 'ENTRYTYPE': 'article', 'ID': 'Heinrich202349'}",Scopus
"Paci, Federica and Pizzoli, Jacopo and Zannone, Nicola",A Comprehensive Study on Third-Party User Tracking in Mobile Applications,,"Third-party tracking is becoming a prevalent practice in mobile app ecosystems. While providing benefits for app developers, this practice also introduces several privacy issues for end-users. The European General Data Protection Regulation (GDPR) and the ePrivacy Directive (ePD) mandate that mobile apps must obtain user consent before sharing users' personal data with third-party trackers. This work presents an empirical study investigating the compliance of 400 popular mobile apps (200 Android apps and their corresponding version for iOS) with the ePD and GDPR requirements on valid consent. Moreover, we determined whether these mobile apps actually enforce the consent given by users on being tracked and which are the more common third-party tracker domains contacted by the apps. The analysis shows that none of the studied apps fully comply with ePD and GDPR requirements on valid consent. The most common violations were associated with the principles of freely-given, specific, and revocable consent. Moreover, we found that almost half of the analyzed apps contact third-party tracker domains even when the user has not given their consent to be tracked. © 2023 ACM.",2023,ACM International Conference Proceeding Series,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169667945&doi=10.1145%2f3600160.3605079&partnerID=40&md5=f6c44e12dd9576b7e5e48da5c670697b,"{'note': 'All Open Access, Hybrid Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': ""Third-party tracking is becoming a prevalent practice in mobile app ecosystems. While providing benefits for app developers, this practice also introduces several privacy issues for end-users. The European General Data Protection Regulation (GDPR) and the ePrivacy Directive (ePD) mandate that mobile apps must obtain user consent before sharing users' personal data with third-party trackers. This work presents an empirical study investigating the compliance of 400 popular mobile apps (200 Android apps and their corresponding version for iOS) with the ePD and GDPR requirements on valid consent. Moreover, we determined whether these mobile apps actually enforce the consent given by users on being tracked and which are the more common third-party tracker domains contacted by the apps. The analysis shows that none of the studied apps fully comply with ePD and GDPR requirements on valid consent. The most common violations were associated with the principles of freely-given, specific, and revocable consent. Moreover, we found that almost half of the analyzed apps contact third-party tracker domains even when the user has not given their consent to be tracked. © 2023 ACM."", 'affiliations': 'University of Verona, Verona, Italy; Eindhoven University of Technology, Eindhoven, Netherlands', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169667945&doi=10.1145%2f3600160.3605079&partnerID=40&md5=f6c44e12dd9576b7e5e48da5c670697b', 'doi': '10.1145/3600160.3605079', 'journal': 'ACM International Conference Proceeding Series', 'year': '2023', 'title': 'A Comprehensive Study on Third-Party User Tracking in Mobile Applications', 'author': 'Paci, Federica and Pizzoli, Jacopo and Zannone, Nicola', 'ENTRYTYPE': 'conference', 'ID': 'Paci2023'}",Scopus
"Huang, Yan and Li, Yi Joy and Cai, Zhipeng",Security and Privacy in Metaverse: A Comprehensive Survey,,"Metaverse describes a new shape of cyberspace and has become a hot-trending word since 2021. There are many explanations about what Meterverse is and attempts to provide a formal standard or definition of Metaverse. However, these definitions could hardly reach universal acceptance. Rather than providing a formal definition of the Metaverse, we list four must-have characteristics of the Metaverse: socialization, immersive interaction, real world-building, and expandability. These characteristics not only carve the Metaverse into a novel and fantastic digital world, but also make it suffer from all security/privacy risks, such as personal information leakage, eavesdropping, unauthorized access, phishing, data injection, broken authentication, insecure design, and more. This paper first introduces the four characteristics, then the current progress and typical applications of the Metaverse are surveyed and categorized into four economic sectors. Based on the four characteristics and the findings of the current progress, the security and privacy issues in the Metaverse are investigated. We then identify and discuss more potential critical security and privacy issues that can be caused by combining the four characteristics. Lastly, the paper also raises some other concerns regarding society and humanity. © 2018 Tsinghua University Press.",2023,Big Data Mining and Analytics,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148698875&doi=10.26599%2fBDMA.2022.9020047&partnerID=40&md5=5f5a81c2aad57da9f5870ba2e06c2b39,"{'note': 'All Open Access, Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Tsinghua University Press', 'abstract': 'Metaverse describes a new shape of cyberspace and has become a hot-trending word since 2021. There are many explanations about what Meterverse is and attempts to provide a formal standard or definition of Metaverse. However, these definitions could hardly reach universal acceptance. Rather than providing a formal definition of the Metaverse, we list four must-have characteristics of the Metaverse: socialization, immersive interaction, real world-building, and expandability. These characteristics not only carve the Metaverse into a novel and fantastic digital world, but also make it suffer from all security/privacy risks, such as personal information leakage, eavesdropping, unauthorized access, phishing, data injection, broken authentication, insecure design, and more. This paper first introduces the four characteristics, then the current progress and typical applications of the Metaverse are surveyed and categorized into four economic sectors. Based on the four characteristics and the findings of the current progress, the security and privacy issues in the Metaverse are investigated. We then identify and discuss more potential critical security and privacy issues that can be caused by combining the four characteristics. Lastly, the paper also raises some other concerns regarding society and humanity. © 2018 Tsinghua University Press.', 'affiliations': 'Kennesaw State University, Department of Software Engineering and Game Development, Atlanta, 30060, GA, United States; Georgia State University, Department of Computer Science, Atlanta, 30303, GA, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148698875&doi=10.26599%2fBDMA.2022.9020047&partnerID=40&md5=5f5a81c2aad57da9f5870ba2e06c2b39', 'doi': '10.26599/BDMA.2022.9020047', 'pages': '234 – 247', 'number': '2', 'volume': '6', 'journal': 'Big Data Mining and Analytics', 'year': '2023', 'title': 'Security and Privacy in Metaverse: A Comprehensive Survey', 'author': 'Huang, Yan and Li, Yi Joy and Cai, Zhipeng', 'ENTRYTYPE': 'article', 'ID': 'Huang2023234'}",Scopus
"Lola, João and Serrão, Carlos and Casal, João",Towards Transparent and Secure IoT: Improving the Security and Privacy through a User-Centric Rules-Based System,,"In recent years, we have seen a growing wave in the integration of IoT (Internet of Things) technologies into society. This has created new opportunities, but at the same time given rise to several critical issues, creating new challenges that need to be addressed. One of the main challenges is the security and privacy of information that is processed by IoT devices in our daily lives. Users are, most of the time, unaware of IoT devices’ personal information collection and transmission activities that affect their security and privacy. In this work, we propose a solution that aims to increase the privacy and security of data in IoT devices, through a system that controls the IoT device’s communication on the network. This system is based on two basic and simple principles. First, the IoT device manufacturer declares their device’s data collection intentions. Second, the user declares their own preferences of what is permitted to the IoT device. The design of the system includes tools capable of analyzing packets sent by IoT devices and applying network traffic control rules. The objective is to allow the declaration and verification of communication intentions of IoT devices and control the communication of such devices to detect potential security and privacy violations. We have created a test-bed to validate the developed solution, based on virtual machines, and we concluded that our system has little impact on how the overall system performed. © 2023 by the authors.",2023,Electronics (Switzerland),https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163850802&doi=10.3390%2felectronics12122589&partnerID=40&md5=729f73818ff037896662e63e2aa2d9db,"{'note': 'All Open Access, Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'MDPI', 'abstract': 'In recent years, we have seen a growing wave in the integration of IoT (Internet of Things) technologies into society. This has created new opportunities, but at the same time given rise to several critical issues, creating new challenges that need to be addressed. One of the main challenges is the security and privacy of information that is processed by IoT devices in our daily lives. Users are, most of the time, unaware of IoT devices’ personal information collection and transmission activities that affect their security and privacy. In this work, we propose a solution that aims to increase the privacy and security of data in IoT devices, through a system that controls the IoT device’s communication on the network. This system is based on two basic and simple principles. First, the IoT device manufacturer declares their device’s data collection intentions. Second, the user declares their own preferences of what is permitted to the IoT device. The design of the system includes tools capable of analyzing packets sent by IoT devices and applying network traffic control rules. The objective is to allow the declaration and verification of communication intentions of IoT devices and control the communication of such devices to detect potential security and privacy violations. We have created a test-bed to validate the developed solution, based on virtual machines, and we concluded that our system has little impact on how the overall system performed. © 2023 by the authors.', 'affiliations': 'Information Sciences, Technologies and Architecture Research Center (ISTAR), Instituto Universitário de Lisboa (ISCTE-IUL), Lisboa, 1600-189, Portugal; SCNL Truphone, S.A., Lisboa, 1700-158, Portugal', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163850802&doi=10.3390%2felectronics12122589&partnerID=40&md5=729f73818ff037896662e63e2aa2d9db', 'doi': '10.3390/electronics12122589', 'number': '12', 'volume': '12', 'journal': 'Electronics (Switzerland)', 'year': '2023', 'title': 'Towards Transparent and Secure IoT: Improving the Security and Privacy through a User-Centric Rules-Based System', 'author': 'Lola, João and Serrão, Carlos and Casal, João', 'ENTRYTYPE': 'article', 'ID': 'Lola2023'}",Scopus
,WPES 2023 - Proceedings of the 22nd Workshop on Privacy in the Electronic Society,,"The proceedings contain 17 papers. The topics discussed include: Zef: low-latency, scalable, private payments; from privacy policies to privacy threats: a case study in policy-based threat modeling; UA-radar: exploring the impact of user agents on the web; client-specific property inference against secure aggregation in federated learning; comparing privacy labels of applications in android and iOS; Maybenot: a framework for traffic analysis defenses; unveiling the impact of user-agent reduction and client hints: a measurement study; trends in privacy dialog design after the GDPR: the impact of industry and government actions; a quantitative information flow analysis of the topics API; The HandyTech’s coming between 1 and 4: privacy opportunities and challenges for the IoT handyperson; bazaar: anonymous resource sharing; extending browser extension fingerprinting to mobile devices; legitimate interest is the new consent – large-scale measurement and legal compliance of IAB Europe TCF paywalls; and impact analysis of organizational structure of group companies on privacy policies.",2023,WPES 2023 - Proceedings of the 22nd Workshop on Privacy in the Electronic Society,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180104465&partnerID=40&md5=79f901d5339f9ff274d3de43c168f7a7,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference review', 'language': 'English', 'publisher': 'Association for Computing Machinery, Inc', 'abstract': 'The proceedings contain 17 papers. The topics discussed include: Zef: low-latency, scalable, private payments; from privacy policies to privacy threats: a case study in policy-based threat modeling; UA-radar: exploring the impact of user agents on the web; client-specific property inference against secure aggregation in federated learning; comparing privacy labels of applications in android and iOS; Maybenot: a framework for traffic analysis defenses; unveiling the impact of user-agent reduction and client hints: a measurement study; trends in privacy dialog design after the GDPR: the impact of industry and government actions; a quantitative information flow analysis of the topics API; The HandyTech’s coming between 1 and 4: privacy opportunities and challenges for the IoT handyperson; bazaar: anonymous resource sharing; extending browser extension fingerprinting to mobile devices; legitimate interest is the new consent – large-scale measurement and legal compliance of IAB Europe TCF paywalls; and impact analysis of organizational structure of group companies on privacy policies.', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180104465&partnerID=40&md5=79f901d5339f9ff274d3de43c168f7a7', 'journal': 'WPES 2023 - Proceedings of the 22nd Workshop on Privacy in the Electronic Society', 'year': '2023', 'title': 'WPES 2023 - Proceedings of the 22nd Workshop on Privacy in the Electronic Society', 'ENTRYTYPE': 'conference', 'ID': '2023'}",Scopus
"Thalhammer, Philipp and Müller, David and Schmidt, Alexander and Huber, Michael and Schmidt, Albrecht and Feger, Sebastian",ConnectivityControl: A Model Ecosystem for Advanced Smart Home Privacy,,"Smart home devices with their sophisticated sensing technologies raise many privacy concerns. In most cases, they only function when fully connected to the internet in which case privacy exposure is greatest. Users currently have to either accept these privacy risks or remove devices from the internet or power plug, rendering them useless. Our demo is based on recent work advocating for advanced smart device configuration options across a spectrum of connectivity control options. We introduce a model ecosystem with four connectivity levels and a privacy label that informs about connectivity-feature trade-offs across those four modes. The presented ecosystem introduces two functional smart devices and demonstrates intuitively how configuration decisions impact information flow. © 2023 Owner/Author.",2023,ACM International Conference Proceeding Series,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180125767&doi=10.1145%2f3626705.3631876&partnerID=40&md5=9c7b4457804567dd5b764f0826238ffe,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': 'Smart home devices with their sophisticated sensing technologies raise many privacy concerns. In most cases, they only function when fully connected to the internet in which case privacy exposure is greatest. Users currently have to either accept these privacy risks or remove devices from the internet or power plug, rendering them useless. Our demo is based on recent work advocating for advanced smart device configuration options across a spectrum of connectivity control options. We introduce a model ecosystem with four connectivity levels and a privacy label that informs about connectivity-feature trade-offs across those four modes. The presented ecosystem introduces two functional smart devices and demonstrates intuitively how configuration decisions impact information flow. © 2023 Owner/Author.', 'affiliations': 'Lmu Munich, Munich, Germany', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180125767&doi=10.1145%2f3626705.3631876&partnerID=40&md5=9c7b4457804567dd5b764f0826238ffe', 'doi': '10.1145/3626705.3631876', 'pages': '550 – 552', 'journal': 'ACM International Conference Proceeding Series', 'year': '2023', 'title': 'ConnectivityControl: A Model Ecosystem for Advanced Smart Home Privacy', 'author': 'Thalhammer, Philipp and Müller, David and Schmidt, Alexander and Huber, Michael and Schmidt, Albrecht and Feger, Sebastian', 'ENTRYTYPE': 'conference', 'ID': 'Thalhammer2023550'}",Scopus
"Flensburg, Sofie and Lai, Signe Sophus",Follow the Data! A Strategy for Tracing Infrastructural Power,,"Recalling the well-known strategy of “following the money” when investigating the underlying power structures and business models of legacy media, this article argues that studies of digital political economies can benefit instead from following the data. Combining perspectives from critical data studies and infrastructure research, we first discuss how direct money flows can be difficult to trace in digital ecosystems, creating a need for alternative analytical approaches for studying and scrutinising contemporary power configurations in digital societies. As a theoretical backdrop, we elaborate on the concept of infrastructural power and apply it in a walkthrough of critical data infrastructures. To illustrate the efficacy of this strategy, we provide perspectives and examples from the political economies of internet infrastructures in Northern Europe and discuss how control over data is translated into economic profit and societal power. In doing so, we argue that increased attention to data infrastructures is needed to advance both critical data and infrastructure studies, improve digital market monitoring, and ground future regulation and policy. © 2023 by the author(s); licensee Cogitatio Press (Lisbon, Portugal).",2023,Media and Communication,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163324081&doi=10.17645%2fmac.v11i2.6464&partnerID=40&md5=dba7f981108572578eb78925820043ad,"{'note': 'All Open Access, Gold Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Cogitatio Press', 'abstract': 'Recalling the well-known strategy of “following the money” when investigating the underlying power structures and business models of legacy media, this article argues that studies of digital political economies can benefit instead from following the data. Combining perspectives from critical data studies and infrastructure research, we first discuss how direct money flows can be difficult to trace in digital ecosystems, creating a need for alternative analytical approaches for studying and scrutinising contemporary power configurations in digital societies. As a theoretical backdrop, we elaborate on the concept of infrastructural power and apply it in a walkthrough of critical data infrastructures. To illustrate the efficacy of this strategy, we provide perspectives and examples from the political economies of internet infrastructures in Northern Europe and discuss how control over data is translated into economic profit and societal power. In doing so, we argue that increased attention to data infrastructures is needed to advance both critical data and infrastructure studies, improve digital market monitoring, and ground future regulation and policy. © 2023 by the author(s); licensee Cogitatio Press (Lisbon, Portugal).', 'affiliations': 'Center for Tracking and Society, University of Copenhagen, Denmark', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163324081&doi=10.17645%2fmac.v11i2.6464&partnerID=40&md5=dba7f981108572578eb78925820043ad', 'doi': '10.17645/mac.v11i2.6464', 'pages': '319 – 329', 'number': '2', 'volume': '11', 'journal': 'Media and Communication', 'year': '2023', 'title': 'Follow the Data! A Strategy for Tracing Infrastructural Power', 'author': 'Flensburg, Sofie and Lai, Signe Sophus', 'ENTRYTYPE': 'article', 'ID': 'Flensburg2023319'}",Scopus
"Feger, Sebastian S. and Windl, Maximiliane and Grootjen, Jesse and Schmidt, Albrecht",ConnectivityControl: Providing Smart Home Users with Real Privacy Configuration Options,,"Smart home devices become increasingly popular as they allow to automate tedious tasks and often provide a wide variety of entertainment features. Yet, this increase in comfort comes at the cost of exposure to privacy risks as connected devices in smart homes capture most sensitive user data, including video, audio, and movement data of the inhabitants and guests. Smart home owners and bystanders typically have very limited control over these recordings. While few devices do provide physical artifacts to block individual sensors, deactivating recording and transmission capabilities typically requires powering devices off or disconnecting them from the network, typically rendering these smart home appliances useless. In response, we created ConnectivityControl, a framework that allows users to switch between four device connectivity levels: Offline, Access Point mode, Local Network mode, and Online. ConnectivityControl features a privacy label that depicts how those modes impact device features and privacy exposure. The label can be used to inform purchase decisions and to monitor devices across their lifetime. In this paper, we detail the system architecture and the interaction design and showcase ConnectivityControl’s implementation in the context of two common smart home systems: a smart camera and an environmental sensing unit. Finally, we discuss how ConnectivityControl and its labels can transform the way smart home users configure their systems to match individual privacy needs. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",2023,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173565367&doi=10.1007%2f978-3-031-34433-6_11&partnerID=40&md5=5a9ffc04e1592f65a9d8f6b4cf53fcd7,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Springer Science and Business Media Deutschland GmbH', 'abstract': 'Smart home devices become increasingly popular as they allow to automate tedious tasks and often provide a wide variety of entertainment features. Yet, this increase in comfort comes at the cost of exposure to privacy risks as connected devices in smart homes capture most sensitive user data, including video, audio, and movement data of the inhabitants and guests. Smart home owners and bystanders typically have very limited control over these recordings. While few devices do provide physical artifacts to block individual sensors, deactivating recording and transmission capabilities typically requires powering devices off or disconnecting them from the network, typically rendering these smart home appliances useless. In response, we created ConnectivityControl, a framework that allows users to switch between four device connectivity levels: Offline, Access Point mode, Local Network mode, and Online. ConnectivityControl features a privacy label that depicts how those modes impact device features and privacy exposure. The label can be used to inform purchase decisions and to monitor devices across their lifetime. In this paper, we detail the system architecture and the interaction design and showcase ConnectivityControl’s implementation in the context of two common smart home systems: a smart camera and an environmental sensing unit. Finally, we discuss how ConnectivityControl and its labels can transform the way smart home users configure their systems to match individual privacy needs. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.', 'affiliations': 'LMU Munich, Munich, Germany', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173565367&doi=10.1007%2f978-3-031-34433-6_11&partnerID=40&md5=5a9ffc04e1592f65a9d8f6b4cf53fcd7', 'doi': '10.1007/978-3-031-34433-6_11', 'pages': '180 – 188', 'volume': '13917 LNCS', 'journal': 'Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)', 'year': '2023', 'title': 'ConnectivityControl: Providing Smart Home Users with\xa0Real Privacy Configuration Options', 'author': 'Feger, Sebastian S. and Windl, Maximiliane and Grootjen, Jesse and Schmidt, Albrecht', 'ENTRYTYPE': 'article', 'ID': 'Feger2023180'}",Scopus
"Bourdoucen, Amel and Nurgalieva, Leysan and Lindqvist, Janne",Privacy Is the Price: Player Views and Technical Evaluation of Data Practices in Online Games,,"Online games engage players in sharing their personal data with the games themselves and other players, which can pose security, privacy, and integrity risks to players. This paper presents an analysis of data practices in 21 online games and a qualitative interview study (N=20) that explores players' views on sharing their data in online games. Our results show that players' willingness to share personal information is contextual and related to game settings and game design elements. Our findings also highlight players' misconceptions and concerns surrounding data collection in games, and approaches to mitigate these concerns. Finally, this work identifies questionable design practices with online games and suggests design implications that will increase transparency and player control over data sharing.  © 2023 Owner/Author.",2023,Proceedings of the ACM on Human-Computer Interaction,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174385886&doi=10.1145%2f3611064&partnerID=40&md5=708c22fe6c842617be1bc285294442a7,"{'note': 'All Open Access, Hybrid Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': ""Online games engage players in sharing their personal data with the games themselves and other players, which can pose security, privacy, and integrity risks to players. This paper presents an analysis of data practices in 21 online games and a qualitative interview study (N=20) that explores players' views on sharing their data in online games. Our results show that players' willingness to share personal information is contextual and related to game settings and game design elements. Our findings also highlight players' misconceptions and concerns surrounding data collection in games, and approaches to mitigate these concerns. Finally, this work identifies questionable design practices with online games and suggests design implications that will increase transparency and player control over data sharing.  © 2023 Owner/Author."", 'affiliations': 'Aalto University, Espoo, Finland', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174385886&doi=10.1145%2f3611064&partnerID=40&md5=708c22fe6c842617be1bc285294442a7', 'doi': '10.1145/3611064', 'number': 'CHI PLAY', 'volume': '7', 'journal': 'Proceedings of the ACM on Human-Computer Interaction', 'year': '2023', 'title': 'Privacy Is the Price: Player Views and Technical Evaluation of Data Practices in Online Games', 'author': 'Bourdoucen, Amel and Nurgalieva, Leysan and Lindqvist, Janne', 'ENTRYTYPE': 'article', 'ID': 'Bourdoucen2023'}",Scopus
"Labadie, Clément and Legner, Christine",Building data management capabilities to address data protection regulations: Learnings from EU-GDPR,,"The European Union’s General Data Protection Regulation (EU-GDPR) has initiated a paradigm shift in data protection toward greater choice and sovereignty for individuals and more accountability for organizations. Its strict rules have inspired data protection regulations in other parts of the world. However, many organizations are facing difficulty complying with the EU-GDPR: these new types of data protection regulations cannot be addressed by an adaptation of contractual frameworks, but require a fundamental reconceptualization of how companies store and process personal data on an enterprise-wide level. In this paper, we introduce the resource-based view as a theoretical lens to explain the lengthy trajectories towards compliance and argue that these regulations require companies to build dedicated, enterprise-wide data management capabilities. Following a design science research approach, we propose a theoretically and empirically grounded capability model for the EU-GDPR that integrates the interpretation of legal texts, findings from EU-GDPR-related publications, and practical insights from focus groups with experts from 22 companies and four EU-GDPR projects. Our study advances interdisciplinary research at the intersection between IS and law: First, the proposed capability model adds to the regulatory compliance management literature by connecting abstract compliance requirements to three groups of capabilities and the resources required for their implementation, and second, it provides an enterprise-wide perspective that integrates and extends the fragmented body of research on EU-GDPR. Practitioners may use the capability model to assess their current status and set up systematic approaches toward compliance with an increasing number of data protection regulations. © Association for Information Technology Trust 2023.",2023,Journal of Information Technology,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147279828&doi=10.1177%2f02683962221141456&partnerID=40&md5=d48b90069a47575e0ecebbdd74717b9e,"{'note': 'All Open Access, Green Open Access, Hybrid Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'SAGE Publications Ltd', 'abstract': 'The European Union’s General Data Protection Regulation (EU-GDPR) has initiated a paradigm shift in data protection toward greater choice and sovereignty for individuals and more accountability for organizations. Its strict rules have inspired data protection regulations in other parts of the world. However, many organizations are facing difficulty complying with the EU-GDPR: these new types of data protection regulations cannot be addressed by an adaptation of contractual frameworks, but require a fundamental reconceptualization of how companies store and process personal data on an enterprise-wide level. In this paper, we introduce the resource-based view as a theoretical lens to explain the lengthy trajectories towards compliance and argue that these regulations require companies to build dedicated, enterprise-wide data management capabilities. Following a design science research approach, we propose a theoretically and empirically grounded capability model for the EU-GDPR that integrates the interpretation of legal texts, findings from EU-GDPR-related publications, and practical insights from focus groups with experts from 22 companies and four EU-GDPR projects. Our study advances interdisciplinary research at the intersection between IS and law: First, the proposed capability model adds to the regulatory compliance management literature by connecting abstract compliance requirements to three groups of capabilities and the resources required for their implementation, and second, it provides an enterprise-wide perspective that integrates and extends the fragmented body of research on EU-GDPR. Practitioners may use the capability model to assess their current status and set up systematic approaches toward compliance with an increasing number of data protection regulations. © Association for Information Technology Trust 2023.', 'affiliations': 'Faculty of Business and Economics (HEC), University of Lausanne, Switzerland', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147279828&doi=10.1177%2f02683962221141456&partnerID=40&md5=d48b90069a47575e0ecebbdd74717b9e', 'doi': '10.1177/02683962221141456', 'pages': '16 – 44', 'number': '1', 'volume': '38', 'journal': 'Journal of Information Technology', 'year': '2023', 'title': 'Building data management capabilities to address data protection regulations: Learnings from EU-GDPR', 'author': 'Labadie, Clément and Legner, Christine', 'ENTRYTYPE': 'article', 'ID': 'Labadie202316'}",Scopus
"Strickler, Meg",Recent Developments in Privacy Law,,,2022,Business Lawyer,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159714929&partnerID=40&md5=f1e878a673a403ed411331a29f58b695,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'American Bar Association', 'affiliations': ""ABA International Law Section Women's Interest Network, United States"", 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159714929&partnerID=40&md5=f1e878a673a403ed411331a29f58b695', 'pages': '247 – 258', 'number': '1', 'volume': '78', 'journal': 'Business Lawyer', 'year': '2022', 'title': 'Recent Developments in Privacy Law', 'author': 'Strickler, Meg', 'ENTRYTYPE': 'article', 'ID': 'Strickler2022247'}",Scopus
"Tilt, David",International Perspectives on Regulatory Frameworks: AI Through the Lens of Patent Law,,"This chapter considers the approach to regulating artificial intelligence (AI) from a patent law perspective, exploring how existing forms of regulation can help inform our stance vis-à-vis AI. The focus is on contextualising the developments in software and pharmaceutical regulation through patent law, and then applying these lessons to AI. The EU, US and Japan all represent different approaches to the regulation of AI, and this diversity already impacts the existing relationship between AI and the patent system. The chapter concludes by recommending that self-regulation for AI inventions (but supported by robust systems of data protection) will be important in encouraging the commercial growth of AI. The patent system represents an important normative filter for AI, but the experience of software and pharmaceuticals in patent law highlights how it is more successful at excluding the most extreme iterations of a technology. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",2023,"Law, Governance and Technology Series",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178885367&doi=10.1007%2f978-3-031-41081-9_10&partnerID=40&md5=f65d2f2dc9bd786d19aa0c1c7bc04d37,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Book chapter', 'language': 'English', 'publisher': 'Springer Nature', 'abstract': 'This chapter considers the approach to regulating artificial intelligence (AI) from a patent law perspective, exploring how existing forms of regulation can help inform our stance vis-à-vis AI. The focus is on contextualising the developments in software and pharmaceutical regulation through patent law, and then applying these lessons to AI. The EU, US and Japan all represent different approaches to the regulation of AI, and this diversity already impacts the existing relationship between AI and the patent system. The chapter concludes by recommending that self-regulation for AI inventions (but supported by robust systems of data protection) will be important in encouraging the commercial growth of AI. The patent system represents an important normative filter for AI, but the experience of software and pharmaceuticals in patent law highlights how it is more successful at excluding the most extreme iterations of a technology. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.', 'affiliations': 'International Business Law at Central European University (CEU), Vienna, Austria', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178885367&doi=10.1007%2f978-3-031-41081-9_10&partnerID=40&md5=f65d2f2dc9bd786d19aa0c1c7bc04d37', 'doi': '10.1007/978-3-031-41081-9_10', 'pages': '171 – 190', 'volume': '59', 'journal': 'Law, Governance and Technology Series', 'year': '2023', 'title': 'International Perspectives on Regulatory Frameworks: AI Through the Lens of Patent Law', 'author': 'Tilt, David', 'ENTRYTYPE': 'article', 'ID': 'Tilt2023171'}",Scopus
"McGuigan, Lee and Sivan-Sevilla, Ido and Parham, Patrick and Shvartzshnaider, Yan",Private attributes: The meanings and mechanisms of “privacy-preserving” adtech,,"This study analyzes the meanings and technical mechanisms of privacy that leading advertising technology (adtech) companies are deploying under the banner of “privacy-preserving” adtech. We analyze this discourse by examining documents wherein Meta, Google, and Apple each propose to provide advertising attribution services—which aim to measure and optimize advertising effectiveness—while “solving” some of the privacy problems associated with online ad attribution. We find that these solutions define privacy primarily as anonymity, as limiting access to individuals’ information, and as the prevention of third-party tracking. We critique these proposals by drawing on the theory of privacy as contextual integrity. Overall, we argue that these attribution solutions not only fail to achieve meaningful privacy but also leverage privacy rhetoric to advance commercial interests. © The Author(s) 2023.",2023,New Media and Society,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178248410&doi=10.1177%2f14614448231213267&partnerID=40&md5=381b1e96d0783cb09ffb629527be214a,"{'note': 'All Open Access, Hybrid Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Article in press', 'type': 'Article', 'language': 'English', 'publisher': 'SAGE Publications Ltd', 'abstract': 'This study analyzes the meanings and technical mechanisms of privacy that leading advertising technology (adtech) companies are deploying under the banner of “privacy-preserving” adtech. We analyze this discourse by examining documents wherein Meta, Google, and Apple each propose to provide advertising attribution services—which aim to measure and optimize advertising effectiveness—while “solving” some of the privacy problems associated with online ad attribution. We find that these solutions define privacy primarily as anonymity, as limiting access to individuals’ information, and as the prevention of third-party tracking. We critique these proposals by drawing on the theory of privacy as contextual integrity. Overall, we argue that these attribution solutions not only fail to achieve meaningful privacy but also leverage privacy rhetoric to advance commercial interests. © The Author(s) 2023.', 'affiliations': 'The University of North Carolina at Chapel Hill, United States; University of Maryland, United States; York University, Canada', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178248410&doi=10.1177%2f14614448231213267&partnerID=40&md5=381b1e96d0783cb09ffb629527be214a', 'doi': '10.1177/14614448231213267', 'journal': 'New Media and Society', 'year': '2023', 'title': 'Private attributes: The meanings and mechanisms of “privacy-preserving” adtech', 'author': 'McGuigan, Lee and Sivan-Sevilla, Ido and Parham, Patrick and Shvartzshnaider, Yan', 'ENTRYTYPE': 'article', 'ID': 'McGuigan2023'}",Scopus
"Li, Tianshi and Reiman, Kayla and Agarwal, Yuvraj and Cranor, Lorrie Faith and Hong, Jason I.",Understanding Challenges for Developers to Create Accurate Privacy Nutrition Labels,,"Apple announced the introduction of app privacy details to their App Store in December 2020, marking the first ever real-world, large-scale deployment of the privacy nutrition label concept, which had been introduced by researchers over a decade earlier. The Apple labels are created by app developers, who self-report their app's data practices. In this paper, we present the first study examining the usability and understandability of Apple's privacy nutrition label creation process from the developer's perspective. By observing and interviewing 12 iOS app developers about how they created the privacy label for a real-world app that they developed, we identified common challenges for correctly and efficiently creating privacy labels. We discuss design implications both for improving Apple's privacy label design and for future deployment of other standardized privacy notices. © 2022 Owner/Author.",2022,Conference on Human Factors in Computing Systems - Proceedings,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129736713&doi=10.1145%2f3491102.3502012&partnerID=40&md5=55514ece87c0edd78ee2de42784fa603,"{'note': 'All Open Access, Bronze Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': ""Apple announced the introduction of app privacy details to their App Store in December 2020, marking the first ever real-world, large-scale deployment of the privacy nutrition label concept, which had been introduced by researchers over a decade earlier. The Apple labels are created by app developers, who self-report their app's data practices. In this paper, we present the first study examining the usability and understandability of Apple's privacy nutrition label creation process from the developer's perspective. By observing and interviewing 12 iOS app developers about how they created the privacy label for a real-world app that they developed, we identified common challenges for correctly and efficiently creating privacy labels. We discuss design implications both for improving Apple's privacy label design and for future deployment of other standardized privacy notices. © 2022 Owner/Author."", 'affiliations': 'Carnegie Mellon University, Pittsburgh, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129736713&doi=10.1145%2f3491102.3502012&partnerID=40&md5=55514ece87c0edd78ee2de42784fa603', 'doi': '10.1145/3491102.3502012', 'journal': 'Conference on Human Factors in Computing Systems - Proceedings', 'year': '2022', 'title': 'Understanding Challenges for Developers to Create Accurate Privacy Nutrition Labels', 'author': 'Li, Tianshi and Reiman, Kayla and Agarwal, Yuvraj and Cranor, Lorrie Faith and Hong, Jason I.', 'ENTRYTYPE': 'conference', 'ID': 'Li2022'}",Scopus
"Koch, Simon and Altpeter, Benjamin and Johns, Martin",The OK Is Not Enough: A Large Scale Study of Consent Dialogs in Smartphone Applications,,"Mobile applications leaking personal information is a well established observation pre and post GDPR. The legal requirements for personal data collection in the context of tracking are specified by GDPR and the common understanding is, that tracking must be based on proper consent. Studies of the consent dialogs on websites revealed severe issues including dark patterns. However, the mobile space is currently under-explored with initial observations pointing towards a similar state of affairs. To address this research gap we analyze a subset of possible consent dialogs, namely privacy consent dialogs, in 3006 Android and 1773 iOS applications. We show that 22.3% of all apps have any form of dialog with only 11.9% giving the user some form of actionable choice, e.g., at least an accept button. However, this choice is limited as a large proportion of all such dialogs employ some form of dark pattern coercing the user to consent. © (2023) by Usenix Association All rights reserved.",2023,"32nd USENIX Security Symposium, USENIX Security 2023",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176503281&partnerID=40&md5=d49dfbe2d62e1f9be80854a62a9effd9,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'USENIX Association', 'abstract': 'Mobile applications leaking personal information is a well established observation pre and post GDPR. The legal requirements for personal data collection in the context of tracking are specified by GDPR and the common understanding is, that tracking must be based on proper consent. Studies of the consent dialogs on websites revealed severe issues including dark patterns. However, the mobile space is currently under-explored with initial observations pointing towards a similar state of affairs. To address this research gap we analyze a subset of possible consent dialogs, namely privacy consent dialogs, in 3006 Android and 1773 iOS applications. We show that 22.3% of all apps have any form of dialog with only 11.9% giving the user some form of actionable choice, e.g., at least an accept button. However, this choice is limited as a large proportion of all such dialogs employ some form of dark pattern coercing the user to consent. © (2023) by Usenix Association All rights reserved.', 'affiliations': 'TU Braunschweig, Germany; Datenanfragen.de e.V., Germany', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176503281&partnerID=40&md5=d49dfbe2d62e1f9be80854a62a9effd9', 'pages': '5467 – 5484', 'volume': '8', 'journal': '32nd USENIX Security Symposium, USENIX Security 2023', 'year': '2023', 'title': 'The OK Is Not Enough: A Large Scale Study of Consent Dialogs in Smartphone Applications', 'author': 'Koch, Simon and Altpeter, Benjamin and Johns, Martin', 'ENTRYTYPE': 'conference', 'ID': 'Koch20235467'}",Scopus
"Novović, Miloš","Privacy nutrition labels, App Store and the GDPR: Unintended consequences?",,"In an effort to increase the transparency of personal data processing carried out via applications listed on their mobile store, Apple recently announced the launch of privacy nutrition labels (PNLs). Aimed at informing users about an application’s use of data, these card-like labels are prominently visible on each application’s App Store page. This paper explores whether such disclosures made via PNLs can help data controllers fulfil their duty of transparency under the EU General Data Protection Regulation (GDPR). It establishes that the PNLs, in their current, highly standardised fashion, cannot convey the mandatory obligations required by the GDPR. Added to this, they cannot adequately supplement existing privacy policies, either — as they neither serve an adequate role as a ‘first layer’ of a privacy notice, nor help communicate information more efficiently. However, the paper finds that the PNLs might serve another purpose: enhancing data controllers’ internal compliance routines. PNLs, even with their current limitations, can bring tangible improvements to cross-functional communication, third-party sharing awareness, records of processing accuracy, adherence to the data protection principles and adequate resource assignment. The overall conclusion of the paper, counterintuitive as it might appear, is that PNLs should be viewed as an organisational measure-enhancing mechanism rather than a transparency tool. © 2022, Henry Stewart Publications. All rights reserved.",2022,Journal of Data Protection and Privacy,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146994870&partnerID=40&md5=6f6813e36a98f2a6c15782dcb4dead1b,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Henry Stewart Publications', 'abstract': 'In an effort to increase the transparency of personal data processing carried out via applications listed on their mobile store, Apple recently announced the launch of privacy nutrition labels (PNLs). Aimed at informing users about an application’s use of data, these card-like labels are prominently visible on each application’s App Store page. This paper explores whether such disclosures made via PNLs can help data controllers fulfil their duty of transparency under the EU General Data Protection Regulation (GDPR). It establishes that the PNLs, in their current, highly standardised fashion, cannot convey the mandatory obligations required by the GDPR. Added to this, they cannot adequately supplement existing privacy policies, either — as they neither serve an adequate role as a ‘first layer’ of a privacy notice, nor help communicate information more efficiently. However, the paper finds that the PNLs might serve another purpose: enhancing data controllers’ internal compliance routines. PNLs, even with their current limitations, can bring tangible improvements to cross-functional communication, third-party sharing awareness, records of processing accuracy, adherence to the data protection principles and adequate resource assignment. The overall conclusion of the paper, counterintuitive as it might appear, is that PNLs should be viewed as an organisational measure-enhancing mechanism rather than a transparency tool. © 2022, Henry Stewart Publications. All rights reserved.', 'affiliations': 'BI Norwegian Business School, Nydalsveien 37, Oslo, 0484, Norway', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146994870&partnerID=40&md5=6f6813e36a98f2a6c15782dcb4dead1b', 'pages': '267 – 280', 'number': '3', 'volume': '5', 'journal': 'Journal of Data Protection and Privacy', 'year': '2022', 'title': 'Privacy nutrition labels, App Store and the GDPR: Unintended consequences?', 'author': 'Novović, Miloš', 'ENTRYTYPE': 'article', 'ID': 'Novović2022267'}",Scopus
"Zhang, Shaokun and Lei, Hanwen and Wang, Yuanpeng and Li, Ding and Guo, Yao and Chen, Xiangqun",How Android Apps Break the Data Minimization Principle: An Empirical Study,,"The Data Minimization Principle is crucial for protecting individual privacy. However, existing Android runtime permissions do not guarantee this principle. Moreover, the lack of an automatic enforcement mechanism leads to uncertainty as to whether apps strictly comply with this principle. To bridge this gap, we conduct the first systematic empirical study on violations of the Data Minimization Principle and design a new enforcement tool called GUIMind to detect them. GUIMind first utilizes a reinforcement learning model to explore app activities and monitor access to sensitive APIs that require sensitive permissions, and then it leverages an existing tool to detect such violations. We evaluate the performance of GUIMind using 120 real-world Android apps. The results indicate that GUIMind can achieve a detection accuracy of 96.1%, effectively accelerating the empirical study. Our empirical research is mainly focused on the prevalence of violations, the responses of administrators to violations, and the potential factors and characteristics that lead to violations, such as typical violations, app categories, and personal data types. Our study reveals that 83.5% of apps contain at least one privacy violation, with health apps being the most severe. In addition, telephony information is the most commonly leaked personal data type, accounting for 71.1%. Finally, we randomly selected 60 non-compliant apps for reporting to the administrator, whose responses confirm the effectiveness of our approach.  © 2023 IEEE.",2023,"Proceedings - 2023 38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178998520&doi=10.1109%2fASE56229.2023.00141&partnerID=40&md5=6391a32304087c6e791df76ad3119675,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Institute of Electrical and Electronics Engineers Inc.', 'abstract': 'The Data Minimization Principle is crucial for protecting individual privacy. However, existing Android runtime permissions do not guarantee this principle. Moreover, the lack of an automatic enforcement mechanism leads to uncertainty as to whether apps strictly comply with this principle. To bridge this gap, we conduct the first systematic empirical study on violations of the Data Minimization Principle and design a new enforcement tool called GUIMind to detect them. GUIMind first utilizes a reinforcement learning model to explore app activities and monitor access to sensitive APIs that require sensitive permissions, and then it leverages an existing tool to detect such violations. We evaluate the performance of GUIMind using 120 real-world Android apps. The results indicate that GUIMind can achieve a detection accuracy of 96.1%, effectively accelerating the empirical study. Our empirical research is mainly focused on the prevalence of violations, the responses of administrators to violations, and the potential factors and characteristics that lead to violations, such as typical violations, app categories, and personal data types. Our study reveals that 83.5% of apps contain at least one privacy violation, with health apps being the most severe. In addition, telephony information is the most commonly leaked personal data type, accounting for 71.1%. Finally, we randomly selected 60 non-compliant apps for reporting to the administrator, whose responses confirm the effectiveness of our approach.  © 2023 IEEE.', 'affiliations': 'School of Computer Science, Peking University, Key Lab of High-Confidence Software Technologies (MOE), Beijing, China', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178998520&doi=10.1109%2fASE56229.2023.00141&partnerID=40&md5=6391a32304087c6e791df76ad3119675', 'doi': '10.1109/ASE56229.2023.00141', 'pages': '1238 – 1250', 'journal': 'Proceedings - 2023 38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023', 'year': '2023', 'title': 'How Android Apps Break the Data Minimization Principle: An Empirical Study', 'author': 'Zhang, Shaokun and Lei, Hanwen and Wang, Yuanpeng and Li, Ding and Guo, Yao and Chen, Xiangqun', 'ENTRYTYPE': 'conference', 'ID': 'Zhang20231238'}",Scopus
"Fernández-Fuentes, Xosé and F. Pena, Tomás and Cabaleiro, José C.",Digital forensic analysis of the private mode of browsers on Android,,"The smartphone has become an essential electronic device in our daily lives. We carry our most precious and important data on it, from family videos of the last few years to credit card information so that we can pay with our phones. In addition, in recent years, mobile devices have become the preferred device for surfing the web, already representing more than 50% of Internet traffic. As one of the devices we spend the most time with throughout the day, it is not surprising that we are increasingly demanding a higher level of privacy. One of the measures introduced to help us protect our data by isolating certain activities on the Internet is the private mode integrated in most modern browsers. Of course, this feature is not new, and has been available on desktop platforms for more than a decade. Reviewing the literature, one can find several studies that test the correct functioning of the private mode on the desktop. However, the number of studies conducted on mobile devices is incredibly small. And not only is it small, but also most of them perform the tests using various emulators or virtual machines running obsolete versions of Android. Therefore, in this paper we apply the methodology we presented in a previous work to Google Chrome, Brave, Mozilla Firefox, and Tor Browser running on a tablet with Android 13 and on two virtual devices created with Android Emulator. The results confirm that these browsers do not store information about the browsing performed in private mode in the file system. However, the analysis of the volatile memory made it possible to recover the username and password used to log in to a website or the keywords typed in a search engine, even after the devices had been rebooted. © 2023 The Author(s)",2023,Computers and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168734015&doi=10.1016%2fj.cose.2023.103425&partnerID=40&md5=ed82930ccda229b41e97cce73f3f6a37,"{'note': 'All Open Access, Green Open Access, Hybrid Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Elsevier Ltd', 'abstract': 'The smartphone has become an essential electronic device in our daily lives. We carry our most precious and important data on it, from family videos of the last few years to credit card information so that we can pay with our phones. In addition, in recent years, mobile devices have become the preferred device for surfing the web, already representing more than 50% of Internet traffic. As one of the devices we spend the most time with throughout the day, it is not surprising that we are increasingly demanding a higher level of privacy. One of the measures introduced to help us protect our data by isolating certain activities on the Internet is the private mode integrated in most modern browsers. Of course, this feature is not new, and has been available on desktop platforms for more than a decade. Reviewing the literature, one can find several studies that test the correct functioning of the private mode on the desktop. However, the number of studies conducted on mobile devices is incredibly small. And not only is it small, but also most of them perform the tests using various emulators or virtual machines running obsolete versions of Android. Therefore, in this paper we apply the methodology we presented in a previous work to Google Chrome, Brave, Mozilla Firefox, and Tor Browser running on a tablet with Android 13 and on two virtual devices created with Android Emulator. The results confirm that these browsers do not store information about the browsing performed in private mode in the file system. However, the analysis of the volatile memory made it possible to recover the username and password used to log in to a website or the keywords typed in a search engine, even after the devices had been rebooted. © 2023 The Author(s)', 'affiliations': 'Centro Singular de Investigación en Tecnoloxías Intelixentes (CiTIUS), Departamento de Electrónica e Computación, Universidade de Santiago de Compostela, Santiago de Compostela, 15782, Spain', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168734015&doi=10.1016%2fj.cose.2023.103425&partnerID=40&md5=ed82930ccda229b41e97cce73f3f6a37', 'doi': '10.1016/j.cose.2023.103425', 'volume': '134', 'journal': 'Computers and Security', 'year': '2023', 'title': 'Digital forensic analysis of the private mode of browsers on Android', 'author': 'Fernández-Fuentes, Xosé and F. Pena, Tomás and Cabaleiro, José C.', 'ENTRYTYPE': 'article', 'ID': 'Fernández-Fuentes2023'}",Scopus
"Hanneke, Björn and Baum, Lorenz and Schlereth, Christian and Hinz, Oliver",Consumer Preferences for Privacy Management Systems,,"This work presents insights into consumer preferences regarding Privacy Management Systems in the context of the General Data Protection Regulation (GDPR). The authors perform a Choice-Based Conjoint experiment with consumers (n = 589) to elicit preferences over four attributes and compute usage likelihoods for all product configurations. Results show that data sharing for marketing purposes and discounts are the most important attributes for consumers. Furthermore, consumers prefer digital access to privacy-related information, detailed rights management for data sharing and no data sharing for marketing purposes. Moreover, a cluster analysis reveals differing importance weights across clusters. The study concludes that incorporating consumer preferences into the design and development process of Privacy Management Systems could increase their use and effectiveness, ultimately strengthening consumers’ privacy rights and companies’ legal compliance. The authors suggest researching legal, business, and consumer requirements more holistically to converge these perspectives to improve Privacy Management Systems adoptions. © 2023 International Conference on Information Systems, ICIS 2023: ""Rising like a Phoenix: Emerging from the Pandemic and Reshaping Hu. All Rights Reserved.",2023,"International Conference on Information Systems, ICIS 2023: ""Rising like a Phoenix: Emerging from the Pandemic and Reshaping Human Endeavors with Digital Technologies""",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192575471&partnerID=40&md5=fc2cd800b3a85dc5bf6abcfd10259862,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Information Systems', 'abstract': 'This work presents insights into consumer preferences regarding Privacy Management Systems in the context of the General Data Protection Regulation (GDPR). The authors perform a Choice-Based Conjoint experiment with consumers (n = 589) to elicit preferences over four attributes and compute usage likelihoods for all product configurations. Results show that data sharing for marketing purposes and discounts are the most important attributes for consumers. Furthermore, consumers prefer digital access to privacy-related information, detailed rights management for data sharing and no data sharing for marketing purposes. Moreover, a cluster analysis reveals differing importance weights across clusters. The study concludes that incorporating consumer preferences into the design and development process of Privacy Management Systems could increase their use and effectiveness, ultimately strengthening consumers’ privacy rights and companies’ legal compliance. The authors suggest researching legal, business, and consumer requirements more holistically to converge these perspectives to improve Privacy Management Systems adoptions. © 2023 International Conference on Information Systems, ICIS 2023: ""Rising like a Phoenix: Emerging from the Pandemic and Reshaping Hu. All Rights Reserved.', 'affiliations': 'Goethe University Frankfurt, Theodor-W.-Adorno-Platz 4, Frankfurt am Main, 60323, Germany; WHU – Otto Beisheim School of Management, Burgplatz 2, Vallendar, 56179, Germany', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192575471&partnerID=40&md5=fc2cd800b3a85dc5bf6abcfd10259862', 'journal': 'International Conference on Information Systems, ICIS 2023: ""Rising like a Phoenix: Emerging from the Pandemic and Reshaping Human Endeavors with Digital Technologies""', 'year': '2023', 'title': 'Consumer Preferences for Privacy Management Systems', 'author': 'Hanneke, Björn and Baum, Lorenz and Schlereth, Christian and Hinz, Oliver', 'ENTRYTYPE': 'conference', 'ID': 'Hanneke2023'}",Scopus
"Wei, Chengkun and Zhao, Minghu and Zhang, Zhikun and Chen, Min and Meng, Wenlong and Liu, Bo and Fan, Yuan and Chen, Wenzhi",DPMLBench: Holistic Evaluation of Differentially Private Machine Learning,,"Differential privacy (DP), as a rigorous mathematical definition quantifying privacy leakage, has become a well-accepted standard for privacy protection. Combined with powerful machine learning (ML) techniques, differentially private machine learning (DPML) is increasingly important. As the most classic DPML algorithm, DP-SGD incurs a significant loss of utility, which hinders DPML's deployment in practice. Many studies have recently proposed improved algorithms based on DP-SGD to mitigate utility loss. However, these studies are isolated and cannot comprehensively measure the performance of improvements proposed in algorithms. More importantly, there is a lack of comprehensive research to compare improvements in these DPML algorithms across utility, defensive capabilities, and generalizability. We fill this gap by performing a holistic measurement of improved DPML algorithms on utility and defense capability against membership inference attacks (MIAs) on image classification tasks. We first present a taxonomy of where improvements are located in the ML life cycle. Based on our taxonomy, we jointly perform an extensive measurement study of the improved DPML algorithms, over twelve algorithms, four model architectures, four datasets, two attacks, and various privacy budget configurations. We also cover state-of-the-art label differential privacy (Label DP) algorithms in the evaluation. According to our empirical results, DP can effectively defend against MIAs, and sensitivity-bounding techniques such as per-sample gradient clipping play an important role in defense. We also explore some improvements that can maintain model utility and defend against MIAs more effectively. Experiments show that Label DP algorithms achieve less utility loss but are fragile to MIAs. ML practitioners may benefit from these evaluations to select appropriate algorithms. To support our evaluation, we implement a modular re-usable software, DPMLBench, which enables sensitive data owners to deploy DPML algorithms and serves as a benchmark tool for researchers and practitioners. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM",2023,CCS 2023 - Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179836936&doi=10.1145%2f3576915.3616593&partnerID=40&md5=ba5694996f6697838709686401c838a6,"{'note': 'All Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery, Inc', 'abstract': ""Differential privacy (DP), as a rigorous mathematical definition quantifying privacy leakage, has become a well-accepted standard for privacy protection. Combined with powerful machine learning (ML) techniques, differentially private machine learning (DPML) is increasingly important. As the most classic DPML algorithm, DP-SGD incurs a significant loss of utility, which hinders DPML's deployment in practice. Many studies have recently proposed improved algorithms based on DP-SGD to mitigate utility loss. However, these studies are isolated and cannot comprehensively measure the performance of improvements proposed in algorithms. More importantly, there is a lack of comprehensive research to compare improvements in these DPML algorithms across utility, defensive capabilities, and generalizability. We fill this gap by performing a holistic measurement of improved DPML algorithms on utility and defense capability against membership inference attacks (MIAs) on image classification tasks. We first present a taxonomy of where improvements are located in the ML life cycle. Based on our taxonomy, we jointly perform an extensive measurement study of the improved DPML algorithms, over twelve algorithms, four model architectures, four datasets, two attacks, and various privacy budget configurations. We also cover state-of-the-art label differential privacy (Label DP) algorithms in the evaluation. According to our empirical results, DP can effectively defend against MIAs, and sensitivity-bounding techniques such as per-sample gradient clipping play an important role in defense. We also explore some improvements that can maintain model utility and defend against MIAs more effectively. Experiments show that Label DP algorithms achieve less utility loss but are fragile to MIAs. ML practitioners may benefit from these evaluations to select appropriate algorithms. To support our evaluation, we implement a modular re-usable software, DPMLBench, which enables sensitive data owners to deploy DPML algorithms and serves as a benchmark tool for researchers and practitioners. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM"", 'affiliations': 'Zhejiang University, Hangzhou, China; Stanford University, Stanford, United States; CISPA Helmholtz Center for Information Security, Saarbrücken, Germany; Dbappsecurity, Hangzhou, China', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179836936&doi=10.1145%2f3576915.3616593&partnerID=40&md5=ba5694996f6697838709686401c838a6', 'doi': '10.1145/3576915.3616593', 'pages': '2621 – 2635', 'journal': 'CCS 2023 - Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security', 'year': '2023', 'title': 'DPMLBench: Holistic Evaluation of Differentially Private Machine Learning', 'author': 'Wei, Chengkun and Zhao, Minghu and Zhang, Zhikun and Chen, Min and Meng, Wenlong and Liu, Bo and Fan, Yuan and Chen, Wenzhi', 'ENTRYTYPE': 'conference', 'ID': 'Wei20232621'}",Scopus
"Fenwick, Mark and Jurcys, Paulius",From Cyborgs to Quantified Selves Augmenting Privacy Rights with User-Centric Technology and Design,,"Transhuman enhancements – technologies that boost human capabilities – are everywhere: bodily implants, wearables, portable devices, and smart devices embedded in everyday spaces. A key feature of these technologies is their capacity to generate data from the user side and ‘give back’ that data to users in the form of personalized insights that can influence future choices and actions. Increasingly, our choices are made at the shifting interface between freedom and data, and these enhancements are transforming everyone into human-digital cyborgs or quantified selves. These personalized insights promise multiple benefits for diverse stakeholders, most obviously greater self-understanding, and better decision-making for end-users, and new business opportunities for firms. Nevertheless, concerns remain. These technologies contribute to the emergence of new forms of post-Foucauldian surveillance that raise difficult questions about the meaning, limits, and even possibility of privacy. As personal choice becomes increasingly dependent on data, traditional legal conceptions of privacy that presuppose an independent and settled sphere of private life over which an autonomous ‘person’ enjoys dominion become strained. Transformations in the practice of privacy are occurring, and we are experiencing the augmentation of a narrative of the protection of privacy rights of persons with a more situational, human-centered, and technology-driven conception of privacy-by-design. This article describes such privacy enhancing technologies and raises the question of whether such an approach to privacy is adequate to the complex realities of the contemporary data ecosystem and emerging forms of digital subjectivity. © 2022 Mark Fenwick and Paulius Jurcys.",2022,"Journal of Intellectual Property, Information Technology and E-Commerce Law",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132606852&partnerID=40&md5=0b7fb960abffda9c9331a32569cc2929,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Digital Peer Publishing Licenses', 'abstract': 'Transhuman enhancements – technologies that boost human capabilities – are everywhere: bodily implants, wearables, portable devices, and smart devices embedded in everyday spaces. A key feature of these technologies is their capacity to generate data from the user side and ‘give back’ that data to users in the form of personalized insights that can influence future choices and actions. Increasingly, our choices are made at the shifting interface between freedom and data, and these enhancements are transforming everyone into human-digital cyborgs or quantified selves. These personalized insights promise multiple benefits for diverse stakeholders, most obviously greater self-understanding, and better decision-making for end-users, and new business opportunities for firms. Nevertheless, concerns remain. These technologies contribute to the emergence of new forms of post-Foucauldian surveillance that raise difficult questions about the meaning, limits, and even possibility of privacy. As personal choice becomes increasingly dependent on data, traditional legal conceptions of privacy that presuppose an independent and settled sphere of private life over which an autonomous ‘person’ enjoys dominion become strained. Transformations in the practice of privacy are occurring, and we are experiencing the augmentation of a narrative of the protection of privacy rights of persons with a more situational, human-centered, and technology-driven conception of privacy-by-design. This article describes such privacy enhancing technologies and raises the question of whether such an approach to privacy is adequate to the complex realities of the contemporary data ecosystem and emerging forms of digital subjectivity. © 2022 Mark Fenwick and Paulius Jurcys.', 'affiliations': 'Graduate School of Law, Kyushu University, Japan; Faculty of Law, Vilnius University, Lithuania', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132606852&partnerID=40&md5=0b7fb960abffda9c9331a32569cc2929', 'pages': '20 – 35', 'number': '1', 'volume': '13', 'journal': 'Journal of Intellectual Property, Information Technology and E-Commerce Law', 'year': '2022', 'title': 'From Cyborgs to Quantified Selves Augmenting Privacy Rights with User-Centric Technology and Design', 'author': 'Fenwick, Mark and Jurcys, Paulius', 'ENTRYTYPE': 'article', 'ID': 'Fenwick202220'}",Scopus
"Krishnaraj, N. and Sangeetha, S.",A study of Data Privacy in Internet of Things using Privacy Preserving Techniques with its Management,,"The living standards of human lives in societies are enhanced and move towards sophisticated automation by implementing the Internet of Things (IoT) in their daily life. However, limited storage, power and computational capabilities are presented in IoT devices. Hence, users' data are collected using various devices, and they can be modified and sent to the clouds. People can access the data from anywhere and anytime due to access credentials, and this leads to problems such as an explosion of sensitive information and loss of trust between parties. Privacy and security issues are raised from this explosion of users' personal information over the IoT environment, and this must be addressed. However, researchers focused on this as a major concern for IoT. In this research work, the explanation of data privacy is given, and in order to fulfil its requirements, privacy-preserving techniques are studied. Differential privacy is the most widely used technique to ensure the user's data privacy, which is also discussed in this work. Before uploading any data to cloud storage, it must be encrypted using cryptographic techniques, where the importance of these techniques are also presented in the survey. More data are collected via wearable devices in IoT, and its challenges along with privacy management are given in the study. Finally, the threats and major challenges of privacy with its future directions about IoT based applications' privacy is explained. © 2022 Seventh Sense Research Group®",2022,International Journal of Engineering Trends and Technology,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124940437&doi=10.14445%2f22315381%2fIJETT-V70I2P207&partnerID=40&md5=2d322ff4cc540494601303581d0f329c,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Seventh Sense Research Group', 'abstract': ""The living standards of human lives in societies are enhanced and move towards sophisticated automation by implementing the Internet of Things (IoT) in their daily life. However, limited storage, power and computational capabilities are presented in IoT devices. Hence, users' data are collected using various devices, and they can be modified and sent to the clouds. People can access the data from anywhere and anytime due to access credentials, and this leads to problems such as an explosion of sensitive information and loss of trust between parties. Privacy and security issues are raised from this explosion of users' personal information over the IoT environment, and this must be addressed. However, researchers focused on this as a major concern for IoT. In this research work, the explanation of data privacy is given, and in order to fulfil its requirements, privacy-preserving techniques are studied. Differential privacy is the most widely used technique to ensure the user's data privacy, which is also discussed in this work. Before uploading any data to cloud storage, it must be encrypted using cryptographic techniques, where the importance of these techniques are also presented in the survey. More data are collected via wearable devices in IoT, and its challenges along with privacy management are given in the study. Finally, the threats and major challenges of privacy with its future directions about IoT based applications' privacy is explained. © 2022 Seventh Sense Research Group®"", 'affiliations': 'Department of Networking and Communications, School of Computing, SRM Institute of Science and Technology, Tamilnadu, Kattankulathur, India; Department of Computer Science and Engineering, Veltech Multitech Dr Rangarajan Dr Sakunthala Engineering College, Tamilnadu, Chennai, India', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124940437&doi=10.14445%2f22315381%2fIJETT-V70I2P207&partnerID=40&md5=2d322ff4cc540494601303581d0f329c', 'doi': '10.14445/22315381/IJETT-V70I2P207', 'pages': '43 – 52', 'number': '2', 'volume': '70', 'journal': 'International Journal of Engineering Trends and Technology', 'year': '2022', 'title': 'A study of Data Privacy in Internet of Things using Privacy Preserving Techniques with its Management', 'author': 'Krishnaraj, N. and Sangeetha, S.', 'ENTRYTYPE': 'article', 'ID': 'Krishnaraj202243'}",Scopus
"Cennamo, Carmelo and Kretschmer, Tobias and Constantinides, Panos and Alaimo, Cristina and Santaló, Juan",Digital Platforms Regulation: An Innovation-Centric View of the EU's Digital Markets Act,,,2023,Journal of European Competition Law and Practice,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161127652&doi=10.1093%2fjeclap%2flpac043&partnerID=40&md5=d6813e9fe235a8f496ff9250860cd6bf,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Oxford University Press', 'affiliations': 'Copenhagen Business School, Copenhagen, Denmark; Ludwig-Maximilians-University(LMU), Munich, Germany; Alliance Manchester Business School, Manchester, United Kingdom; LUISS University, Rome, Italy; IE University, Madrid, Spain; SDABocconi, Milan, Italy', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161127652&doi=10.1093%2fjeclap%2flpac043&partnerID=40&md5=d6813e9fe235a8f496ff9250860cd6bf', 'doi': '10.1093/jeclap/lpac043', 'pages': '44 – 51', 'number': '1', 'volume': '14', 'journal': 'Journal of European Competition Law and Practice', 'year': '2023', 'title': ""Digital Platforms Regulation: An Innovation-Centric View of the EU's Digital Markets Act"", 'author': 'Cennamo, Carmelo and Kretschmer, Tobias and Constantinides, Panos and Alaimo, Cristina and Santaló, Juan', 'ENTRYTYPE': 'article', 'ID': 'Cennamo202344'}",Scopus
"Chhetri, Chola and Motti, Vivian Genaro",Enhancing the design of data-related privacy controls for smart home devices,,"Purpose: Past research shows that users of smart home devices (SHDs) have privacy concerns. These concerns have been validated from technical research that shows SHDs introduce a lot of privacy risks. However, there is limited research in addressing these concerns and risks. This paper aims to bridge this gap by informing the design of data-related privacy controls for SHDs. Design/methodology/approach: In this paper, the authors follow a user-centered design approach to design data-related privacy controls from design requirements backed by literature. The authors test the design for usability and perceived information control using psychometrically validated scales. For this purpose, two variations of the prototype (MyCam1 with a listing of data-related privacy controls and MyCam2 with three privacy presets) were created and tested them in a between-subjects experimental setting. Study participants (n = 207) were recruited via Mechanical Turk and asked to use the prototype app. An online survey was distributed to the participants to measure some usability and privacy-related constructs. Findings: Findings show that the presented prototype designs were usable and met the privacy control needs of users. The prototype design with privacy presets (MyCam2) was found to be significantly more usable than the list of privacy controls (MyCam1). Originality: The findings of this paper are original and build on the paper presented at the International Symposium on Human Aspects of Information Security and Assurance (HAISA 2022). This paper contributes improved and usable designs of privacy controls for smart home applications. © 2023, Emerald Publishing Limited.",2023,Information and Computer Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149681027&doi=10.1108%2fICS-11-2022-0173&partnerID=40&md5=968484f3646f252b044e1b7d6cd7c556,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Emerald Publishing', 'abstract': 'Purpose: Past research shows that users of smart home devices (SHDs) have privacy concerns. These concerns have been validated from technical research that shows SHDs introduce a lot of privacy risks. However, there is limited research in addressing these concerns and risks. This paper aims to bridge this gap by informing the design of data-related privacy controls for SHDs. Design/methodology/approach: In this paper, the authors follow a user-centered design approach to design data-related privacy controls from design requirements backed by literature. The authors test the design for usability and perceived information control using psychometrically validated scales. For this purpose, two variations of the prototype (MyCam1 with a listing of data-related privacy controls and MyCam2 with three privacy presets) were created and tested them in a between-subjects experimental setting. Study participants (n = 207) were recruited via Mechanical Turk and asked to use the prototype app. An online survey was distributed to the participants to measure some usability and privacy-related constructs. Findings: Findings show that the presented prototype designs were usable and met the privacy control needs of users. The prototype design with privacy presets (MyCam2) was found to be significantly more usable than the list of privacy controls (MyCam1). Originality: The findings of this paper are original and build on the paper presented at the International Symposium on Human Aspects of Information Security and Assurance (HAISA 2022). This paper contributes improved and usable designs of privacy controls for smart home applications. © 2023, Emerald Publishing Limited.', 'affiliations': 'Department of Information Sciences and Technology, George Mason University, Fairfax, VA, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149681027&doi=10.1108%2fICS-11-2022-0173&partnerID=40&md5=968484f3646f252b044e1b7d6cd7c556', 'doi': '10.1108/ICS-11-2022-0173', 'pages': '368 – 384', 'number': '3', 'volume': '31', 'journal': 'Information and Computer Security', 'year': '2023', 'title': 'Enhancing the design of data-related privacy controls for smart home devices', 'author': 'Chhetri, Chola and Motti, Vivian Genaro', 'ENTRYTYPE': 'article', 'ID': 'Chhetri2023368'}",Scopus
"Usman, Warda and Hu, Jackie and Wilson, McKynlee and Zappala, Daniel",Distrust of big tech and a desire for privacy: Understanding the motivations of people who have voluntarily adopted secure email,,"Secure email systems that use end-to-end encryption are the best method we have for ensuring user privacy and security in email communication. However, the adoption of secure email remains low, with previous studies suggesting mainly that secure email is too complex or inconvenient to use. However, the perspectives of those who have, in fact, chosen to use an encrypted email system are largely overlooked. To understand these perspectives, we conducted a semi-structured interview study that aims to provide a comprehensive understanding of the mindsets underlying adoption and use of secure email services. Our participants come from a variety of countries and vary in the amount of time they have been using secure email, how often they use it, and whether they use it as their primary account. Our results uncover that a defining reason for adopting a secure email system is to avoid surveillance from big tech companies. However, regardless of the complexity and accuracy of a person’s mental model, our participants rarely send and receive encrypted emails, thus not making full use of the privacy they could obtain. These findings indicate that secure email systems could potentially find greater adoption by appealing to their privacy advantages, but privacy gains will be limited until a critical mass are able to join these systems and easily send encrypted emails to each other. © 2023 by The USENIX Association.All rights reserved.",2023,"Proceedings of the 19th Symposium on Usable Privacy and Security, SOUPS 2023",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177803403&partnerID=40&md5=a5a15a60f69c33426f1957db1b46f89d,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'USENIX Association', 'abstract': 'Secure email systems that use end-to-end encryption are the best method we have for ensuring user privacy and security in email communication. However, the adoption of secure email remains low, with previous studies suggesting mainly that secure email is too complex or inconvenient to use. However, the perspectives of those who have, in fact, chosen to use an encrypted email system are largely overlooked. To understand these perspectives, we conducted a semi-structured interview study that aims to provide a comprehensive understanding of the mindsets underlying adoption and use of secure email services. Our participants come from a variety of countries and vary in the amount of time they have been using secure email, how often they use it, and whether they use it as their primary account. Our results uncover that a defining reason for adopting a secure email system is to avoid surveillance from big tech companies. However, regardless of the complexity and accuracy of a person’s mental model, our participants rarely send and receive encrypted emails, thus not making full use of the privacy they could obtain. These findings indicate that secure email systems could potentially find greater adoption by appealing to their privacy advantages, but privacy gains will be limited until a critical mass are able to join these systems and easily send encrypted emails to each other. © 2023 by The USENIX Association.All rights reserved.', 'affiliations': 'Brigham Young University, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177803403&partnerID=40&md5=a5a15a60f69c33426f1957db1b46f89d', 'pages': '473 – 490', 'journal': 'Proceedings of the 19th Symposium on Usable Privacy and Security, SOUPS 2023', 'year': '2023', 'title': 'Distrust of big tech and a desire for privacy: Understanding the motivations of people who have voluntarily adopted secure email', 'author': 'Usman, Warda and Hu, Jackie and Wilson, McKynlee and Zappala, Daniel', 'ENTRYTYPE': 'conference', 'ID': 'Usman2023473'}",Scopus
"Emami-Naeini, Pardis and Dheenadhayalan, Janarth and Agarwal, Yuvraj and Cranor, Lorrie Faith",Are Consumers Willing to Pay for Security and Privacy of IoT Devices?,,"Internet of Things (IoT) device manufacturers provide little information to consumers about their security and data handling practices. Therefore, IoT consumers cannot make informed purchase choices around security and privacy. While prior research has found that consumers would likely consider security and privacy when purchasing IoT devices, past work lacks empirical evidence as to whether they would actually pay more to purchase devices with enhanced security and privacy. To fill this gap, we conducted a two-phase incentive-compatible online study with 180 Prolific participants. We measured the impact of five security and privacy factors (e.g., access control) on participants’ purchase behaviors when presented individually or together on an IoT label. Participants were willing to pay a significant premium for devices with better security and privacy practices. The biggest price differential we found was for de-identified rather than identifiable cloud storage. Mainly due to its usability challenges, the least valuable improvement for participants was to have multi-factor authentication as opposed to passwords. Based on our findings, we provide recommendations on creating more effective IoT security and privacy labeling programs. © USENIX Security 2023. All rights reserved.",2023,"32nd USENIX Security Symposium, USENIX Security 2023",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172438142&partnerID=40&md5=f6bca7ac5cd1d1e6b4c78cc2ceb398d2,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'USENIX Association', 'abstract': 'Internet of Things (IoT) device manufacturers provide little information to consumers about their security and data handling practices. Therefore, IoT consumers cannot make informed purchase choices around security and privacy. While prior research has found that consumers would likely consider security and privacy when purchasing IoT devices, past work lacks empirical evidence as to whether they would actually pay more to purchase devices with enhanced security and privacy. To fill this gap, we conducted a two-phase incentive-compatible online study with 180 Prolific participants. We measured the impact of five security and privacy factors (e.g., access control) on participants’ purchase behaviors when presented individually or together on an IoT label. Participants were willing to pay a significant premium for devices with better security and privacy practices. The biggest price differential we found was for de-identified rather than identifiable cloud storage. Mainly due to its usability challenges, the least valuable improvement for participants was to have multi-factor authentication as opposed to passwords. Based on our findings, we provide recommendations on creating more effective IoT security and privacy labeling programs. © USENIX Security 2023. All rights reserved.', 'affiliations': 'Duke University, United States; Carnegie Mellon University, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172438142&partnerID=40&md5=f6bca7ac5cd1d1e6b4c78cc2ceb398d2', 'pages': '1505 – 1522', 'volume': '3', 'journal': '32nd USENIX Security Symposium, USENIX Security 2023', 'year': '2023', 'title': 'Are Consumers Willing to Pay for Security and Privacy of IoT Devices?', 'author': 'Emami-Naeini, Pardis and Dheenadhayalan, Janarth and Agarwal, Yuvraj and Cranor, Lorrie Faith', 'ENTRYTYPE': 'conference', 'ID': 'Emami-Naeini20231505'}",Scopus
"Fenwick, Mark and Jurcys, Paulius",Building a 'Green Data' Future: how a human-centric approach to data and nudges can help fight climate change,,"A defining feature of digital transformation is the sensorization of everything and the concomi-tant creation of vast amounts of data covering every aspect of social and economic life. It is unfortunate that the value of this vast data pool has not been fully leveraged in tackling climate change and other environmental challenges facinghumanity. This article suggests that this failure is a product of the closed and siloed character of the mod-ern data ecosystem in which some stakehold-ers deem the collected data as their proprietary asset and have little incentive to share it with those interested in creating new value from such data, including, for example, by developing inno-vative technologies relevant for tackling climatechange. This article argues that a user-held data model, in which data are reconceptualized as the property of the users who generate it, might better unlock or activate the 'green value' of these data and, by doing so, facilitate the creation of innovative green technologies. This paper focuses on three settings where a user-centric approach to data might use-fully contribute to achieving these environmental goals, namely, facilitating green lifestyles, fos-tering sustainability in green cities and building green innovation ecosystems. Based on the fore-going discussion, this article concludes by iden-tifying some normative principles that might be useful to guide regulatory interventions in this context. © The Author(s) 2023.",2023,Journal of Intellectual Property Law and Practice,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168657185&doi=10.1093%2fjiplp%2fjpad031&partnerID=40&md5=41f5b789d5121dc2381813f69184fe51,"{'note': 'All Open Access, Hybrid Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Oxford University Press', 'abstract': ""A defining feature of digital transformation is the sensorization of everything and the concomi-tant creation of vast amounts of data covering every aspect of social and economic life. It is unfortunate that the value of this vast data pool has not been fully leveraged in tackling climate change and other environmental challenges facinghumanity. This article suggests that this failure is a product of the closed and siloed character of the mod-ern data ecosystem in which some stakehold-ers deem the collected data as their proprietary asset and have little incentive to share it with those interested in creating new value from such data, including, for example, by developing inno-vative technologies relevant for tackling climatechange. This article argues that a user-held data model, in which data are reconceptualized as the property of the users who generate it, might better unlock or activate the 'green value' of these data and, by doing so, facilitate the creation of innovative green technologies. This paper focuses on three settings where a user-centric approach to data might use-fully contribute to achieving these environmental goals, namely, facilitating green lifestyles, fos-tering sustainability in green cities and building green innovation ecosystems. Based on the fore-going discussion, this article concludes by iden-tifying some normative principles that might be useful to guide regulatory interventions in this context. © The Author(s) 2023."", 'affiliations': 'International Business Law, Graduate School of Law, Kyushu University, Fukuoka, Japan; Vilnius University, Law Faculty, Vilnius, Lithuania', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168657185&doi=10.1093%2fjiplp%2fjpad031&partnerID=40&md5=41f5b789d5121dc2381813f69184fe51', 'doi': '10.1093/jiplp/jpad031', 'pages': '386 – 396', 'number': '5', 'volume': '18', 'journal': 'Journal of Intellectual Property Law and Practice', 'year': '2023', 'title': ""Building a 'Green Data' Future: how a human-centric approach to data and nudges can help fight climate change"", 'author': 'Fenwick, Mark and Jurcys, Paulius', 'ENTRYTYPE': 'article', 'ID': 'Fenwick2023386'}",Scopus
"Hong, Geng and Wu, Mengying and Chen, Pei and Liao, Xiaojing and Ye, Guoyi and Yang, Min",Understanding and Detecting Abused Image Hosting Modules as Malicious Services,,"As a new type of underground ecosystem, the exploitation of Abused IHMs as MalIcious sErvices (AIMIEs) is becoming increasingly prevalent among miscreants to host illegal images and propagate harmful content. However, there has been little effort to understand this new menace, in terms of its magnitude, impact, and techniques, not to mention any serious effort to detect vulnerable image hosting modules on a large scale. To fulfill this gap, this paper presents the first measurement study of AIMIEs. By collecting and analyzing 89 open-sourced AIMIEs, we reveal the landscape of AIMIEs, report the evolution and evasiveness of abused image hosting APIs from reputable companies such as Alibaba, Tencent, and Bytedance, and identify real-world abused images uploaded through those AIMIEs. In addition, we propose a tool, called Viola, to detect vulnerable image hosting modules (IHMs) in the wild. We find 477 vulnerable IHM upload APIs associated with 338 web services, which integrated vulnerable IHMs, and 207 victim FQDNs. The highest-ranked domain with vulnerable web service is baidu.com, followed by bilibili.com and 163.com. We have reported abused and vulnerable IHM upload APIs and received acknowledgments from 69 of them by the time of paper submission. © 2023 Copyright held by the owner/author(s).",2023,CCS 2023 - Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179838376&doi=10.1145%2f3576915.3623143&partnerID=40&md5=2e8afda3fc213de1573014321eea430c,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery, Inc', 'abstract': 'As a new type of underground ecosystem, the exploitation of Abused IHMs as MalIcious sErvices (AIMIEs) is becoming increasingly prevalent among miscreants to host illegal images and propagate harmful content. However, there has been little effort to understand this new menace, in terms of its magnitude, impact, and techniques, not to mention any serious effort to detect vulnerable image hosting modules on a large scale. To fulfill this gap, this paper presents the first measurement study of AIMIEs. By collecting and analyzing 89 open-sourced AIMIEs, we reveal the landscape of AIMIEs, report the evolution and evasiveness of abused image hosting APIs from reputable companies such as Alibaba, Tencent, and Bytedance, and identify real-world abused images uploaded through those AIMIEs. In addition, we propose a tool, called Viola, to detect vulnerable image hosting modules (IHMs) in the wild. We find 477 vulnerable IHM upload APIs associated with 338 web services, which integrated vulnerable IHMs, and 207 victim FQDNs. The highest-ranked domain with vulnerable web service is baidu.com, followed by bilibili.com and 163.com. We have reported abused and vulnerable IHM upload APIs and received acknowledgments from 69 of them by the time of paper submission. © 2023 Copyright held by the owner/author(s).', 'affiliations': 'Fudan University, China; Indiana University, Bloomington, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179838376&doi=10.1145%2f3576915.3623143&partnerID=40&md5=2e8afda3fc213de1573014321eea430c', 'doi': '10.1145/3576915.3623143', 'pages': '3213 – 3227', 'journal': 'CCS 2023 - Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security', 'year': '2023', 'title': 'Understanding and Detecting Abused Image Hosting Modules as Malicious Services', 'author': 'Hong, Geng and Wu, Mengying and Chen, Pei and Liao, Xiaojing and Ye, Guoyi and Yang, Min', 'ENTRYTYPE': 'conference', 'ID': 'Hong20233213'}",Scopus
"Obada-Obieh, Borke and Huang, Yue and Spagnolo, Lucrezia and Beznosov, Konstantin",SoK: The Dual Nature of Technology in Sexual Abuse,,"This paper systematizes and contextualizes the existing body of knowledge on on technology's dual nature regarding sexual abuse: facilitator of it and assistant to its prevention, reporting, and restriction. By reviewing 224 research papers, we identified 10 characteristics of technology that facilitate sexual abuse: covertness, publicness, anonymity, evolution, boundlessness, reproducibility, accessibility, indispensability, malleability, and opaqueness. We also analyzed how technology assists victims and other stakeholders in coping with and responding to sexual abuse. Our research questions examined the challenges in using technology to address sexual abuse too. For instance, its use by victims can lead to revictimization. To address technology's challenges, we offer recommendations and suggest new research directions. These findings about the dual nature of technology can inform research and development toward better support for victims of sexual abuse.  © 2022 IEEE.",2022,Proceedings - IEEE Symposium on Security and Privacy,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135914758&doi=10.1109%2fSP46214.2022.9833663&partnerID=40&md5=432bc6a8836f96c473b2fbbad80507d4,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Institute of Electrical and Electronics Engineers Inc.', 'abstract': ""This paper systematizes and contextualizes the existing body of knowledge on on technology's dual nature regarding sexual abuse: facilitator of it and assistant to its prevention, reporting, and restriction. By reviewing 224 research papers, we identified 10 characteristics of technology that facilitate sexual abuse: covertness, publicness, anonymity, evolution, boundlessness, reproducibility, accessibility, indispensability, malleability, and opaqueness. We also analyzed how technology assists victims and other stakeholders in coping with and responding to sexual abuse. Our research questions examined the challenges in using technology to address sexual abuse too. For instance, its use by victims can lead to revictimization. To address technology's challenges, we offer recommendations and suggest new research directions. These findings about the dual nature of technology can inform research and development toward better support for victims of sexual abuse.  © 2022 IEEE."", 'affiliations': 'University of British Columbia, Canada; Vesta Social Innovation Technologies, Canada', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135914758&doi=10.1109%2fSP46214.2022.9833663&partnerID=40&md5=432bc6a8836f96c473b2fbbad80507d4', 'doi': '10.1109/SP46214.2022.9833663', 'pages': '2320 – 2343', 'volume': '2022-May', 'journal': 'Proceedings - IEEE Symposium on Security and Privacy', 'year': '2022', 'title': 'SoK: The Dual Nature of Technology in Sexual Abuse', 'author': 'Obada-Obieh, Borke and Huang, Yue and Spagnolo, Lucrezia and Beznosov, Konstantin', 'ENTRYTYPE': 'conference', 'ID': 'Obada-Obieh20222320'}",Scopus
"Sas, Martin and Denoo, Maarten and Mühlberg, Jan Tobias",Informing Children about Privacy: A Review and Assessment of Age-Appropriate Information Designs in Kids-Oriented F2P Video Games,,"With the rise of free-to-play (F2P) games, the profitability of video-gaming apps critically depends on the ability of developers to acquire, retain, and monetize large numbers of players. In this context, most game designers have no viable alternative than massively collecting players' personal data and monitoring their behavior to target them with personalized advertising and in-game purchases. Given the risks associated with such data practices, players, in particular children, need to be aware that a video game might compromise their privacy. Game designers should therefore ensure that players receive appropriate information about the data practices associated with their games. This might, however, be challenging, especially when the game is directed at children, given the complexity of privacy information and the limited literacy capacities of children and their parents. To answer game designers' need for comprehensive guidance regarding the communication of privacy information to children, we provide a survey of the age-appropriate information design strategies which been recommended by data protection authorities, children protection organizations and the relevant scientific literature. On this occasion, we also refer to illustrative examples of designs which can be considered good practices. Finally, by using an ""evaluation matrix"", we reviewed and assessed the implementation of those design strategies in nine F2P mobile games committed to following Google Play's Families Policies. Our findings show that, despite being child-oriented, the reviewed games largely fail at communicating privacy information in an age-appropriate way.  © 2023 ACM.",2023,Proceedings of the ACM on Human-Computer Interaction,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175839894&doi=10.1145%2f3611036&partnerID=40&md5=20fda2b36227e2e3d6c3dd62ce91c570,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': 'With the rise of free-to-play (F2P) games, the profitability of video-gaming apps critically depends on the ability of developers to acquire, retain, and monetize large numbers of players. In this context, most game designers have no viable alternative than massively collecting players\' personal data and monitoring their behavior to target them with personalized advertising and in-game purchases. Given the risks associated with such data practices, players, in particular children, need to be aware that a video game might compromise their privacy. Game designers should therefore ensure that players receive appropriate information about the data practices associated with their games. This might, however, be challenging, especially when the game is directed at children, given the complexity of privacy information and the limited literacy capacities of children and their parents. To answer game designers\' need for comprehensive guidance regarding the communication of privacy information to children, we provide a survey of the age-appropriate information design strategies which been recommended by data protection authorities, children protection organizations and the relevant scientific literature. On this occasion, we also refer to illustrative examples of designs which can be considered good practices. Finally, by using an ""evaluation matrix"", we reviewed and assessed the implementation of those design strategies in nine F2P mobile games committed to following Google Play\'s Families Policies. Our findings show that, despite being child-oriented, the reviewed games largely fail at communicating privacy information in an age-appropriate way.  © 2023 ACM.', 'affiliations': 'KU Leuven, Leuven, Belgium; Universite Libre de Bruxelles, Brussels, Belgium', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175839894&doi=10.1145%2f3611036&partnerID=40&md5=20fda2b36227e2e3d6c3dd62ce91c570', 'doi': '10.1145/3611036', 'volume': '7', 'journal': 'Proceedings of the ACM on Human-Computer Interaction', 'year': '2023', 'title': 'Informing Children about Privacy: A Review and Assessment of Age-Appropriate Information Designs in Kids-Oriented F2P Video Games', 'author': 'Sas, Martin and Denoo, Maarten and Mühlberg, Jan Tobias', 'ENTRYTYPE': 'article', 'ID': 'Sas2023'}",Scopus
"Zarsky, Tal Z.","SERIOUS NOTICE: A CELEBRATION, DISCUSSION, AND RECOGNITION OF JOEL REIDENBERG’S WORK ON PRIVACY NOTICES AND DISCLOSURES",,"This Essay pays tribute to Professor Joel Reidenberg’s rich academic career and, specifically, to his contributions to the study of privacy policies. In doing so, this Essay takes a close look at privacy policies and possible ways to effectively intermediate their content through various labeling schemes. While severely flawed, privacy policies are here to stay. Therefore, an in-depth analysis of ways to enhance their efficiency is merited. This Essay thus examines key strategies for privacy-related intermediation, obstacles, and problems arising in the process, as well as possible solutions. The analysis weaves together theoretical and empirical privacy law scholarship (much of it by Professor Reidenberg), “classic” work on the limits of disclosure policy, and general scholarship on certification. Part I of this Essay provides a brief introduction to privacy policies and the challenges of their intermediation. Part II examines the additional steps that must be taken to ensure that privacy intermediation is effective and efficient in terms of the system’s design, especially through setting disclosure objectives and priorities. It also addresses the use of personalized disclosure and its possible shortcomings. Part III assumes that privacy intermediation is successful and confronts the potential problems that may lead to the trivialization of labels and rankings over time. These dynamics result from a possible flood of appeals for reevaluation and ensuing grade inflation. This part also briefly explains how such concerns may be mitigated through proper design, tailored disclosures, and tinkering with the liability regime of intermediaries. This Essay concludes with some parting thoughts about Reidenberg’s substantial contribution to “law and technology” scholarship and the ways others may develop it in years to come. © 2022 Fordham University School of Law. All rights reserved.",2022,Fordham Law Review,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130401198&partnerID=40&md5=4b8dd6706ca78c6de8b0537d3619c5dc,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Fordham University School of Law', 'abstract': 'This Essay pays tribute to Professor Joel Reidenberg’s rich academic career and, specifically, to his contributions to the study of privacy policies. In doing so, this Essay takes a close look at privacy policies and possible ways to effectively intermediate their content through various labeling schemes. While severely flawed, privacy policies are here to stay. Therefore, an in-depth analysis of ways to enhance their efficiency is merited. This Essay thus examines key strategies for privacy-related intermediation, obstacles, and problems arising in the process, as well as possible solutions. The analysis weaves together theoretical and empirical privacy law scholarship (much of it by Professor Reidenberg), “classic” work on the limits of disclosure policy, and general scholarship on certification. Part I of this Essay provides a brief introduction to privacy policies and the challenges of their intermediation. Part II examines the additional steps that must be taken to ensure that privacy intermediation is effective and efficient in terms of the system’s design, especially through setting disclosure objectives and priorities. It also addresses the use of personalized disclosure and its possible shortcomings. Part III assumes that privacy intermediation is successful and confronts the potential problems that may lead to the trivialization of labels and rankings over time. These dynamics result from a possible flood of appeals for reevaluation and ensuing grade inflation. This part also briefly explains how such concerns may be mitigated through proper design, tailored disclosures, and tinkering with the liability regime of intermediaries. This Essay concludes with some parting thoughts about Reidenberg’s substantial contribution to “law and technology” scholarship and the ways others may develop it in years to come. © 2022 Fordham University School of Law. All rights reserved.', 'affiliations': 'University of Haifa, Faculty of Law, Israel', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130401198&partnerID=40&md5=4b8dd6706ca78c6de8b0537d3619c5dc', 'pages': '1457 – 1487', 'number': '4', 'volume': '90', 'journal': 'Fordham Law Review', 'year': '2022', 'title': 'SERIOUS NOTICE: A CELEBRATION, DISCUSSION, AND RECOGNITION OF JOEL REIDENBERG’S WORK ON PRIVACY NOTICES AND DISCLOSURES', 'author': 'Zarsky, Tal Z.', 'ENTRYTYPE': 'article', 'ID': 'Zarsky20221457'}",Scopus
"Rosadi, Aden and Marta, M. Sandi and Supriadi, Dedi and Sanusi, Ahmad and Somawinata, Yusuf",Career opportunity of whistle-blower in the workplace: the role of privacy legislation and supervisor support,,"Purpose: This study aims to explain the interaction of perceived privacy legislation on the relationship between affective commitment and whistle-blowing. Additionally, it seeks to determine the consequences of whistle-blowing on employee careers moderated by perceived supervisor support in government organizations. Design/methodology/approach: A Moderated Regression Analysis was used to analyze survey data from 411 local government employees in West Java, Indonesia. Findings: The result found a positive relationship between affective commitment and whistle-blowing. Perceived privacy legislation also had a significant moderating effect on the correlation between the two variables. Furthermore, whistle-blowing found a positive relationship with career opportunities, moderated by perceived supervisor support. Originality/value: The finding may contribute to the extension of scientific literature by making privacy legislation a moderator with the potential to increase employee affective commitment to whistle-blowing behavior. It determines the relationship between whistle-blowing on employee careers opportunity moderated by perceived supervisor support. In contrast, previous studies only focused on factors influencing whistle-blowing behavior. © 2022 The Author(s)",2022,Heliyon,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139725292&doi=10.1016%2fj.heliyon.2022.e10962&partnerID=40&md5=c9324a40abe39f2c1bcdaffc9f0719a5,"{'note': 'All Open Access, Gold Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Elsevier Ltd', 'abstract': 'Purpose: This study aims to explain the interaction of perceived privacy legislation on the relationship between affective commitment and whistle-blowing. Additionally, it seeks to determine the consequences of whistle-blowing on employee careers moderated by perceived supervisor support in government organizations. Design/methodology/approach: A Moderated Regression Analysis was used to analyze survey data from 411 local government employees in West Java, Indonesia. Findings: The result found a positive relationship between affective commitment and whistle-blowing. Perceived privacy legislation also had a significant moderating effect on the correlation between the two variables. Furthermore, whistle-blowing found a positive relationship with career opportunities, moderated by perceived supervisor support. Originality/value: The finding may contribute to the extension of scientific literature by making privacy legislation a moderator with the potential to increase employee affective commitment to whistle-blowing behavior. It determines the relationship between whistle-blowing on employee careers opportunity moderated by perceived supervisor support. In contrast, previous studies only focused on factors influencing whistle-blowing behavior. © 2022 The Author(s)', 'affiliations': 'Faculty of Sharia and Law, UIN Sunan Gunung Djati, West Java, Indonesia; Faculty of Economic and Islamic Business, UIN Sunan Gunung Djati, West Java, Indonesia; Faculty of Adab and Humanities, UIN Sunan Gunung Djati, West Java, Indonesia; Faculty of Sharia and Law, Sultan Maulana Hasanuddin State Islamic University of Banten, Indonesia', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139725292&doi=10.1016%2fj.heliyon.2022.e10962&partnerID=40&md5=c9324a40abe39f2c1bcdaffc9f0719a5', 'doi': '10.1016/j.heliyon.2022.e10962', 'number': '10', 'volume': '8', 'journal': 'Heliyon', 'year': '2022', 'title': 'Career opportunity of whistle-blower in the workplace: the role of privacy legislation and supervisor support', 'author': 'Rosadi, Aden and Marta, M. Sandi and Supriadi, Dedi and Sanusi, Ahmad and Somawinata, Yusuf', 'ENTRYTYPE': 'article', 'ID': 'Rosadi2022'}",Scopus
"Jesus, Vitor and Patel, Asma and Kumar, Deepak","Feasibility of Structured, Machine-Readable Privacy Notices",,"This paper offers a novel approach to the long standing problem of the interface of humans and online privacy notices. As literature and practice, and even art, for more than a decade have identified, privacy notices are nearly always ignored and ""accepted""with little thought, mostly because it is not practical nor user-friendly to depend on reading a long text simply to access, e.g., a news website. Nevertheless, privacy notices are a central element, often mandated by law.We approach the problem by (partially) relieving the human from the task of inspecting such documents. Because they are documents written in natural language, often legal language, we assess the feasibility of representing privacy notices in a machine-readable format. Should this be feasible, automated processing of notices that still respect individual choices could be enabled. To this end, we manually inspected privacy notices under EU/UK's GDPR from common websites, and designed a JSON schema that captures their structure.  © 2023 IEEE.",2023,"Proceedings of the 2023 IEEE International Conference on Behavioural and Social Computing, BESC 2023",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184664627&doi=10.1109%2fBESC59560.2023.10386763&partnerID=40&md5=0c869c7068c19da72b75d4be0a376883,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Institute of Electrical and Electronics Engineers Inc.', 'abstract': 'This paper offers a novel approach to the long standing problem of the interface of humans and online privacy notices. As literature and practice, and even art, for more than a decade have identified, privacy notices are nearly always ignored and ""accepted""with little thought, mostly because it is not practical nor user-friendly to depend on reading a long text simply to access, e.g., a news website. Nevertheless, privacy notices are a central element, often mandated by law.We approach the problem by (partially) relieving the human from the task of inspecting such documents. Because they are documents written in natural language, often legal language, we assess the feasibility of representing privacy notices in a machine-readable format. Should this be feasible, automated processing of notices that still respect individual choices could be enabled. To this end, we manually inspected privacy notices under EU/UK\'s GDPR from common websites, and designed a JSON schema that captures their structure.  © 2023 IEEE.', 'affiliations': 'Aston University, Birmingham, United Kingdom', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184664627&doi=10.1109%2fBESC59560.2023.10386763&partnerID=40&md5=0c869c7068c19da72b75d4be0a376883', 'doi': '10.1109/BESC59560.2023.10386763', 'journal': 'Proceedings of the 2023 IEEE International Conference on Behavioural and Social Computing, BESC 2023', 'year': '2023', 'title': 'Feasibility of Structured, Machine-Readable Privacy Notices', 'author': 'Jesus, Vitor and Patel, Asma and Kumar, Deepak', 'ENTRYTYPE': 'conference', 'ID': 'Jesus2023'}",Scopus
,"Proceedings - 8th IEEE European Symposium on Security and Privacy Workshops, Euro S and PW 2023",,The proceedings contain 73 papers. The topics discussed include: vulnerability analysis of vehicular coordinated maneuvers; a preliminary study of privilege life cycle in software management platform automation workflows; an investigation of quality issues in vulnerability detection datasets; guiding directed fuzzing with feasibility; effective machine learning-based access control administration through unlearning; an analysis system to test security of software on continuous integration-continuous delivery pipeline; tales from the git: automating the detection of secrets on code and assessing developers’ passwords choices; a ‘human-in-the-loop’ approach for information extraction from privacy policies under data scarcity; an analysis of requirements and privacy threats in mobile data donations; automating privacy decisions -where to draw the line?; lessons learned: building a privacy-preserving entity resolution adaptation of PPJoin using end-to-end homomorphic encryption; privacy as an architectural quality: a definition and an architectural view; unified communication: what do digital activists need?; comparing privacy label disclosures of apps published in both the app store and Google play stores; and ‘get a higher return on your savings!’: comparing adverts for cryptocurrency investment scams across platforms.,2023,"Proceedings - 8th IEEE European Symposium on Security and Privacy Workshops, Euro S and PW 2023",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168268286&partnerID=40&md5=fbf511fb33d4ec2d3772d7d2dd819249,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference review', 'language': 'English', 'publisher': 'Institute of Electrical and Electronics Engineers Inc.', 'abstract': 'The proceedings contain 73 papers. The topics discussed include: vulnerability analysis of vehicular coordinated maneuvers; a preliminary study of privilege life cycle in software management platform automation workflows; an investigation of quality issues in vulnerability detection datasets; guiding directed fuzzing with feasibility; effective machine learning-based access control administration through unlearning; an analysis system to test security of software on continuous integration-continuous delivery pipeline; tales from the git: automating the detection of secrets on code and assessing developers’ passwords choices; a ‘human-in-the-loop’ approach for information extraction from privacy policies under data scarcity; an analysis of requirements and privacy threats in mobile data donations; automating privacy decisions -where to draw the line?; lessons learned: building a privacy-preserving entity resolution adaptation of PPJoin using end-to-end homomorphic encryption; privacy as an architectural quality: a definition and an architectural view; unified communication: what do digital activists need?; comparing privacy label disclosures of apps published in both the app store and Google play stores; and ‘get a higher return on your savings!’: comparing adverts for cryptocurrency investment scams across platforms.', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168268286&partnerID=40&md5=fbf511fb33d4ec2d3772d7d2dd819249', 'journal': 'Proceedings - 8th IEEE European Symposium on Security and Privacy Workshops, Euro S and PW 2023', 'year': '2023', 'title': 'Proceedings - 8th IEEE European Symposium on Security and Privacy Workshops, Euro S and PW 2023', 'ENTRYTYPE': 'conference', 'ID': '2023'}",Scopus
"Oser, Pascal and Van Der Heijden, Rens W. and Lüders, Stefan and Kargl, Frank",Risk Prediction of IoT Devices Based on Vulnerability Analysis,,"Internet of Things (IoT) devices are becoming more widespread not only in areas such as smart homes and smart cities but also in research and office environments. The sheer number, heterogeneity, and limited patch availability provide significant challenges for the security of both office networks and the Internet in general. The systematic estimation of device risks, which is essential for mitigation decisions, is currently a skill-intensive task that requires expertise in network vulnerability scanning, as well as manual effort in firmware binary analysis.This article introduces SAFER,1 the Security Assessment Framework for Embedded-device Risks, which enables a semi-automated risk assessment of IoT devices in any network. SAFER combines information from network device identification and automated firmware analysis to estimate the current risk associated with the device. Based on past vulnerability data and vendor patch intervals for device models, SAFER extrapolates those observations into the future using different automatically parameterized prediction models. Based on that, SAFER also estimates an indicator for future security risks. This enables users to be aware of devices exposing high risks in the future.One major strength of SAFER over other approaches is its scalability, achieved through significant automation. To demonstrate this strength, we apply SAFER in the network of a large multinational organization, to systematically assess the security level of hundreds of IoT devices on large-scale networks.Results indicate that SAFER successfully identified 531 out of 572 devices leading to a device identification rate of 92.83 %, analyzed 825 firmware images, and predicted the current and future security risk for 240 devices.  © 2022 Copyright held by the owner/author(s).",2022,ACM Transactions on Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133729261&doi=10.1145%2f3510360&partnerID=40&md5=7a22ca8430203d9a789db0dbcab3a506,"{'note': 'All Open Access, Bronze Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': 'Internet of Things (IoT) devices are becoming more widespread not only in areas such as smart homes and smart cities but also in research and office environments. The sheer number, heterogeneity, and limited patch availability provide significant challenges for the security of both office networks and the Internet in general. The systematic estimation of device risks, which is essential for mitigation decisions, is currently a skill-intensive task that requires expertise in network vulnerability scanning, as well as manual effort in firmware binary analysis.This article introduces SAFER,1 the Security Assessment Framework for Embedded-device Risks, which enables a semi-automated risk assessment of IoT devices in any network. SAFER combines information from network device identification and automated firmware analysis to estimate the current risk associated with the device. Based on past vulnerability data and vendor patch intervals for device models, SAFER extrapolates those observations into the future using different automatically parameterized prediction models. Based on that, SAFER also estimates an indicator for future security risks. This enables users to be aware of devices exposing high risks in the future.One major strength of SAFER over other approaches is its scalability, achieved through significant automation. To demonstrate this strength, we apply SAFER in the network of a large multinational organization, to systematically assess the security level of hundreds of IoT devices on large-scale networks.Results indicate that SAFER successfully identified 531 out of 572 devices leading to a device identification rate of 92.83 %, analyzed 825 firmware images, and predicted the current and future security risk for 240 devices.  © 2022 Copyright held by the owner/author(s).', 'affiliations': 'Ulm University, Ulm, Germany; Inmdependent Researcher, Nuremberg, Germany; European Organization for Nuclear Research (CERN), Geneva, Switzerland', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133729261&doi=10.1145%2f3510360&partnerID=40&md5=7a22ca8430203d9a789db0dbcab3a506', 'doi': '10.1145/3510360', 'number': '2', 'volume': '25', 'journal': 'ACM Transactions on Privacy and Security', 'year': '2022', 'title': 'Risk Prediction of IoT Devices Based on Vulnerability Analysis', 'author': 'Oser, Pascal and Van Der Heijden, Rens W. and Lüders, Stefan and Kargl, Frank', 'ENTRYTYPE': 'article', 'ID': 'Oser2022'}",Scopus
"Cranor, Lorrie Faith and Agarwal, Yuvraj and Naeini, Pardis Emami",Internet of things security and privacy labels should empower consumers,,Designs should offer useful information and convenience. © 2024 Association for Computing Machinery. All rights reserved.,2024,Communications of the ACM,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186145255&doi=10.1145%2f3637630&partnerID=40&md5=c761f386f0f059ab00f32a0ca884f61e,"{'note': 'All Open Access, Bronze Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': 'Designs should offer useful information and convenience. © 2024 Association for Computing Machinery. All rights reserved.', 'affiliations': 'Bosch Distinguished Professor in Security and Privacy Technologies, CyLab Security and Privacy Institute and FORE Systems Professor, Computer Science and Engineering and Public Policy, Carnegie Mellon University, Pittsburgh, PA, United States; Systems Networking and Energy Efficiency (SYNERGY) Lab, Carnegie Mellon University, Pittsburgh, PA, United States; Duke Interdisciplinary Security, Privacy, and Interaction Research (InSPIre) Lab, Duke University, Durham, NC, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186145255&doi=10.1145%2f3637630&partnerID=40&md5=c761f386f0f059ab00f32a0ca884f61e', 'doi': '10.1145/3637630', 'pages': '29 – 31', 'number': '3', 'volume': '67', 'journal': 'Communications of the ACM', 'year': '2024', 'title': 'Internet of things security and privacy labels should empower consumers', 'author': 'Cranor, Lorrie Faith and Agarwal, Yuvraj and Naeini, Pardis Emami', 'ENTRYTYPE': 'article', 'ID': 'Cranor202429'}",Scopus
"Paspatis, Ioannis and Tsohou, Aggeliki and Kokolakis, Spyros",How Is Privacy Behavior Formulated? A Review of Current Research and Synthesis of Information Privacy Behavioral Factors,,"What influences Information Communications and Technology (ICT) users’ privacy behavior? Several studies have shown that users state to care about their personal data. Contrary to that though, they perform unsafe privacy actions, such as ignoring to configure privacy settings. In this research, we present the results of an in-depth literature review on the factors affecting privacy behavior. We seek to investigate the underlying factors that influence individuals’ privacy-conscious behavior in the digital domain, as well as effective interventions to promote such behavior. Privacy decisions regarding the disclosure of personal information may have negative consequences on individuals’ lives, such as becoming a victim of identity theft, impersonation, etc. Moreover, third parties may exploit this information for their own benefit, such as targeted advertising practices. By identifying the factors that may affect SNS users’ privacy awareness, we can assist in creating methods for effective privacy protection and/or user-centered design. Examining the results of several research studies, we found evidence that privacy behavior is affected by a variety of factors, including individual ones (e.g., demographics) and contextual ones (e.g., financial exchanges). We synthesize a framework that aggregates the scattered factors that have been found in the literature to affect privacy behavior. Our framework can be beneficial to academics and practitioners in the private and public sectors. For example, academics can utilize our findings to create specialized information privacy courses and theoretical or laboratory modules. © 2023 by the authors.",2023,Multimodal Technologies and Interaction,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169026680&doi=10.3390%2fmti7080076&partnerID=40&md5=2d8b5c2d49506aee055e80201d2991a8,"{'note': 'All Open Access, Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Review', 'language': 'English', 'publisher': 'Multidisciplinary Digital Publishing Institute (MDPI)', 'abstract': 'What influences Information Communications and Technology (ICT) users’ privacy behavior? Several studies have shown that users state to care about their personal data. Contrary to that though, they perform unsafe privacy actions, such as ignoring to configure privacy settings. In this research, we present the results of an in-depth literature review on the factors affecting privacy behavior. We seek to investigate the underlying factors that influence individuals’ privacy-conscious behavior in the digital domain, as well as effective interventions to promote such behavior. Privacy decisions regarding the disclosure of personal information may have negative consequences on individuals’ lives, such as becoming a victim of identity theft, impersonation, etc. Moreover, third parties may exploit this information for their own benefit, such as targeted advertising practices. By identifying the factors that may affect SNS users’ privacy awareness, we can assist in creating methods for effective privacy protection and/or user-centered design. Examining the results of several research studies, we found evidence that privacy behavior is affected by a variety of factors, including individual ones (e.g., demographics) and contextual ones (e.g., financial exchanges). We synthesize a framework that aggregates the scattered factors that have been found in the literature to affect privacy behavior. Our framework can be beneficial to academics and practitioners in the private and public sectors. For example, academics can utilize our findings to create specialized information privacy courses and theoretical or laboratory modules. © 2023 by the authors.', 'affiliations': 'Department of Informatics, Ionian University, Corfu, 49100, Greece; Department of Information and Communication Systems Engineering, University of Aegean, Samos, 83200, Greece', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169026680&doi=10.3390%2fmti7080076&partnerID=40&md5=2d8b5c2d49506aee055e80201d2991a8', 'doi': '10.3390/mti7080076', 'number': '8', 'volume': '7', 'journal': 'Multimodal Technologies and Interaction', 'year': '2023', 'title': 'How Is Privacy Behavior Formulated? A Review of Current Research and Synthesis of Information Privacy Behavioral Factors', 'author': 'Paspatis, Ioannis and Tsohou, Aggeliki and Kokolakis, Spyros', 'ENTRYTYPE': 'article', 'ID': 'Paspatis2023'}",Scopus
"Nguyen, Trung Tin and Backes, Michael and Stock, Ben",Freely Given Consent?: Studying Consent Notice of Third-Party Tracking and Its Violations of GDPR in Android Apps,,"Adopted in May 2018, the European Union's General Data Protection Regulation (GDPR) requires the consent for processing users' personal data to be freely given, specific, informed, and unambiguous. While prior work has shown that this often is not given through automated network traffic analysis, no research has systematically studied how consent notices are currently implemented and whether they conform to GDPR in mobile apps. To close this research gap, we perform the first large-scale study into consent notices for third-party tracking in Android apps to understand the current practices and the current state of GDPR's consent violations. Specifically, we propose a mostly automated and scalable approach to identify the currently implemented consent notices and apply it to a set of 239,381 Android apps. As a result, we recognize four widely implemented mechanisms to interact with the consent user interfaces from 13,082 apps. We then develop a tool that automatically detects users' personal data sent out to the Internet with different consent conditions based on the identified mechanisms. Doing so, we find 30,160 apps do not even attempt to implement consent notices for sharing users' personal data with third-party data controllers, which mandate explicit consent under GDPR. In contrast, out of 13,082 apps implemented consent notices, we identify 2,688 (20.54%) apps violate at least one of the GDPR consent requirements, such as trying to deceive users into accepting all data sharing or even continuously transmitting data when users have explicitly opted out. To allow developers to address the problems, we send emails to notify affected developers and gather insights from their responses. Our study shows the urgent need for more transparent processing of personal data and supporting developers in this endeavor to comply with legislation, ensuring users can make free and informed choices regarding their data. © 2022 ACM.",2022,Proceedings of the ACM Conference on Computer and Communications Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143071146&doi=10.1145%2f3548606.3560564&partnerID=40&md5=b0b11ebc9c3eea8fe87b7fcd2919aa8d,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': ""Adopted in May 2018, the European Union's General Data Protection Regulation (GDPR) requires the consent for processing users' personal data to be freely given, specific, informed, and unambiguous. While prior work has shown that this often is not given through automated network traffic analysis, no research has systematically studied how consent notices are currently implemented and whether they conform to GDPR in mobile apps. To close this research gap, we perform the first large-scale study into consent notices for third-party tracking in Android apps to understand the current practices and the current state of GDPR's consent violations. Specifically, we propose a mostly automated and scalable approach to identify the currently implemented consent notices and apply it to a set of 239,381 Android apps. As a result, we recognize four widely implemented mechanisms to interact with the consent user interfaces from 13,082 apps. We then develop a tool that automatically detects users' personal data sent out to the Internet with different consent conditions based on the identified mechanisms. Doing so, we find 30,160 apps do not even attempt to implement consent notices for sharing users' personal data with third-party data controllers, which mandate explicit consent under GDPR. In contrast, out of 13,082 apps implemented consent notices, we identify 2,688 (20.54%) apps violate at least one of the GDPR consent requirements, such as trying to deceive users into accepting all data sharing or even continuously transmitting data when users have explicitly opted out. To allow developers to address the problems, we send emails to notify affected developers and gather insights from their responses. Our study shows the urgent need for more transparent processing of personal data and supporting developers in this endeavor to comply with legislation, ensuring users can make free and informed choices regarding their data. © 2022 ACM."", 'affiliations': 'Cispa Helmholtz Center for Information Security, Saarbrücken, Germany; Saarland University, Germany', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143071146&doi=10.1145%2f3548606.3560564&partnerID=40&md5=b0b11ebc9c3eea8fe87b7fcd2919aa8d', 'doi': '10.1145/3548606.3560564', 'pages': '2369 – 2383', 'journal': 'Proceedings of the ACM Conference on Computer and Communications Security', 'year': '2022', 'title': 'Freely Given Consent?: Studying Consent Notice of Third-Party Tracking and Its Violations of GDPR in Android Apps', 'author': 'Nguyen, Trung Tin and Backes, Michael and Stock, Ben', 'ENTRYTYPE': 'conference', 'ID': 'Nguyen20222369'}",Scopus
"Ghorashi, Seyed Ramin and Zia, Tanveer and Bewong, Michael and Jiang, Yinhao",An Analytical Review of Industrial Privacy Frameworks and Regulations for Organisational Data Sharing,,"This study examines the privacy protection challenges in data sharing between organisations and third-party entities, focusing on changing collaborations in the digital age. Utilising a mixed-method approach, we categorise data-sharing practices into three business models, each with unique privacy concerns. The research reviews legal regulations like the General Data Protection Regulation (GDPR), highlighting their emphasis on user privacy protection but noting a lack of specific technical guidance. In contrast, industrial privacy frameworks such as NIST and Five Safes are explored for their comprehensive procedural and technical guidance, bridging the gap between legal mandates and practical applications. A key component of this study is the analysis of the Facebook–Cambridge Analytica data breach, which illustrates the significant privacy violations and their wider implications. This case study demonstrates how the principles of the NIST and Five Safes frameworks can effectively mitigate privacy risks, enhancing transparency and accountability in data sharing. Our findings highlight the dynamic nature of data sharing and the vital role of both privacy regulations and industry-specific frameworks in protecting individual privacy rights. This study contributes insights into the development of robust privacy strategies, highlighting the necessity of integrating comprehensive privacy frameworks into organisational practices for improved decision making, operational efficiency, and privacy protection in collaborative data environments. © 2023 by the authors.",2023,Applied Sciences (Switzerland),https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192447947&doi=10.3390%2fapp132312727&partnerID=40&md5=3a0997f240a9351eb3eaa865071151b2,"{'note': 'All Open Access, Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Review', 'language': 'English', 'publisher': 'Multidisciplinary Digital Publishing Institute (MDPI)', 'abstract': 'This study examines the privacy protection challenges in data sharing between organisations and third-party entities, focusing on changing collaborations in the digital age. Utilising a mixed-method approach, we categorise data-sharing practices into three business models, each with unique privacy concerns. The research reviews legal regulations like the General Data Protection Regulation (GDPR), highlighting their emphasis on user privacy protection but noting a lack of specific technical guidance. In contrast, industrial privacy frameworks such as NIST and Five Safes are explored for their comprehensive procedural and technical guidance, bridging the gap between legal mandates and practical applications. A key component of this study is the analysis of the Facebook–Cambridge Analytica data breach, which illustrates the significant privacy violations and their wider implications. This case study demonstrates how the principles of the NIST and Five Safes frameworks can effectively mitigate privacy risks, enhancing transparency and accountability in data sharing. Our findings highlight the dynamic nature of data sharing and the vital role of both privacy regulations and industry-specific frameworks in protecting individual privacy rights. This study contributes insights into the development of robust privacy strategies, highlighting the necessity of integrating comprehensive privacy frameworks into organisational practices for improved decision making, operational efficiency, and privacy protection in collaborative data environments. © 2023 by the authors.', 'affiliations': 'School of Computing, Mathematics, and Engineering, Charles Sturt University, 2678, NSW, Australia; Cyber Security Cooperative Research Centre, 6027, WA, Australia; School of Arts and Sciences, University of Notre Dame, Australia', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192447947&doi=10.3390%2fapp132312727&partnerID=40&md5=3a0997f240a9351eb3eaa865071151b2', 'doi': '10.3390/app132312727', 'number': '23', 'volume': '13', 'journal': 'Applied Sciences (Switzerland)', 'year': '2023', 'title': 'An Analytical Review of Industrial Privacy Frameworks and Regulations for Organisational Data Sharing', 'author': 'Ghorashi, Seyed Ramin and Zia, Tanveer and Bewong, Michael and Jiang, Yinhao', 'ENTRYTYPE': 'article', 'ID': 'Ghorashi2023'}",Scopus
"Cranor, Lorrie Faith",Mobile-app privacy nutrition labels missing key ingredients for success,,,2022,Communications of the ACM,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148068205&doi=10.1145%2f3563967&partnerID=40&md5=25e0b70d3151ca7d2da284e416cb8f49,"{'note': 'All Open Access, Bronze Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Short survey', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'affiliations': 'Security and Privacy Technologies, CyLab Security and Privacy Institute, Computer Science and Engineering and Public Policy, Carnegie Mellon University, Pittsburgh, PA, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148068205&doi=10.1145%2f3563967&partnerID=40&md5=25e0b70d3151ca7d2da284e416cb8f49', 'doi': '10.1145/3563967', 'pages': '26 – 28', 'number': '11', 'volume': '65', 'journal': 'Communications of the ACM', 'year': '2022', 'title': 'Mobile-app privacy nutrition labels missing key ingredients for success', 'author': 'Cranor, Lorrie Faith', 'ENTRYTYPE': 'article', 'ID': 'Cranor202226'}",Scopus
"Wang, Yong",Design of Intelligent Operation and Maintenance System for Information Security Based on Web,,"In order to solve the problems of poor communication, low efficiency and poor service quality in information operation and security management, a Web-based intelligent information security operation and maintenance system is proposed. Adopting SOA (service-oriented architecture) architecture and based on IitLL (information technology infrastructure library) technology, an integrated management system of information security operation and maintenance services is established to meet business and management requirements. The system is mainly composed of data acquisition layer, summary analysis layer and presentation layer, and realizes three management functions: business operation, operation and maintenance services and information security. Through configuration management tracking and intelligent log analysis, the automatic collection, analysis and early warning of information security incidents are realized, which provides a basis for dealing with all kinds of incidents. The application shows that the system realizes the unified scheduling of operation and maintenance human resources, and realizes the unified management and process standardization of information security and operation and maintenance services through real-time monitoring of business systems and infrastructure. (Abstract)  © 2022 IEEE.",2022,"Proceedings - 2022 2nd International Conference on Electronic Information Engineering and Computer Technology, EIECT 2022",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151524558&doi=10.1109%2fEIECT58010.2022.00043&partnerID=40&md5=99524f66de4e43a614c462de93e498d2,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Institute of Electrical and Electronics Engineers Inc.', 'abstract': 'In order to solve the problems of poor communication, low efficiency and poor service quality in information operation and security management, a Web-based intelligent information security operation and maintenance system is proposed. Adopting SOA (service-oriented architecture) architecture and based on IitLL (information technology infrastructure library) technology, an integrated management system of information security operation and maintenance services is established to meet business and management requirements. The system is mainly composed of data acquisition layer, summary analysis layer and presentation layer, and realizes three management functions: business operation, operation and maintenance services and information security. Through configuration management tracking and intelligent log analysis, the automatic collection, analysis and early warning of information security incidents are realized, which provides a basis for dealing with all kinds of incidents. The application shows that the system realizes the unified scheduling of operation and maintenance human resources, and realizes the unified management and process standardization of information security and operation and maintenance services through real-time monitoring of business systems and infrastructure. (Abstract)  © 2022 IEEE.', 'affiliations': 'GS-UNIS Intelligent Transportation System & Control Technology Co., Ltd, Lanzhou Gansu, 730010, China', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151524558&doi=10.1109%2fEIECT58010.2022.00043&partnerID=40&md5=99524f66de4e43a614c462de93e498d2', 'doi': '10.1109/EIECT58010.2022.00043', 'pages': '192 – 195', 'journal': 'Proceedings - 2022 2nd International Conference on Electronic Information Engineering and Computer Technology, EIECT 2022', 'year': '2022', 'title': 'Design of Intelligent Operation and Maintenance System for Information Security Based on Web', 'author': 'Wang, Yong', 'ENTRYTYPE': 'conference', 'ID': 'Wang2022192'}",Scopus
"Krämer, Julia",The death of privacy policies: How app stores shape GDPR compliance of apps,,"The General Data Protection Regulation (GDPR) obliges data controllers to inform users about data processing practices. Long criticised for inefficiency, privacy policies face a substantive shift with the recent introduction of privacy labels by the Apple App Store and the Google Play Store. This paper illustrates how privacy disclosures of apps are governed by both the GDPR and the contractual obligations of app stores and is complemented by empirical insights into the privacy disclosures of 845,375 apps from the Apple App Store and 1,657,353 apps from the Google Play Store. While the GDPR allows for the use of privacy labels as a complementary tool next to privacy policies, the design of the privacy labels does not satisfy the standards set in Art. 5(1)(a) GDPR and Art. 12-14 GDPR. The app stores may consequently distort the compliance of apps with data protection laws. The empirical data highlight further problems with the privacy labels. The design of the labels favours disclosures of developers that offer a variety of apps that can process data across different services and contradictory disclosures do not get flagged nor verified by app stores. The paper contributes to the overall discussion of how app stores in their role as intermediaries govern privacy standards and the impact of private sector-led initiatives. © 2024, Alexander von Humboldt Institute for Internet and Society. All rights reserved.",2024,Internet Policy Review,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192146381&doi=10.14763%2f2024.2.1757&partnerID=40&md5=cf3fdbf1c8c4ed4896e0915ef3f55585,"{'note': 'All Open Access, Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Alexander von Humboldt Institute for Internet and Society', 'abstract': 'The General Data Protection Regulation (GDPR) obliges data controllers to inform users about data processing practices. Long criticised for inefficiency, privacy policies face a substantive shift with the recent introduction of privacy labels by the Apple App Store and the Google Play Store. This paper illustrates how privacy disclosures of apps are governed by both the GDPR and the contractual obligations of app stores and is complemented by empirical insights into the privacy disclosures of 845,375 apps from the Apple App Store and 1,657,353 apps from the Google Play Store. While the GDPR allows for the use of privacy labels as a complementary tool next to privacy policies, the design of the privacy labels does not satisfy the standards set in Art. 5(1)(a) GDPR and Art. 12-14 GDPR. The app stores may consequently distort the compliance of apps with data protection laws. The empirical data highlight further problems with the privacy labels. The design of the labels favours disclosures of developers that offer a variety of apps that can process data across different services and contradictory disclosures do not get flagged nor verified by app stores. The paper contributes to the overall discussion of how app stores in their role as intermediaries govern privacy standards and the impact of private sector-led initiatives. © 2024, Alexander von Humboldt Institute for Internet and Society. All rights reserved.', 'affiliations': 'Erasmus University Rotterdam, Netherlands', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192146381&doi=10.14763%2f2024.2.1757&partnerID=40&md5=cf3fdbf1c8c4ed4896e0915ef3f55585', 'doi': '10.14763/2024.2.1757', 'number': '2', 'volume': '13', 'journal': 'Internet Policy Review', 'year': '2024', 'title': 'The death of privacy policies: How app stores shape GDPR compliance of apps', 'author': 'Krämer, Julia', 'ENTRYTYPE': 'article', 'ID': 'Krämer2024'}",Scopus
"Sloane, Mona and Solano-Kamaiko, Ian René and Yuan, Jun and Dasgupta, Aritra and Stoyanovich, Julia",Introducing contextual transparency for automated decision systems,,"As automated decision systems (ADS) get more deeply embedded into business processes worldwide, there is a growing need for practical ways to establish meaningful transparency. Here we argue that universally perfect transparency is impossible to achieve. We introduce the concept of contextual transparency as an approach that integrates social science, engineering and information design to help improve ADS transparency for specific professions, business processes and stakeholder groups. We demonstrate the applicability of the contextual transparency approach by using it for a well-established ADS transparency tool: nutritional labels that display specific information about an ADS. Empirically, it focuses on the profession of recruiting. Presenting data from an ongoing study about ADS use in recruiting alongside a typology of ADS nutritional labels, we suggest a nutritional label prototype for ADS-driven rankers such as LinkedIn Recruiter before closing with directions for future work. © 2023, Springer Nature Limited.",2023,Nature Machine Intelligence,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149914148&doi=10.1038%2fs42256-023-00623-7&partnerID=40&md5=3bb7f8a92b137ea634cf4e9eaa8a7010,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Nature Research', 'abstract': 'As automated decision systems (ADS) get more deeply embedded into business processes worldwide, there is a growing need for practical ways to establish meaningful transparency. Here we argue that universally perfect transparency is impossible to achieve. We introduce the concept of contextual transparency as an approach that integrates social science, engineering and information design to help improve ADS transparency for specific professions, business processes and stakeholder groups. We demonstrate the applicability of the contextual transparency approach by using it for a well-established ADS transparency tool: nutritional labels that display specific information about an ADS. Empirically, it focuses on the profession of recruiting. Presenting data from an ongoing study about ADS use in recruiting alongside a typology of ADS nutritional labels, we suggest a nutritional label prototype for ADS-driven rankers such as LinkedIn Recruiter before closing with directions for future work. © 2023, Springer Nature Limited.', 'affiliations': 'Tandon School of Engineering, New York University, Brooklyn, NY, United States; New Jersey Institute of Technology, Department of Informatics, University Heights, Newark, NJ, United States; New Jersey Institute of Technology, Department of Data Science, University Heights, Newark, NJ, United States; Tandon School of Engineering and Center for Data Science, New York University, New York City, NY, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149914148&doi=10.1038%2fs42256-023-00623-7&partnerID=40&md5=3bb7f8a92b137ea634cf4e9eaa8a7010', 'doi': '10.1038/s42256-023-00623-7', 'pages': '187 – 195', 'number': '3', 'volume': '5', 'journal': 'Nature Machine Intelligence', 'year': '2023', 'title': 'Introducing contextual transparency for automated decision systems', 'author': 'Sloane, Mona and Solano-Kamaiko, Ian René and Yuan, Jun and Dasgupta, Aritra and Stoyanovich, Julia', 'ENTRYTYPE': 'article', 'ID': 'Sloane2023187'}",Scopus
"Lenhart, Anna and Park, Sunyup and Zimmer, Michael and Vitak, Jessica","You Shouldn't Need to Share Your Data"": Perceived Privacy Risks and Mitigation Strategies Among Privacy-Conscious Smart Home Power Users",,"Fueled by Internet-of-Things technologies and spanning a wide range of sensors, speakers, and cameras, smart homes promise to make our lives easier and automate routine tasks. From speakers to security cameras, smart home devices (SHDs) answer our questions, monitor our home environment, and conserve energy. They also collect significant data, ranging from on/off commands to audio and video data, and they do this in some of our most private spaces. In this paper, we explore the privacy risks associated with SHDs by focusing on privacy-conscious smart home power users - those who spend significant time and money to research, install, and integrate devices throughout their homes and engage in advanced device and network management strategies to mitigate privacy concerns. Drawing on data from 10 focus groups with 32 privacy-conscious power users, we identify the key privacy risks they perceive from this technology, as well as how they mitigate those risks through increasingly complex strategies. Our findings reveal that navigating the technical landscape that makes up the smart home environment - including what data is collected, what options are available for managing or restricting data flows, and who has access to data collected by SHDs - is complex and often confusing, even for people who spend significant time researching devices and integration options. We use these findings to argue for further development of tools that are transparent, easy to use, and aligned with the privacy needs of a diverse userbase.  © 2023 Owner/Author.",2023,Proceedings of the ACM on Human-Computer Interaction,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174410492&doi=10.1145%2f3610038&partnerID=40&md5=bc096eec370ac531cdc086bba49450b2,"{'note': 'All Open Access, Hybrid Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': 'Fueled by Internet-of-Things technologies and spanning a wide range of sensors, speakers, and cameras, smart homes promise to make our lives easier and automate routine tasks. From speakers to security cameras, smart home devices (SHDs) answer our questions, monitor our home environment, and conserve energy. They also collect significant data, ranging from on/off commands to audio and video data, and they do this in some of our most private spaces. In this paper, we explore the privacy risks associated with SHDs by focusing on privacy-conscious smart home power users - those who spend significant time and money to research, install, and integrate devices throughout their homes and engage in advanced device and network management strategies to mitigate privacy concerns. Drawing on data from 10 focus groups with 32 privacy-conscious power users, we identify the key privacy risks they perceive from this technology, as well as how they mitigate those risks through increasingly complex strategies. Our findings reveal that navigating the technical landscape that makes up the smart home environment - including what data is collected, what options are available for managing or restricting data flows, and who has access to data collected by SHDs - is complex and often confusing, even for people who spend significant time researching devices and integration options. We use these findings to argue for further development of tools that are transparent, easy to use, and aligned with the privacy needs of a diverse userbase.  © 2023 Owner/Author.', 'affiliations': 'University of Maryland, College Park, MD, United States; Marquette University, Milwaukee, WI, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174410492&doi=10.1145%2f3610038&partnerID=40&md5=bc096eec370ac531cdc086bba49450b2', 'doi': '10.1145/3610038', 'number': 'CSCW2', 'volume': '7', 'journal': 'Proceedings of the ACM on Human-Computer Interaction', 'year': '2023', 'title': 'You Shouldn\'t Need to Share Your Data"": Perceived Privacy Risks and Mitigation Strategies Among Privacy-Conscious Smart Home Power Users', 'author': 'Lenhart, Anna and Park, Sunyup and Zimmer, Michael and Vitak, Jessica', 'ENTRYTYPE': 'article', 'ID': 'Lenhart2023'}",Scopus
"Lindquist, Jan",Introducing Privacy Receipts into DLT and eIDAS,,"The introduction of digital identification (e.g., eIDAS) and wallet standards (e.g., EUDI wallet) require compliance with privacy principles and clear communication of the principles through privacy notice and record of consent in the form of a privacy receipt. Regulation needs standards to help set the bar for reducing the privacy infringement risk. Without a standard-based implementation, solutions will be proprietary and siloed with no concern for interoperability, like privacy labels in Google and Apple app stores. Do existing standards address the gap, or do new ones need to be introduced? This article looks at the standards and regulations in three areas to answer this question: privacy protection standards, blockchain and DLT standards, and digital identification and wallet standards. © 2023 River Publishers.",2023,Journal of ICT Standardization,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163196679&doi=10.13052%2fjicts2245-800X.1121&partnerID=40&md5=cf2d584b9d3962f5e8ed9a9606d07627,"{'note': 'All Open Access, Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'River Publishers', 'abstract': 'The introduction of digital identification (e.g., eIDAS) and wallet standards (e.g., EUDI wallet) require compliance with privacy principles and clear communication of the principles through privacy notice and record of consent in the form of a privacy receipt. Regulation needs standards to help set the bar for reducing the privacy infringement risk. Without a standard-based implementation, solutions will be proprietary and siloed with no concern for interoperability, like privacy labels in Google and Apple app stores. Do existing standards address the gap, or do new ones need to be introduced? This article looks at the standards and regulations in three areas to answer this question: privacy protection standards, blockchain and DLT standards, and digital identification and wallet standards. © 2023 River Publishers.', 'affiliations': 'Swedish Institute for Standards (SiS), StantICT, Stockholm, Sweden', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163196679&doi=10.13052%2fjicts2245-800X.1121&partnerID=40&md5=cf2d584b9d3962f5e8ed9a9606d07627', 'doi': '10.13052/jicts2245-800X.1121', 'pages': '117 – 134', 'number': '2', 'volume': '11', 'journal': 'Journal of ICT Standardization', 'year': '2023', 'title': 'Introducing Privacy Receipts into DLT and eIDAS', 'author': 'Lindquist, Jan', 'ENTRYTYPE': 'article', 'ID': 'Lindquist2023117'}",Scopus
"Lipford, Heather Richter and Tabassum, Madiha and Bahirat, Paritosh and Yao, Yaxing and Knijnenburg, Bart P.",Privacy and the internet of things,,"Using networks of Internet-connected sensors, the Internet of Things (IoT) makes technologies ""smart"" by enabling automation, personalization, and remote control. At the same time, IoT technologies introduce challenging privacy issues that may frustrate their widespread adoption. This chapter addresses the privacy challenges of IoT technologies from a user-centered perspective and demonstrates these prevalent issues in the domains of wearables (e.g., fitness trackers), household technologies (e.g., smart voice assistants), and devices that exist in the public domain (e.g., security cameras). The chapter ends with a comprehensive list of solutions and guidelines that can help researchers and practitioners introduce usable privacy to the domain of IoT. © The Author(s) 2022.",2022,Modern Socio-Technical Perspectives on Privacy,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192631182&doi=10.1007%2f978-3-030-82786-1_11&partnerID=40&md5=d37ea5211ebdbd4469a23cca0a741806,"{'note': 'All Open Access, Hybrid Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Book chapter', 'language': 'English', 'publisher': 'Springer International Publishing', 'abstract': 'Using networks of Internet-connected sensors, the Internet of Things (IoT) makes technologies ""smart"" by enabling automation, personalization, and remote control. At the same time, IoT technologies introduce challenging privacy issues that may frustrate their widespread adoption. This chapter addresses the privacy challenges of IoT technologies from a user-centered perspective and demonstrates these prevalent issues in the domains of wearables (e.g., fitness trackers), household technologies (e.g., smart voice assistants), and devices that exist in the public domain (e.g., security cameras). The chapter ends with a comprehensive list of solutions and guidelines that can help researchers and practitioners introduce usable privacy to the domain of IoT. © The Author(s) 2022.', 'affiliations': 'College of Computing and Informatics, UNC Charlotte, Charlotte, NC, United States; School of Computing, Clemson University, Clemson, SC, United States; Department of Information Systems, University of Maryland Baltimore County, Baltimore, MD, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192631182&doi=10.1007%2f978-3-030-82786-1_11&partnerID=40&md5=d37ea5211ebdbd4469a23cca0a741806', 'doi': '10.1007/978-3-030-82786-1_11', 'pages': '233 – 264', 'journal': 'Modern Socio-Technical Perspectives on Privacy', 'year': '2022', 'title': 'Privacy and the internet of things', 'author': 'Lipford, Heather Richter and Tabassum, Madiha and Bahirat, Paritosh and Yao, Yaxing and Knijnenburg, Bart P.', 'ENTRYTYPE': 'book', 'ID': 'Lipford2022233'}",Scopus
"Kollnig, Konrad and Shuba, Anastasia and Van Kleek, Max and Binns, Reuben and Shadbolt, Nigel",Goodbye Tracking? Impact of iOS App Tracking Transparency and Privacy Labels,,"Tracking is a highly privacy-invasive data collection practice that has been ubiquitous in mobile apps for many years due to its role in supporting advertising-based revenue models. In response, Apple introduced two significant changes with iOS 14: App Tracking Transparency (ATT), a mandatory opt-in system for enabling tracking on iOS, and Privacy Nutrition Labels, which disclose what kinds of data each app processes. So far, the impact of these changes on individual privacy and control has not been well understood. This paper addresses this gap by analysing two versions of 1, 759 iOS apps from the UK App Store: one version from before iOS 14 and one that has been updated to comply with the new rules. We find that Apple's new policies, as promised, prevent the collection of the Identifier for Advertisers (IDFA), an identifier for cross-app tracking. Smaller data brokers that engage in invasive data practices will now face higher challenges in tracking users - a positive development for privacy. However, the number of tracking libraries has - on average - roughly stayed the same in the studied apps. Many apps still collect device information that can be used to track users at a group level (cohort tracking) or identify individuals probabilistically (fingerprinting). We find real-world evidence of apps computing and agreeing on a fingerprinting-derived identifier through the use of server-side code, thereby violating Apple's policies. We find that Apple itself engages in some forms of tracking and exempts invasive data practices like first-party tracking and credit scoring from its new tracking rules. We also find that the new Privacy Nutrition Labels are sometimes inaccurate and misleading, especially in less popular apps. Overall, our observations suggest that, while Apple's changes make tracking individual users more difficult, they motivate a countermovement, and reinforce existing market power of gatekeeper companies with access to large troves of first-party data. Making the privacy properties of apps transparent through large-scale analysis remains a difficult target for independent researchers, and a key obstacle to meaningful, accountable and verifiable privacy protections. © 2022 ACM.",2022,ACM International Conference Proceeding Series,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132302679&doi=10.1145%2f3531146.3533116&partnerID=40&md5=cce14ae33a52f3c2f432709bfbab5059,"{'note': 'All Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': ""Tracking is a highly privacy-invasive data collection practice that has been ubiquitous in mobile apps for many years due to its role in supporting advertising-based revenue models. In response, Apple introduced two significant changes with iOS 14: App Tracking Transparency (ATT), a mandatory opt-in system for enabling tracking on iOS, and Privacy Nutrition Labels, which disclose what kinds of data each app processes. So far, the impact of these changes on individual privacy and control has not been well understood. This paper addresses this gap by analysing two versions of 1, 759 iOS apps from the UK App Store: one version from before iOS 14 and one that has been updated to comply with the new rules. We find that Apple's new policies, as promised, prevent the collection of the Identifier for Advertisers (IDFA), an identifier for cross-app tracking. Smaller data brokers that engage in invasive data practices will now face higher challenges in tracking users - a positive development for privacy. However, the number of tracking libraries has - on average - roughly stayed the same in the studied apps. Many apps still collect device information that can be used to track users at a group level (cohort tracking) or identify individuals probabilistically (fingerprinting). We find real-world evidence of apps computing and agreeing on a fingerprinting-derived identifier through the use of server-side code, thereby violating Apple's policies. We find that Apple itself engages in some forms of tracking and exempts invasive data practices like first-party tracking and credit scoring from its new tracking rules. We also find that the new Privacy Nutrition Labels are sometimes inaccurate and misleading, especially in less popular apps. Overall, our observations suggest that, while Apple's changes make tracking individual users more difficult, they motivate a countermovement, and reinforce existing market power of gatekeeper companies with access to large troves of first-party data. Making the privacy properties of apps transparent through large-scale analysis remains a difficult target for independent researchers, and a key obstacle to meaningful, accountable and verifiable privacy protections. © 2022 ACM."", 'affiliations': 'University of Oxford, Department of Computer Science, Oxford, United Kingdom; Independent Researcher, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132302679&doi=10.1145%2f3531146.3533116&partnerID=40&md5=cce14ae33a52f3c2f432709bfbab5059', 'doi': '10.1145/3531146.3533116', 'pages': '508 – 520', 'journal': 'ACM International Conference Proceeding Series', 'year': '2022', 'title': 'Goodbye Tracking? Impact of iOS App Tracking Transparency and Privacy Labels', 'author': 'Kollnig, Konrad and Shuba, Anastasia and Van Kleek, Max and Binns, Reuben and Shadbolt, Nigel', 'ENTRYTYPE': 'conference', 'ID': 'Kollnig2022508'}",Scopus
"Mehta, Adwait and Hameed, Fariha and Prasad, Pooja and Kane, Allison and Cox, Grant and Iyer, Raj",Where to find apps?,,"In addition to traditional treatment, mobile health (mHealth) applications have shown great promise in providing valuable clinical care. This chapter will discuss the most common ways to discover apps and verify their credibility and safety prior to use. © 2023 Elsevier Inc. All rights reserved.",2023,Smartphone Apps for Health and Wellness,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150570315&doi=10.1016%2fB978-0-323-99271-8.00014-0&partnerID=40&md5=3bdfe3bd841b4da1ac902a7f4b58d444,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Book chapter', 'language': 'English', 'publisher': 'Elsevier', 'abstract': 'In addition to traditional treatment, mobile health (mHealth) applications have shown great promise in providing valuable clinical care. This chapter will discuss the most common ways to discover apps and verify their credibility and safety prior to use. © 2023 Elsevier Inc. All rights reserved.', 'affiliations': 'McGovern Medical School, UT Health Houston, TX, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150570315&doi=10.1016%2fB978-0-323-99271-8.00014-0&partnerID=40&md5=3bdfe3bd841b4da1ac902a7f4b58d444', 'doi': '10.1016/B978-0-323-99271-8.00014-0', 'pages': '23 – 36', 'journal': 'Smartphone Apps for Health and Wellness', 'year': '2023', 'title': 'Where to find apps?', 'author': 'Mehta, Adwait and Hameed, Fariha and Prasad, Pooja and Kane, Allison and Cox, Grant and Iyer, Raj', 'ENTRYTYPE': 'book', 'ID': 'Mehta202323'}",Scopus
"Ramokapane, Kopo Marvin and Rashid, Awais",ExD: Explainable Deletion,,"This paper focuses on a critical yet often overlooked aspect of data in digital systems and services-deletion. Through a review of existing literature we highlight the challenges that user face when attempting to delete data from systems and services, the lack of transparency in how such requests are handled or processed and the lack of clear assurance that the data has been deleted. We highlight that this not only impacts users' agency over their data but also poses issues with regards to compliance with fundamental legal rights such as the right to be forgotten. We propose a new paradigm-explainable deletion-to improve users' agency and control over their data and enable systems to deliver effective assurance, transparency and compliance. We discuss the properties required of such explanations and their relevance and benefit for various individuals and groups involved or having an interest in data deletion processes and implications. We discuss various design implications pertaining to explainable deletion and present a research agenda for the community.  © 2023 Owner/Author.",2023,ACM International Conference Proceeding Series,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182738228&doi=10.1145%2f3633500.3633503&partnerID=40&md5=595f28dad668988f12254da019e09566,"{'note': 'All Open Access, Green Open Access, Hybrid Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': ""This paper focuses on a critical yet often overlooked aspect of data in digital systems and services-deletion. Through a review of existing literature we highlight the challenges that user face when attempting to delete data from systems and services, the lack of transparency in how such requests are handled or processed and the lack of clear assurance that the data has been deleted. We highlight that this not only impacts users' agency over their data but also poses issues with regards to compliance with fundamental legal rights such as the right to be forgotten. We propose a new paradigm-explainable deletion-to improve users' agency and control over their data and enable systems to deliver effective assurance, transparency and compliance. We discuss the properties required of such explanations and their relevance and benefit for various individuals and groups involved or having an interest in data deletion processes and implications. We discuss various design implications pertaining to explainable deletion and present a research agenda for the community.  © 2023 Owner/Author."", 'affiliations': 'University of Bristol, Bristol, United Kingdom', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182738228&doi=10.1145%2f3633500.3633503&partnerID=40&md5=595f28dad668988f12254da019e09566', 'doi': '10.1145/3633500.3633503', 'pages': '34 – 47', 'journal': 'ACM International Conference Proceeding Series', 'year': '2023', 'title': 'ExD: Explainable Deletion', 'author': 'Ramokapane, Kopo Marvin and Rashid, Awais', 'ENTRYTYPE': 'conference', 'ID': 'Ramokapane202334'}",Scopus
"Ekambaranathan, Anirudh and Zhao, Jun and Van Kleek, Max",How Can We Design Privacy-Friendly Apps for Children? Using a Research through Design Process to Understand Developers' Needs and Challenges,,"Mobile apps used by children often make use of harmful techniques, such as data tracking and targeted advertising. Previous research has suggested that developers face several systemic challenges in designing apps that prioritise children's best interests. To understand how developers can be better supported, we used a Research through Design (RtD) method to explore what the future of privacy-friendly app development could look like. We performed an elicitation study with 20 children's app developers to understand their needs and requirements. We found a number of specific technical requirements from the participants about how they would like to be supported, such as having actionable transnational design guidelines and easy-to-use development libraries. However, participants were reluctant to adopt these design ideas in their development practices due to perceived financial risks associated with increased privacy in apps. To overcome this critical gap, participants formulated socio-technical requirements that extend to other stakeholders in the mobile industry, including parents and marketplaces. Our findings provide important immediate and long-term design opportunities for the HCI community, and indicate that support for changing app developers' practices must be designed in the context of their relationship with other stakeholders.  © 2023 ACM.",2023,Proceedings of the ACM on Human-Computer Interaction,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174482705&doi=10.1145%2f3610066&partnerID=40&md5=a5faf1f3addfe9295783810584298e60,"{'note': 'All Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': ""Mobile apps used by children often make use of harmful techniques, such as data tracking and targeted advertising. Previous research has suggested that developers face several systemic challenges in designing apps that prioritise children's best interests. To understand how developers can be better supported, we used a Research through Design (RtD) method to explore what the future of privacy-friendly app development could look like. We performed an elicitation study with 20 children's app developers to understand their needs and requirements. We found a number of specific technical requirements from the participants about how they would like to be supported, such as having actionable transnational design guidelines and easy-to-use development libraries. However, participants were reluctant to adopt these design ideas in their development practices due to perceived financial risks associated with increased privacy in apps. To overcome this critical gap, participants formulated socio-technical requirements that extend to other stakeholders in the mobile industry, including parents and marketplaces. Our findings provide important immediate and long-term design opportunities for the HCI community, and indicate that support for changing app developers' practices must be designed in the context of their relationship with other stakeholders.  © 2023 ACM."", 'affiliations': 'University of Oxford, Oxfordshire, Oxford, United Kingdom', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174482705&doi=10.1145%2f3610066&partnerID=40&md5=a5faf1f3addfe9295783810584298e60', 'doi': '10.1145/3610066', 'number': 'CSCW2', 'volume': '7', 'journal': 'Proceedings of the ACM on Human-Computer Interaction', 'year': '2023', 'title': ""How Can We Design Privacy-Friendly Apps for Children? Using a Research through Design Process to Understand Developers' Needs and Challenges"", 'author': 'Ekambaranathan, Anirudh and Zhao, Jun and Van Kleek, Max', 'ENTRYTYPE': 'article', 'ID': 'Ekambaranathan2023'}",Scopus
"Corbett, Eric and Denton, Emily",Interrogating the T in FAccT,,"Fairness, accountability, and transparency are the three conceptual foundations of the FAccT conference. Transparency, however, has yet to be scrutinized to the same degree as accountability and fairness. As a result, we don't know: What does this community mean when it talks about transparency? How are we doing transparency? And to what ends? What commitments does (or should) the T in FAccT signify? This paper interrogates the T in FAccT using perspectives from critical transparency literature. Subsequently, we argue that FAccT might be better off dropping the T from its title for two reasons: (1) transparency can often be counterproductive to FAccT's primary objectives and (2) it is misleading as FAccT is mainly preoccupied with explainability rather than actual transparency. If we want to keep the T, we need to reframe how we think about and do transparency by making transparency contingent, reclaiming it from explainability, and bringing people into transparency processes. © 2023 Owner/Author.",2023,ACM International Conference Proceeding Series,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163675092&doi=10.1145%2f3593013.3594104&partnerID=40&md5=b6174fbe6b3d8d9ad22bf08e769f16c8,"{'note': 'All Open Access, Bronze Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': ""Fairness, accountability, and transparency are the three conceptual foundations of the FAccT conference. Transparency, however, has yet to be scrutinized to the same degree as accountability and fairness. As a result, we don't know: What does this community mean when it talks about transparency? How are we doing transparency? And to what ends? What commitments does (or should) the T in FAccT signify? This paper interrogates the T in FAccT using perspectives from critical transparency literature. Subsequently, we argue that FAccT might be better off dropping the T from its title for two reasons: (1) transparency can often be counterproductive to FAccT's primary objectives and (2) it is misleading as FAccT is mainly preoccupied with explainability rather than actual transparency. If we want to keep the T, we need to reframe how we think about and do transparency by making transparency contingent, reclaiming it from explainability, and bringing people into transparency processes. © 2023 Owner/Author."", 'affiliations': 'Google Research, New York, NY, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163675092&doi=10.1145%2f3593013.3594104&partnerID=40&md5=b6174fbe6b3d8d9ad22bf08e769f16c8', 'doi': '10.1145/3593013.3594104', 'pages': '1624 – 1634', 'journal': 'ACM International Conference Proceeding Series', 'year': '2023', 'title': 'Interrogating the T in FAccT', 'author': 'Corbett, Eric and Denton, Emily', 'ENTRYTYPE': 'conference', 'ID': 'Corbett20231624'}",Scopus
"Michler, Oliver and Stummer, Christian and Decker, Reinhold","Can the GDPR Allay Privacy Concerns Towards Smart Products? The Effect of a Compliance Seal on Perceived Data Security, Trust, and Intention to Use",,"Smart consumer products are designed to provide their users with various benefits. To utilise smart products and enjoy their benefits, users usually have to provide some kind of information to the product and its manufacturer—often personal data. This can raise privacy and data security concerns and may hamper the use of smart products. The European Union’s (EU) General Data Protection Regulation (GDPR) addresses these concerns and provides requirements for an appropriate handling of data. Our study assumes that a positive perception of the GDPR can encourage smart product usage. Therefore, we explore the effect of a GDPR compliance seal that signals data security and trustworthiness. By means of an online experiment with 142 participants from Germany, we investigate the seal’s effect on perceived data security, perceived trust, and the intention to use a smart robot vacuum cleaner. The results indicate that a GDPR compliance seal indeed has a positive effect on perceived data security and, through perceived data security as a mediator, also on perceived trust. While the direct impact of a GDPR compliance seal on the intention to use a smart product lacks statistical significance, our model reveals an indirect effect via perceived data security and perceived trust as well as a positive total effect of the seal on intention to use. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",2022,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135830297&doi=10.1007%2f978-3-031-12673-4_6&partnerID=40&md5=0d02f0243636aa8474087f22b13ea0b7,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Springer Science and Business Media Deutschland GmbH', 'abstract': 'Smart consumer products are designed to provide their users with various benefits. To utilise smart products and enjoy their benefits, users usually have to provide some kind of information to the product and its manufacturer—often personal data. This can raise privacy and data security concerns and may hamper the use of smart products. The European Union’s (EU) General Data Protection Regulation (GDPR) addresses these concerns and provides requirements for an appropriate handling of data. Our study assumes that a positive perception of the GDPR can encourage smart product usage. Therefore, we explore the effect of a GDPR compliance seal that signals data security and trustworthiness. By means of an online experiment with 142 participants from Germany, we investigate the seal’s effect on perceived data security, perceived trust, and the intention to use a smart robot vacuum cleaner. The results indicate that a GDPR compliance seal indeed has a positive effect on perceived data security and, through perceived data security as a mediator, also on perceived trust. While the direct impact of a GDPR compliance seal on the intention to use a smart product lacks statistical significance, our model reveals an indirect effect via perceived data security and perceived trust as well as a positive total effect of the seal on intention to use. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.', 'affiliations': 'Bielefeld University, Universitätsstr. 25, Bielefeld, 33615, Germany', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135830297&doi=10.1007%2f978-3-031-12673-4_6&partnerID=40&md5=0d02f0243636aa8474087f22b13ea0b7', 'doi': '10.1007/978-3-031-12673-4_6', 'pages': '77 – 91', 'volume': '13429 LNCS', 'journal': 'Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)', 'year': '2022', 'title': 'Can the GDPR Allay Privacy Concerns Towards Smart Products? The Effect of a Compliance Seal on Perceived Data Security, Trust, and Intention to Use', 'author': 'Michler, Oliver and Stummer, Christian and Decker, Reinhold', 'ENTRYTYPE': 'article', 'ID': 'Michler202277'}",Scopus
"Wilkinson, Dino and Christie, Alec and Tarr, Anthony A. and Tarr, Julie-Anne","Big Data, Artificial Intelligence and Insurance",,"Central to the enormous changes, challenges and opportunities that the insurance industry is experiencing (and will be navigating over the next decade) is the use of artificial intelligence (AI) technologies, particularly in combination with so-called “big data.” Big data refers to the enormous datasets which insurers have been collecting for many years and can now augment with other datasets and analyse for insights relevant to particular categories of risk, the risk profile of individual insureds, potential fraud and for targeted personalised marketing. Access to big data, AI analytics and the resultant predictive insights will transform insurance practices with consequential and significant impacts on existing principles of insurance law. AI (including machine learning) is an indispensable fellow traveller with big data that allows insurers, for the first time, to get answers to all the questions they wish to ask of their original and augmented data. AI analytics has the power to rapidly and efficiently analyse enormous amounts of data, identifying and using correlations or patterns that would elude most non-AI analytics, even the most expert human analyst. The availability of big data in conjunction with technological advances in AI analytics and the resulting predictive insights simultaneously opens the door to new and exciting opportunities. However, at the same time, this changing insurance landscape is exacerbating several existing risks and creating new challenges in a way that is likely to ultimately result in significantly more regulatory focus and legislative tightening. For example, questions arise as to the appropriateness of the data being utilised and analysed (both as regards the insurer’s base data and that data it is augmenting it with), the underlying assumptions (or bias) in the predictive models being deployed in delineating the scope of cover provided or in determining whether cover is provided at all, and which regulatory frameworks apply. Significant data protection/privacy and cybersecurity concerns in respect of the personal data used (and created by the AI analytics) also arise in relation to big data, AI analytics and other uses of AI, in addition to matters such as bias, fairness and discrimination, intrusiveness and the contextual integrity of the results. These are all areas that will be “front of mind” for insurers during the next decade and are considered in this chapter. © 2024 selection and editorial matter, Anthony A Tarr, Julie-Anne Tarr, Maurice Thompson and Dino Wilkinson; individual chapters, the contributors.",2023,"The Global Insurance Market and Change: Emerging Technologies, Risks and Legal Challenges",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169373995&doi=10.4324%2f9781003319054-2&partnerID=40&md5=12eb2789b8fbac710db51a356c730a2d,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Book chapter', 'language': 'English', 'publisher': 'Taylor and Francis', 'abstract': 'Central to the enormous changes, challenges and opportunities that the insurance industry is experiencing (and will be navigating over the next decade) is the use of artificial intelligence (AI) technologies, particularly in combination with so-called “big data.” Big data refers to the enormous datasets which insurers have been collecting for many years and can now augment with other datasets and analyse for insights relevant to particular categories of risk, the risk profile of individual insureds, potential fraud and for targeted personalised marketing. Access to big data, AI analytics and the resultant predictive insights will transform insurance practices with consequential and significant impacts on existing principles of insurance law. AI (including machine learning) is an indispensable fellow traveller with big data that allows insurers, for the first time, to get answers to all the questions they wish to ask of their original and augmented data. AI analytics has the power to rapidly and efficiently analyse enormous amounts of data, identifying and using correlations or patterns that would elude most non-AI analytics, even the most expert human analyst. The availability of big data in conjunction with technological advances in AI analytics and the resulting predictive insights simultaneously opens the door to new and exciting opportunities. However, at the same time, this changing insurance landscape is exacerbating several existing risks and creating new challenges in a way that is likely to ultimately result in significantly more regulatory focus and legislative tightening. For example, questions arise as to the appropriateness of the data being utilised and analysed (both as regards the insurer’s base data and that data it is augmenting it with), the underlying assumptions (or bias) in the predictive models being deployed in delineating the scope of cover provided or in determining whether cover is provided at all, and which regulatory frameworks apply. Significant data protection/privacy and cybersecurity concerns in respect of the personal data used (and created by the AI analytics) also arise in relation to big data, AI analytics and other uses of AI, in addition to matters such as bias, fairness and discrimination, intrusiveness and the contextual integrity of the results. These are all areas that will be “front of mind” for insurers during the next decade and are considered in this chapter. © 2024 selection and editorial matter, Anthony A Tarr, Julie-Anne Tarr, Maurice Thompson and Dino Wilkinson; individual chapters, the contributors.', 'affiliations': 'Clyde & Co, Abu Dhabi, United Arab Emirates; Clyde & Co, Sydney, Australia; Clyde & Co, Brisbane, Australia; Robyn Ashton Consulting Pty Ltd, Australia; Commercial Law, Faculty of Business and Law, Queensland University of Technology, Australia', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169373995&doi=10.4324%2f9781003319054-2&partnerID=40&md5=12eb2789b8fbac710db51a356c730a2d', 'doi': '10.4324/9781003319054-2', 'pages': '22 – 46', 'journal': 'The Global Insurance Market and Change: Emerging Technologies, Risks and Legal Challenges', 'year': '2023', 'title': 'Big Data, Artificial Intelligence and Insurance', 'author': 'Wilkinson, Dino and Christie, Alec and Tarr, Anthony A. and Tarr, Julie-Anne', 'ENTRYTYPE': 'book', 'ID': 'Wilkinson202322'}",Scopus
"Sui, Anna and Sui, Wuyou and Liu, Sam and Rhodes, Ryan",Ethical considerations for the use of consumer wearables in health research,,"Background: The UN's High Commissioner's request for a moratorium on the use and adoption of specific Artificial Intelligence (AI) systems that pose serious risk to human rights, this commentary explores the current environment and future implications of using third-party wearable technologies in research for participants’ data privacy and data security. While wearables have been identified as tools for improving users’ physical and mental health and wellbeing by providing users with more personalized data and tailored interventions, the use of this technology does not come without concern. Objective: Primarily, as researchers, we are concerned with enmeshment of corporate and research interests and what this can mean for participant data. Methods: By drawing on specific sections of the UN Report ‘The right to privacy in the digital age’, we discuss the conflicts between corporate and research agendas and point out the current and future implications of the involvement of third-party companies for participant data privacy, data security and data usage. Finally, we offer suggestions for researchers and third-party wearable developers for conducting ethical and transparent research with wearable tech. Conclusion: We propose that this commentary be used as a foothold for further discussions about the ethical implications of using third-party wearable tech in research. © The Author(s) 2023.",2023,Digital Health,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147383498&doi=10.1177%2f20552076231153740&partnerID=40&md5=40f70928fa5cd43b962da8d40534552f,"{'note': 'All Open Access, Gold Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'SAGE Publications Inc.', 'abstract': ""Background: The UN's High Commissioner's request for a moratorium on the use and adoption of specific Artificial Intelligence (AI) systems that pose serious risk to human rights, this commentary explores the current environment and future implications of using third-party wearable technologies in research for participants’ data privacy and data security. While wearables have been identified as tools for improving users’ physical and mental health and wellbeing by providing users with more personalized data and tailored interventions, the use of this technology does not come without concern. Objective: Primarily, as researchers, we are concerned with enmeshment of corporate and research interests and what this can mean for participant data. Methods: By drawing on specific sections of the UN Report ‘The right to privacy in the digital age’, we discuss the conflicts between corporate and research agendas and point out the current and future implications of the involvement of third-party companies for participant data privacy, data security and data usage. Finally, we offer suggestions for researchers and third-party wearable developers for conducting ethical and transparent research with wearable tech. Conclusion: We propose that this commentary be used as a foothold for further discussions about the ethical implications of using third-party wearable tech in research. © The Author(s) 2023."", 'affiliations': 'School of Health Studies, Western University, Canada; School of Exercise Science, Physical and Health Education, University of Victoria, VIC, Canada', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147383498&doi=10.1177%2f20552076231153740&partnerID=40&md5=40f70928fa5cd43b962da8d40534552f', 'doi': '10.1177/20552076231153740', 'volume': '9', 'journal': 'Digital Health', 'year': '2023', 'title': 'Ethical considerations for the use of consumer wearables in health research', 'author': 'Sui, Anna and Sui, Wuyou and Liu, Sam and Rhodes, Ryan', 'ENTRYTYPE': 'article', 'ID': 'Sui2023'}",Scopus
"Deldari, Elmira and Freed, Diana and Poveda, Julio and Yao, Yaxing","An Investigation of Teenager Experiences in Social Virtual Reality from Teenagers’, Parents’, and Bystanders’ Perspectives",,"The recent rise of social virtual reality (VR) platforms has introduced new technology characteristics and user experiences, which may lead to new forms of online harassment, particularly among teenagers (aged 13-17). In this paper, we took a multi-stakeholder approach and investigate teenagers’ experiences and safety threats in social VR from three perspectives (teenagers, parents, and bystanders) to cover complementary perspectives. Through an interview study with 24 participants (8 teenagers, 7 parents, and 9 bystanders), we found several safety threats that teenagers may face, such as virtual grooming, ability-based discrimination, unforeseeable threats in privacy rooms, etc. We highlight new forms of harassment in the social VR context, such as erotic role-play and abuse through phantom sense, as well as the discrepancies among teenagers, parents, and bystanders regarding their perceptions of such threats. We draw design implications to better support safer social VR environments for teenagers. © 2023 by The USENIX Association.All rights reserved.",2023,"Proceedings of the 19th Symposium on Usable Privacy and Security, SOUPS 2023",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180126406&partnerID=40&md5=8038266c24270bde75ab6fdc8aed3b5c,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'USENIX Association', 'abstract': 'The recent rise of social virtual reality (VR) platforms has introduced new technology characteristics and user experiences, which may lead to new forms of online harassment, particularly among teenagers (aged 13-17). In this paper, we took a multi-stakeholder approach and investigate teenagers’ experiences and safety threats in social VR from three perspectives (teenagers, parents, and bystanders) to cover complementary perspectives. Through an interview study with 24 participants (8 teenagers, 7 parents, and 9 bystanders), we found several safety threats that teenagers may face, such as virtual grooming, ability-based discrimination, unforeseeable threats in privacy rooms, etc. We highlight new forms of harassment in the social VR context, such as erotic role-play and abuse through phantom sense, as well as the discrepancies among teenagers, parents, and bystanders regarding their perceptions of such threats. We draw design implications to better support safer social VR environments for teenagers. © 2023 by The USENIX Association.All rights reserved.', 'affiliations': 'University of Maryland, Baltimore, United States; Cornell University, United States; University of Maryland, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180126406&partnerID=40&md5=8038266c24270bde75ab6fdc8aed3b5c', 'pages': '1 – 17', 'journal': 'Proceedings of the 19th Symposium on Usable Privacy and Security, SOUPS 2023', 'year': '2023', 'title': 'An Investigation of Teenager Experiences in Social Virtual Reality from Teenagers’, Parents’, and Bystanders’ Perspectives', 'author': 'Deldari, Elmira and Freed, Diana and Poveda, Julio and Yao, Yaxing', 'ENTRYTYPE': 'conference', 'ID': 'Deldari20231'}",Scopus
"Xia, Huichuan",“You Don't Know Where It Will Stop” - An Inquiry into Smartphone Users' Privacy Mental Models of Contextual Integrity,,"The Contextual Integrity (CI) theory provides a benchmark for privacy protection or violation according to the appropriateness of information collection and flows in a certain context. As privacy threats and protections develop and vie in various mobile contexts, how smartphone users represent the benchmark CI in their minds deserves exploration. In this study, we inquired into 18 smartphone users' privacy mental models of CI. We found that they verbalized and visualized three patterns of information flow (i.e., unidirectional lines, branching tree, and complex network) and two categories of information collection (i.e., monetization-oriented and monitoring-based). With these mental models, our participants expressed numerous privacy concerns, such as unstoppable information sharing, data monetization, and surveillance. We discussed these findings and concluded that even though mobile operating systems and apps have claimed to be privacy-friendly and protective, some users remain dubious about such claims even though their privacy mental models may not accurately reflect reality. © 2023 IEEE Computer Society. All rights reserved.",2023,Proceedings of the Annual Hawaii International Conference on System Sciences,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152144336&partnerID=40&md5=1740c83b9109705a7c5b3f0d68f9a86f,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'IEEE Computer Society', 'abstract': ""The Contextual Integrity (CI) theory provides a benchmark for privacy protection or violation according to the appropriateness of information collection and flows in a certain context. As privacy threats and protections develop and vie in various mobile contexts, how smartphone users represent the benchmark CI in their minds deserves exploration. In this study, we inquired into 18 smartphone users' privacy mental models of CI. We found that they verbalized and visualized three patterns of information flow (i.e., unidirectional lines, branching tree, and complex network) and two categories of information collection (i.e., monetization-oriented and monitoring-based). With these mental models, our participants expressed numerous privacy concerns, such as unstoppable information sharing, data monetization, and surveillance. We discussed these findings and concluded that even though mobile operating systems and apps have claimed to be privacy-friendly and protective, some users remain dubious about such claims even though their privacy mental models may not accurately reflect reality. © 2023 IEEE Computer Society. All rights reserved."", 'affiliations': 'Department of Information Management, Peking University, China', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152144336&partnerID=40&md5=1740c83b9109705a7c5b3f0d68f9a86f', 'pages': '2358 – 2367', 'volume': '2023-January', 'journal': 'Proceedings of the Annual Hawaii International Conference on System Sciences', 'year': '2023', 'title': ""“You Don't Know Where It Will Stop” - An Inquiry into Smartphone Users' Privacy Mental Models of Contextual Integrity"", 'author': 'Xia, Huichuan', 'ENTRYTYPE': 'conference', 'ID': 'Xia20232358'}",Scopus
"Kaplan, Berkay and Lopez-Toledo, Israel J and Gunter, Carl and Qian, Jingyu",A Tagging Solution to Discover IoT Devices in Apartments,,"The number of Internet of Things (IoT) devices in smart homes is increasing. This broad adoption facilitates users' lives, but it also brings problems. One such issue is that some IoT devices may invade users' privacy through obscure data collection practices or hidden devices. Specific IoT devices can exist out of sight and still collect user data to send to third parties via the Internet. Owners can easily forget the location or even the existence of these devices, especially if the owner is a landlord managing several properties. The landlord-owner scenario creates multi-user problems as designers typically build IoT devices for single users. We developed tag models that use wireless protocols, buzzers, and LED lighting to guide users toward the hidden device in shared spaces and accommodate multi-user scenarios. They are attached to IoT devices inside a residential unit during their installation to be later discovered by a tenant. These tags are similar to Tile models or Airtag but have different features based on our privacy use case. For instance, our tags do not require pairing; multiple users can interact with them through our Android application. Our tags can also embed the IoT device's information while protecting against unwanted access to that information through a proximity requirement. Researchers have developed several other tools, such as thermal cameras or virtual reality (VR), for discovering devices, but we focused on wireless technologies. We measured specific performance metrics of our tags to analyze their feasibility for this problem. We also conducted a user study to measure the participants' comfort levels while finding objects with our tags attached. Our results indicate that wireless tags can be viable for device tracking in residential properties. © 2023 ACM.",2023,ACM International Conference Proceeding Series,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180155980&doi=10.1145%2f3627106.3627108&partnerID=40&md5=8367193e0f848c44804bec81f8076729,"{'note': 'All Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': ""The number of Internet of Things (IoT) devices in smart homes is increasing. This broad adoption facilitates users' lives, but it also brings problems. One such issue is that some IoT devices may invade users' privacy through obscure data collection practices or hidden devices. Specific IoT devices can exist out of sight and still collect user data to send to third parties via the Internet. Owners can easily forget the location or even the existence of these devices, especially if the owner is a landlord managing several properties. The landlord-owner scenario creates multi-user problems as designers typically build IoT devices for single users. We developed tag models that use wireless protocols, buzzers, and LED lighting to guide users toward the hidden device in shared spaces and accommodate multi-user scenarios. They are attached to IoT devices inside a residential unit during their installation to be later discovered by a tenant. These tags are similar to Tile models or Airtag but have different features based on our privacy use case. For instance, our tags do not require pairing; multiple users can interact with them through our Android application. Our tags can also embed the IoT device's information while protecting against unwanted access to that information through a proximity requirement. Researchers have developed several other tools, such as thermal cameras or virtual reality (VR), for discovering devices, but we focused on wireless technologies. We measured specific performance metrics of our tags to analyze their feasibility for this problem. We also conducted a user study to measure the participants' comfort levels while finding objects with our tags attached. Our results indicate that wireless tags can be viable for device tracking in residential properties. © 2023 ACM."", 'affiliations': 'University of Illinois Urbana-Champaign, Champaign, IL, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180155980&doi=10.1145%2f3627106.3627108&partnerID=40&md5=8367193e0f848c44804bec81f8076729', 'doi': '10.1145/3627106.3627108', 'pages': '205 – 215', 'journal': 'ACM International Conference Proceeding Series', 'year': '2023', 'title': 'A Tagging Solution to Discover IoT Devices in Apartments', 'author': 'Kaplan, Berkay and Lopez-Toledo, Israel J and Gunter, Carl and Qian, Jingyu', 'ENTRYTYPE': 'conference', 'ID': 'Kaplan2023205'}",Scopus
"Wong, Wendy H. and Duncan, Jamie and Lake, David A.",Why data about people are so hard to govern,,"How data on individuals are gathered, analyzed, and stored remains largely ungoverned at both domestic and global levels. We address the unique governance problem posed by digital data to provide a framework for understanding why data governance remains elusive. Data are easily transferable and replicable, making them a useful tool. But this characteristic creates massive governance problems for all of us who want to have some agency and choice over how (or if) our data are collected and used. Moreover, data are co-created: individuals are the object from which data are culled by an interested party. Yet, any data point has a marginal value of close to zero and thus individuals have little bargaining power when it comes to negotiating with data collectors. Relatedly, data follow the rule of winner take all—the parties that have the most can leverage that data for greater accuracy and utility, leading to natural oligopolies. Finally, data's value lies in combination with proprietary algorithms that analyze and predict the patterns. Given these characteristics, private governance solutions are ineffective. Public solutions will also likely be insufficient. The imbalance in market power between platforms that collect data and individuals will be reproduced in the political sphere. We conclude that some form of collective data governance is required. We examine the challenges to the data governance by looking a public effort, the EU's General Data Protection Regulation, a private effort, Apple's “privacy nutrition labels” in their App Store, and a collective effort, the First Nations Information Governance Centre in Canada. © 2024 The Authors. Regulation & Governance published by John Wiley & Sons Australia, Ltd.",2024,Regulation and Governance,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189629774&doi=10.1111%2frego.12591&partnerID=40&md5=ad1ebd2f7ef0326eabd5697b83a388b4,"{'note': 'All Open Access, Hybrid Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Article in press', 'type': 'Article', 'language': 'English', 'publisher': 'John Wiley and Sons Inc', 'abstract': ""How data on individuals are gathered, analyzed, and stored remains largely ungoverned at both domestic and global levels. We address the unique governance problem posed by digital data to provide a framework for understanding why data governance remains elusive. Data are easily transferable and replicable, making them a useful tool. But this characteristic creates massive governance problems for all of us who want to have some agency and choice over how (or if) our data are collected and used. Moreover, data are co-created: individuals are the object from which data are culled by an interested party. Yet, any data point has a marginal value of close to zero and thus individuals have little bargaining power when it comes to negotiating with data collectors. Relatedly, data follow the rule of winner take all—the parties that have the most can leverage that data for greater accuracy and utility, leading to natural oligopolies. Finally, data's value lies in combination with proprietary algorithms that analyze and predict the patterns. Given these characteristics, private governance solutions are ineffective. Public solutions will also likely be insufficient. The imbalance in market power between platforms that collect data and individuals will be reproduced in the political sphere. We conclude that some form of collective data governance is required. We examine the challenges to the data governance by looking a public effort, the EU's General Data Protection Regulation, a private effort, Apple's “privacy nutrition labels” in their App Store, and a collective effort, the First Nations Information Governance Centre in Canada. © 2024 The Authors. Regulation & Governance published by John Wiley & Sons Australia, Ltd."", 'affiliations': 'University of British Columbia, Okanagan, Kelowna, BC, Canada; University of Toronto, Toronto, ON, Canada; University of California, San Diego, San Diego, CA, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189629774&doi=10.1111%2frego.12591&partnerID=40&md5=ad1ebd2f7ef0326eabd5697b83a388b4', 'doi': '10.1111/rego.12591', 'journal': 'Regulation and Governance', 'year': '2024', 'title': 'Why data about people are so hard to govern', 'author': 'Wong, Wendy H. and Duncan, Jamie and Lake, David A.', 'ENTRYTYPE': 'article', 'ID': 'Wong2024'}",Scopus
"Caven, Peter J. and Gopavaram, Shakthidhar Reddy and Camp, L. Jean",Integrating Human Intelligence to Bypass Information Asymmetry in Procurement Decision-Making,,"President Biden's Executive Order on Improving the Nation's Cybersecurity included two core components to enhance the security and integrity of the software supply chain: Labels and Software Bills of Materials. The National Institute of Standards and Technology (NIST) was tasked with establishing a security labeling program. Its initial design was based on Energy Star, a voluntary labeling program established by the Environmental Protection Agency (EPA) to allow businesses to communicate energy consumption information to consumers. Similarly, the National Telecommunications and Information Administration (NTIA) defined the minimum elements for the Software Bill of Materials (SBOM). These SBOMs are analogous to nutrition facts labels, as they detail all the software components used in a product. What combination of information, on labels or bills of materials, should be provided at each stage of the acquisition lifecycle? To answer this question we built on previous research on labels, procurement standards, best practices for IoT and software, and information proposed for labeling and SBOM programs. From that, we identified candidate features (and the purposes of those features) that were potentially salient during the acquisition process. We recruited participants from the Department of Defense community to sort those features according to their importance. We conclude that neither a single label nor a list of information can adequately support risk-informed decision-making across the acquisition process. We report how participants' information requirements correlated with their work roles. We offer recommendations for the next steps to design an effective label system to support cybersecurity-aware procurement.  © 2022 IEEE.",2022,Proceedings - IEEE Military Communications Conference MILCOM,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147324657&doi=10.1109%2fMILCOM55135.2022.10017736&partnerID=40&md5=36f5ab5781dd864a18fcc6667b215022,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Institute of Electrical and Electronics Engineers Inc.', 'abstract': ""President Biden's Executive Order on Improving the Nation's Cybersecurity included two core components to enhance the security and integrity of the software supply chain: Labels and Software Bills of Materials. The National Institute of Standards and Technology (NIST) was tasked with establishing a security labeling program. Its initial design was based on Energy Star, a voluntary labeling program established by the Environmental Protection Agency (EPA) to allow businesses to communicate energy consumption information to consumers. Similarly, the National Telecommunications and Information Administration (NTIA) defined the minimum elements for the Software Bill of Materials (SBOM). These SBOMs are analogous to nutrition facts labels, as they detail all the software components used in a product. What combination of information, on labels or bills of materials, should be provided at each stage of the acquisition lifecycle? To answer this question we built on previous research on labels, procurement standards, best practices for IoT and software, and information proposed for labeling and SBOM programs. From that, we identified candidate features (and the purposes of those features) that were potentially salient during the acquisition process. We recruited participants from the Department of Defense community to sort those features according to their importance. We conclude that neither a single label nor a list of information can adequately support risk-informed decision-making across the acquisition process. We report how participants' information requirements correlated with their work roles. We offer recommendations for the next steps to design an effective label system to support cybersecurity-aware procurement.  © 2022 IEEE."", 'affiliations': 'Luddy School of Informatics, Computing, and Engineering, Indiana University, Bloomington, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147324657&doi=10.1109%2fMILCOM55135.2022.10017736&partnerID=40&md5=36f5ab5781dd864a18fcc6667b215022', 'doi': '10.1109/MILCOM55135.2022.10017736', 'pages': '687 – 692', 'volume': '2022-November', 'journal': 'Proceedings - IEEE Military Communications Conference MILCOM', 'year': '2022', 'title': 'Integrating Human Intelligence to Bypass Information Asymmetry in Procurement Decision-Making', 'author': 'Caven, Peter J. and Gopavaram, Shakthidhar Reddy and Camp, L. Jean', 'ENTRYTYPE': 'conference', 'ID': 'Caven2022687'}",Scopus
"Zhu, Wenhan and Proksch, Sebastian and German, Daniel M. and Godfrey, Michael W. and Li, Li and McIntosh, Shane",What is an app store? The software engineering perspective,,"“App stores” are online software stores where end users may browse, purchase, download, and install software applications. By far, the best known app stores are associated with mobile platforms, such as Google Play for Android and Apple’s App Store for iOS. The ubiquity of smartphones has led to mobile app stores becoming a touchstone experience of modern living. App stores have been the subject of many empirical studies. However, most of this research has concentrated on properties of the apps rather than the stores themselves. Today, there is a rich diversity of app stores and these stores have largely been overlooked by researchers: app stores exist on many distinctive platforms, are aimed at different classes of users, and have different end-goals beyond simply selling a standalone app to a smartphone user. The goal of this paper is to survey and characterize the broader dimensionality of app stores, and to explore how and why they influence software development practices, such as system design and release management. We begin by collecting a set of app store examples from web search queries. By analyzing and curating the results, we derive a set of features common to app stores. We then build a dimensional model of app stores based on these features, and we fit each app store from our web search result set into this model. Next, we performed unsupervised clustering to the app stores to find their natural groupings. Our results suggest that app stores have become an essential stakeholder in modern software development. They control the distribution channel to end users and ensure that the applications are of suitable quality; in turn, this leads to developers adhering to various store guidelines when creating their applications. However, we found the app stores operational model could vary widely between stores, and this variability could in turn affect the generalizability of existing understanding of app stores. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",2024,Empirical Software Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181165816&doi=10.1007%2fs10664-023-10362-3&partnerID=40&md5=28b0c6f1b5f6af105efa958defdb0547,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Springer', 'abstract': '“App stores” are online software stores where end users may browse, purchase, download, and install software applications. By far, the best known app stores are associated with mobile platforms, such as Google Play for Android and Apple’s App Store for iOS. The ubiquity of smartphones has led to mobile app stores becoming a touchstone experience of modern living. App stores have been the subject of many empirical studies. However, most of this research has concentrated on properties of the apps rather than the stores themselves. Today, there is a rich diversity of app stores and these stores have largely been overlooked by researchers: app stores exist on many distinctive platforms, are aimed at different classes of users, and have different end-goals beyond simply selling a standalone app to a smartphone user. The goal of this paper is to survey and characterize the broader dimensionality of app stores, and to explore how and why they influence software development practices, such as system design and release management. We begin by collecting a set of app store examples from web search queries. By analyzing and curating the results, we derive a set of features common to app stores. We then build a dimensional model of app stores based on these features, and we fit each app store from our web search result set into this model. Next, we performed unsupervised clustering to the app stores to find their natural groupings. Our results suggest that app stores have become an essential stakeholder in modern software development. They control the distribution channel to end users and ensure that the applications are of suitable quality; in turn, this leads to developers adhering to various store guidelines when creating their applications. However, we found the app stores operational model could vary widely between stores, and this variability could in turn affect the generalizability of existing understanding of app stores. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.', 'affiliations': 'David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, Canada; Delft University of Technology, Delft, Netherlands; Department of Computer Science, University of Victoria, Victoria, Canada; School of Software, Beihang University, Beijing, China', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181165816&doi=10.1007%2fs10664-023-10362-3&partnerID=40&md5=28b0c6f1b5f6af105efa958defdb0547', 'doi': '10.1007/s10664-023-10362-3', 'number': '1', 'volume': '29', 'journal': 'Empirical Software Engineering', 'year': '2024', 'title': 'What is an app store? The software engineering perspective', 'author': 'Zhu, Wenhan and Proksch, Sebastian and German, Daniel M. and Godfrey, Michael W. and Li, Li and McIntosh, Shane', 'ENTRYTYPE': 'article', 'ID': 'Zhu2024'}",Scopus
"Monteiro, Artur Pericles Lima",Privacy at a crossroads,,,2023,Research Handbook on Law and Technology,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192690072&partnerID=40&md5=9315eee12bce277297d8b430733095e4,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Book chapter', 'language': 'English', 'publisher': 'Edward Elgar Publishing Ltd.', 'affiliations': 'Yale Jackson School of Global Affairs, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192690072&partnerID=40&md5=9315eee12bce277297d8b430733095e4', 'pages': '214 – 221', 'journal': 'Research Handbook on Law and Technology', 'year': '2023', 'title': 'Privacy at a crossroads', 'author': 'Monteiro, Artur Pericles Lima', 'ENTRYTYPE': 'book', 'ID': 'Monteiro2023214'}",Scopus
"Guo, Wentao and Walter, Jason and Mazurek, Michelle L.",The Role of Professional Product Reviewers in Evaluating Security and Privacy,,"Consumers who use Internet-connected products are often exposed to security and privacy vulnerabilities that they lack time or expertise to evaluate themselves. Can professional product reviewers help by evaluating security and privacy on their behalf? We conducted 17 interviews with product reviewers about their procedures, incentives, and assumptions regarding security and privacy. We find that reviewers have some incentives to evaluate security and privacy, but they also face substantial disincentives and challenges, leading them to consider a limited set of relevant criteria and threat models. We recommend future work to help product reviewers provide useful advice to consumers in ways that align with reviewers' business models and incentives. These include developing usable resources and tools, as well as validating the heuristics they use to judge security and privacy expediently. © USENIX Security 2023. All rights reserved.",2023,"32nd USENIX Security Symposium, USENIX Security 2023",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176086007&partnerID=40&md5=a463fa287f56ee05138dce5f86e8dfd7,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'USENIX Association', 'abstract': ""Consumers who use Internet-connected products are often exposed to security and privacy vulnerabilities that they lack time or expertise to evaluate themselves. Can professional product reviewers help by evaluating security and privacy on their behalf? We conducted 17 interviews with product reviewers about their procedures, incentives, and assumptions regarding security and privacy. We find that reviewers have some incentives to evaluate security and privacy, but they also face substantial disincentives and challenges, leading them to consider a limited set of relevant criteria and threat models. We recommend future work to help product reviewers provide useful advice to consumers in ways that align with reviewers' business models and incentives. These include developing usable resources and tools, as well as validating the heuristics they use to judge security and privacy expediently. © USENIX Security 2023. All rights reserved."", 'affiliations': 'University of Maryland, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176086007&partnerID=40&md5=a463fa287f56ee05138dce5f86e8dfd7', 'pages': '2563 – 2580', 'volume': '4', 'journal': '32nd USENIX Security Symposium, USENIX Security 2023', 'year': '2023', 'title': 'The Role of Professional Product Reviewers in Evaluating Security and Privacy', 'author': 'Guo, Wentao and Walter, Jason and Mazurek, Michelle L.', 'ENTRYTYPE': 'conference', 'ID': 'Guo20232563'}",Scopus
"Johansen, Johanna and Pedersen, Tore and Fischer-Hübner, Simone and Johansen, Christian and Schneider, Gerardo and Roosendaal, Arnold and Zwingelberg, Harald and Sivesind, Anders Jakob and Noll, Josef",A multidisciplinary definition of privacy labels,,"Purpose: This paper aims to present arguments about how a complex concept of privacy labeling can be a solution to the current state of privacy. Design/methodology/approach: The authors give a precise definition of Privacy Labeling (PL), painting a panoptic portrait from seven different perspectives: Business, Legal, Regulatory, Usability and Human Factors, Educative, Technological and Multidisciplinary. They describe a common vision, proposing several important “traits of character” of PL as well as identifying “undeveloped potentialities”, i.e. open problems on which the community can focus. Findings: This position paper identifies the stakeholders of the PL and their needs with regard to privacy, describing how PL should be and look like to address these needs. Main aspects considered are the PL’s educational power to change people’s knowledge of privacy, tools useful for constructing PL and the possible visual appearances of PL. They also identify how the present landscape of privacy certifications could be improved by PL. Originality/value: The authors adopt a multidisciplinary approach to defining PL as well as give guidelines in the form of goals, characteristics, open problems, starting points and a roadmap for creating the ideal PL. © 2022, Emerald Publishing Limited.",2022,Information and Computer Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129317908&doi=10.1108%2fICS-06-2021-0080&partnerID=40&md5=7a8a5faf404d46161729c492a70ba576,"{'note': 'All Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Emerald Group Holdings Ltd.', 'abstract': 'Purpose: This paper aims to present arguments about how a complex concept of privacy labeling can be a solution to the current state of privacy. Design/methodology/approach: The authors give a precise definition of Privacy Labeling (PL), painting a panoptic portrait from seven different perspectives: Business, Legal, Regulatory, Usability and Human Factors, Educative, Technological and Multidisciplinary. They describe a common vision, proposing several important “traits of character” of PL as well as identifying “undeveloped potentialities”, i.e. open problems on which the community can focus. Findings: This position paper identifies the stakeholders of the PL and their needs with regard to privacy, describing how PL should be and look like to address these needs. Main aspects considered are the PL’s educational power to change people’s knowledge of privacy, tools useful for constructing PL and the possible visual appearances of PL. They also identify how the present landscape of privacy certifications could be improved by PL. Originality/value: The authors adopt a multidisciplinary approach to defining PL as well as give guidelines in the form of goals, characteristics, open problems, starting points and a roadmap for creating the ideal PL. © 2022, Emerald Publishing Limited.', 'affiliations': 'Department of Computer Science, University of Oslo, Oslo, Norway; Department of Psychology, Oslo New University College, Oslo, Norway; Department of Computer Science, Karlstad University, Karlstad, Sweden; Department of Information Security and Communication Technology, Norwegian University of Science and Technology, Trondheim, Norway; Department of Computer Science and Engineering, University of Gothenburg, Goteborg, Sweden; Privacy Company, The Hague, Netherlands; Unabhängiges Landeszentrum für Datenschutz Schleswig-Holstein, Kiel, Germany; Center for Intelligence Studies, Norwegian Intelligence School, Oslo, Norway', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129317908&doi=10.1108%2fICS-06-2021-0080&partnerID=40&md5=7a8a5faf404d46161729c492a70ba576', 'doi': '10.1108/ICS-06-2021-0080', 'pages': '452 – 469', 'number': '3', 'volume': '30', 'journal': 'Information and Computer Security', 'year': '2022', 'title': 'A multidisciplinary definition of privacy labels', 'author': 'Johansen, Johanna and Pedersen, Tore and Fischer-Hübner, Simone and Johansen, Christian and Schneider, Gerardo and Roosendaal, Arnold and Zwingelberg, Harald and Sivesind, Anders Jakob and Noll, Josef', 'ENTRYTYPE': 'article', 'ID': 'Johansen2022452'}",Scopus
"Hutton, Hannah J. and Ellis, David A.",Exploring User Motivations Behind iOS App Tracking Transparency Decisions,,"Apple's App Tracking Transparency framework allows users to decide whether they want to allow their activity to be tracked for advertising purposes. In this work we examine the tracking decisions made by 312 participants and their associations with privacy concern and personality factors, and conduct a thematic analysis on participants' reasons for choosing to accept or reject tracking requests. Despite 51% of participants reporting that they had rejected tracking for privacy reasons, higher privacy concern scores did not correlate with a lower rate of tracking acceptance. Additionally, 43% of participants held incorrect beliefs about what tracking does, including nearly a quarter who mistakenly believed that accepting a tracking request would share their location with the requesting app. We suggest explanations for these misconceptions and provide recommendations that may improve usability of both App Tracking Transparency and future Privacy Enhancing Technologies. © 2023 Owner/Author.",2023,Conference on Human Factors in Computing Systems - Proceedings,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160007467&doi=10.1145%2f3544548.3580654&partnerID=40&md5=b48f8b9dd13393c4354b5a4bb35a1e5f,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': ""Apple's App Tracking Transparency framework allows users to decide whether they want to allow their activity to be tracked for advertising purposes. In this work we examine the tracking decisions made by 312 participants and their associations with privacy concern and personality factors, and conduct a thematic analysis on participants' reasons for choosing to accept or reject tracking requests. Despite 51% of participants reporting that they had rejected tracking for privacy reasons, higher privacy concern scores did not correlate with a lower rate of tracking acceptance. Additionally, 43% of participants held incorrect beliefs about what tracking does, including nearly a quarter who mistakenly believed that accepting a tracking request would share their location with the requesting app. We suggest explanations for these misconceptions and provide recommendations that may improve usability of both App Tracking Transparency and future Privacy Enhancing Technologies. © 2023 Owner/Author."", 'affiliations': 'School of Management, University of Bath, Bath, United Kingdom', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160007467&doi=10.1145%2f3544548.3580654&partnerID=40&md5=b48f8b9dd13393c4354b5a4bb35a1e5f', 'doi': '10.1145/3544548.3580654', 'journal': 'Conference on Human Factors in Computing Systems - Proceedings', 'year': '2023', 'title': 'Exploring User Motivations Behind iOS App Tracking Transparency Decisions', 'author': 'Hutton, Hannah J. and Ellis, David A.', 'ENTRYTYPE': 'conference', 'ID': 'Hutton2023'}",Scopus
"Wu, Zhenyu and Wang, Haotao and Wang, Zhaowen and Jin, Hailin and Wang, Zhangyang",Privacy-Preserving Deep Action Recognition: An Adversarial Learning Framework and A New Dataset,,"We investigate privacy-preserving, video-based action recognition in deep learning, a problem with growing importance in smart camera applications. A novel adversarial training framework is formulated to learn an anonymization transform for input videos such that the trade-off between target utility task performance and the associated privacy budgets is explicitly optimized on the anonymized videos. Notably, the privacy budget, often defined and measured in task-driven contexts, cannot be reliably indicated using any single model performance because strong protection of privacy should sustain against any malicious model that tries to steal private information. To tackle this problem, we propose two new optimization strategies of model restarting and model ensemble to achieve stronger universal privacy protection against any attacker models. Extensive experiments have been carried out and analyzed. On the other hand, given few public datasets available with both utility and privacy labels, the data-driven (supervised) learning cannot exert its full power on this task. We first discuss an innovative heuristic of cross-dataset training and evaluation, enabling the use of multiple single-task datasets (one with target task labels and the other with privacy labels) in our problem. To further address this dataset challenge, we have constructed a new dataset, termed PA-HMDB51, with both target task labels (action) and selected privacy attributes (skin color, face, gender, nudity, and relationship) annotated on a per-frame basis. This first-of-its-kind video dataset and evaluation protocol can greatly facilitate visual privacy research and open up other opportunities. Our codes, models, and the PA-HMDB51 dataset are available at: https://github.com/VITA-Group/PA-HMDB51  © 1979-2012 IEEE.",2022,IEEE Transactions on Pattern Analysis and Machine Intelligence,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125883159&doi=10.1109%2fTPAMI.2020.3026709&partnerID=40&md5=b936fdc81b833b1d1c1fe3800e5b49ce,"{'note': 'All Open Access, Hybrid Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'IEEE Computer Society', 'abstract': 'We investigate privacy-preserving, video-based action recognition in deep learning, a problem with growing importance in smart camera applications. A novel adversarial training framework is formulated to learn an anonymization transform for input videos such that the trade-off between target utility task performance and the associated privacy budgets is explicitly optimized on the anonymized videos. Notably, the privacy budget, often defined and measured in task-driven contexts, cannot be reliably indicated using any single model performance because strong protection of privacy should sustain against any malicious model that tries to steal private information. To tackle this problem, we propose two new optimization strategies of model restarting and model ensemble to achieve stronger universal privacy protection against any attacker models. Extensive experiments have been carried out and analyzed. On the other hand, given few public datasets available with both utility and privacy labels, the data-driven (supervised) learning cannot exert its full power on this task. We first discuss an innovative heuristic of cross-dataset training and evaluation, enabling the use of multiple single-task datasets (one with target task labels and the other with privacy labels) in our problem. To further address this dataset challenge, we have constructed a new dataset, termed PA-HMDB51, with both target task labels (action) and selected privacy attributes (skin color, face, gender, nudity, and relationship) annotated on a per-frame basis. This first-of-its-kind video dataset and evaluation protocol can greatly facilitate visual privacy research and open up other opportunities. Our codes, models, and the PA-HMDB51 dataset are available at: https://github.com/VITA-Group/PA-HMDB51  © 1979-2012 IEEE.', 'affiliations': 'Department of Computer Science and Engineering, Texas AandM University, College Station, 77840, TX, United States; Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, 78712, TX, United States; Adobe Research, San Jose, 95110, CA, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125883159&doi=10.1109%2fTPAMI.2020.3026709&partnerID=40&md5=b936fdc81b833b1d1c1fe3800e5b49ce', 'doi': '10.1109/TPAMI.2020.3026709', 'pages': '2126 – 2139', 'number': '4', 'volume': '44', 'journal': 'IEEE Transactions on Pattern Analysis and Machine Intelligence', 'year': '2022', 'title': 'Privacy-Preserving Deep Action Recognition: An Adversarial Learning Framework and A New Dataset', 'author': 'Wu, Zhenyu and Wang, Haotao and Wang, Zhaowen and Jin, Hailin and Wang, Zhangyang', 'ENTRYTYPE': 'article', 'ID': 'Wu20222126'}",Scopus
"Benjumea, Jaime and Dorronzoro, Enrique and Ropero, Jorge and Rivera-Romero, Octavio and Carrasco, Alejandro",Privacy in mobile health applications for breast cancer patients,,"Privacy is a major concern for breast cancer patients. When patients use mobile health applications (mHealth apps), many sensitive data are handled by the application developers. General Data Protection Regulation (GDPR) arises as a solution to privacy issues. In this paper, we analyze the privacy policy of a sample of mHealth apps for breast cancer patients, developing a scale to check if GDPR is complied. Despite privacy is a key factor in the adoption of the use of mHealth apps, the low level of compliance with the GDPR of the analyzed applications was quite surprising. Thus, application developers must be concerned about this matter. © 2019 IEEE.",2019,Proceedings - IEEE Symposium on Computer-Based Medical Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071007817&doi=10.1109%2fCBMS.2019.00131&partnerID=40&md5=73e434401f1d0c425ab725c096d56aae,"{'note': 'All Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Institute of Electrical and Electronics Engineers Inc.', 'abstract': 'Privacy is a major concern for breast cancer patients. When patients use mobile health applications (mHealth apps), many sensitive data are handled by the application developers. General Data Protection Regulation (GDPR) arises as a solution to privacy issues. In this paper, we analyze the privacy policy of a sample of mHealth apps for breast cancer patients, developing a scale to check if GDPR is complied. Despite privacy is a key factor in the adoption of the use of mHealth apps, the low level of compliance with the GDPR of the analyzed applications was quite surprising. Thus, application developers must be concerned about this matter. © 2019 IEEE.', 'affiliations': 'Universidad de Sevilla, Department of Electronic Technology, Seville, Spain', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071007817&doi=10.1109%2fCBMS.2019.00131&partnerID=40&md5=73e434401f1d0c425ab725c096d56aae', 'doi': '10.1109/CBMS.2019.00131', 'pages': '634 – 639', 'volume': '2019-June', 'journal': 'Proceedings - IEEE Symposium on Computer-Based Medical Systems', 'year': '2019', 'title': 'Privacy in mobile health applications for breast cancer patients', 'author': 'Benjumea, Jaime and Dorronzoro, Enrique and Ropero, Jorge and Rivera-Romero, Octavio and Carrasco, Alejandro', 'ENTRYTYPE': 'conference', 'ID': 'Benjumea2019634'}",Scopus
"Ruotsalainen, Pekka and Pharow, Peter and Petersen, Francoise",Privacy management and networked PPD systems - Challenges and solutions,,"Modern personal portable health devices (PPDs) become increasingly part of a larger, inhomogeneous information system. Information collected by sensors are stored and processed in global clouds. Services are often free of charge, but at the same time service providers' business model is based on the disclosure of users' intimate health information. Health data processed in PPD networks is not regulated by health care specific legislation. In PPD networks, there is no guarantee that stakeholders share same ethical principles with the user. Often service providers have own security and privacy policies and they rarely offer to the user possibilities to define own, or adapt existing privacy policies. This all raises huge ethical and privacy concerns. In this paper, the authors have analyzed privacy challenges in PPD networks from users' viewpoint using system modeling method and propose the principle ""Personal Health Data under Personal Control"" must generally be accepted at global level. Among possible implementation of this principle, the authors propose encryption, computer understandable privacy policies, and privacy labels or trust based privacy management methods. The latter can be realized using infrastructural trust calculation and monitoring service. A first step is to require the protection of personal health information and the principle proposed being internationally mandatory. This requires both regulatory and standardization activities, and the availability of open and certified software application which all service providers can implement. One of those applications should be the independent Trust verifier. © 2015 The authors and IOS Press. All rights reserved.",2015,Studies in Health Technology and Informatics,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939222498&doi=10.3233%2f978-1-61499-516-6-271&partnerID=40&md5=b7a5f675cf8dfa2896d64d75eeb40d20,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'IOS Press', 'abstract': 'Modern personal portable health devices (PPDs) become increasingly part of a larger, inhomogeneous information system. Information collected by sensors are stored and processed in global clouds. Services are often free of charge, but at the same time service providers\' business model is based on the disclosure of users\' intimate health information. Health data processed in PPD networks is not regulated by health care specific legislation. In PPD networks, there is no guarantee that stakeholders share same ethical principles with the user. Often service providers have own security and privacy policies and they rarely offer to the user possibilities to define own, or adapt existing privacy policies. This all raises huge ethical and privacy concerns. In this paper, the authors have analyzed privacy challenges in PPD networks from users\' viewpoint using system modeling method and propose the principle ""Personal Health Data under Personal Control"" must generally be accepted at global level. Among possible implementation of this principle, the authors propose encryption, computer understandable privacy policies, and privacy labels or trust based privacy management methods. The latter can be realized using infrastructural trust calculation and monitoring service. A first step is to require the protection of personal health information and the principle proposed being internationally mandatory. This requires both regulatory and standardization activities, and the availability of open and certified software application which all service providers can implement. One of those applications should be the independent Trust verifier. © 2015 The authors and IOS Press. All rights reserved.', 'affiliations': 'Tampere University, School for Information Science, Tampere, Finland; Fraunhofer Institute for Digital Media Technology IDMT, Ilmenau, Germany; APICA, Malmö, Sweden', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939222498&doi=10.3233%2f978-1-61499-516-6-271&partnerID=40&md5=b7a5f675cf8dfa2896d64d75eeb40d20', 'doi': '10.3233/978-1-61499-516-6-271', 'pages': '271 – 279', 'volume': '211', 'journal': 'Studies in Health Technology and Informatics', 'year': '2015', 'title': 'Privacy management and networked PPD systems - Challenges and solutions', 'author': 'Ruotsalainen, Pekka and Pharow, Peter and Petersen, Francoise', 'ENTRYTYPE': 'article', 'ID': 'Ruotsalainen2015271'}",Scopus
,"ACI 2021 - 8th International Conference on Animal-Computer Interaction, Proceedings",,The proceedings contain 22 papers. The topics discussed include: leashing the city: dog-leash-human entanglements and the urban space; supporting animal-mediated interventions at home: the role of animals and technology to facilitate daily activities; privacy labels should go to the dogs; exploring digitalization of animal-assisted reading; wearable sensors for canine nosework sniffing interaction; from ideation to deployment: a narrative case study of citizen science supported wearables for raising guide dogs; ECG and respiration signal reconstruction from an IMU at various orientations during rest or sleep for dog welfare monitoring; reflecting on methods in animal computer interaction: novelty effect and habituation; smart bee houses: designing to support urban pollination; and payload drones and ACI: drone navigation system prototype.,2021,ACM International Conference Proceeding Series,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130813689&partnerID=40&md5=c58d4a3c6bc5545315504d34e8bf779e,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference review', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': 'The proceedings contain 22 papers. The topics discussed include: leashing the city: dog-leash-human entanglements and the urban space; supporting animal-mediated interventions at home: the role of animals and technology to facilitate daily activities; privacy labels should go to the dogs; exploring digitalization of animal-assisted reading; wearable sensors for canine nosework sniffing interaction; from ideation to deployment: a narrative case study of citizen science supported wearables for raising guide dogs; ECG and respiration signal reconstruction from an IMU at various orientations during rest or sleep for dog welfare monitoring; reflecting on methods in animal computer interaction: novelty effect and habituation; smart bee houses: designing to support urban pollination; and payload drones and ACI: drone navigation system prototype.', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130813689&partnerID=40&md5=c58d4a3c6bc5545315504d34e8bf779e', 'journal': 'ACM International Conference Proceeding Series', 'year': '2021', 'title': 'ACI 2021 - 8th International Conference on Animal-Computer Interaction, Proceedings', 'ENTRYTYPE': 'conference', 'ID': '2021'}",Scopus
"Zhong, Jian and Bertok, Peter and Tari, Zahir","Security, privacy and interoperability in heterogeneous systems",,"Partners in VOs can share large amount of data. Sharing of individual data items is straightforward, but sharing components of complex data structures stored in heterogeneous systems is often a challenge. Sharing is typically governed by rules and policies that need to be translated into access right / privilege control and data granularity control. Simultaneous control of privileges and data granularity across different organizations is a difficult task, and most traditional approaches, such role-based access control can become prohibitively complex in such scenarios. We propose a scheme for concurrent control of subject privileges and object granularity. It includes participants, duties and operations, and generates security labels that describe security features. To facilitate interoperability between heterogeneous systems, the labels also carry information about the data model, including dynamic hierarchy description. The model supports subject activity control over objects with variable data access granularity. It encompasses the advantages of existing role based and label based control. First, an abstract subject privilege control model is built, and the mathematical relationships between privileges in the label system are defined. Second, an abstract object dynamic granularity model is produced and the mathematical relationship between granularity levels is established. At last, a pair-wise privacy label system is provided as an integrated information protection mechanism, where relationships between subject activities and privileges are described for actual access control. A formal verification of the proposed method has also been performed. © 2010 IFIP.",2010,IFIP Advances in Information and Communication Technology,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78449269206&doi=10.1007%2f978-3-642-15961-9_84&partnerID=40&md5=8a885f8a73030fc998ee65fb7dc06055,"{'note': 'All Open Access, Bronze Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'abstract': 'Partners in VOs can share large amount of data. Sharing of individual data items is straightforward, but sharing components of complex data structures stored in heterogeneous systems is often a challenge. Sharing is typically governed by rules and policies that need to be translated into access right / privilege control and data granularity control. Simultaneous control of privileges and data granularity across different organizations is a difficult task, and most traditional approaches, such role-based access control can become prohibitively complex in such scenarios. We propose a scheme for concurrent control of subject privileges and object granularity. It includes participants, duties and operations, and generates security labels that describe security features. To facilitate interoperability between heterogeneous systems, the labels also carry information about the data model, including dynamic hierarchy description. The model supports subject activity control over objects with variable data access granularity. It encompasses the advantages of existing role based and label based control. First, an abstract subject privilege control model is built, and the mathematical relationships between privileges in the label system are defined. Second, an abstract object dynamic granularity model is produced and the mathematical relationship between granularity levels is established. At last, a pair-wise privacy label system is provided as an integrated information protection mechanism, where relationships between subject activities and privileges are described for actual access control. A formal verification of the proposed method has also been performed. © 2010 IFIP.', 'affiliations': 'Computer Science and Information Technology, RMIT University, Melbourne, VIC, Australia', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-78449269206&doi=10.1007%2f978-3-642-15961-9_84&partnerID=40&md5=8a885f8a73030fc998ee65fb7dc06055', 'doi': '10.1007/978-3-642-15961-9_84', 'pages': '713 – 721', 'volume': '336 AICT', 'journal': 'IFIP Advances in Information and Communication Technology', 'year': '2010', 'title': 'Security, privacy and interoperability in heterogeneous systems', 'author': 'Zhong, Jian and Bertok, Peter and Tari, Zahir', 'ENTRYTYPE': 'article', 'ID': 'Zhong2010713'}",Scopus
"Reeder, Robert W. and Kelley, Patrick Gage and McDonald, Aleecia M. and Cranor, Lorrie Faith",A user study of the expandable grid applied to P3P privacy policy visualization,,"Displaying website privacy policies to consumers in ways they understand is an important part of gaining consumers' trust and informed consent, yet most website privacy policies today are presented in confusing, legalistic natural language. Moreover, because website privacy policy presentations vary from website to website, policies are difficult to compare and it is difficult for consumers to determine which websites offer the best privacy protections. The Platform for Privacy Preferences (P3P) addresses part of the problem with natural language policies by providing a formal, machine-readable language for expressing privacy policies in a manner that is standardized across websites. To address remaining problems, an automated tool must be developed to read P3P policies and display them to users in a comprehensible way. To this end, we have developed a P3P policy presentation tool based on the Expandable Grid, a visualization technique for displaying policies in an interactive matrix. In prior work, the Expandable Grid has been shown to work well for displaying file permissions policies, so it appears to hold promise for presenting online privacy policies as well. To evaluate our Expandable Grid interface, we conducted two user studies, an online study with 520 participants and a laboratory study with 12 participants. The studies compared participants' comprehension of privacy policies presented with the Grid interface with their comprehension of the same policies presented in natural language. To our surprise, comprehension of policies was, for the most part, no better with the Grid interface than with natural language. We describe why the Grid interface did not perform well in our study and discuss implications for when and how the Expandable Grid concept can be usefully applied. Copyright 2008 ACM.",2008,Proceedings of the ACM Conference on Computer and Communications Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-69949145370&doi=10.1145%2f1456403.1456413&partnerID=40&md5=c89cf97830ca04a85ef8883046fed8ac,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'abstract': ""Displaying website privacy policies to consumers in ways they understand is an important part of gaining consumers' trust and informed consent, yet most website privacy policies today are presented in confusing, legalistic natural language. Moreover, because website privacy policy presentations vary from website to website, policies are difficult to compare and it is difficult for consumers to determine which websites offer the best privacy protections. The Platform for Privacy Preferences (P3P) addresses part of the problem with natural language policies by providing a formal, machine-readable language for expressing privacy policies in a manner that is standardized across websites. To address remaining problems, an automated tool must be developed to read P3P policies and display them to users in a comprehensible way. To this end, we have developed a P3P policy presentation tool based on the Expandable Grid, a visualization technique for displaying policies in an interactive matrix. In prior work, the Expandable Grid has been shown to work well for displaying file permissions policies, so it appears to hold promise for presenting online privacy policies as well. To evaluate our Expandable Grid interface, we conducted two user studies, an online study with 520 participants and a laboratory study with 12 participants. The studies compared participants' comprehension of privacy policies presented with the Grid interface with their comprehension of the same policies presented in natural language. To our surprise, comprehension of policies was, for the most part, no better with the Grid interface than with natural language. We describe why the Grid interface did not perform well in our study and discuss implications for when and how the Expandable Grid concept can be usefully applied. Copyright 2008 ACM."", 'affiliations': 'Microsoft, Redmond, WA 98052, 1 Microsoft Way, United States; Carnegie Mellon University, Pittsburgh, PA, 15213, 5000 Forbes Ave., United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-69949145370&doi=10.1145%2f1456403.1456413&partnerID=40&md5=c89cf97830ca04a85ef8883046fed8ac', 'doi': '10.1145/1456403.1456413', 'pages': '45 – 54', 'journal': 'Proceedings of the ACM Conference on Computer and Communications Security', 'year': '2008', 'title': 'A user study of the expandable grid applied to P3P privacy policy visualization', 'author': 'Reeder, Robert W. and Kelley, Patrick Gage and McDonald, Aleecia M. and Cranor, Lorrie Faith', 'ENTRYTYPE': 'conference', 'ID': 'Reeder200845'}",Scopus
"Tonge, Ashwini and Caragea, Cornelia",Dynamic deep multi-modal fusion for image privacy prediction,,"With millions of images that are shared online on social networking sites, effective methods for image privacy prediction are highly needed. In this paper, we propose an approach for fusing object, scene context, and image tags modalities derived from convolutional neural networks for accurately predicting the privacy of images shared online. Specifically, our approach identifies the set of most competent modalities on the fly, according to each new target image whose privacy has to be predicted. The approach considers three stages to predict the privacy of a target image, wherein we first identify the neighborhood images that are visually similar and/or have similar sensitive content as the target image. Then, we estimate the competence of the modalities based on the neighborhood images. Finally, we fuse the decisions of the most competent modalities and predict the privacy label for the target image. Experimental results show that our approach predicts the sensitive (or private) content more accurately than the models trained on individual modalities (object, scene, and tags) and prior privacy prediction works. Also, our approach outperforms strong baselines, that train meta-classifiers to obtain an optimal combination of modalities. © 2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY 4.0 License.",2019,"The Web Conference 2019 - Proceedings of the World Wide Web Conference, WWW 2019",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066892597&doi=10.1145%2f3308558.3313691&partnerID=40&md5=c1cb0cf4be7700833316716a8a21913e,"{'note': 'All Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery, Inc', 'abstract': 'With millions of images that are shared online on social networking sites, effective methods for image privacy prediction are highly needed. In this paper, we propose an approach for fusing object, scene context, and image tags modalities derived from convolutional neural networks for accurately predicting the privacy of images shared online. Specifically, our approach identifies the set of most competent modalities on the fly, according to each new target image whose privacy has to be predicted. The approach considers three stages to predict the privacy of a target image, wherein we first identify the neighborhood images that are visually similar and/or have similar sensitive content as the target image. Then, we estimate the competence of the modalities based on the neighborhood images. Finally, we fuse the decisions of the most competent modalities and predict the privacy label for the target image. Experimental results show that our approach predicts the sensitive (or private) content more accurately than the models trained on individual modalities (object, scene, and tags) and prior privacy prediction works. Also, our approach outperforms strong baselines, that train meta-classifiers to obtain an optimal combination of modalities. © 2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY 4.0 License.', 'affiliations': 'Department of Computer Science, Kansas State University, United States; Department of Computer Science, University of Illinois at Chicago, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066892597&doi=10.1145%2f3308558.3313691&partnerID=40&md5=c1cb0cf4be7700833316716a8a21913e', 'doi': '10.1145/3308558.3313691', 'pages': '1829 – 1840', 'journal': 'The Web Conference 2019 - Proceedings of the World Wide Web Conference, WWW 2019', 'year': '2019', 'title': 'Dynamic deep multi-modal fusion for image privacy prediction', 'author': 'Tonge, Ashwini and Caragea, Cornelia', 'ENTRYTYPE': 'conference', 'ID': 'Tonge20191829'}",Scopus
"Morkonda, Srivathsan G. and Chiasson, Sonia and Van Oorschot, Paul C.",Empirical Analysis and Privacy Implications in OAuth-based Single Sign-On Systems,,"Single sign-on authentication systems such as OAuth 2.0 are widely used in web services. They allow users to use accounts registered with major identity providers such as Google and Facebook to login to a wide variety of independent services (relying parties). These services can both identify users and access a subset of the user's data stored with the provider. We empirically investigate the end-user privacy implications of OAuth implementations by relying parties around the world. We collect data on the use of OAuth-based logins in the Alexa Top 500 sites per country for five countries. We categorize user data made available by four identity providers (Google, Facebook, Apple, and LinkedIn) and evaluate popular services accessing user data from the SSO platforms of these providers. Many services allow users to choose from multiple login options (with different identity providers). Our results reveal that services request different categories and amounts of personal data from different providers, often with at least one choice undeniably more privacy-intrusive. We find that privacy-friendly login choices tend to be listed last, suggesting a dark pattern favoring options that release more user data. These privacy choices (and their privacy implications) are highly invisible to users. Based on our analysis, we consider challenges (e.g., opposing goals of stakeholders) in addressing these concerns and discuss ideas for further exploration.  © 2021 ACM.",2021,"WPES 2021 - Proceedings of the 20th Workshop on Privacy in the Electronic Society, co-located with CCS 2021",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120532733&doi=10.1145%2f3463676.3485600&partnerID=40&md5=1153112b143f5c350679e4b9e5abe39e,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery, Inc', 'abstract': ""Single sign-on authentication systems such as OAuth 2.0 are widely used in web services. They allow users to use accounts registered with major identity providers such as Google and Facebook to login to a wide variety of independent services (relying parties). These services can both identify users and access a subset of the user's data stored with the provider. We empirically investigate the end-user privacy implications of OAuth implementations by relying parties around the world. We collect data on the use of OAuth-based logins in the Alexa Top 500 sites per country for five countries. We categorize user data made available by four identity providers (Google, Facebook, Apple, and LinkedIn) and evaluate popular services accessing user data from the SSO platforms of these providers. Many services allow users to choose from multiple login options (with different identity providers). Our results reveal that services request different categories and amounts of personal data from different providers, often with at least one choice undeniably more privacy-intrusive. We find that privacy-friendly login choices tend to be listed last, suggesting a dark pattern favoring options that release more user data. These privacy choices (and their privacy implications) are highly invisible to users. Based on our analysis, we consider challenges (e.g., opposing goals of stakeholders) in addressing these concerns and discuss ideas for further exploration.  © 2021 ACM."", 'affiliations': 'Carleton University, Ottawa, ON, Canada', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120532733&doi=10.1145%2f3463676.3485600&partnerID=40&md5=1153112b143f5c350679e4b9e5abe39e', 'doi': '10.1145/3463676.3485600', 'pages': '195 – 208', 'journal': 'WPES 2021 - Proceedings of the 20th Workshop on Privacy in the Electronic Society, co-located with CCS 2021', 'year': '2021', 'title': 'Empirical Analysis and Privacy Implications in OAuth-based Single Sign-On Systems', 'author': 'Morkonda, Srivathsan G. and Chiasson, Sonia and Van Oorschot, Paul C.', 'ENTRYTYPE': 'conference', 'ID': 'Morkonda2021195'}",Scopus
"Zorzo, Sergio Donizetti and De Pontes, Diego Roberto Gonçalves and Dias, Diego Henrique and De Mello, José Santiago Moreira",Privacy rules: Approach in the label or textual format,,"Users usually don't read privacy policies of the websites accessed. This paper presents the privacy policy of the websites in a format named Privacy Label for being similar to nutritional labels. It is presented on the standardized-table format of items of privacy policies, including governmental policies. This format was compared to the policies described as full text written in natural language based on the perception of 198 participant students of the different areas. The results indicate that the Privacy Label format facilitates users' comprehension of the policy content and made them more aware of elements that they would usually dismiss when reading a textual privacy policy.",2016,AMCIS 2016: Surfing the IT Innovation Wave - 22nd Americas Conference on Information Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987653366&partnerID=40&md5=d745bf1b9af6288f6bec15c11d0784ea,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Information Systems', 'abstract': ""Users usually don't read privacy policies of the websites accessed. This paper presents the privacy policy of the websites in a format named Privacy Label for being similar to nutritional labels. It is presented on the standardized-table format of items of privacy policies, including governmental policies. This format was compared to the policies described as full text written in natural language based on the perception of 198 participant students of the different areas. The results indicate that the Privacy Label format facilitates users' comprehension of the policy content and made them more aware of elements that they would usually dismiss when reading a textual privacy policy."", 'affiliations': 'Computer Science Department, Federal University of São Carlos, Brazil', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987653366&partnerID=40&md5=d745bf1b9af6288f6bec15c11d0784ea', 'journal': 'AMCIS 2016: Surfing the IT Innovation Wave - 22nd Americas Conference on Information Systems', 'year': '2016', 'title': 'Privacy rules: Approach in the label or textual format', 'author': 'Zorzo, Sergio Donizetti and De Pontes, Diego Roberto Gonçalves and Dias, Diego Henrique and De Mello, José Santiago Moreira', 'ENTRYTYPE': 'conference', 'ID': 'Zorzo2016'}",Scopus
"Stabauer, Martin",The Effects of Privacy Awareness and Content Sensitivity on User Engagement,,"To increase user engagement is an important goal and major business model for many web applications and online publishers. An established tool for this purpose is online polling, where user opinions, preferences, attitudes and possibly personal information are collected to help publishers to a better understanding of their target audiences. These polls are often provided as supplements to online newspaper articles, the topics of which are typically also reflected in the content of the polls. We analyzed and categorized this content, and related it with the user engagement rate given as the proportion of people who voluntarily disclose personal information. Recently, public privacy awareness has increased, especially since the introduction of the European Union’s General Data Protection Regulation (GDPR). Extensive media coverage has led to public discussions about data protection and privacy. This study additionally investigated the effect of increased public privacy awareness on individual privacy awareness and subsequently user engagement. The results are based on live data of more than 60,000 polls and more than 22 million user votes, mainly collected in German-speaking countries, and give insights into user behavior when confronted with requests for personal information in various settings and over time. © 2019, Springer Nature Switzerland AG.",2019,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069824732&doi=10.1007%2f978-3-030-22338-0_20&partnerID=40&md5=a87e6d89733c4fdd1fc5aead64959093,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Springer Verlag', 'abstract': 'To increase user engagement is an important goal and major business model for many web applications and online publishers. An established tool for this purpose is online polling, where user opinions, preferences, attitudes and possibly personal information are collected to help publishers to a better understanding of their target audiences. These polls are often provided as supplements to online newspaper articles, the topics of which are typically also reflected in the content of the polls. We analyzed and categorized this content, and related it with the user engagement rate given as the proportion of people who voluntarily disclose personal information. Recently, public privacy awareness has increased, especially since the introduction of the European Union’s General Data Protection Regulation (GDPR). Extensive media coverage has led to public discussions about data protection and privacy. This study additionally investigated the effect of increased public privacy awareness on individual privacy awareness and subsequently user engagement. The results are based on live data of more than 60,000 polls and more than 22 million user votes, mainly collected in German-speaking countries, and give insights into user behavior when confronted with requests for personal information in various settings and over time. © 2019, Springer Nature Switzerland AG.', 'affiliations': 'Johannes Kepler University, Linz, Austria', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069824732&doi=10.1007%2f978-3-030-22338-0_20&partnerID=40&md5=a87e6d89733c4fdd1fc5aead64959093', 'doi': '10.1007/978-3-030-22338-0_20', 'pages': '242 – 255', 'volume': '11589 LNCS', 'journal': 'Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)', 'year': '2019', 'title': 'The Effects of Privacy Awareness and Content Sensitivity on User Engagement', 'author': 'Stabauer, Martin', 'ENTRYTYPE': 'article', 'ID': 'Stabauer2019242'}",Scopus
"Xia, Yang and Zhu, Tianqing and Ding, Xiaofeng and Jin, Hai and Zou, Deqing",Heterogeneous differential privacy for vertically partitioned databases,,"Existing privacy-preserving approaches are generally designed to provide privacy guarantee for individual data in a database, which reduces the utility of the database for data analysis. In this paper, we propose a novel differential privacy mechanism to preserve the heterogeneous privacy of a vertically partitioned database based on attributes. We first present the concept of privacy label, which characterizes the privacy information of the database and is instantiated by the classification. Then, we use an information-based method to systematically explore the dependencies between all attributes and the privacy label. We finally assign privacy weights to every attribute and design a heterogeneous mechanism according to the basic Laplace mechanism. Evaluations using real datasets demonstrate that the proposed mechanism achieves a balanced privacy and utility. © 2019 John Wiley & Sons, Ltd.",2021,Concurrency and Computation: Practice and Experience,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076904119&doi=10.1002%2fcpe.5607&partnerID=40&md5=a5b3d2ef7a3af82013b0f594cff0339f,"{'note': 'All Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'John Wiley and Sons Ltd', 'abstract': 'Existing privacy-preserving approaches are generally designed to provide privacy guarantee for individual data in a database, which reduces the utility of the database for data analysis. In this paper, we propose a novel differential privacy mechanism to preserve the heterogeneous privacy of a vertically partitioned database based on attributes. We first present the concept of privacy label, which characterizes the privacy information of the database and is instantiated by the classification. Then, we use an information-based method to systematically explore the dependencies between all attributes and the privacy label. We finally assign privacy weights to every attribute and design a heterogeneous mechanism according to the basic Laplace mechanism. Evaluations using real datasets demonstrate that the proposed mechanism achieves a balanced privacy and utility. © 2019 John Wiley & Sons, Ltd.', 'affiliations': 'National Engineering Research Center for Big Data Technology and System, Service Computing Technology and System Lab, Cluster and Grid Computing Lab, Huazhong University of Science and Technology, Wuhan, China; Deakin University, Victoria, Australia', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076904119&doi=10.1002%2fcpe.5607&partnerID=40&md5=a5b3d2ef7a3af82013b0f594cff0339f', 'doi': '10.1002/cpe.5607', 'number': '8', 'volume': '33', 'journal': 'Concurrency and Computation: Practice and Experience', 'year': '2021', 'title': 'Heterogeneous differential privacy for vertically partitioned databases', 'author': 'Xia, Yang and Zhu, Tianqing and Ding, Xiaofeng and Jin, Hai and Zou, Deqing', 'ENTRYTYPE': 'article', 'ID': 'Xia2021'}",Scopus
"Varghese, Arathi",Engaging consumers through effective label designs,,"The design of product labels is of high importance for it ensures that the label communicates the necessary information accurately and efficiently to the consumers. This project follows the design development of one such label used primarily for anti-counterfeiting. In this project, usability studies and 5-Seconds Tests(5STs) are designed and conducted to understand how consumers would verify such a label and also to gauge the usability of the label's information. Through the tests, we understand consumer behavior and their perceptions of the label. Thus, aiding to identify factors such as the label's prominence, placement of the text and clarity of the label's purpose that affects the degree to which a consumer engages with it. Ultimately, design recommendations are made to assist in overcoming the identified bottlenecks. Moreover, the project highlights the importance of user research and how comprehending consumers can guide designers to build information formats with a prominent outcome. © 2019 Association for Computing Machinery.",2019,ACM International Conference Proceeding Series,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075439855&doi=10.1145%2f3364183.3364198&partnerID=40&md5=3f3539174066b42d61d47d00c71b6136,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': ""The design of product labels is of high importance for it ensures that the label communicates the necessary information accurately and efficiently to the consumers. This project follows the design development of one such label used primarily for anti-counterfeiting. In this project, usability studies and 5-Seconds Tests(5STs) are designed and conducted to understand how consumers would verify such a label and also to gauge the usability of the label's information. Through the tests, we understand consumer behavior and their perceptions of the label. Thus, aiding to identify factors such as the label's prominence, placement of the text and clarity of the label's purpose that affects the degree to which a consumer engages with it. Ultimately, design recommendations are made to assist in overcoming the identified bottlenecks. Moreover, the project highlights the importance of user research and how comprehending consumers can guide designers to build information formats with a prominent outcome. © 2019 Association for Computing Machinery."", 'affiliations': 'Srishti Institute of Art, Design and Technology, Bangalore, Karnataka, India', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075439855&doi=10.1145%2f3364183.3364198&partnerID=40&md5=3f3539174066b42d61d47d00c71b6136', 'doi': '10.1145/3364183.3364198', 'journal': 'ACM International Conference Proceeding Series', 'year': '2019', 'title': 'Engaging consumers through effective label designs', 'author': 'Varghese, Arathi', 'ENTRYTYPE': 'conference', 'ID': 'Varghese2019'}",Scopus
"Garg, Vaibhav",A Lemon by Any Other Label,,"Apparent under-investment in IoT security is often explained by the lack of consumer demand engendered by information asymmetries. One proposed solution is to create IoT security labels as a market signal of differentiation. Such labeling may be binary, graded, or descriptive. Each label type can be further differentiated based on distinct implementations. This paper surveys the existing efforts to create IoT security labels along with the inherent limitations of individual approaches. Overall, we find that there is limited research in this area, which makes it difficult to ascertain the components of an effective IoT security label. We recommend that label designs should limit complexity and leverage existing institutions, such as trade groups, for sustainability as well as adoption. © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.",2021,International Conference on Information Systems Security and Privacy,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176371810&doi=10.5220%2f0010295205580565&partnerID=40&md5=fd7c0cb767d026c1215d2bf667aac880,"{'note': 'All Open Access, Hybrid Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Science and Technology Publications, Lda', 'abstract': 'Apparent under-investment in IoT security is often explained by the lack of consumer demand engendered by information asymmetries. One proposed solution is to create IoT security labels as a market signal of differentiation. Such labeling may be binary, graded, or descriptive. Each label type can be further differentiated based on distinct implementations. This paper surveys the existing efforts to create IoT security labels along with the inherent limitations of individual approaches. Overall, we find that there is limited research in this area, which makes it difficult to ascertain the components of an effective IoT security label. We recommend that label designs should limit complexity and leverage existing institutions, such as trade groups, for sustainability as well as adoption. © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.', 'affiliations': 'Comcast Cable, Philadelphia, PA, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176371810&doi=10.5220%2f0010295205580565&partnerID=40&md5=fd7c0cb767d026c1215d2bf667aac880', 'doi': '10.5220/0010295205580565', 'pages': '558 – 565', 'journal': 'International Conference on Information Systems Security and Privacy', 'year': '2021', 'title': 'A Lemon by Any Other Label', 'author': 'Garg, Vaibhav', 'ENTRYTYPE': 'conference', 'ID': 'Garg2021558'}",Scopus
"Shepherd, Lynsay A. and Renaud, Karen",How to design browser security and privacy alerts,,"It is important to design browser security and privacy alerts so as to maximise their value to the end user, and their efficacy in terms of communicating risk. We derived a list of design guidelines from the research literature by carrying out a systematic review. We analysed the papers both quantitatively and qualitatively to arrive at a comprehensive set of guidelines. Our findings aim to to provide designers and developers with guidance as to how to construct privacy and security alerts. We conclude by providing an alert template, highlighting its adherence to the derived guidelines. © Proceedings of AISB Annual Convention 2018. All rights reserved.",2018,Proceedings of AISB Annual Convention 2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056844307&partnerID=40&md5=abaaf877ecf23ce989c1ec90f0ecf7a4,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'The Society for the Study of Artificial Intelligence and the Simulation of Behaviour (AISB)', 'abstract': 'It is important to design browser security and privacy alerts so as to maximise their value to the end user, and their efficacy in terms of communicating risk. We derived a list of design guidelines from the research literature by carrying out a systematic review. We analysed the papers both quantitatively and qualitatively to arrive at a comprehensive set of guidelines. Our findings aim to to provide designers and developers with guidance as to how to construct privacy and security alerts. We conclude by providing an alert template, highlighting its adherence to the derived guidelines. © Proceedings of AISB Annual Convention 2018. All rights reserved.', 'affiliations': 'School of Design and Informatics, Abertay University, Dundee, United Kingdom', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056844307&partnerID=40&md5=abaaf877ecf23ce989c1ec90f0ecf7a4', 'pages': '21 – 28', 'journal': 'Proceedings of AISB Annual Convention 2018', 'year': '2018', 'title': 'How to design browser security and privacy alerts', 'author': 'Shepherd, Lynsay A. and Renaud, Karen', 'ENTRYTYPE': 'conference', 'ID': 'Shepherd201821'}",Scopus
"Pontes, Diego Roberto Gonçalves and Zorzo, Sergio Donizetti and de Mello, Jose Santiago Moreira",Evaluation of the reliability of using the prototype ppmark - A tool to support the computer human interaction in readings the privacy policies - Using the GQM and TAM models,,"For the past years, a number of researches have shown that most users do not have a habit of reading privacy policies. This fact may occur due to the time spent on reading these policies technical or even users’ lack of interest. On a previous work, in order to facilitate the presentation of privacy policies from online services, a prototype called PPMark was developed in order to read policy texts and show what kind of data was being collected and to what end are were presented in a privacy label format. The goal of this work is to assess the users’ confidence on the information extracted by this prototype. Given the results, the prototype proved that it is easy to use, it can decrease the time spent on reading policies and that users trust the information extracted, thus facilitating the computer human interaction (user x privacy policies). © 2017 AIS/ICIS Administrative Office. All Rights Reserved.",2017,AMCIS 2017 - America's Conference on Information Systems: A Tradition of Innovation,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048456624&partnerID=40&md5=de86f901325a512ac1981cad9fd5df90,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Americas Conference on Information Systems', 'abstract': 'For the past years, a number of researches have shown that most users do not have a habit of reading privacy policies. This fact may occur due to the time spent on reading these policies technical or even users’ lack of interest. On a previous work, in order to facilitate the presentation of privacy policies from online services, a prototype called PPMark was developed in order to read policy texts and show what kind of data was being collected and to what end are were presented in a privacy label format. The goal of this work is to assess the users’ confidence on the information extracted by this prototype. Given the results, the prototype proved that it is easy to use, it can decrease the time spent on reading policies and that users trust the information extracted, thus facilitating the computer human interaction (user x privacy policies). © 2017 AIS/ICIS Administrative Office. All Rights Reserved.', 'affiliations': 'Computer Science Department, Federal University of São Carlos, Brazil', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048456624&partnerID=40&md5=de86f901325a512ac1981cad9fd5df90', 'volume': '2017-August', 'journal': ""AMCIS 2017 - America's Conference on Information Systems: A Tradition of Innovation"", 'year': '2017', 'title': 'Evaluation of the reliability of using the prototype ppmark - A tool to support the computer human interaction in readings the privacy policies - Using the GQM and TAM models', 'author': 'Pontes, Diego Roberto Gonçalves and Zorzo, Sergio Donizetti and de Mello, Jose Santiago Moreira', 'ENTRYTYPE': 'conference', 'ID': 'Pontes2017'}",Scopus
"Ghassemi, Mohsen and Sarwate, Anand D. and Wright, Rebecca N.",Differentially private online active learning with applications to anomaly detection,,"In settings where data instances are generated sequentially or in streaming fashion, online learning algorithms can learn predictors using incremental training algorithms such as stochastic gradient descent. In some security applications such as training anomaly detectors, the data streams may consist of private information or transactions and the output of the learning algorithms may reveal information about the training data. Differential privacy is a framework for quantifying the privacy risk in such settings. This paper proposes two differentially private strategies to mitigate privacy risk when training a classifier for anomaly detection in an online setting. The first is to use a randomized active learning heuristic to screen out uninformative data points in the stream. The second is to use mini-batching to improve classifier performance. Experimental results show how these two strategies can trade off privacy, label complexity, and generalization performance. © 2016 ACM.",2016,"AISec 2016 - Proceedings of the 2016 ACM Workshop on Artificial Intelligence and Security, co-located with CCS 2016",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002235360&doi=10.1145%2f2996758.2996766&partnerID=40&md5=16c70c65ba04fdb950bfba62992cb78c,"{'note': 'All Open Access, Bronze Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery, Inc', 'abstract': 'In settings where data instances are generated sequentially or in streaming fashion, online learning algorithms can learn predictors using incremental training algorithms such as stochastic gradient descent. In some security applications such as training anomaly detectors, the data streams may consist of private information or transactions and the output of the learning algorithms may reveal information about the training data. Differential privacy is a framework for quantifying the privacy risk in such settings. This paper proposes two differentially private strategies to mitigate privacy risk when training a classifier for anomaly detection in an online setting. The first is to use a randomized active learning heuristic to screen out uninformative data points in the stream. The second is to use mini-batching to improve classifier performance. Experimental results show how these two strategies can trade off privacy, label complexity, and generalization performance. © 2016 ACM.', 'affiliations': 'Department of ECE, Rutgers University, Piscataway, NJ, United States; Department of CS, Rutgers University, Piscataway, NJ, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002235360&doi=10.1145%2f2996758.2996766&partnerID=40&md5=16c70c65ba04fdb950bfba62992cb78c', 'doi': '10.1145/2996758.2996766', 'pages': '117 – 128', 'journal': 'AISec 2016 - Proceedings of the 2016 ACM Workshop on Artificial Intelligence and Security, co-located with CCS 2016', 'year': '2016', 'title': 'Differentially private online active learning with applications to anomaly detection', 'author': 'Ghassemi, Mohsen and Sarwate, Anand D. and Wright, Rebecca N.', 'ENTRYTYPE': 'conference', 'ID': 'Ghassemi2016117'}",Scopus
"Payne, Dinah and Landry, Brett J. L. and Dean, Matthew D.",Data mining and privacy: An initial attempt at a comprehensive code of conduct for online business,,"The prevalence of data mining by businesses and government organizations raises concerns among many individuals about the privacy of their personal data. We address this issue by offering a different perspective that reconciles the conflicting desires of businesses and consumers. We describe privacy, data mining, and their interaction in the larger context, identify the costs and benefits of the uses of data mining, and discuss potential stakeholders found at the intersection of the two subjects. To help synthesize our proposed code of ethical conduct, we examine existing codes of conduct and how they relate to the issue of privacy in the context of data mining with people, processes, and technology. Showing that a uniform code of ethical conduct for online privacy is feasible from both a managerial and ethical perspective, we provide an initial philosophical and principle synthesis that businesses and organizations can tailor for their own specific customers and needs. The developed code of ethical conduct respects consumers’ desire for privacy while allowing businesses to use data mining techniques to elicit information that benefits both the business and the consumer. © 2015 by the Association for Information Systems.",2015,Communications of the Association for Information Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945424531&doi=10.17705%2f1cais.03734&partnerID=40&md5=36cbc68c6e353e1d9d5feb015e239968,"{'note': 'All Open Access, Bronze Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Association for Information Systems', 'abstract': 'The prevalence of data mining by businesses and government organizations raises concerns among many individuals about the privacy of their personal data. We address this issue by offering a different perspective that reconciles the conflicting desires of businesses and consumers. We describe privacy, data mining, and their interaction in the larger context, identify the costs and benefits of the uses of data mining, and discuss potential stakeholders found at the intersection of the two subjects. To help synthesize our proposed code of ethical conduct, we examine existing codes of conduct and how they relate to the issue of privacy in the context of data mining with people, processes, and technology. Showing that a uniform code of ethical conduct for online privacy is feasible from both a managerial and ethical perspective, we provide an initial philosophical and principle synthesis that businesses and organizations can tailor for their own specific customers and needs. The developed code of ethical conduct respects consumers’ desire for privacy while allowing businesses to use data mining techniques to elicit information that benefits both the business and the consumer. © 2015 by the Association for Information Systems.', 'affiliations': 'Department of Management, University of New Orleans, United States; Satish and Yasmin Gupta College of Business, University of Dallas, United States; School of Business, University of Southern Maine, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945424531&doi=10.17705%2f1cais.03734&partnerID=40&md5=36cbc68c6e353e1d9d5feb015e239968', 'doi': '10.17705/1cais.03734', 'pages': '717 – 732', 'number': '1', 'volume': '37', 'journal': 'Communications of the Association for Information Systems', 'year': '2015', 'title': 'Data mining and privacy: An initial attempt at a comprehensive code of conduct for online business', 'author': 'Payne, Dinah and Landry, Brett J. L. and Dean, Matthew D.', 'ENTRYTYPE': 'article', 'ID': 'Payne2015717'}",Scopus
"Fukushima, Keishiro and Ikeda, Daisuke and Nakamura, Toru and Kiyomoto, Shinsaku",Challenges in classifying privacy policies by machine learning with word-based features,,"In this paper, we discuss challenges when we try to automatically classify privacy policies using machine learning with words as the features. Since it is difficult for general public to understand privacy policies, it is necessary to support them to do that. To this end, the authors believe that machine learning is one of the promising ways because users can grasp the meaning of policies through outputs by a machine learning algorithm. Our final goal is to develop a system which automatically translates privacy policies into privacy labels [1]. Toward this goal, we classify sentences in privacy policies with category labels, using popular machine learning algorithms, such as a naive Bayes classifier. We choose these algorithms because we could use trained classifiers to evaluate keywords appropriate for privacy labels. Therefore, we adopt words as the features of those algorithms. Experimental results show about 85% accuracy. We think that much higher accuracy is necessary to achieve our final goal. By changing learning settings, we identified one reason of low accuracies such that privacy policies include many sentences which are not direct description of information about categories. It seems that such sentences are redundant but maybe they are essential in case of legal documents in order to prevent misinterpreting. Thus, it is important for machine learning algorithms to handle these redundant sentences appropriately. © 2018 Association for Computing Machinery.",2018,ACM International Conference Proceeding Series,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052022874&doi=10.1145%2f3199478.3199486&partnerID=40&md5=313f4c490f57b70213d267bd4bb475b2,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': 'In this paper, we discuss challenges when we try to automatically classify privacy policies using machine learning with words as the features. Since it is difficult for general public to understand privacy policies, it is necessary to support them to do that. To this end, the authors believe that machine learning is one of the promising ways because users can grasp the meaning of policies through outputs by a machine learning algorithm. Our final goal is to develop a system which automatically translates privacy policies into privacy labels [1]. Toward this goal, we classify sentences in privacy policies with category labels, using popular machine learning algorithms, such as a naive Bayes classifier. We choose these algorithms because we could use trained classifiers to evaluate keywords appropriate for privacy labels. Therefore, we adopt words as the features of those algorithms. Experimental results show about 85% accuracy. We think that much higher accuracy is necessary to achieve our final goal. By changing learning settings, we identified one reason of low accuracies such that privacy policies include many sentences which are not direct description of information about categories. It seems that such sentences are redundant but maybe they are essential in case of legal documents in order to prevent misinterpreting. Thus, it is important for machine learning algorithms to handle these redundant sentences appropriately. © 2018 Association for Computing Machinery.', 'affiliations': 'Department of Informatics, Kyushu University, Fukuoka, Japan; KDDI, Fujimino, Saitama, Japan', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052022874&doi=10.1145%2f3199478.3199486&partnerID=40&md5=313f4c490f57b70213d267bd4bb475b2', 'doi': '10.1145/3199478.3199486', 'pages': '62 – 66', 'journal': 'ACM International Conference Proceeding Series', 'year': '2018', 'title': 'Challenges in classifying privacy policies by machine learning with word-based features', 'author': 'Fukushima, Keishiro and Ikeda, Daisuke and Nakamura, Toru and Kiyomoto, Shinsaku', 'ENTRYTYPE': 'conference', 'ID': 'Fukushima201862'}",Scopus
"Prieto, Rafael Rodríguez","Food, Capitalism and Internet of Things",,"This chapter highlights the growing technological impact on the food industry as well as the advantages, risks and threats of IoT on food control and basic rights. I analyze the automated intervention by IoT devices and the rights of individuals and the productive process itself. As a result, new approaches for democratic food sovereign need to be developed. © 2021 by Nova Science Publishers, Inc.",2021,Food Security Issues and Challenges,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130666307&partnerID=40&md5=183d79bf874d5980ebe4af040343e603,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Book chapter', 'language': 'English', 'publisher': 'Nova Science Publishers, Inc.', 'abstract': 'This chapter highlights the growing technological impact on the food industry as well as the advantages, risks and threats of IoT on food control and basic rights. I analyze the automated intervention by IoT devices and the rights of individuals and the productive process itself. As a result, new approaches for democratic food sovereign need to be developed. © 2021 by Nova Science Publishers, Inc.', 'affiliations': 'Public Law Department, Pablo de Olavide University, Seville, Spain', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130666307&partnerID=40&md5=183d79bf874d5980ebe4af040343e603', 'pages': '315 – 330', 'journal': 'Food Security Issues and Challenges', 'year': '2021', 'title': 'Food, Capitalism and Internet of Things', 'author': 'Prieto, Rafael Rodríguez', 'ENTRYTYPE': 'book', 'ID': 'Prieto2021315'}",Scopus
"Zimmeck, Sebastian and Bellovin, Steven M.",Privee: An architecture for automatically analyzing web privacy policies,,"Privacy policies on websites are based on the notice-and-choice principle. They notify Web users of their privacy choices. However, many users do not read privacy policies or have difficulties understanding them. In order to increase privacy transparency we propose Privee - a software architecture for analyzing essential policy terms based on crowdsourcing and automatic classification techniques. We implement Privee in a proof of concept browser extension that retrieves policy analysis results from an online privacy policy repository or, if no such results are available, performs automatic classifications. While our classifiers achieve an overall F-1 score of 90%, our experimental results suggest that classifier performance is inherently limited as it correlates to the same variable to which human interpretations correlate - the ambiguity of natural language. This finding might be interpreted to call the notice-and-choice principle into question altogether. However, as our results further suggest that policy ambiguity decreases over time, we believe that the principle is workable. Consequently, we see Privee as a promising avenue for facilitating the notice-and-choice principle by accurately notifying Web users of privacy practices and increasing privacy transparency on the Web. copyright © 2014  USENIX Security Symposium.All right reserved.",2014,Proceedings of the 23rd USENIX Security Symposium,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066762295&partnerID=40&md5=d3c1ef40fcd7a8788919d1fbdc4cebde,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'USENIX Association', 'abstract': 'Privacy policies on websites are based on the notice-and-choice principle. They notify Web users of their privacy choices. However, many users do not read privacy policies or have difficulties understanding them. In order to increase privacy transparency we propose Privee - a software architecture for analyzing essential policy terms based on crowdsourcing and automatic classification techniques. We implement Privee in a proof of concept browser extension that retrieves policy analysis results from an online privacy policy repository or, if no such results are available, performs automatic classifications. While our classifiers achieve an overall F-1 score of 90%, our experimental results suggest that classifier performance is inherently limited as it correlates to the same variable to which human interpretations correlate - the ambiguity of natural language. This finding might be interpreted to call the notice-and-choice principle into question altogether. However, as our results further suggest that policy ambiguity decreases over time, we believe that the principle is workable. Consequently, we see Privee as a promising avenue for facilitating the notice-and-choice principle by accurately notifying Web users of privacy practices and increasing privacy transparency on the Web. copyright © 2014  USENIX Security Symposium.All right reserved.', 'affiliations': 'Department of Computer Science, Columbia University, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066762295&partnerID=40&md5=d3c1ef40fcd7a8788919d1fbdc4cebde', 'pages': '1 – 16', 'journal': 'Proceedings of the 23rd USENIX Security Symposium', 'year': '2014', 'title': 'Privee: An architecture for automatically analyzing web privacy policies', 'author': 'Zimmeck, Sebastian and Bellovin, Steven M.', 'ENTRYTYPE': 'conference', 'ID': 'Zimmeck20141'}",Scopus
"McDonald, Aleecia M. and Reeder, Robert W. and Kelley, Patrick Gage and Cranor, Lorrie Faith",A comparative study of online privacy policies and formats,,"Online privacy policies are difficult to understand. Most privacy policies require a college reading level and an ability to decode legalistic, confusing, or jargon-laden phrases. Privacy researchers and industry groups have devised several standardized privacy policy formats to address these issues and help people compare policies. We evaluated three formats in this paper: layered policies, which present a short form with standardized components in addition to a full policy; the Privacy Finder privacy report, which standardizes the text descriptions of privacy practices in a brief bulleted format; and conventional non-standardized human-readable policies. We contrasted six companies' policies, deliberately selected to span the range from unusually readable to challenging. Based on the results of our online study of 749 Internet users, we found participants were not able to reliably understand companies' privacy practices with any of the formats. Compared to natural language, participants were faster with standardized formats but at the expense of accuracy for layered policies. Privacy Finder formats supported accuracy more than natural language for harder questions. Improved readability scores did not translate to improved performance. All formats and policies were similarly disliked. We discuss our findings as well as public policy implications. © 2009 Springer Berlin Heidelberg.",2009,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),https://www.scopus.com/inward/record.uri?eid=2-s2.0-69949164208&doi=10.1007%2f978-3-642-03168-7_3&partnerID=40&md5=4aaeb627b904b3c3a7ea48c1ffbae58b,"{'note': 'All Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'abstract': ""Online privacy policies are difficult to understand. Most privacy policies require a college reading level and an ability to decode legalistic, confusing, or jargon-laden phrases. Privacy researchers and industry groups have devised several standardized privacy policy formats to address these issues and help people compare policies. We evaluated three formats in this paper: layered policies, which present a short form with standardized components in addition to a full policy; the Privacy Finder privacy report, which standardizes the text descriptions of privacy practices in a brief bulleted format; and conventional non-standardized human-readable policies. We contrasted six companies' policies, deliberately selected to span the range from unusually readable to challenging. Based on the results of our online study of 749 Internet users, we found participants were not able to reliably understand companies' privacy practices with any of the formats. Compared to natural language, participants were faster with standardized formats but at the expense of accuracy for layered policies. Privacy Finder formats supported accuracy more than natural language for harder questions. Improved readability scores did not translate to improved performance. All formats and policies were similarly disliked. We discuss our findings as well as public policy implications. © 2009 Springer Berlin Heidelberg."", 'affiliations': 'Carnegie Mellon, Pittsburgh, PA, United States; Microsoft, Redmond, WA, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-69949164208&doi=10.1007%2f978-3-642-03168-7_3&partnerID=40&md5=4aaeb627b904b3c3a7ea48c1ffbae58b', 'doi': '10.1007/978-3-642-03168-7_3', 'pages': '37 – 55', 'volume': '5672 LNCS', 'journal': 'Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)', 'year': '2009', 'title': 'A comparative study of online privacy policies and formats', 'author': 'McDonald, Aleecia M. and Reeder, Robert W. and Kelley, Patrick Gage and Cranor, Lorrie Faith', 'ENTRYTYPE': 'article', 'ID': 'McDonald200937'}",Scopus
"Al-Harbi, Aiman Lafi and Osborn, Sylvia L.",Mixing privacy with role-based access control,,"In this paper we investigate different alternatives for including privacy purposes into role-based access control. We emphasize that not all permissions have a purpose, only those which deal with the use of data about individuals stored in a system need to have privacy labels. We develop a model for including privacy purposes in the Role Graph Model, and show its implementation in a prototype. © 2011 ACM.",2011,ACM International Conference Proceeding Series,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959832222&doi=10.1145%2f1992896.1992897&partnerID=40&md5=6223b5d85708b037f2f5b96d90712adf,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'abstract': 'In this paper we investigate different alternatives for including privacy purposes into role-based access control. We emphasize that not all permissions have a purpose, only those which deal with the use of data about individuals stored in a system need to have privacy labels. We develop a model for including privacy purposes in the Role Graph Model, and show its implementation in a prototype. © 2011 ACM.', 'affiliations': 'Department of Computer Science, University of Western Ontario, London, ON N6A 5B7, Canada; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON N2L 3G1, Canada', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959832222&doi=10.1145%2f1992896.1992897&partnerID=40&md5=6223b5d85708b037f2f5b96d90712adf', 'doi': '10.1145/1992896.1992897', 'pages': '1 – 7', 'journal': 'ACM International Conference Proceeding Series', 'year': '2011', 'title': 'Mixing privacy with role-based access control', 'author': 'Al-Harbi, Aiman Lafi and Osborn, Sylvia L.', 'ENTRYTYPE': 'conference', 'ID': 'Al-Harbi20111'}",Scopus
"Jakobi, Timo and von Grafenstein, Maximilian and Legner, Christine and Labadie, Clément and Mertens, Peter and Öksüz, Ayten and Stevens, Gunnar",The Role of IS in the Conflicting Interests Regarding GDPR,,,2020,Business and Information Systems Engineering,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081675644&doi=10.1007%2fs12599-020-00633-4&partnerID=40&md5=9631795d47c9bcd200645bd5446ce96a,"{'note': 'All Open Access, Green Open Access, Hybrid Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Springer Gabler', 'affiliations': 'Information Systems esp. IT-Security and Privacy, University of Siegen, Siegen, Germany; Berlin University of the Arts, Einstein Center Digital Future, Berlin, Germany; Faculty of Business and Economics (HEC), University of Lausanne, Lausanne, Switzerland; School of Business, Economics and Society and Faculty of Engineering, University of Erlangen-Nuremberg, Nuremberg, Germany; Consumer Association of North Rhine-Westphalia, Düsseldorf, North Rhine-Westphalia, Germany', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081675644&doi=10.1007%2fs12599-020-00633-4&partnerID=40&md5=9631795d47c9bcd200645bd5446ce96a', 'doi': '10.1007/s12599-020-00633-4', 'pages': '261 – 272', 'number': '3', 'volume': '62', 'journal': 'Business and Information Systems Engineering', 'year': '2020', 'title': 'The Role of IS in the Conflicting Interests Regarding GDPR', 'author': 'Jakobi, Timo and von Grafenstein, Maximilian and Legner, Christine and Labadie, Clément and Mertens, Peter and Öksüz, Ayten and Stevens, Gunnar', 'ENTRYTYPE': 'article', 'ID': 'Jakobi2020261'}",Scopus
,"International Conference on Computational Science and Its Applications, ICCSA 2004",,"The proceedings contain 117 papers. The special focus in this conference is on Grid Computing, Resource Management, Scheduling Techniques for Cluster, Grid Computing Systems and Distributed Computing. The topics include: Advanced simulation technique for modeling multiphase fluid flow in porous media; a smart agent-based grid computing platform; publishing and executing parallel legacy code using an OGSI grid service; the prove trace visualisation tool as a grid service; privacy protection in ubiquitous computing based on privacy label and information flow; application-oriented scheduling in the knowledge grid; a monitoring and prediction tool for time-constraint grid application; optimal server allocation in reconfigurable clusters with multiple job types; design and evaluation of an agent-based communication model for a parallel file system; task allocation for minimizing programs completion time in multicomputer systems; adaptive interval-based caching management scheme for cluster video server; data discovery mechanism for a large peer-to-peer based scientific data grid environment; running data mining applications on the grid; application of block design to a load balancing algorithm on distributed networks; maintenance strategy for efficient communication at data warehouse; a framework for orthogonal data and control parallelism exploitation; unified development solution for cluster and grid computing and its application in chemistry; a modified parallel computation model based on cluster; a parallel volume splatting algorithm based on pc-clusters and numerical revelation and analysis of critical ignition conditions for branch chain reactions by Hamiltonian systematization methods of kinetic models.",2004,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945274882&partnerID=40&md5=ecd8cb87e44956349dc8c993529e0f57,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference review', 'language': 'English', 'publisher': 'Springer Verlag', 'abstract': 'The proceedings contain 117 papers. The special focus in this conference is on Grid Computing, Resource Management, Scheduling Techniques for Cluster, Grid Computing Systems and Distributed Computing. The topics include: Advanced simulation technique for modeling multiphase fluid flow in porous media; a smart agent-based grid computing platform; publishing and executing parallel legacy code using an OGSI grid service; the prove trace visualisation tool as a grid service; privacy protection in ubiquitous computing based on privacy label and information flow; application-oriented scheduling in the knowledge grid; a monitoring and prediction tool for time-constraint grid application; optimal server allocation in reconfigurable clusters with multiple job types; design and evaluation of an agent-based communication model for a parallel file system; task allocation for minimizing programs completion time in multicomputer systems; adaptive interval-based caching management scheme for cluster video server; data discovery mechanism for a large peer-to-peer based scientific data grid environment; running data mining applications on the grid; application of block design to a load balancing algorithm on distributed networks; maintenance strategy for efficient communication at data warehouse; a framework for orthogonal data and control parallelism exploitation; unified development solution for cluster and grid computing and its application in chemistry; a modified parallel computation model based on cluster; a parallel volume splatting algorithm based on pc-clusters and numerical revelation and analysis of critical ignition conditions for branch chain reactions by Hamiltonian systematization methods of kinetic models.', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945274882&partnerID=40&md5=ecd8cb87e44956349dc8c993529e0f57', 'pages': '1 – 1139', 'volume': '3044', 'journal': 'Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)', 'year': '2004', 'title': 'International Conference on Computational Science and Its Applications, ICCSA 2004', 'ENTRYTYPE': 'article', 'ID': '20041'}",Scopus
"Xie, Rongna and Fan, Xiaonan and Yuan, Lin and Guo, Zichen and Zhu, Jiayu and Shi, Guozhen",Research on extended access control mechanism in online social network,,"Aiming at the problem of inability to extend control over the data published by users in social networks, an extended access mechanism based on privacy labels was proposed. This mechanism granted users and data different types of labels based on the number of user relationship hops and resource forwarding hops, so as to achieve fine-grained extended access control to the data. The generation algorithm and distribution method of privacy labels were proposed. The constraint rules of privacy label were designed and the possible policy conflicts were analyzed. Finally, the test proves that the mechanism achieves fine-grained extended control in social networks, and proves its security and validity of the mechanism. © 2021, Beijing Xintong Media Co., Ltd.. All rights reserved.",2021,Chinese Journal of Network and Information Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120861982&doi=10.11959%2fj.issn.2096-109x.2021075&partnerID=40&md5=866266aeacaf9c5ad8741572a8f79bbe,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'Chinese', 'publisher': 'Beijing Xintong Media Co., Ltd.', 'abstract': 'Aiming at the problem of inability to extend control over the data published by users in social networks, an extended access mechanism based on privacy labels was proposed. This mechanism granted users and data different types of labels based on the number of user relationship hops and resource forwarding hops, so as to achieve fine-grained extended access control to the data. The generation algorithm and distribution method of privacy labels were proposed. The constraint rules of privacy label were designed and the possible policy conflicts were analyzed. Finally, the test proves that the mechanism achieves fine-grained extended control in social networks, and proves its security and validity of the mechanism. © 2021, Beijing Xintong Media Co., Ltd.. All rights reserved.', 'affiliations': 'Department of Cryptography and Science Technology, Beijing Electronic Science and Technology Institute, Beijing, 100070, China', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120861982&doi=10.11959%2fj.issn.2096-109x.2021075&partnerID=40&md5=866266aeacaf9c5ad8741572a8f79bbe', 'doi': '10.11959/j.issn.2096-109x.2021075', 'pages': '123 – 131', 'number': '5', 'volume': '7', 'journal': 'Chinese Journal of Network and Information Security', 'year': '2021', 'title': 'Research on extended access control mechanism in online social network', 'author': 'Xie, Rongna and Fan, Xiaonan and Yuan, Lin and Guo, Zichen and Zhu, Jiayu and Shi, Guozhen', 'ENTRYTYPE': 'article', 'ID': 'Xie2021123'}",Scopus
"Hwang, Seong Oun and Yoon, Ki Song",Privacy protection in ubiquitous computing based on privacy label and information flow,,"The vision of upcoming ubiquitous computing environment allows us to exchange and share information with any parties any time, anywhere if we want. However, the widespread use of computing devices and sensors networked together could be a considerable threat to the privacy of individuals living in the ubiquitous computing environment. In the paper, we investigate privacy issues in the ubiquitous computing environment and present a model of privacy protection and an example architecture to support it. The proposed architecture ensures that individuals not only get benefits and services from ubiquitous environment by freely exchanging and sharing information, but they also preserve their own privacy. © Springer-Verlag 2004.",2004,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),https://www.scopus.com/inward/record.uri?eid=2-s2.0-35048814020&doi=10.1007%2f978-3-540-24709-8_6&partnerID=40&md5=9d2bb268ac01601db9379e9166f0e5e1,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Springer Verlag', 'abstract': 'The vision of upcoming ubiquitous computing environment allows us to exchange and share information with any parties any time, anywhere if we want. However, the widespread use of computing devices and sensors networked together could be a considerable threat to the privacy of individuals living in the ubiquitous computing environment. In the paper, we investigate privacy issues in the ubiquitous computing environment and present a model of privacy protection and an example architecture to support it. The proposed architecture ensures that individuals not only get benefits and services from ubiquitous environment by freely exchanging and sharing information, but they also preserve their own privacy. © Springer-Verlag 2004.', 'affiliations': 'Electronics and Telecommunications Research Institute, Yuseong-gu, Daejeon, 161 Gajeong-dong, South Korea', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-35048814020&doi=10.1007%2f978-3-540-24709-8_6&partnerID=40&md5=9d2bb268ac01601db9379e9166f0e5e1', 'doi': '10.1007/978-3-540-24709-8_6', 'pages': '46 – 54', 'volume': '3044', 'journal': 'Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)', 'year': '2004', 'title': 'Privacy protection in ubiquitous computing based on privacy label and information flow', 'author': 'Hwang, Seong Oun and Yoon, Ki Song', 'ENTRYTYPE': 'article', 'ID': 'Hwang200446'}",Scopus
"Fox, Grace and Tonge, Colin and Lynn, Theo and Mooney, John",Communicating compliance: Developing a GDPR privacy label,,"The growing pervasiveness of technology enables the collection of copious volumes of personal data which creates risks for consumer privacy and makes data protection increasingly complex for organizations. The difficulties facing organizations are further exasperated by the EU General Data Protection Regulation (GDPR), which introduces stringent requirements for gaining consent, communicating privacy practices, and transparency. Furthermore, consumers' current lack of privacy knowledge can heighten privacy concerns. This study aims to (1) build consumer privacy knowledge and (2) assist organizations in gaining explicit consent and communicating their privacy practices to current and potential customers, through the development of a GDPR privacy label. The paper contributes to practice by providing actionable guidelines for developing GDPR compliant privacy notices and advances privacy literature by extending the privacy knowledge gap model and testing the effectiveness of the GDPR label in improving consumers' privacy knowledge thereby building self-efficacy and enabling informed decision making. © 2018 Association for Information Systems. All rights reserved.",2018,"Americas Conference on Information Systems 2018: Digital Disruption, AMCIS 2018",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054269735&partnerID=40&md5=16c5937e83e871395d9d18a5401e5edd,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Information Systems', 'abstract': ""The growing pervasiveness of technology enables the collection of copious volumes of personal data which creates risks for consumer privacy and makes data protection increasingly complex for organizations. The difficulties facing organizations are further exasperated by the EU General Data Protection Regulation (GDPR), which introduces stringent requirements for gaining consent, communicating privacy practices, and transparency. Furthermore, consumers' current lack of privacy knowledge can heighten privacy concerns. This study aims to (1) build consumer privacy knowledge and (2) assist organizations in gaining explicit consent and communicating their privacy practices to current and potential customers, through the development of a GDPR privacy label. The paper contributes to practice by providing actionable guidelines for developing GDPR compliant privacy notices and advances privacy literature by extending the privacy knowledge gap model and testing the effectiveness of the GDPR label in improving consumers' privacy knowledge thereby building self-efficacy and enabling informed decision making. © 2018 Association for Information Systems. All rights reserved."", 'affiliations': 'Irish Centre for Cloud Computing and Commerce, Dublin City University, Ireland; Pepperdine University, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054269735&partnerID=40&md5=16c5937e83e871395d9d18a5401e5edd', 'journal': 'Americas Conference on Information Systems 2018: Digital Disruption, AMCIS 2018', 'year': '2018', 'title': 'Communicating compliance: Developing a GDPR privacy label', 'author': 'Fox, Grace and Tonge, Colin and Lynn, Theo and Mooney, John', 'ENTRYTYPE': 'conference', 'ID': 'Fox2018'}",Scopus
"Armac, Ibrahim and Panchenko, Andriy and Pettau, Marcel and Retkowitz, Daniel",Privacy-friendly smart environments,,"In this paper we describe our approach on protecting user privacy in smart environments, particularly smart homes, which we call eHomes. These are environments with devices such as sensors, computational units, actors, which are seamlessly integrated in the environment, and objects we use in our everyday life. In order to provide more convenience to its users such environments can be personalized. As these environments become ubiquitous, thus supporting mobility of the users, new privacy threats arise. These are based on the digital traces and personal information which is left while visiting different environments. We provide a practical approach to minimize these traces and information disclosure by applying negotiation, identity management, and anonymous credentials. Also, we discuss the protection of eHomes from malicious users. © 2009 IEEE.",2009,"NGMAST 2009 - 3rd International Conference on Next Generation Mobile Applications, Services and Technologies",https://www.scopus.com/inward/record.uri?eid=2-s2.0-74049140815&doi=10.1109%2fNGMAST.2009.23&partnerID=40&md5=96b86839f8a579ee63be0c2a38b8b921,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'abstract': 'In this paper we describe our approach on protecting user privacy in smart environments, particularly smart homes, which we call eHomes. These are environments with devices such as sensors, computational units, actors, which are seamlessly integrated in the environment, and objects we use in our everyday life. In order to provide more convenience to its users such environments can be personalized. As these environments become ubiquitous, thus supporting mobility of the users, new privacy threats arise. These are based on the digital traces and personal information which is left while visiting different environments. We provide a practical approach to minimize these traces and information disclosure by applying negotiation, identity management, and anonymous credentials. Also, we discuss the protection of eHomes from malicious users. © 2009 IEEE.', 'affiliations': 'Department of Computer Science, RWTH Aachen University, 52074 Aachen, Ahornstr. 55, Germany', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-74049140815&doi=10.1109%2fNGMAST.2009.23&partnerID=40&md5=96b86839f8a579ee63be0c2a38b8b921', 'doi': '10.1109/NGMAST.2009.23', 'pages': '425 – 431', 'journal': 'NGMAST 2009 - 3rd International Conference on Next Generation Mobile Applications, Services and Technologies', 'year': '2009', 'title': 'Privacy-friendly smart environments', 'author': 'Armac, Ibrahim and Panchenko, Andriy and Pettau, Marcel and Retkowitz, Daniel', 'ENTRYTYPE': 'conference', 'ID': 'Armac2009425'}",Scopus
"Finn, Lisa",Complications: An analysis of medical abortions in the US,,"Introduction The advent of medical abortion methods, using either methotrexate or mifepristone (RU 486) combined with misoprostol, represents the first new abortion option for women in twenty years. Medical abortion, a procedure during which abortion is induced by a medication rather than through surgery, has the potential to change the terms in which abortion debates are fought. In comparison to surgical procedures, such as suction curettage, medical abortions can be performed earlier (at four to seven weeks’ gestation as opposed to seven weeks and later), will allow women to avoid surgery and anesthetics, will eliminate the risk of cervical laceration or perforation, and can be managed in the privacy of a physician’s office and a woman’s home, thus making direct intervention by anti-abortionists less likely. Though both mifepristone and methotrexate share these assets, methotrexate is more difficult for anti-abortionists to track; while mifepristone is primarily employed to induce abortion, methotrexate is indispensable for other applications, including the treatment of psoriasis, rheumatoid arthritis, systemic lupus erythematosus, Crohn’s disease, a variety of cancerous tumors, and ectopic pregnancies (Schaff et at. 1996: 198). In the US, this advantage represents a significant political and practical consideration in relation to current anti-abortion tactics in that, though its use may be regulated, methotrexate will not be taken off the market. © 2000 Selection and editorial matte r Jan ine Marchessault and Kim Sawchuk; and individual chapters the contributors. All rights reserved.",2013,"Wild Science: Reading Feminism, Medicine and the Media",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070023036&doi=10.4324%2f9781315008851-20&partnerID=40&md5=7857ecb7608a1591101897bd7baa3571,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Book chapter', 'language': 'English', 'publisher': 'Taylor and Francis', 'abstract': 'Introduction The advent of medical abortion methods, using either methotrexate or mifepristone (RU 486) combined with misoprostol, represents the first new abortion option for women in twenty years. Medical abortion, a procedure during which abortion is induced by a medication rather than through surgery, has the potential to change the terms in which abortion debates are fought. In comparison to surgical procedures, such as suction curettage, medical abortions can be performed earlier (at four to seven weeks’ gestation as opposed to seven weeks and later), will allow women to avoid surgery and anesthetics, will eliminate the risk of cervical laceration or perforation, and can be managed in the privacy of a physician’s office and a woman’s home, thus making direct intervention by anti-abortionists less likely. Though both mifepristone and methotrexate share these assets, methotrexate is more difficult for anti-abortionists to track; while mifepristone is primarily employed to induce abortion, methotrexate is indispensable for other applications, including the treatment of psoriasis, rheumatoid arthritis, systemic lupus erythematosus, Crohn’s disease, a variety of cancerous tumors, and ectopic pregnancies (Schaff et at. 1996: 198). In the US, this advantage represents a significant political and practical consideration in relation to current anti-abortion tactics in that, though its use may be regulated, methotrexate will not be taken off the market. © 2000 Selection and editorial matte r Jan ine Marchessault and Kim Sawchuk; and individual chapters the contributors. All rights reserved.', 'affiliations': 'University of Rochester, Rochester, NY, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070023036&doi=10.4324%2f9781315008851-20&partnerID=40&md5=7857ecb7608a1591101897bd7baa3571', 'doi': '10.4324/9781315008851-20', 'pages': '151 – 166', 'journal': 'Wild Science: Reading Feminism, Medicine and the Media', 'year': '2013', 'title': 'Complications: An analysis of medical abortions in the US', 'author': 'Finn, Lisa', 'ENTRYTYPE': 'book', 'ID': 'Finn2013151'}",Scopus
"Herzog, Lisa and Kellmeyer, Philipp and Wild, Verina","Digital behavioral technology, vulnerability and justice: towards an integrated approach",,"The paper introduces the notion of ‘digital behavioral technologies’ and discusses them from the perspectives of vulnerability and justice, thereby integrating perspectives from bioethics or public health ethics and political philosophy. Digital behavioral technologies have seen a massive uptake in recent years, but the market for them is hardly regulated. We argue that understanding the impact of digital behavioral technologies requires understanding individuals not as abstract, atomized agents, but rather to take their embeddedness into social structures into account. This also allows extending the focus to groups, relationships and whole societies, which are often structurally unjust. This perspective provides a corrective to an overly individualistic consideration of digital behavioral technologies, which may suggest itself because of their focus on individual bodies. We point out some implications of this integrated approach with regard to the regulation of digital behavioral technologies. We conclude by describing some implications both for those who work on digital behavioral technologies and for those who work on questions of vulnerability and justice. © 2021 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",2022,Review of Social Economy,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121860467&doi=10.1080%2f00346764.2021.1943755&partnerID=40&md5=effa4a27971f5c5c1332f0a057567625,"{'note': 'All Open Access, Hybrid Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Routledge', 'abstract': 'The paper introduces the notion of ‘digital behavioral technologies’ and discusses them from the perspectives of vulnerability and justice, thereby integrating perspectives from bioethics or public health ethics and political philosophy. Digital behavioral technologies have seen a massive uptake in recent years, but the market for them is hardly regulated. We argue that understanding the impact of digital behavioral technologies requires understanding individuals not as abstract, atomized agents, but rather to take their embeddedness into social structures into account. This also allows extending the focus to groups, relationships and whole societies, which are often structurally unjust. This perspective provides a corrective to an overly individualistic consideration of digital behavioral technologies, which may suggest itself because of their focus on individual bodies. We point out some implications of this integrated approach with regard to the regulation of digital behavioral technologies. We conclude by describing some implications both for those who work on digital behavioral technologies and for those who work on questions of vulnerability and justice. © 2021 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.', 'affiliations': 'Faculty of Philosophy and Center for Philosophy, Politics and Economics, University of Groningen, Groningen, Netherlands; Neuroethics and AI Ethics Lab, University Medical Center Freiburg, Freiburg im Breisgau, Germany; Ethik der Medizin, Universität Augsburg, Medizinische Fakultät, Augsburg, Germany', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121860467&doi=10.1080%2f00346764.2021.1943755&partnerID=40&md5=effa4a27971f5c5c1332f0a057567625', 'doi': '10.1080/00346764.2021.1943755', 'pages': '7 – 28', 'number': '1', 'volume': '80', 'journal': 'Review of Social Economy', 'year': '2022', 'title': 'Digital behavioral technology, vulnerability and justice: towards an integrated approach', 'author': 'Herzog, Lisa and Kellmeyer, Philipp and Wild, Verina', 'ENTRYTYPE': 'article', 'ID': 'Herzog20227'}",Scopus
"Grewal, Rajdeep and Gupta, Sachin and Hamilton, Rebecca","Marketing Insights from Multimedia Data: Text, Image, Audio, and Video",,,2021,Journal of Marketing Research,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119022626&doi=10.1177%2f00222437211054601&partnerID=40&md5=27ec20651e3ee78b550d69b7f3b7138e,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Editorial', 'language': 'English', 'publisher': 'SAGE Publications Ltd', 'affiliations': 'Kenan-Flagler Business School, University of North Carolina at Chapel Hill, United States; S.C. Johnson College of Business, Cornell University, United States; McDonough School of Business, Georgetown University, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119022626&doi=10.1177%2f00222437211054601&partnerID=40&md5=27ec20651e3ee78b550d69b7f3b7138e', 'doi': '10.1177/00222437211054601', 'pages': '1025 – 1033', 'number': '6', 'volume': '58', 'journal': 'Journal of Marketing Research', 'year': '2021', 'title': 'Marketing Insights from Multimedia Data: Text, Image, Audio, and Video', 'author': 'Grewal, Rajdeep and Gupta, Sachin and Hamilton, Rebecca', 'ENTRYTYPE': 'article', 'ID': 'Grewal20211025'}",Scopus
,"7th Annual Privacy Forum, APF 2019",,"The proceedings contain 12 papers. The special focus in this conference is on Annual Privacy Forum. The topics include: A Data Protection by Design Model for Privacy Management in Electronic Health Records; security Analysis of Subject Access Request Procedures: How to Authenticate Data Subjects Safely When They Request for Their Data; towards Transparency in Email Tracking; sharing Cyber Threat Intelligence Under the General Data Protection Regulation; fight to Be Forgotten: Exploring the Efficacy of Data Erasure in Popular Operating Systems; privacy Beyond Confidentiality, Data Science Beyond Spying: From Movement Data and Data Privacy Towards a Wider Fundamental Rights Discourse; making Machine Learning Forget; a Multilateral Privacy Impact Analysis Method for Android Apps; re-using Personal Data for Statistical and Research Purposes in the Context of Big Data and Artificial Intelligence; ioT Security and Privacy Labels.",2019,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067814936&partnerID=40&md5=8745e5efac7a62ccfbbedd526bf6e7d2,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference review', 'language': 'English', 'publisher': 'Springer Verlag', 'abstract': 'The proceedings contain 12 papers. The special focus in this conference is on Annual Privacy Forum. The topics include: A Data Protection by Design Model for Privacy Management in Electronic Health Records; security Analysis of Subject Access Request Procedures: How to Authenticate Data Subjects Safely When They Request for Their Data; towards Transparency in Email Tracking; sharing Cyber Threat Intelligence Under the General Data Protection Regulation; fight to Be Forgotten: Exploring the Efficacy of Data Erasure in Popular Operating Systems; privacy Beyond Confidentiality, Data Science Beyond Spying: From Movement Data and Data Privacy Towards a Wider Fundamental Rights Discourse; making Machine Learning Forget; a Multilateral Privacy Impact Analysis Method for Android Apps; re-using Personal Data for Statistical and Research Purposes in the Context of Big Data and Artificial Intelligence; ioT Security and Privacy Labels.', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067814936&partnerID=40&md5=8745e5efac7a62ccfbbedd526bf6e7d2', 'volume': '11498 LNCS', 'journal': 'Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)', 'year': '2019', 'title': '7th Annual Privacy Forum, APF 2019', 'ENTRYTYPE': 'article', 'ID': '2019'}",Scopus
"Pikulík, Tomáš and Štarchoň, Peter",GDPR: The Battle for European Consumer Data,,"Implementation of the GDPR changed the way how personal data of EU customers are processed. The purpose of this chapter is to explore the links between the rights of customers as a data subject and related aspects of customer satisfaction. Entities in modern economy (encompassing not only goods and services but also intellectual property) generate and process huge quantities of customer data. Information and communication technology (ICT) infrastructure became a basis for the digital economy and society in the EU (settled by Eurostat as ISOC) that definitely replaced the previous era of the information economy that was based on the effective acquisition, dissemination, and use of information. Data-driven marketing puts data at the center of additional value creation and brings new insights and perspectives, included in the results of this research. The impact of GDPR on customer-centric ICT, stronger consumer awareness of data protection rights, creates new pathways to customer centricity and the legal and technical aspects of data processing within the digital economy ecosystem. © 2021, IGI Global.",2021,Research Anthology on Privatizing and Securing Data,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134898712&doi=10.4018%2f978-1-7998-8954-0.ch085&partnerID=40&md5=3ead05d6975b3abb0ef3f21b0a611c0e,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Book chapter', 'language': 'English', 'publisher': 'IGI Global', 'abstract': 'Implementation of the GDPR changed the way how personal data of EU customers are processed. The purpose of this chapter is to explore the links between the rights of customers as a data subject and related aspects of customer satisfaction. Entities in modern economy (encompassing not only goods and services but also intellectual property) generate and process huge quantities of customer data. Information and communication technology (ICT) infrastructure became a basis for the digital economy and society in the EU (settled by Eurostat as ISOC) that definitely replaced the previous era of the information economy that was based on the effective acquisition, dissemination, and use of information. Data-driven marketing puts data at the center of additional value creation and brings new insights and perspectives, included in the results of this research. The impact of GDPR on customer-centric ICT, stronger consumer awareness of data protection rights, creates new pathways to customer centricity and the legal and technical aspects of data processing within the digital economy ecosystem. © 2021, IGI Global.', 'affiliations': 'Faculty of Management, Comenius University, Bratislava, Slovakia', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134898712&doi=10.4018%2f978-1-7998-8954-0.ch085&partnerID=40&md5=3ead05d6975b3abb0ef3f21b0a611c0e', 'doi': '10.4018/978-1-7998-8954-0.ch085', 'pages': '1769 – 1789', 'journal': 'Research Anthology on Privatizing and Securing Data', 'year': '2021', 'title': 'GDPR: The Battle for European Consumer Data', 'author': 'Pikulík, Tomáš and Štarchoň, Peter', 'ENTRYTYPE': 'book', 'ID': 'Pikulík20211769'}",Scopus
"Fang, Lujun and LeFevre, Kristen",Privacy wizards for social networking sites,,"Privacy is an enormous problem in online social networking sites. While sites such as Facebook allow users fine-grained control over who can see their profiles, it is difficult for average users to specify this kind of detailed policy. In this paper, we propose a template for the design of a social networking privacy wizard. The intuition for the design comes from the observation that real users conceive their privacy preferences (which friends should be able to see which information) based on an implicit set of rules. Thus, with a limited amount of user input, it is usually possible to build a machine learning model that concisely describes a particular user's preferences, and then use this model to configure the user's privacy settings automatically. As an instance of this general framework, we have built a wizard based on an active learning paradigm called uncertainty sampling. The wizard iteratively asks the user to assign privacy ""labels"" to selected (""informative"") friends, and it uses this input to construct a classifier, which can in turn be used to automatically assign privileges to the rest of the user's (unlabeled) friends. To evaluate our approach, we collected detailed privacy preference data from 45 real Facebook users. Our study revealed two important things. First, real users tend to conceive their privacy preferences in terms of communities, which can easily be extracted from a social network graph using existing techniques. Second, our active learning wizard, using communities as features, is able to recommend high-accuracy privacy settings using less user input than existing policy-specification tools. © 2010 International World Wide Web Conference Committee (IW3C2).",2010,"Proceedings of the 19th International Conference on World Wide Web, WWW '10",https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954614450&doi=10.1145%2f1772690.1772727&partnerID=40&md5=1f6972edb3b34252a5c5a27254c32d58,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'abstract': 'Privacy is an enormous problem in online social networking sites. While sites such as Facebook allow users fine-grained control over who can see their profiles, it is difficult for average users to specify this kind of detailed policy. In this paper, we propose a template for the design of a social networking privacy wizard. The intuition for the design comes from the observation that real users conceive their privacy preferences (which friends should be able to see which information) based on an implicit set of rules. Thus, with a limited amount of user input, it is usually possible to build a machine learning model that concisely describes a particular user\'s preferences, and then use this model to configure the user\'s privacy settings automatically. As an instance of this general framework, we have built a wizard based on an active learning paradigm called uncertainty sampling. The wizard iteratively asks the user to assign privacy ""labels"" to selected (""informative"") friends, and it uses this input to construct a classifier, which can in turn be used to automatically assign privileges to the rest of the user\'s (unlabeled) friends. To evaluate our approach, we collected detailed privacy preference data from 45 real Facebook users. Our study revealed two important things. First, real users tend to conceive their privacy preferences in terms of communities, which can easily be extracted from a social network graph using existing techniques. Second, our active learning wizard, using communities as features, is able to recommend high-accuracy privacy settings using less user input than existing policy-specification tools. © 2010 International World Wide Web Conference Committee (IW3C2).', 'affiliations': 'Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI 48109, 2260 Hayward Ave., United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954614450&doi=10.1145%2f1772690.1772727&partnerID=40&md5=1f6972edb3b34252a5c5a27254c32d58', 'doi': '10.1145/1772690.1772727', 'pages': '351 – 360', 'journal': ""Proceedings of the 19th International Conference on World Wide Web, WWW '10"", 'year': '2010', 'title': 'Privacy wizards for social networking sites', 'author': 'Fang, Lujun and LeFevre, Kristen', 'ENTRYTYPE': 'conference', 'ID': 'Fang2010351'}",Scopus
"Jaradat, Shatha and Dokoohaki, Nima and Matskin, Mihhail and Ferrari, Elena",Trust and privacy correlations in social networks: A deep learning framework,,"Online Social Networks (OSNs) remain the focal point of Internet usage. Since the beginning, networking sites tried best to have right privacy mechanisms in place for users, enabling them to share the right content with the right audience. With all these efforts, privacy customizations remain hard for users across the sites. Existing research that address this problem mainly focus on semi-supervised strategies that introduce extra complexity by requiring the user to manually specify initial privacy preferences for their friends. In this work, we suggest an adaptive solution that can dynamically generate privacy labels for users in OSNs. To this end, we introduce a deep reinforcement learning framework that targets two key problems in OSNs like Facebook: the exposure of users' interactions through the network to less trusted direct friends, and the possibility of propagating user updates through direct friends' interactions to indirect friends. By implementing this framework, we aim at understanding how social trust and privacy could be correlated, specifically in a dynamic fashion. We report the ranked dependence between the generated privacy labels and the estimated user trust values, which indicate the ability of the framework to identify the highly trusted users and share with them higher percentages of data. © 2016 IEEE.",2016,"Proceedings of the 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2016",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006765626&doi=10.1109%2fASONAM.2016.7752236&partnerID=40&md5=fb08bc9dfc0d971eb728bd1856cff9d7,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Institute of Electrical and Electronics Engineers Inc.', 'abstract': ""Online Social Networks (OSNs) remain the focal point of Internet usage. Since the beginning, networking sites tried best to have right privacy mechanisms in place for users, enabling them to share the right content with the right audience. With all these efforts, privacy customizations remain hard for users across the sites. Existing research that address this problem mainly focus on semi-supervised strategies that introduce extra complexity by requiring the user to manually specify initial privacy preferences for their friends. In this work, we suggest an adaptive solution that can dynamically generate privacy labels for users in OSNs. To this end, we introduce a deep reinforcement learning framework that targets two key problems in OSNs like Facebook: the exposure of users' interactions through the network to less trusted direct friends, and the possibility of propagating user updates through direct friends' interactions to indirect friends. By implementing this framework, we aim at understanding how social trust and privacy could be correlated, specifically in a dynamic fashion. We report the ranked dependence between the generated privacy labels and the estimated user trust values, which indicate the ability of the framework to identify the highly trusted users and share with them higher percentages of data. © 2016 IEEE."", 'affiliations': 'KTH, Royal Institute of Technology, Sweden; University of Insubria, Italy', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006765626&doi=10.1109%2fASONAM.2016.7752236&partnerID=40&md5=fb08bc9dfc0d971eb728bd1856cff9d7', 'doi': '10.1109/ASONAM.2016.7752236', 'pages': '203 – 206', 'journal': 'Proceedings of the 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2016', 'year': '2016', 'title': 'Trust and privacy correlations in social networks: A deep learning framework', 'author': 'Jaradat, Shatha and Dokoohaki, Nima and Matskin, Mihhail and Ferrari, Elena', 'ENTRYTYPE': 'conference', 'ID': 'Jaradat2016203'}",Scopus
"Seymour, William and Kraemer, Martin J. and Binns, Reuben and Van Kleek, Max",Informing the Design of Privacy-Empowering Tools for the Connected Home,,"Connected devices in the home represent a potentially grave new privacy threat due to their unfettered access to the most personal spaces in people's lives. Prior work has shown that despite concerns about such devices, people often lack sufficient awareness, understanding, or means of taking effective action. To explore the potential for new tools that support such needs directly we developed Aretha, a privacy assistant technology probe that combines a network disaggregator, personal tutor, and firewall, to empower end-users with both the knowledge and mechanisms to control disclosures from their homes. We deployed Aretha in three households over six weeks, with the aim of understanding how this combination of capabilities might enable users to gain awareness of data disclosures by their devices, form educated privacy preferences, and to block unwanted data flows. The probe, with its novel affordances-and its limitations-prompted users to co-adapt, finding new control mechanisms and suggesting new approaches to address the challenge of regaining privacy in the connected home. © 2020 ACM.",2020,Conference on Human Factors in Computing Systems - Proceedings,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090495795&doi=10.1145%2f3313831.3376264&partnerID=40&md5=86b70233a987de90712165b5dad031c2,"{'note': 'All Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': ""Connected devices in the home represent a potentially grave new privacy threat due to their unfettered access to the most personal spaces in people's lives. Prior work has shown that despite concerns about such devices, people often lack sufficient awareness, understanding, or means of taking effective action. To explore the potential for new tools that support such needs directly we developed Aretha, a privacy assistant technology probe that combines a network disaggregator, personal tutor, and firewall, to empower end-users with both the knowledge and mechanisms to control disclosures from their homes. We deployed Aretha in three households over six weeks, with the aim of understanding how this combination of capabilities might enable users to gain awareness of data disclosures by their devices, form educated privacy preferences, and to block unwanted data flows. The probe, with its novel affordances-and its limitations-prompted users to co-adapt, finding new control mechanisms and suggesting new approaches to address the challenge of regaining privacy in the connected home. © 2020 ACM."", 'affiliations': 'University of Oxford, Oxford, United Kingdom', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090495795&doi=10.1145%2f3313831.3376264&partnerID=40&md5=86b70233a987de90712165b5dad031c2', 'doi': '10.1145/3313831.3376264', 'journal': 'Conference on Human Factors in Computing Systems - Proceedings', 'year': '2020', 'title': 'Informing the Design of Privacy-Empowering Tools for the Connected Home', 'author': 'Seymour, William and Kraemer, Martin J. and Binns, Reuben and Van Kleek, Max', 'ENTRYTYPE': 'conference', 'ID': 'Seymour2020'}",Scopus
"Kelley, Patrick Gage and Bresee, Joanna and Cranor, Lorrie Faith and Reeder, Robert W.","A ""nutrition label"" for privacy",,"We used an iterative design process to develop a privacy label that presents to consumers the ways organizations collect, use, and share personal information. Many surveys have shown that consumers are concerned about online privacy, yet current mechanisms to present website privacy policies have not been successful. This research addresses the present gap in the communication and understanding of privacy policies, by creating an information design that improves the visual presentation and comprehensibility of privacy policies. Drawing from nutrition, warning, and energy labeling, as well as from the effort towards creating a standardized banking privacy notification, we present our process for constructing and refining a label tuned to privacy. This paper describes our design methodology; findings from two focus groups; and accuracy, timing, and likeability results from a laboratory study with 24 participants. Our study results demonstrate that compared to existing natural language privacy policies, the proposed privacy label allows participants to find information more quickly and accurately, and provides a more enjoyable information seeking experience.",2009,SOUPS 2009 - Proceedings of the 5th Symposium On Usable Privacy and Security,https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350731253&doi=10.1145%2f1572532.1572538&partnerID=40&md5=f96efa164a1c3404085402df590a0fdb,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'abstract': 'We used an iterative design process to develop a privacy label that presents to consumers the ways organizations collect, use, and share personal information. Many surveys have shown that consumers are concerned about online privacy, yet current mechanisms to present website privacy policies have not been successful. This research addresses the present gap in the communication and understanding of privacy policies, by creating an information design that improves the visual presentation and comprehensibility of privacy policies. Drawing from nutrition, warning, and energy labeling, as well as from the effort towards creating a standardized banking privacy notification, we present our process for constructing and refining a label tuned to privacy. This paper describes our design methodology; findings from two focus groups; and accuracy, timing, and likeability results from a laboratory study with 24 participants. Our study results demonstrate that compared to existing natural language privacy policies, the proposed privacy label allows participants to find information more quickly and accurately, and provides a more enjoyable information seeking experience.', 'affiliations': 'Carnegie Mellon University, School of Computer Science, United States; Microsoft, Trust User Experience (TUX)', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350731253&doi=10.1145%2f1572532.1572538&partnerID=40&md5=f96efa164a1c3404085402df590a0fdb', 'doi': '10.1145/1572532.1572538', 'journal': 'SOUPS 2009 - Proceedings of the 5th Symposium On Usable Privacy and Security', 'year': '2009', 'title': 'A ""nutrition label"" for privacy', 'author': 'Kelley, Patrick Gage and Bresee, Joanna and Cranor, Lorrie Faith and Reeder, Robert W.', 'ENTRYTYPE': 'conference', 'ID': 'Kelley2009'}",Scopus
"Fox, Grace and Lynn, Theo",Examining Privacy Disclosure and Trust in the Consumer Internet of Things: An Integrated Research Framework,,"The Internet of Things (IoT) and the various applications it encompasses offer great potential for personalisation and convenience in all aspects of individuals’ lives from healthcare to transport and smart homes. However, IoT devices collect and share large volumes of personal data leading to concerns for the security and privacy of the data. While computer science research has explored technical solutions to security issues, it is important to explore privacy from the perspective of consumers. To foster a sense of privacy and trust among consumers, IoT service providers must communicate with consumers regarding their data practices in a transparent manner. To do this, we propose that IoT service providers refine adopt transparent privacy disclosure approaches. We present a framework for testing the effectiveness of privacy disclosures in building consumers’ perceptions of privacy and trust and empowering consumers to adopt IoT devices whilst retaining some level of privacy. We illustrate this framework with reference to a privacy label approach. © 2020, The Author(s).",2020,Palgrave Studies in Digital Business and Enabling Technologies,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109816353&doi=10.1007%2f978-3-030-41110-7_7&partnerID=40&md5=6dbd4a3bf0c0281097baf3fb177204f6,"{'note': 'All Open Access, Gold Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Book chapter', 'language': 'English', 'publisher': 'Palgrave Macmillan', 'abstract': 'The Internet of Things (IoT) and the various applications it encompasses offer great potential for personalisation and convenience in all aspects of individuals’ lives from healthcare to transport and smart homes. However, IoT devices collect and share large volumes of personal data leading to concerns for the security and privacy of the data. While computer science research has explored technical solutions to security issues, it is important to explore privacy from the perspective of consumers. To foster a sense of privacy and trust among consumers, IoT service providers must communicate with consumers regarding their data practices in a transparent manner. To do this, we propose that IoT service providers refine adopt transparent privacy disclosure approaches. We present a framework for testing the effectiveness of privacy disclosures in building consumers’ perceptions of privacy and trust and empowering consumers to adopt IoT devices whilst retaining some level of privacy. We illustrate this framework with reference to a privacy label approach. © 2020, The Author(s).', 'affiliations': 'Irish Institute of Digital Business, DCU Business School, Dublin, Ireland', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109816353&doi=10.1007%2f978-3-030-41110-7_7&partnerID=40&md5=6dbd4a3bf0c0281097baf3fb177204f6', 'doi': '10.1007/978-3-030-41110-7_7', 'pages': '123 – 140', 'journal': 'Palgrave Studies in Digital Business and Enabling Technologies', 'year': '2020', 'title': 'Examining Privacy Disclosure and Trust in the Consumer Internet of Things: An Integrated Research Framework', 'author': 'Fox, Grace and Lynn, Theo', 'ENTRYTYPE': 'article', 'ID': 'Fox2020123'}",Scopus
"Lie, David and Austin, Lisa M. and Sun, Peter Yi Ping and Qiu, Wenjun","AUTOMATING ACCOUNTABILITY? PRIVACY POLICIES, DATA TRANSPARENCY, AND THE THIRD PARTY PROBLEM",,"We have a data transparency problem. Currently, one of the main mechanisms we have to understand data flows is through the self-reporting that organizations provide through privacy policies. These suffer from many well-known problems, problems that are becoming more acute with the increasing complexity of the data ecosystem and the role of third parties – the affiliates, partners, processors, ad agencies, analytic services, and data brokers involved in the contemporary data practices of organizations. In this article, we argue that automating privacy policy analysis can improve the usability of privacy policies as a transparency mechanism. Our argument has five parts. First, we claim that we need to shift from thinking about privacy policies as a transparency mechanism that enhances consumer choice and see them as a transparency mechanism that enhances meaningful accountability. Second, we discuss a research tool that we prototyped, called AppTrans (for Application Transparency), which can detect inconsistencies between the declarations in a privacy policy and the actions the mobile application can potentially take if it is used. We used AppTrans to test seven hundred applications and found that 59.5 per cent were collecting data in ways that were not declared in their policies. The vast majority of the discrepancies were due to third party data collection such as advertising and analytics. Third, we outline the follow-on research we did to extend AppTrans to analyse the information sharing of mobile applications with third parties, with mixed results. Fourth, we situate our findings in relation to the third party issues that came to light in the recent Cambridge Analytica scandal and the calls from regulators for enhanced technical safeguards in managing these third party relationships. Fifth, we discuss some of the limitations of privacy policy automation as a strategy for enhanced data transparency and the policy implications of these limitations. © UNIVERSITY OF TORONTO PRESS.",2021,University of Toronto Law Journal,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126561713&doi=10.3138%2futlj-2020-0136&partnerID=40&md5=a9d84d64d1972af647da9059c407f0db,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'University of Toronto Press', 'abstract': 'We have a data transparency problem. Currently, one of the main mechanisms we have to understand data flows is through the self-reporting that organizations provide through privacy policies. These suffer from many well-known problems, problems that are becoming more acute with the increasing complexity of the data ecosystem and the role of third parties – the affiliates, partners, processors, ad agencies, analytic services, and data brokers involved in the contemporary data practices of organizations. In this article, we argue that automating privacy policy analysis can improve the usability of privacy policies as a transparency mechanism. Our argument has five parts. First, we claim that we need to shift from thinking about privacy policies as a transparency mechanism that enhances consumer choice and see them as a transparency mechanism that enhances meaningful accountability. Second, we discuss a research tool that we prototyped, called AppTrans (for Application Transparency), which can detect inconsistencies between the declarations in a privacy policy and the actions the mobile application can potentially take if it is used. We used AppTrans to test seven hundred applications and found that 59.5 per cent were collecting data in ways that were not declared in their policies. The vast majority of the discrepancies were due to third party data collection such as advertising and analytics. Third, we outline the follow-on research we did to extend AppTrans to analyse the information sharing of mobile applications with third parties, with mixed results. Fourth, we situate our findings in relation to the third party issues that came to light in the recent Cambridge Analytica scandal and the calls from regulators for enhanced technical safeguards in managing these third party relationships. Fifth, we discuss some of the limitations of privacy policy automation as a strategy for enhanced data transparency and the policy implications of these limitations. © UNIVERSITY OF TORONTO PRESS.', 'affiliations': 'Department of Electrical and Computer Engineering, University of Toronto, Canada; Faculty of Law, University of Toronto, Canada; Bloomberg, NY, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126561713&doi=10.3138%2futlj-2020-0136&partnerID=40&md5=a9d84d64d1972af647da9059c407f0db', 'doi': '10.3138/utlj-2020-0136', 'pages': '155 – 188', 'number': '2', 'volume': '72', 'journal': 'University of Toronto Law Journal', 'year': '2021', 'title': 'AUTOMATING ACCOUNTABILITY? PRIVACY POLICIES, DATA TRANSPARENCY, AND THE THIRD PARTY PROBLEM', 'author': 'Lie, David and Austin, Lisa M. and Sun, Peter Yi Ping and Qiu, Wenjun', 'ENTRYTYPE': 'article', 'ID': 'Lie2021155'}",Scopus
"Ruff, Christopher and Horch, Andrea and Benthien, Benedict and Loh, Wulf and Orlowski, Alexander",DAMA - A transparent meta-assistant for data self-determination in smart environments,,"Global sales of AI-based smart voice assistants and other smart devices are increasing every year. Smart devices are becoming ubiquitous, including living and workspaces. These spaces often have very high privacy requirements, like living rooms, bedrooms or meeting rooms in office environments. Users of smart devices have security and privacy concerns regarding personal data collection, data storage and the use of such data by the devices and the providers. These concerns are aggravated by a lack of transparency by the device manufacturers. As a result, users have limited possibilities to make an informed decision due to missing information or interfaces. While this leads to limited trust regarding the security and privacy of smart devices, for most users, the practical benefit dominates. The project DAMA wants to address user's security and privacy concerns by creating transparency and regulating the smart devices in connection with the respective context (e.g. when users are alone at home or when they have visitors). For this purpose, the project is developing a “meta-assistant”, an assistant that regulates other AI-based assistants and other smart devices. It uses artificial intelligence (AI) for context detection and device regulation. The regulation processes are based on established ethical guidelines, which are adjusted to the project context. © 2021 Gesellschaft fur Informatik (GI). All rights reserved.",2021,"Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120530136&partnerID=40&md5=e642bd016229f9b401c975aea44a980b,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Gesellschaft fur Informatik (GI)', 'abstract': ""Global sales of AI-based smart voice assistants and other smart devices are increasing every year. Smart devices are becoming ubiquitous, including living and workspaces. These spaces often have very high privacy requirements, like living rooms, bedrooms or meeting rooms in office environments. Users of smart devices have security and privacy concerns regarding personal data collection, data storage and the use of such data by the devices and the providers. These concerns are aggravated by a lack of transparency by the device manufacturers. As a result, users have limited possibilities to make an informed decision due to missing information or interfaces. While this leads to limited trust regarding the security and privacy of smart devices, for most users, the practical benefit dominates. The project DAMA wants to address user's security and privacy concerns by creating transparency and regulating the smart devices in connection with the respective context (e.g. when users are alone at home or when they have visitors). For this purpose, the project is developing a “meta-assistant”, an assistant that regulates other AI-based assistants and other smart devices. It uses artificial intelligence (AI) for context detection and device regulation. The regulation processes are based on established ethical guidelines, which are adjusted to the project context. © 2021 Gesellschaft fur Informatik (GI). All rights reserved."", 'affiliations': 'Fraunhofer IAO, Identity Management, Nobelstr. 12, Stuttgart, 70569, Germany; Internationales Zentrum für Ethik in den Wissenschaften (IZEW), Wilhelmstr. 19, Tübingen, 72074, Germany', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120530136&partnerID=40&md5=e642bd016229f9b401c975aea44a980b', 'pages': '119 – 130', 'volume': 'P-312', 'journal': 'Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)', 'year': '2021', 'title': 'DAMA - A transparent meta-assistant for data self-determination in smart environments', 'author': 'Ruff, Christopher and Horch, Andrea and Benthien, Benedict and Loh, Wulf and Orlowski, Alexander', 'ENTRYTYPE': 'conference', 'ID': 'Ruff2021119'}",Scopus
"Renaud, Karen and Shepherd, Lynsay A.",How to make privacy policies both GDPR-compliant and usable,,"It is important for organisations to ensure that their privacy policies are General Data Protection Regulation (GDPR) compliant, and this has to be done by the May 2018 deadline. However, it is also important for these policies to be designed with the needs of the human recipient in mind. We carried out an investigation to find out how best to achieve this.We commenced by synthesising the GDPR requirements into a checklist-type format. We then derived a list of usability design guidelines for privacy notifications from the research literature.We augmented the recommendations with other findings reported in the research literature, in order to confirm the guidelines. We conclude by providing a usable and GDPR-compliant privacy policy template for the benefit of policy writers. © 2018 IEEE.",2018,"2018 International Conference on Cyber Situational Awareness, Data Analytics and Assessment, CyberSA 2018",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059989091&doi=10.1109%2fCyberSA.2018.8551442&partnerID=40&md5=15d153ec45c92ceebbbf9384c58adf72,"{'note': 'All Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Institute of Electrical and Electronics Engineers Inc.', 'abstract': 'It is important for organisations to ensure that their privacy policies are General Data Protection Regulation (GDPR) compliant, and this has to be done by the May 2018 deadline. However, it is also important for these policies to be designed with the needs of the human recipient in mind. We carried out an investigation to find out how best to achieve this.We commenced by synthesising the GDPR requirements into a checklist-type format. We then derived a list of usability design guidelines for privacy notifications from the research literature.We augmented the recommendations with other findings reported in the research literature, in order to confirm the guidelines. We conclude by providing a usable and GDPR-compliant privacy policy template for the benefit of policy writers. © 2018 IEEE.', 'affiliations': 'School of Design and Informatics, Abertay University, Dundee, United Kingdom', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059989091&doi=10.1109%2fCyberSA.2018.8551442&partnerID=40&md5=15d153ec45c92ceebbbf9384c58adf72', 'doi': '10.1109/CyberSA.2018.8551442', 'journal': '2018 International Conference on Cyber Situational Awareness, Data Analytics and Assessment, CyberSA 2018', 'year': '2018', 'title': 'How to make privacy policies both GDPR-compliant and usable', 'author': 'Renaud, Karen and Shepherd, Lynsay A.', 'ENTRYTYPE': 'conference', 'ID': 'Renaud2018'}",Scopus
"Kelley, Patrick Gage",Designing a privacy label: Assisting consumer understanding of online privacy practices,,"This project describes the continuing development of a Privacy Label to present to consumers the ways organizations collect, use, and share personal information. Several studies have indicated the importance of privacy for consumers, yet current mechanisms to present privacy policies of websites have not been successful. This research addresses the present gap in the communication and understanding of privacy policies, by creating an information design that improves the visual presentation and comprehensibility of privacy policies. Drawing from the nutrition, warning, and energy labeling, as well as from the effort towards creating a standardized banking privacy notification, I present the process and ongoing results of the development of a usable information design for privacy policies.",2009,Conference on Human Factors in Computing Systems - Proceedings,https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349190297&doi=10.1145%2f1520340.1520484&partnerID=40&md5=7a397204a81d54d96e976cb279367fc4,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'abstract': 'This project describes the continuing development of a Privacy Label to present to consumers the ways organizations collect, use, and share personal information. Several studies have indicated the importance of privacy for consumers, yet current mechanisms to present privacy policies of websites have not been successful. This research addresses the present gap in the communication and understanding of privacy policies, by creating an information design that improves the visual presentation and comprehensibility of privacy policies. Drawing from the nutrition, warning, and energy labeling, as well as from the effort towards creating a standardized banking privacy notification, I present the process and ongoing results of the development of a usable information design for privacy policies.', 'affiliations': 'Carnegie Mellon University, Pittsburgh, PA 15213, 5820 Forbes Avenue, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349190297&doi=10.1145%2f1520340.1520484&partnerID=40&md5=7a397204a81d54d96e976cb279367fc4', 'doi': '10.1145/1520340.1520484', 'pages': '3347 – 3352', 'journal': 'Conference on Human Factors in Computing Systems - Proceedings', 'year': '2009', 'title': 'Designing a privacy label: Assisting consumer understanding of online privacy practices', 'author': 'Kelley, Patrick Gage', 'ENTRYTYPE': 'conference', 'ID': 'Kelley20093347'}",Scopus
"Kung, Sun-Yuan and Chanyaswad, Thee and Chang, J. Morris and Wu, Peiyuan",Collaborative PCA/DCA learning methods for compressive privacy,,"In the Internet era, the data being collected on consumers like us are growing exponentially, and attacks on our privacy are becoming a real threat. To better ensure our privacy, it is safer to let the data owner control the data to be uploaded to the network as opposed to taking chance with data servers or third parties. To this end, we propose compressive privacy, a privacy-preserving technique to enable the data creator to compress data via collaborative learning so that the compressed data uploaded onto the Internet will be useful only for the intended utility and not be easily diverted to malicious applications. For data in a high-dimensional feature vector space, a common approach to data compression is dimension reduction or, equivalently subspace projection. The most prominent tool is principal component analysis (PCA). For unsupervised learning, PCA can best recover the original data given a specific reduced dimensionality. However, for the supervised learning environment, it is more effective to adopt a supervised PCA, known as discriminant component analysis (DCA), to maximize the discriminant capability. The DCA subspace analysis embraces two different subspaces. The signal-subspace components of DCA are associated with the discriminant distance/power (related to the classification effectiveness), whereas the noise subspace components of DCA are tightly coupled with recoverability and/or privacy protection. This article presents three DCA-related data compression methods useful for privacy-preserving applications: -Utility-driven DCA: Because the rank of the signal subspace is limited by the number of classes, DCA can effectively support classification using a relatively small dimensionality (i.e., high compression). -Desensitized PCA: By incorporating a signal-subspace ridge into DCA, it leads to a variant especially effective for extracting privacy-preserving components. In this case, the eigenvalues of the noise-space are made to become insensitive to the privacy labels and are ordered according to their corresponding component powers. -Desensitized K-means/SOM: Since the revelation of the K-means or SOM cluster structure could leak sensitive information, it is safer to perform K-means or SOM clustering on a desensitized PCA subspace. © 2017 ACM.",2017,ACM Transactions on Embedded Computing Systems,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025155283&doi=10.1145%2f2996460&partnerID=40&md5=d9830cab21b0038b32bdd68a754d75b7,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': 'In the Internet era, the data being collected on consumers like us are growing exponentially, and attacks on our privacy are becoming a real threat. To better ensure our privacy, it is safer to let the data owner control the data to be uploaded to the network as opposed to taking chance with data servers or third parties. To this end, we propose compressive privacy, a privacy-preserving technique to enable the data creator to compress data via collaborative learning so that the compressed data uploaded onto the Internet will be useful only for the intended utility and not be easily diverted to malicious applications. For data in a high-dimensional feature vector space, a common approach to data compression is dimension reduction or, equivalently subspace projection. The most prominent tool is principal component analysis (PCA). For unsupervised learning, PCA can best recover the original data given a specific reduced dimensionality. However, for the supervised learning environment, it is more effective to adopt a supervised PCA, known as discriminant component analysis (DCA), to maximize the discriminant capability. The DCA subspace analysis embraces two different subspaces. The signal-subspace components of DCA are associated with the discriminant distance/power (related to the classification effectiveness), whereas the noise subspace components of DCA are tightly coupled with recoverability and/or privacy protection. This article presents three DCA-related data compression methods useful for privacy-preserving applications: -Utility-driven DCA: Because the rank of the signal subspace is limited by the number of classes, DCA can effectively support classification using a relatively small dimensionality (i.e., high compression). -Desensitized PCA: By incorporating a signal-subspace ridge into DCA, it leads to a variant especially effective for extracting privacy-preserving components. In this case, the eigenvalues of the noise-space are made to become insensitive to the privacy labels and are ordered according to their corresponding component powers. -Desensitized K-means/SOM: Since the revelation of the K-means or SOM cluster structure could leak sensitive information, it is safer to perform K-means or SOM clustering on a desensitized PCA subspace. © 2017 ACM.', 'affiliations': 'Department of Electrical Engineering, Engineering Quadrangle, Princeton University, 41 Olden St, Princeton, 08544, NJ, United States; Department of Electrical Engineering, University of South Florida, Tampa, 33647, FL, United States; Taiwan Semiconductor Manufacturing Company Limited, 8 LiHsin Rd. 6, Hsinchu Science Park, Hsinchu, 300-78, Taiwan', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025155283&doi=10.1145%2f2996460&partnerID=40&md5=d9830cab21b0038b32bdd68a754d75b7', 'doi': '10.1145/2996460', 'number': '3', 'volume': '16', 'journal': 'ACM Transactions on Embedded Computing Systems', 'year': '2017', 'title': 'Collaborative PCA/DCA learning methods for compressive privacy', 'author': 'Kung, Sun-Yuan and Chanyaswad, Thee and Chang, J. Morris and Wu, Peiyuan', 'ENTRYTYPE': 'article', 'ID': 'Kung2017'}",Scopus
"Rizk, Ramzi and Gürses, Seda and Günther, Oliver",SNS and 3rd party application privacy policies and their construction of privacy concerns,,"In this paper we use template analysis to study the content of privacy policies both of online social networks as well as 3rd party application providers. After analysing and prioritising the topics mentioned in these policies, we discuss potential problems, limitations of privacy policies, and the responsibilities they assign to various stakeholders. These findings will, in future work serve as stakeholder input for aligning social networking sites' privacy definitions, concerns, and practices.",2010,"18th European Conference on Information Systems, ECIS 2010",https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870638697&partnerID=40&md5=32f60630956602c25ef955fe44687e07,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'abstract': ""In this paper we use template analysis to study the content of privacy policies both of online social networks as well as 3rd party application providers. After analysing and prioritising the topics mentioned in these policies, we discuss potential problems, limitations of privacy policies, and the responsibilities they assign to various stakeholders. These findings will, in future work serve as stakeholder input for aligning social networking sites' privacy definitions, concerns, and practices."", 'affiliations': 'Institute of Information Systems, Humboldt University, Berlin, Germany; IBBT and Department of Computer Science, ESAT/COSIC, K.U. Leuven, Heverlee, Belgium', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870638697&partnerID=40&md5=32f60630956602c25ef955fe44687e07', 'journal': '18th European Conference on Information Systems, ECIS 2010', 'year': '2010', 'title': 'SNS and 3rd party application privacy policies and their construction of privacy concerns', 'author': 'Rizk, Ramzi and Gürses, Seda and Günther, Oliver', 'ENTRYTYPE': 'conference', 'ID': 'Rizk2010'}",Scopus
"Hansen, Marit",Putting privacy pictograms into practice-a european perspective,,"Recent proposals for privacy pictograms show a growing interest of simplifying privacy-related statements. Such pictograms can be useful to enhance the users' understanding of privacy issues and empower to react accordingly. In this text we bring together various mostly independently developed approaches and compare them with each other. We distinguish different categories, e.g., pictograms for privacy seals, for matching privacy preferences or for interpreting privacy policies. Further, we elaborate requirements for a widespread use of privacy pictograms by applying the perspective of European data protection regulation.",2009,"INFORMATIK 2009 - Im Focus das Leben, Beitrage der 39. Jahrestagung der Gesellschaft fur Informatik e.V. (GI)",https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867317204&partnerID=40&md5=2ac6b70d734c8bc32ecc294f3dd23a12,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'abstract': ""Recent proposals for privacy pictograms show a growing interest of simplifying privacy-related statements. Such pictograms can be useful to enhance the users' understanding of privacy issues and empower to react accordingly. In this text we bring together various mostly independently developed approaches and compare them with each other. We distinguish different categories, e.g., pictograms for privacy seals, for matching privacy preferences or for interpreting privacy policies. Further, we elaborate requirements for a widespread use of privacy pictograms by applying the perspective of European data protection regulation."", 'affiliations': 'Unabhängiges Landeszentrum für Datenschutz Schleswig-Holstein, 24103 Kiel, Holstenstr. 98, Germany', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867317204&partnerID=40&md5=2ac6b70d734c8bc32ecc294f3dd23a12', 'pages': '1703 – 1716', 'journal': 'INFORMATIK 2009 - Im Focus das Leben, Beitrage der 39. Jahrestagung der Gesellschaft fur Informatik e.V. (GI)', 'year': '2009', 'title': 'Putting privacy pictograms into practice-a european perspective', 'author': 'Hansen, Marit', 'ENTRYTYPE': 'conference', 'ID': 'Hansen20091703'}",Scopus
"Railean, Alexandr and Reinhardt, Delphine",OnLITE: On-line Label for IoT Transparency Enhancement,,"We present a privacy transparency tool, which helps non-expert consumers understand and compare how Internet of Things (IoT) devices handle data. The need for such tools arises with the growing number of IoT products and the privacy implications of their use. This research is further motivated by legal acts, such as the General Data Protection Regulation (GDPR), which mandates the communication of privacy practices in a clear language. Our solution summarizes key privacy facts and visualizes information flows in a way that facilitates quick assessments, even for large data sets. We followed an interdisciplinary iterative design process that combines input from legal and usability experts, as well as feedback from 15 participants of our think-aloud task analysis study. In addition to explaining the rationale behind the design and evaluation methodology, we compare our solution, implemented as a graphical user interface, with existing ones. The results show that participants consider the interface straightforward and useful. Our solution encourages them to think critically about privacy and question some of the manufacturers’ claims. Participants also reported that they would be glad if such tools were widely available, to further improve privacy awareness. Besides, our solution can be a part of an evidence-based standardization process, enabling policy-makers to further promote privacy. © 2021, Springer Nature Switzerland AG.",2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103564238&doi=10.1007%2f978-3-030-70852-8_14&partnerID=40&md5=3b2d8de9919972b8b07da1b287401f02,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Springer Science and Business Media Deutschland GmbH', 'abstract': 'We present a privacy transparency tool, which helps non-expert consumers understand and compare how Internet of Things (IoT) devices handle data. The need for such tools arises with the growing number of IoT products and the privacy implications of their use. This research is further motivated by legal acts, such as the General Data Protection Regulation (GDPR), which mandates the communication of privacy practices in a clear language. Our solution summarizes key privacy facts and visualizes information flows in a way that facilitates quick assessments, even for large data sets. We followed an interdisciplinary iterative design process that combines input from legal and usability experts, as well as feedback from 15 participants of our think-aloud task analysis study. In addition to explaining the rationale behind the design and evaluation methodology, we compare our solution, implemented as a graphical user interface, with existing ones. The results show that participants consider the interface straightforward and useful. Our solution encourages them to think critically about privacy and question some of the manufacturers’ claims. Participants also reported that they would be glad if such tools were widely available, to further improve privacy awareness. Besides, our solution can be a part of an evidence-based standardization process, enabling policy-makers to further promote privacy. © 2021, Springer Nature Switzerland AG.', 'affiliations': 'Institute of Computer Science, Georg-August-Universität Göttingen, Göttingen, Germany', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103564238&doi=10.1007%2f978-3-030-70852-8_14&partnerID=40&md5=3b2d8de9919972b8b07da1b287401f02', 'doi': '10.1007/978-3-030-70852-8_14', 'pages': '229 – 245', 'volume': '12556 LNCS', 'journal': 'Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)', 'year': '2021', 'title': 'OnLITE: On-line Label for IoT Transparency Enhancement', 'author': 'Railean, Alexandr and Reinhardt, Delphine', 'ENTRYTYPE': 'article', 'ID': 'Railean2021229'}",Scopus
"Akhgarnush, Eljar",Data sustainability-a thorough consideration,,"The two main topics in this article are virtually omnipresent these days: data and sustainability. Linking them together seems obvious, considering the urgency of dealing with both. In this article, we explain which aspects are linked to a sustainable dealing with data, before we transition to direct and indirect impacts on the environment. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2021.",2021,"The Digital Journey of Banking and Insurance, Volume III: Data Storage, Data Processing and Data Analysis",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159087097&doi=10.1007%2f978-3-030-78821-6_8&partnerID=40&md5=4f46d65c424afe0c886c3098f99307c7,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Book chapter', 'language': 'English', 'publisher': 'Springer International Publishing', 'abstract': 'The two main topics in this article are virtually omnipresent these days: data and sustainability. Linking them together seems obvious, considering the urgency of dealing with both. In this article, we explain which aspects are linked to a sustainable dealing with data, before we transition to direct and indirect impacts on the environment. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2021.', 'affiliations': 'ifb SE, Grünwald, Germany', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159087097&doi=10.1007%2f978-3-030-78821-6_8&partnerID=40&md5=4f46d65c424afe0c886c3098f99307c7', 'doi': '10.1007/978-3-030-78821-6_8', 'pages': '119 – 129', 'journal': 'The Digital Journey of Banking and Insurance, Volume III: Data Storage, Data Processing and Data Analysis', 'year': '2021', 'title': 'Data sustainability-a thorough consideration', 'author': 'Akhgarnush, Eljar', 'ENTRYTYPE': 'book', 'ID': 'Akhgarnush2021119'}",Scopus
"Diamond, Lisa and Fröhlich, Peter",Communicating Privacy: User Priorities for Privacy Requirements in Home Energy Applications,,"Perceived privacy plays a crucial role in the acceptance of technologies that rely on sensitive data. To mitigate concerns and build trust, privacy must not only be protected, but this protection should also be successfully communicated. Residential energy consumption data are at the center of applications that facilitate improved energy management and support a more sustainable future, but such data are privacy-sensitive since they have the potential to reveal a great number of details about the daily life of users. Our study contributes to an understanding of how to communicate energy data privacy via user interfaces by looking into the relevancy and accessibility priorities of potential privacy requirements in home energy monitoring, management, and production applications. All investigated requirements showed themselves to be of relevance to users, with control aspects (access, transfer, and deletion of data) being both perceived as most important and receiving the highest accessibility priority ratings, and control of data storage joining them as top access priority requirement. Our results indicate that placing the settings and information emphasized in our results prominently in the user interface, going through extra effort to ensure easy comprehensibility, and communicating them proactively, is likely to go a long way in successfully communicating privacy. Investigation of accessibility priority differences in relation to data storage location provided less clear answers but suggests a higher importance of access to general information on data collection if data are stored centrally and of the ability to view data if stored decentrally. © 2021, IFIP International Federation for Information Processing.",2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115203881&doi=10.1007%2f978-3-030-85610-6_38&partnerID=40&md5=775f3005c1a5f71f6d89345cafc39f81,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Springer Science and Business Media Deutschland GmbH', 'abstract': 'Perceived privacy plays a crucial role in the acceptance of technologies that rely on sensitive data. To mitigate concerns and build trust, privacy must not only be protected, but this protection should also be successfully communicated. Residential energy consumption data are at the center of applications that facilitate improved energy management and support a more sustainable future, but such data are privacy-sensitive since they have the potential to reveal a great number of details about the daily life of users. Our study contributes to an understanding of how to communicate energy data privacy via user interfaces by looking into the relevancy and accessibility priorities of potential privacy requirements in home energy monitoring, management, and production applications. All investigated requirements showed themselves to be of relevance to users, with control aspects (access, transfer, and deletion of data) being both perceived as most important and receiving the highest accessibility priority ratings, and control of data storage joining them as top access priority requirement. Our results indicate that placing the settings and information emphasized in our results prominently in the user interface, going through extra effort to ensure easy comprehensibility, and communicating them proactively, is likely to go a long way in successfully communicating privacy. Investigation of accessibility priority differences in relation to data storage location provided less clear answers but suggests a higher importance of access to general information on data collection if data are stored centrally and of the ability to view data if stored decentrally. © 2021, IFIP International Federation for Information Processing.', 'affiliations': 'AIT Austrian Institute of Technology, Giefinggasse 2, Vienna, 1210, Austria', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115203881&doi=10.1007%2f978-3-030-85610-6_38&partnerID=40&md5=775f3005c1a5f71f6d89345cafc39f81', 'doi': '10.1007/978-3-030-85610-6_38', 'pages': '665 – 675', 'volume': '12935 LNCS', 'journal': 'Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)', 'year': '2021', 'title': 'Communicating Privacy: User Priorities for Privacy Requirements in Home Energy Applications', 'author': 'Diamond, Lisa and Fröhlich, Peter', 'ENTRYTYPE': 'article', 'ID': 'Diamond2021665'}",Scopus
"Oulasvirta, Antti and Suomalainen, Tiia and Hamari, Juho and Lampinen, Airi and Karvonen, Kristiina",Transparency of intentions decreases privacy concerns in ubiquitous surveillance,,"An online experiment (n=1,897) was carried out to understand how data disclosure practices in ubiquitous surveillance affect users' privacy concerns. Information about the identity and intentions of a data collector was manipulated in hypothetical surveillance scenarios. Privacy concerns were found to differ across the scenarios and moderated by knowledge about the collector's identity and intentions. Knowledge about intentions exhibited a stronger effect. When no information about intentions was disclosed, the respondents postulated negative intentions. A positive effect was found for disclosing neutral intentions of an organization or unknown data collector, but not for a private data collector. The findings underline the importance of disclosing intentions of data use to users in an easily understandable manner. © 2014, Mary Ann Liebert, Inc. 2014.",2014,"Cyberpsychology, Behavior, and Social Networking",https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907285570&doi=10.1089%2fcyber.2013.0585&partnerID=40&md5=a44a9cd1c19896ff2f24dd984f2c21ad,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Mary Ann Liebert Inc.', 'abstract': ""An online experiment (n=1,897) was carried out to understand how data disclosure practices in ubiquitous surveillance affect users' privacy concerns. Information about the identity and intentions of a data collector was manipulated in hypothetical surveillance scenarios. Privacy concerns were found to differ across the scenarios and moderated by knowledge about the collector's identity and intentions. Knowledge about intentions exhibited a stronger effect. When no information about intentions was disclosed, the respondents postulated negative intentions. A positive effect was found for disclosing neutral intentions of an organization or unknown data collector, but not for a private data collector. The findings underline the importance of disclosing intentions of data use to users in an easily understandable manner. © 2014, Mary Ann Liebert, Inc. 2014."", 'affiliations': 'Helsinki Institute for Information Technology HIIT, Department of Communications and Networking, Aalto University, Otakaari 5, Helsinki, Finland; Max Planck Institute for Informatics, Saarbruecken, Germany; Cluster of Excellence on Multimodal Computing and Interaction, Saarland University, Saarbruecken, Germany; Department of Information and Service Economy, Aalto University School of Business, Helsinki, Finland; Game Research Lab, School of Information Sciences, University of Tampere, Tampere, Finland', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907285570&doi=10.1089%2fcyber.2013.0585&partnerID=40&md5=a44a9cd1c19896ff2f24dd984f2c21ad', 'doi': '10.1089/cyber.2013.0585', 'pages': '633 – 638', 'number': '10', 'volume': '17', 'journal': 'Cyberpsychology, Behavior, and Social Networking', 'year': '2014', 'title': 'Transparency of intentions decreases privacy concerns in ubiquitous surveillance', 'author': 'Oulasvirta, Antti and Suomalainen, Tiia and Hamari, Juho and Lampinen, Airi and Karvonen, Kristiina', 'ENTRYTYPE': 'article', 'ID': 'Oulasvirta2014633'}",Scopus
"Pierson, Jo",Digital platforms as entangled infrastructures: Addressing public values and trust in messaging apps,,"Digital platforms have increasingly become accepted and trusted by European citizens as indispensable utilities for social interaction and communication in everyday life. This article aims to analyze how trust in and dependence of these ubiquitous platforms for mediated communication is configured and the kind of consequences this has for user (dis)empowerment and public values. Our analysis builds on insights from the domestication perspective and infrastructure studies. In order to illustrate our conceptual approach, we use the case of messaging apps. We demonstrate how these apps as an essential social infrastructure are entangled with a corporate-computational infrastructure. The entangling of both types of infrastructures leads to a paradox where users feel compelled to appropriate these socially indispensable apps in everyday life, while also making them dependent on their corporate control mechanisms. In order to get out of the paradox and empower users these infrastructures and their data sharing need to be disentangled. For this, we apply the notion of ‘infrastructural inversion’ as a way to surface opaque and hidden properties of the digital platforms. We conclude with a discussion of potential other routes for infrastructural inversion in order to establish data disentanglement that serves public interest values. © The Author(s) 2021.",2021,European Journal of Communication,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113384611&doi=10.1177%2f02673231211028374&partnerID=40&md5=4a51a33e4a33bac1cf9d5eeec4777d0c,"{'note': 'All Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'SAGE Publications Ltd', 'abstract': 'Digital platforms have increasingly become accepted and trusted by European citizens as indispensable utilities for social interaction and communication in everyday life. This article aims to analyze how trust in and dependence of these ubiquitous platforms for mediated communication is configured and the kind of consequences this has for user (dis)empowerment and public values. Our analysis builds on insights from the domestication perspective and infrastructure studies. In order to illustrate our conceptual approach, we use the case of messaging apps. We demonstrate how these apps as an essential social infrastructure are entangled with a corporate-computational infrastructure. The entangling of both types of infrastructures leads to a paradox where users feel compelled to appropriate these socially indispensable apps in everyday life, while also making them dependent on their corporate control mechanisms. In order to get out of the paradox and empower users these infrastructures and their data sharing need to be disentangled. For this, we apply the notion of ‘infrastructural inversion’ as a way to surface opaque and hidden properties of the digital platforms. We conclude with a discussion of potential other routes for infrastructural inversion in order to establish data disentanglement that serves public interest values. © The Author(s) 2021.', 'affiliations': 'Vrije Universiteit Brussel, imec-SMIT, Belgium', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113384611&doi=10.1177%2f02673231211028374&partnerID=40&md5=4a51a33e4a33bac1cf9d5eeec4777d0c', 'doi': '10.1177/02673231211028374', 'pages': '349 – 361', 'number': '4', 'volume': '36', 'journal': 'European Journal of Communication', 'year': '2021', 'title': 'Digital platforms as entangled infrastructures: Addressing public values and trust in messaging apps', 'author': 'Pierson, Jo', 'ENTRYTYPE': 'article', 'ID': 'Pierson2021349'}",Scopus
"Emami-Naeini, Pardis and Dheenadhayalan, Janarth and Agarwal, Yuvraj and Cranor, Lorrie Faith",An Informative Security and Privacy 'Nutrition' Label for Internet of Things Devices,,"Consumers are concerned about the security and privacy of their Internet of Things (IoT) devices. However, they cannot easily learn about their devices' security protections and data practices before purchasing them. We designed a usable and informative IoT security and privacy label.  © 2003-2012 IEEE.",2022,IEEE Security and Privacy,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122307368&doi=10.1109%2fMSEC.2021.3132398&partnerID=40&md5=167b5bb0cdb40fcf76336b3c39290809,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Institute of Electrical and Electronics Engineers Inc.', 'abstract': ""Consumers are concerned about the security and privacy of their Internet of Things (IoT) devices. However, they cannot easily learn about their devices' security protections and data practices before purchasing them. We designed a usable and informative IoT security and privacy label.  © 2003-2012 IEEE."", 'affiliations': 'University of Washington, United States; Amazon Web Services, United States; Carnegie Mellon University, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122307368&doi=10.1109%2fMSEC.2021.3132398&partnerID=40&md5=167b5bb0cdb40fcf76336b3c39290809', 'doi': '10.1109/MSEC.2021.3132398', 'pages': '31 – 39', 'number': '2', 'volume': '20', 'journal': 'IEEE Security and Privacy', 'year': '2022', 'title': ""An Informative Security and Privacy 'Nutrition' Label for Internet of Things Devices"", 'author': 'Emami-Naeini, Pardis and Dheenadhayalan, Janarth and Agarwal, Yuvraj and Cranor, Lorrie Faith', 'ENTRYTYPE': 'article', 'ID': 'Emami-Naeini202231'}",Scopus
"Rösch, Daniel and Schuster, Thomas and Waidelich, Lukas and Alpers, Sascha",Privacy control patterns for compliant application of GDPR,,"The exchange of sensitive information has become an important part of our daily lives. This does effect business and personal data. Data exchange is subject to legal regulations. Since May 2018, the European Data Protection Regulation (EU-GDPR) has specifically regulated the protection of personal data. The regulations and possible penalties for non-compliance still lead to uncertainty in many companies. This article exposes techniques in which day-to-day work can be designed in conformity with EU-GDPR. Therefore, we define privacy control patterns that transfer existing GDPR requirements into technical solution templates for compliant services. These patterns contain generally applicable guidelines in the sense of data protection and privacy. The catalogue of patterns serves as a book of reference for providers and users of ICT-services to reduce and overcome uncertainties associated with GDPR implementation and compliance. To demonstrate the implementation of our patterns, we introduce the application system EDV. © 2019 Association for Information Systems. All rights reserved.",2019,"25th Americas Conference on Information Systems, AMCIS 2019",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084020399&partnerID=40&md5=fb4c2fe0bfb89770496252c877e3333e,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Information Systems', 'abstract': 'The exchange of sensitive information has become an important part of our daily lives. This does effect business and personal data. Data exchange is subject to legal regulations. Since May 2018, the European Data Protection Regulation (EU-GDPR) has specifically regulated the protection of personal data. The regulations and possible penalties for non-compliance still lead to uncertainty in many companies. This article exposes techniques in which day-to-day work can be designed in conformity with EU-GDPR. Therefore, we define privacy control patterns that transfer existing GDPR requirements into technical solution templates for compliant services. These patterns contain generally applicable guidelines in the sense of data protection and privacy. The catalogue of patterns serves as a book of reference for providers and users of ICT-services to reduce and overcome uncertainties associated with GDPR implementation and compliance. To demonstrate the implementation of our patterns, we introduce the application system EDV. © 2019 Association for Information Systems. All rights reserved.', 'affiliations': 'Pforzheim University, Germany; Forschungszentrum Informatik, Germany', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084020399&partnerID=40&md5=fb4c2fe0bfb89770496252c877e3333e', 'journal': '25th Americas Conference on Information Systems, AMCIS 2019', 'year': '2019', 'title': 'Privacy control patterns for compliant application of GDPR', 'author': 'Rösch, Daniel and Schuster, Thomas and Waidelich, Lukas and Alpers, Sascha', 'ENTRYTYPE': 'conference', 'ID': 'Rösch2019'}",Scopus
"McParlan, James and Van Der Linden, Dirk",Privacy labels should go to the dogs,,"Data privacy is a complex multi-faceted concept which is not easy to get a grip on, even more so when it's about you and your dog. Modern data-driven tech often has long and unreadable privacy policies making it difficult for consumers to understand what is being captured - and technology for dogs is no exception to that. Privacy labels present an alternative approach to informing consumers, aiming to provide a clear, visual summary of relevant data privacy concerns. However, no labels tailored to technology for dogs, let alone animals, seem to exist as of yet. In this work, we present an initial set of informative privacy labels usable in different contexts that inform dog owners of the most important privacy considerations for them and their dogs. The label design is grounded in the results of a mixed-method study eliciting requirements from dog owners towards typical pet technologies' data handling, cross-referenced with analysis of actual dog tech's data handling. We discuss the design of the labels, who could and should use them, and the additional uses that such labels may have for human-dog relationships.  © 2021 ACM.",2021,ACM International Conference Proceeding Series,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130854144&doi=10.1145%2f3493842.3493888&partnerID=40&md5=59c7d45e486623b6bb3e583d679f9c6d,"{'note': 'All Open Access, Green Open Access', 'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': ""Data privacy is a complex multi-faceted concept which is not easy to get a grip on, even more so when it's about you and your dog. Modern data-driven tech often has long and unreadable privacy policies making it difficult for consumers to understand what is being captured - and technology for dogs is no exception to that. Privacy labels present an alternative approach to informing consumers, aiming to provide a clear, visual summary of relevant data privacy concerns. However, no labels tailored to technology for dogs, let alone animals, seem to exist as of yet. In this work, we present an initial set of informative privacy labels usable in different contexts that inform dog owners of the most important privacy considerations for them and their dogs. The label design is grounded in the results of a mixed-method study eliciting requirements from dog owners towards typical pet technologies' data handling, cross-referenced with analysis of actual dog tech's data handling. We discuss the design of the labels, who could and should use them, and the additional uses that such labels may have for human-dog relationships.  © 2021 ACM."", 'affiliations': 'Northumbria University, Newcastle-upon-Tyne, United Kingdom', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130854144&doi=10.1145%2f3493842.3493888&partnerID=40&md5=59c7d45e486623b6bb3e583d679f9c6d', 'doi': '10.1145/3493842.3493888', 'journal': 'ACM International Conference Proceeding Series', 'year': '2021', 'title': 'Privacy labels should go to the dogs', 'author': 'McParlan, James and Van Der Linden, Dirk', 'ENTRYTYPE': 'conference', 'ID': 'McParlan2021'}",Scopus
"Lagan, Sarah and D'Mello, Ryan and Vaidyam, Aditya and Bilden, Rebecca and Torous, John","Assessing mental health apps marketplaces with objective metrics from 29,190 data points from 278 apps",,"Objective: Utilizing a standard framework that may help clinicians and patients to identify relevant mental health apps, we sought to gain a comprehensive picture of the space by searching for, downloading, and reviewing 278 mental health apps from both the iOS and Android stores. Methods: 278 mental health apps from the Apple iOS store and Google Play store were downloaded and reviewed in a standardized manner by trained app raters using a validated framework. Apps were evaluated with this framework comprising 105 questions and covering app origin and accessibility, privacy and security, inputs and outputs, clinical foundation, features and engagement style, and interoperability. Results: Our results confirm that app stars and downloads—even for the most popular apps by these metrics—did not correlate with more clinically relevant metrics related to privacy/security, effectiveness, and engagement. Most mental health apps offer similar functionality, with 16.5% offering both mood tracking and journaling and 7% offering psychoeducation, deep breathing, mindfulness, journaling, and mood tracking. Only 36.4% of apps were updated with a 100-day window, and 7.5% of apps had not been updated in four years. Conclusion: Current app marketplace metrics commonly used to evaluate apps do not offer an accurate representation of individual apps or a comprehensive overview of the entire space. The majority of apps overlap in terms of features offered, with many domains and other features not well represented. Selecting an appropriate app continues to require personal matching given no clear trends or guidance offered by quantitative metrics alone. © 2021 John Wiley & Sons A/S. Published by John Wiley & Sons Ltd",2021,Acta Psychiatrica Scandinavica,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105165966&doi=10.1111%2facps.13306&partnerID=40&md5=a538aff5f60f514d2ba1665cf0d02426,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'John Wiley and Sons Inc', 'abstract': 'Objective: Utilizing a standard framework that may help clinicians and patients to identify relevant mental health apps, we sought to gain a comprehensive picture of the space by searching for, downloading, and reviewing 278 mental health apps from both the iOS and Android stores. Methods: 278 mental health apps from the Apple iOS store and Google Play store were downloaded and reviewed in a standardized manner by trained app raters using a validated framework. Apps were evaluated with this framework comprising 105 questions and covering app origin and accessibility, privacy and security, inputs and outputs, clinical foundation, features and engagement style, and interoperability. Results: Our results confirm that app stars and downloads—even for the most popular apps by these metrics—did not correlate with more clinically relevant metrics related to privacy/security, effectiveness, and engagement. Most mental health apps offer similar functionality, with 16.5% offering both mood tracking and journaling and 7% offering psychoeducation, deep breathing, mindfulness, journaling, and mood tracking. Only 36.4% of apps were updated with a 100-day window, and 7.5% of apps had not been updated in four years. Conclusion: Current app marketplace metrics commonly used to evaluate apps do not offer an accurate representation of individual apps or a comprehensive overview of the entire space. The majority of apps overlap in terms of features offered, with many domains and other features not well represented. Selecting an appropriate app continues to require personal matching given no clear trends or guidance offered by quantitative metrics alone. © 2021 John Wiley & Sons A/S. Published by John Wiley & Sons Ltd', 'affiliations': 'Department of Psychiatry, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105165966&doi=10.1111%2facps.13306&partnerID=40&md5=a538aff5f60f514d2ba1665cf0d02426', 'doi': '10.1111/acps.13306', 'pages': '201 – 210', 'number': '2', 'volume': '144', 'journal': 'Acta Psychiatrica Scandinavica', 'year': '2021', 'title': 'Assessing mental health apps marketplaces with objective metrics from 29,190 data points from 278 apps', 'author': ""Lagan, Sarah and D'Mello, Ryan and Vaidyam, Aditya and Bilden, Rebecca and Torous, John"", 'ENTRYTYPE': 'article', 'ID': 'Lagan2021201'}",Scopus
"Paterson, Jeannie Marie and Chang, Shanton and Cheong, Marc and Culnane, Chris and Dreyfus, Suelette and McKay, Dana",The Hidden Harms of Targeted Advertising by Algorithm and Interventions from the Consumer Protection Toolkit,,"Developments in pervasive data collection and predictive data analytics are allowing firms to target consumers with increas ingly precise personalisedbehavioural and contextual advertising. These techniques give rise to new risks of harm in the attention economy by unduly influencing or manipulating consumers' deci sions and choices, and by narrowing the product options visible and available to them. In many countries, the legal response to concerns about targeted advertising by algorithm has been focused on privacy protection and data rights. These are important initiatives. However; consent-based data rights are unlikely to provide a comprehensive or even adequate response to the risks of harm to consumers occasioned by the kinds of algo- rithmically targeted advertising that are now possible. This paper suggests that a suite of responses from the consumer protection toolkit are required to address the different and potentially harm ful manifestations of algorithmic ally targeted advertising. These include bans and warnings as well as making use of standard safe- ty-net prohibitions on misleading and unconscionable/unfair con duct already in place in many jurisdictions. © 2021 International Journal on Consumer Law and Practice. All rights reserved.",2021,International Journal on Consumer Law and Practice,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117202097&partnerID=40&md5=8ad75fdd4ce393d4248f176b037a5b12,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'Chair on Consumer law and practice, National Law School of India University', 'abstract': ""Developments in pervasive data collection and predictive data analytics are allowing firms to target consumers with increas ingly precise personalisedbehavioural and contextual advertising. These techniques give rise to new risks of harm in the attention economy by unduly influencing or manipulating consumers' deci sions and choices, and by narrowing the product options visible and available to them. In many countries, the legal response to concerns about targeted advertising by algorithm has been focused on privacy protection and data rights. These are important initiatives. However; consent-based data rights are unlikely to provide a comprehensive or even adequate response to the risks of harm to consumers occasioned by the kinds of algo- rithmically targeted advertising that are now possible. This paper suggests that a suite of responses from the consumer protection toolkit are required to address the different and potentially harm ful manifestations of algorithmic ally targeted advertising. These include bans and warnings as well as making use of standard safe- ty-net prohibitions on misleading and unconscionable/unfair con duct already in place in many jurisdictions. © 2021 International Journal on Consumer Law and Practice. All rights reserved."", 'affiliations': 'Centre for Artificial Intelligence and Digital Ethics, Melbourne Law School, University of Melbourne, Australia; Faculty of Engineering and Information Technology, School of Computing and Information Systems, University of Melbourne, Information Behaviour, Australia; Faculty of Engineering and Information Technology, School of Computing and Information Systems, University of Melbourne, Digital Ethics, Australia; Faculty of Engineering and Information Technology, School of Computing and Information Systems, University of Melbourne, Australia; Faculty of Engineering and Information Technology, School of Computing and Information Systems, University of Melbourne, Australia; Rmit, Innovative Interactive Technologies, Australia', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117202097&partnerID=40&md5=8ad75fdd4ce393d4248f176b037a5b12', 'pages': '1 – 24', 'volume': '9', 'journal': 'International Journal on Consumer Law and Practice', 'year': '2021', 'title': 'The Hidden Harms of Targeted Advertising by Algorithm and Interventions from the Consumer Protection Toolkit', 'author': 'Paterson, Jeannie Marie and Chang, Shanton and Cheong, Marc and Culnane, Chris and Dreyfus, Suelette and McKay, Dana', 'ENTRYTYPE': 'article', 'ID': 'Paterson20211'}",Scopus
"Sumeeth, M. and Miller, J.","Evaluating the readability of privacy policies in mobile environments: R. I. Singh, University of Alberta, Canada",,"Recent work has suggested that the current ""breed"" of privacy policy represents a significant challenge in terms of comprehension to the average Internet-user. Due to display limitations, it is easy to represent the conjecture that this comprehension level should drop when these policies are moved into a mobile environment. This paper explores the question of how much does comprehension decrease when privacy policies are viewed on mobile versus desktop environments and does this decrease make them useless in their current format? It reports on a formal subject-based experiment, which seeks to evaluate how readable are privacy policy statements found on the Internet but presented in mobile environments. This experiment uses fifty participants and privacy policies collected from ten of the most popular web sites on the Internet. It evaluates, using a Cloze test, the subject's ability to comprehend the content of these privacy policies. Copyright © 2011, IGI Global.",2011,International Journal of Mobile Human Computer Interaction,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944525790&doi=10.4018%2fjmhci.2011010104&partnerID=40&md5=b1619f515e861586e1f5725351dd8fd1,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Article', 'language': 'English', 'publisher': 'IGI Global', 'abstract': 'Recent work has suggested that the current ""breed"" of privacy policy represents a significant challenge in terms of comprehension to the average Internet-user. Due to display limitations, it is easy to represent the conjecture that this comprehension level should drop when these policies are moved into a mobile environment. This paper explores the question of how much does comprehension decrease when privacy policies are viewed on mobile versus desktop environments and does this decrease make them useless in their current format? It reports on a formal subject-based experiment, which seeks to evaluate how readable are privacy policy statements found on the Internet but presented in mobile environments. This experiment uses fifty participants and privacy policies collected from ten of the most popular web sites on the Internet. It evaluates, using a Cloze test, the subject\'s ability to comprehend the content of these privacy policies. Copyright © 2011, IGI Global.', 'affiliations': 'University of Alberta, Canada', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944525790&doi=10.4018%2fjmhci.2011010104&partnerID=40&md5=b1619f515e861586e1f5725351dd8fd1', 'doi': '10.4018/jmhci.2011010104', 'pages': '55 – 78', 'number': '1', 'volume': '3', 'journal': 'International Journal of Mobile Human Computer Interaction', 'year': '2011', 'title': 'Evaluating the readability of privacy policies in mobile environments: R. I. Singh, University of Alberta, Canada', 'author': 'Sumeeth, M. and Miller, J.', 'ENTRYTYPE': 'article', 'ID': 'Sumeeth201155'}",Scopus
"Krupp, Brian and Hadden, Joshua and Matthews, Malik",An Analysis of Web Tracking Domains in Mobile Applications,,"Modern web browsers provide users an improved awareness of how websites track them and the potential use of data that is gathered. These features can be built into the browser or provided through an extension. Recently, DuckDuckGo, a privacy advocate and privacy focused search engine company, made publicly available the data they use to inform users of trackers in their browsers and extensions. While users can install extensions or use default browser features to inform themselves of how websites use trackers and potentially block trackers, this availability is limited in mobile applications that communicate with the same services as websites. In this paper, we utilize the data set from DuckDuckGo to analyze mobile applications on iOS. We investigate the top applications in categories designed to provide information to users or that are used in social networks. We also identify which of these applications utilize personal data on the device including location, contacts, and photos. From this investigation, 84% of the applications communicated with domains categorized as advertisement or analytics services that track users. 18% of the applications transmitted the user's location where of these, 95% communicated with domains classified as trackers. The most common tracker utilized is from Google where 55% of the applications utilize their tracking services and in general, 89% of the applications communicated with Google's services. While progress has been made in providing more transparency in web browsers, there is still work to be done in mobile operating systems. We advocate that the same features in web browsers become available through the native mobile operating system. As mobile operating system producers shift towards more privacy controls being generally available to users, this can be one more step in providing more transparency to the user in how applications use their data.  © 2021 ACM.",2021,ACM International Conference Proceeding Series,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108994856&doi=10.1145%2f3447535.3462507&partnerID=40&md5=7fe48b08fc36fbf24f4b75d053af6885,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Association for Computing Machinery', 'abstract': ""Modern web browsers provide users an improved awareness of how websites track them and the potential use of data that is gathered. These features can be built into the browser or provided through an extension. Recently, DuckDuckGo, a privacy advocate and privacy focused search engine company, made publicly available the data they use to inform users of trackers in their browsers and extensions. While users can install extensions or use default browser features to inform themselves of how websites use trackers and potentially block trackers, this availability is limited in mobile applications that communicate with the same services as websites. In this paper, we utilize the data set from DuckDuckGo to analyze mobile applications on iOS. We investigate the top applications in categories designed to provide information to users or that are used in social networks. We also identify which of these applications utilize personal data on the device including location, contacts, and photos. From this investigation, 84% of the applications communicated with domains categorized as advertisement or analytics services that track users. 18% of the applications transmitted the user's location where of these, 95% communicated with domains classified as trackers. The most common tracker utilized is from Google where 55% of the applications utilize their tracking services and in general, 89% of the applications communicated with Google's services. While progress has been made in providing more transparency in web browsers, there is still work to be done in mobile operating systems. We advocate that the same features in web browsers become available through the native mobile operating system. As mobile operating system producers shift towards more privacy controls being generally available to users, this can be one more step in providing more transparency to the user in how applications use their data.  © 2021 ACM."", 'affiliations': 'Baldwin Wallace University, Berea, OH, United States', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108994856&doi=10.1145%2f3447535.3462507&partnerID=40&md5=7fe48b08fc36fbf24f4b75d053af6885', 'doi': '10.1145/3447535.3462507', 'pages': '291 – 298', 'journal': 'ACM International Conference Proceeding Series', 'year': '2021', 'title': 'An Analysis of Web Tracking Domains in Mobile Applications', 'author': 'Krupp, Brian and Hadden, Joshua and Matthews, Malik', 'ENTRYTYPE': 'conference', 'ID': 'Krupp2021291'}",Scopus
"Lu, Tsung-Hui and Lee, Zne-Jung",A case study on privacy information protection in campus,,"Privacy protection currently circulating in global IT industries could potentially cause the next wave in information security. However, currently still lack of success story among different industries. We aimed to develop an influenza solution and assessed its effectiveness to help school planned to build up their own system. © 2013 IEEE.",2013,"ICSSE 2013 - IEEE International Conference on System Science and Engineering, Proceedings",https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887448306&doi=10.1109%2fICSSE.2013.6614702&partnerID=40&md5=3750256200115daac86ecb292a0a482c,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'abstract': 'Privacy protection currently circulating in global IT industries could potentially cause the next wave in information security. However, currently still lack of success story among different industries. We aimed to develop an influenza solution and assessed its effectiveness to help school planned to build up their own system. © 2013 IEEE.', 'affiliations': 'Department of Mechatronic Engineering, Huafan University, NEW Taipei City, Taiwan; Department of Information Management, Huafan University, NEW Taipei City, Taiwan', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887448306&doi=10.1109%2fICSSE.2013.6614702&partnerID=40&md5=3750256200115daac86ecb292a0a482c', 'doi': '10.1109/ICSSE.2013.6614702', 'pages': '419 – 424', 'journal': 'ICSSE 2013 - IEEE International Conference on System Science and Engineering, Proceedings', 'year': '2013', 'title': 'A case study on privacy information protection in campus', 'author': 'Lu, Tsung-Hui and Lee, Zne-Jung', 'ENTRYTYPE': 'conference', 'ID': 'Lu2013419'}",Scopus
"Shen, Yun and Vervier, Pierre-Antoine",IoT Security and Privacy Labels,,"IoT devices are riddled with vulnerabilities and design flaws. In consequence, we have witnessed the rise of IoT specific malware and botnets with devastating consequences on the security and privacy of consumers using those devices. Despite the growing attacks targeting these vulnerable IoT devices, manufacturers are yet to strengthen the security posture of their devices and adopt best-practices and a security by design approach. To this end, we devise an concise, informative IoT labelling scheme to convey high-level security and privacy facts about an IoT device to the consumers so as to raise their security and privacy awareness. © Springer Nature Switzerland AG 2019.",2019,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067833654&doi=10.1007%2f978-3-030-21752-5_9&partnerID=40&md5=eba43096485bf9b092940de36961f457,"{'source': 'Scopus', 'publication_stage': 'Final', 'type': 'Conference paper', 'language': 'English', 'publisher': 'Springer Verlag', 'abstract': 'IoT devices are riddled with vulnerabilities and design flaws. In consequence, we have witnessed the rise of IoT specific malware and botnets with devastating consequences on the security and privacy of consumers using those devices. Despite the growing attacks targeting these vulnerable IoT devices, manufacturers are yet to strengthen the security posture of their devices and adopt best-practices and a security by design approach. To this end, we devise an concise, informative IoT labelling scheme to convey high-level security and privacy facts about an IoT device to the consumers so as to raise their security and privacy awareness. © Springer Nature Switzerland AG 2019.', 'affiliations': 'Symantec Research Labs, Reading, United Kingdom; Symantec Research Labs, Sophia Antipolis, France', 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067833654&doi=10.1007%2f978-3-030-21752-5_9&partnerID=40&md5=eba43096485bf9b092940de36961f457', 'doi': '10.1007/978-3-030-21752-5_9', 'pages': '136 – 147', 'volume': '11498 LNCS', 'journal': 'Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)', 'year': '2019', 'title': 'IoT Security and Privacy Labels', 'author': 'Shen, Yun and Vervier, Pierre-Antoine', 'ENTRYTYPE': 'article', 'ID': 'Shen2019136'}",Scopus
"Fox, Grace and Tonge, Colin and Lynn, Theo and Mooney, John","Communicating Compliance: Developing a GDPR Privacy Label <i>Emergent
Research Forum</i> (<i>ERF</i>)",,"The growing pervasiveness of technology enables the collection of
copious volumes of personal data which creates risks for consumer
privacy and makes data protection increasingly complex for
organizations. The difficulties facing organizations are further
exasperated by the EU General Data Protection Regulation (GDPR), which
introduces stringent requirements for gaining consent, communicating
privacy practices, and transparency. Furthermore, consumers' current
lack of privacy knowledge can heighten privacy concerns. This study aims
to (1) build consumer privacy knowledge and (2) assist organizations in
gaining explicit consent and communicating their privacy practices to
current and potential customers, through the development of a GDPR
privacy label. The paper contributes to practice by providing actionable
guidelines for developing GDPR compliant privacy notices and advances
privacy literature by extending the privacy knowledge gap model and
testing the effectiveness of the GDPR label in improving consumers'
privacy knowledge thereby building self-efficacy and enabling informed
decision making.",2018,AMCIS 2018 PROCEEDINGS,,"{'unique-id': 'WOS:000589328100132', 'orcid-numbers': 'Lynn, Theo/0000-0001-9284-7580', 'researcherid-numbers': 'Lynn, Theo/AAE-8832-2020', 'isbn': '978-0-9966831-6-6', 'abstract': ""The growing pervasiveness of technology enables the collection of\ncopious volumes of personal data which creates risks for consumer\nprivacy and makes data protection increasingly complex for\norganizations. The difficulties facing organizations are further\nexasperated by the EU General Data Protection Regulation (GDPR), which\nintroduces stringent requirements for gaining consent, communicating\nprivacy practices, and transparency. Furthermore, consumers' current\nlack of privacy knowledge can heighten privacy concerns. This study aims\nto (1) build consumer privacy knowledge and (2) assist organizations in\ngaining explicit consent and communicating their privacy practices to\ncurrent and potential customers, through the development of a GDPR\nprivacy label. The paper contributes to practice by providing actionable\nguidelines for developing GDPR compliant privacy notices and advances\nprivacy literature by extending the privacy knowledge gap model and\ntesting the effectiveness of the GDPR label in improving consumers'\nprivacy knowledge thereby building self-efficacy and enabling informed\ndecision making."", 'note': '24th Americas Conference on Information Systems (AMCIS) - Digital\nDisruption, New Orleans, LA, AUG 16-18, 2018', 'year': '2018', 'booktitle': 'AMCIS 2018 PROCEEDINGS', 'title': 'Communicating Compliance: Developing a GDPR Privacy Label <i>Emergent\nResearch Forum</i> (<i>ERF</i>)', 'book-group-author': 'Assoc Informat Syst', 'author': 'Fox, Grace and Tonge, Colin and Lynn, Theo and Mooney, John', 'ENTRYTYPE': 'inproceedings', 'ID': 'WOS:000589328100132'}",Web of Science
"Bargh, Mortaza S. and van de Mosselaar, Maud and Rutten, Paul and
Choenni, Sunil",On Using Privacy Labels for Visualizing the Privacy Practice of SMEs,,"Privacy is a comprehensive notion which is hard to grasp for the layman.
To make the privacy notion tangible, creating transparency about privacy
practices is an important necessity. Transparency about privacy
practices is traditionally (sought to be) established via providing
privacy policies and privacy seals. These traditional transparency
mechanisms have resulted in limited success in society, where digital
transformation takes place with a fast pace. To address these
challenges, privacy visualization via a label representation, like
energy and food labels, is considered a promising solution direction.
Visualizing privacy, in general, and using privacy labels, in
particular, are not straightforward in practice due to, among others,
the subjectivity and context dependency of privacy and the adverse
(side) impacts of privacy violations. This practicality issue is more
evident for Small and Medium-sized Enterprises (SME's) because, compared
to large enterprises, they have limited resources for protecting and
managing the personal data they process. In this contribution, we
investigate the capabilities and limitations of a privacy label and its
labeling tool for use by SMEs in three business domains. Accordingly,
and within SME settings, we identify the following directions for future
research: Enhancing trust in privacy labels, dealing with network
aspects, adopting privacy labels and labeling tools, using the labeling
process and outcome for auditing own privacy practice, and improving the
current privacy labels and labeling tools.",2022,"PROCEEDINGS OF THE 23RD ANNUAL INTERNATIONAL CONFERENCE ON DIGITAL
GOVERNMENT RESEARCH, DGO 2022: Intelligent Technologies, Governments and
Citizens",,"{'unique-id': 'WOS:001141849300018', 'isbn': '978-1-4503-9750-6', 'doi': '10.1145/3543434.3543480', 'abstract': ""Privacy is a comprehensive notion which is hard to grasp for the layman.\nTo make the privacy notion tangible, creating transparency about privacy\npractices is an important necessity. Transparency about privacy\npractices is traditionally (sought to be) established via providing\nprivacy policies and privacy seals. These traditional transparency\nmechanisms have resulted in limited success in society, where digital\ntransformation takes place with a fast pace. To address these\nchallenges, privacy visualization via a label representation, like\nenergy and food labels, is considered a promising solution direction.\nVisualizing privacy, in general, and using privacy labels, in\nparticular, are not straightforward in practice due to, among others,\nthe subjectivity and context dependency of privacy and the adverse\n(side) impacts of privacy violations. This practicality issue is more\nevident for Small and Medium-sized Enterprises (SME's) because, compared\nto large enterprises, they have limited resources for protecting and\nmanaging the personal data they process. In this contribution, we\ninvestigate the capabilities and limitations of a privacy label and its\nlabeling tool for use by SMEs in three business domains. Accordingly,\nand within SME settings, we identify the following directions for future\nresearch: Enhancing trust in privacy labels, dealing with network\naspects, adopting privacy labels and labeling tools, using the labeling\nprocess and outcome for auditing own privacy practice, and improving the\ncurrent privacy labels and labeling tools."", 'organization': 'Digital Govt Soc', 'note': '23rd Annual International Conference on Digital Government Research\n(DGO) - Intelligent Technologies, Governments and Citizens, ELECTR\nNETWORK, JUN 15-17, 2022', 'pages': '166-175', 'year': '2022', 'booktitle': 'PROCEEDINGS OF THE 23RD ANNUAL INTERNATIONAL CONFERENCE ON DIGITAL\nGOVERNMENT RESEARCH, DGO 2022: Intelligent Technologies, Governments and\nCitizens', 'title': 'On Using Privacy Labels for Visualizing the Privacy Practice of SMEs', 'editor': 'Hagen, L and Solvak, M and Hwang, S', 'author': 'Bargh, Mortaza S. and van de Mosselaar, Maud and Rutten, Paul and\nChoenni, Sunil', 'ENTRYTYPE': 'inproceedings', 'ID': 'WOS:001141849300018'}",Web of Science
"Goncalves de Pontes, Diego Roberto and Zorzo, Sergio Donizetti","PPMark: An Architecture to Generate Privacy Labels Using TF-IDF
Techniques and the Rabin Karp Algorithm",,"Layman and non-layman users often have difficulties to understand
privacy policy texts. The amount of time spent on reading and
comprehending a policy poses a challenge to the user, who rarely pays
attention to what he or she is agreeing to. Given this scenario, this
paper aims to facilitate privacy policy terms presentation regarding
data collection and sharing by introducing a new format called Privacy
Label. Using natural language processing techniques, a model able to
extract information about data collection in privacy policies and
present them in an automated and easy-to-understand way to the user was
built. To validate this model we used a precision assessment method
where the accuracy of the extracted information was measured. The
precision of our modelwas 0.685 (69\%) when recovering information
regarding data handling, making it possible for the final user to
understand which data is being collected without reading the whole
policy. The PPMark architecture can facilitate the notice-and-choice by
presenting privacy policy information in an alternative way for online
users.",2016,INFORMATION TECHNOLOGY: NEW GENERATIONS,,"{'unique-id': 'WOS:000385289400089', 'isbn': '978-3-319-32467-8; 978-3-319-32466-1', 'eissn': '2194-5365', 'issn': '2194-5357', 'doi': '10.1007/978-3-319-32467-8\\_89', 'abstract': 'Layman and non-layman users often have difficulties to understand\nprivacy policy texts. The amount of time spent on reading and\ncomprehending a policy poses a challenge to the user, who rarely pays\nattention to what he or she is agreeing to. Given this scenario, this\npaper aims to facilitate privacy policy terms presentation regarding\ndata collection and sharing by introducing a new format called Privacy\nLabel. Using natural language processing techniques, a model able to\nextract information about data collection in privacy policies and\npresent them in an automated and easy-to-understand way to the user was\nbuilt. To validate this model we used a precision assessment method\nwhere the accuracy of the extracted information was measured. The\nprecision of our modelwas 0.685 (69\\%) when recovering information\nregarding data handling, making it possible for the final user to\nunderstand which data is being collected without reading the whole\npolicy. The PPMark architecture can facilitate the notice-and-choice by\npresenting privacy policy information in an alternative way for online\nusers.', 'note': '13th International Conference on Information Technology - New\nGenerations (ITNG), Las Vegas, NV, APR 11-13, 2016', 'pages': '1029-1040', 'volume': '448', 'year': '2016', 'series': 'Advances in Intelligent Systems and Computing', 'booktitle': 'INFORMATION TECHNOLOGY: NEW GENERATIONS', 'title': 'PPMark: An Architecture to Generate Privacy Labels Using TF-IDF\nTechniques and the Rabin Karp Algorithm', 'editor': 'Latifi, S', 'author': 'Goncalves de Pontes, Diego Roberto and Zorzo, Sergio Donizetti', 'ENTRYTYPE': 'inproceedings', 'ID': 'WOS:000385289400089'}",Web of Science
"Chen, Claire C and Shu, Dillon and Ravishankar, Hamsini and Li, Xinran and Agarwal, Yuvraj and Cranor, Lorrie Faith",Is a Trustmark and QR Code Enough? The Effect of IoT Security and Privacy Label Information Complexity on Consumer Comprehension and Behavior,"Ambient Devices / Internet of Things, Privacy, Security, Smart Environments / Connected Home","The U.S. Government is developing a package label to help consumers access reliable security and privacy information about Internet of Things (IoT) devices when making purchase decisions. The label will include the U.S. Cyber Trust Mark, a QR code to scan for more details, and potentially additional information. To examine how label information complexity and educational interventions affect comprehension of security and privacy attributes and label QR code use, we conducted an online survey with 518 IoT purchasers. We examined participants’ comprehension and preferences for three labels of varying complexities, with and without an educational intervention. Participants favored and correctly utilized the two higher-complexity labels, showing a special interest in the privacy-relevant content. Furthermore, while the educational intervention improved understanding of the QR code’s purpose, it had a modest effect on QR scanning behavior. We highlight clear design and policy directions for creating and deploying IoT security and privacy labels.",2024,Proceedings of the CHI Conference on Human Factors in Computing Systems,https://doi.org/10.1145/3613904.3642011,"{'series': ""CHI '24"", 'location': '<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>', 'keywords': 'Ambient Devices / Internet of Things, Privacy, Security, Smart Environments / Connected Home', 'numpages': '32', 'articleno': '832', 'booktitle': 'Proceedings of the CHI Conference on Human Factors in Computing Systems', 'abstract': 'The U.S. Government is developing a package label to help consumers access reliable security and privacy information about Internet of Things (IoT) devices when making purchase decisions. The label will include the U.S. Cyber Trust Mark, a QR code to scan for more details, and potentially additional information. To examine how label information complexity and educational interventions affect comprehension of security and privacy attributes and label QR code use, we conducted an online survey with 518 IoT purchasers. We examined participants’ comprehension and preferences for three labels of varying complexities, with and without an educational intervention. Participants favored and correctly utilized the two higher-complexity labels, showing a special interest in the privacy-relevant content. Furthermore, while the educational intervention improved understanding of the QR code’s purpose, it had a modest effect on QR scanning behavior. We highlight clear design and policy directions for creating and deploying IoT security and privacy labels.', 'doi': '10.1145/3613904.3642011', 'url': 'https://doi.org/10.1145/3613904.3642011', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400703300', 'year': '2024', 'title': 'Is a Trustmark and QR Code Enough? The Effect of IoT Security and Privacy Label Information Complexity on Consumer Comprehension and Behavior', 'author': 'Chen, Claire C and Shu, Dillon and Ravishankar, Hamsini and Li, Xinran and Agarwal, Yuvraj and Cranor, Lorrie Faith', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3613904.3642011'}",ACM
"S. Bargh, Mortaza and van de Mosselaar, Maud and Rutten, Paul and Choenni, Sunil",On Using Privacy Labels for Visualizing the Privacy Practice of SMEs: Challenges and Research Directions,"trust, transparency, privacy label, SMEs, Online services","Privacy is a comprehensive notion which is hard to grasp for the layman. To make the privacy notion tangible, creating transparency about privacy practices is an important necessity. Transparency about privacy practices is traditionally (sought to be) established via providing privacy policies and privacy seals. These traditional transparency mechanisms have resulted in limited success in society, where digital transformation takes place with a fast pace. To address these challenges, privacy visualization via a label representation, like energy and food labels, is considered a promising solution direction. Visualizing privacy, in general, and using privacy labels, in particular, are not straightforward in practice due to, among others, the subjectivity and context dependency of privacy and the adverse (side) impacts of privacy violations. This practicality issue is more evident for Small and Medium-sized Enterprises (SME's) because, compared to large enterprises, they have limited resources for protecting and managing the personal data they process. In this contribution, we investigate the capabilities and limitations of a privacy label and its labeling tool for use by SMEs in three business domains. Accordingly, and within SME settings, we identify the following directions for future research: Enhancing trust in privacy labels, dealing with network aspects, adopting privacy labels and labeling tools, using the labeling process and outcome for auditing own privacy practice, and improving the current privacy labels and labeling tools.",2022,DG.O 2022: The 23rd Annual International Conference on Digital Government Research,https://doi.org/10.1145/3543434.3543480,"{'series': 'dg.o 2022', 'location': 'Virtual Event, Republic of Korea', 'keywords': 'trust, transparency, privacy label, SMEs, Online services', 'numpages': '10', 'pages': '166–175', 'booktitle': 'DG.O 2022: The 23rd Annual International Conference on Digital Government Research', 'abstract': ""Privacy is a comprehensive notion which is hard to grasp for the layman. To make the privacy notion tangible, creating transparency about privacy practices is an important necessity. Transparency about privacy practices is traditionally (sought to be) established via providing privacy policies and privacy seals. These traditional transparency mechanisms have resulted in limited success in society, where digital transformation takes place with a fast pace. To address these challenges, privacy visualization via a label representation, like energy and food labels, is considered a promising solution direction. Visualizing privacy, in general, and using privacy labels, in particular, are not straightforward in practice due to, among others, the subjectivity and context dependency of privacy and the adverse (side) impacts of privacy violations. This practicality issue is more evident for Small and Medium-sized Enterprises (SME's) because, compared to large enterprises, they have limited resources for protecting and managing the personal data they process. In this contribution, we investigate the capabilities and limitations of a privacy label and its labeling tool for use by SMEs in three business domains. Accordingly, and within SME settings, we identify the following directions for future research: Enhancing trust in privacy labels, dealing with network aspects, adopting privacy labels and labeling tools, using the labeling process and outcome for auditing own privacy practice, and improving the current privacy labels and labeling tools."", 'doi': '10.1145/3543434.3543480', 'url': 'https://doi.org/10.1145/3543434.3543480', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450397490', 'year': '2022', 'title': 'On Using Privacy Labels for Visualizing the Privacy Practice of SMEs: Challenges and Research Directions', 'author': 'S. Bargh, Mortaza and van de Mosselaar, Maud and Rutten, Paul and Choenni, Sunil', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3543434.3543480'}",ACM
"Li, Tianshi and Cranor, Lorrie Faith and Agarwal, Yuvraj and Hong, Jason I.",Matcha: An IDE Plugin for Creating Accurate Privacy Nutrition Labels,,"Apple and Google introduced their versions of privacy nutrition labels to the mobile app stores to better inform users of the apps' data practices. However, these labels are self-reported by developers and have been found to contain many inaccuracies due to misunderstandings of the label taxonomy. In this work, we present Matcha, an IDE plugin that uses automated code analysis to help developers create accurate Google Play data safety labels. Developers can benefit from Matcha's ability to detect user data accesses and transmissions while staying in control of the generated label by adding custom Java annotations and modifying an auto-generated XML specification. Our evaluation with 12 developers showed that Matcha helped our participants improved the accuracy of a label they created with Google's official tool for a real-world app they developed. We found that participants preferred Matcha for its accuracy benefits. Drawing on Matcha, we discuss general design recommendations for developer tools used to create accurate standardized privacy notices.",2024,Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.,https://doi.org/10.1145/3643544,"{'numpages': '38', 'articleno': '33', 'month': 'mar', 'journal': 'Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.', 'abstract': ""Apple and Google introduced their versions of privacy nutrition labels to the mobile app stores to better inform users of the apps' data practices. However, these labels are self-reported by developers and have been found to contain many inaccuracies due to misunderstandings of the label taxonomy. In this work, we present Matcha, an IDE plugin that uses automated code analysis to help developers create accurate Google Play data safety labels. Developers can benefit from Matcha's ability to detect user data accesses and transmissions while staying in control of the generated label by adding custom Java annotations and modifying an auto-generated XML specification. Our evaluation with 12 developers showed that Matcha helped our participants improved the accuracy of a label they created with Google's official tool for a real-world app they developed. We found that participants preferred Matcha for its accuracy benefits. Drawing on Matcha, we discuss general design recommendations for developer tools used to create accurate standardized privacy notices."", 'doi': '10.1145/3643544', 'url': 'https://doi.org/10.1145/3643544', 'number': '1', 'volume': '8', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'issue_date': 'March 2024', 'year': '2024', 'title': 'Matcha: An IDE Plugin for Creating Accurate Privacy Nutrition Labels', 'author': 'Li, Tianshi and Cranor, Lorrie Faith and Agarwal, Yuvraj and Hong, Jason I.', 'ENTRYTYPE': 'article', 'ID': '10.1145/3643544'}",ACM
"Vishwamitra, Nishant and Li, Yifang and Hu, Hongxin and Caine, Kelly and Cheng, Long and Zhao, Ziming and Ahn, Gail-Joon",Towards Automated Content-based Photo Privacy Control in User-Centered Social Networks,"social media, privacy control, deep learning","A large number of photos shared online often contain private user information, which can cause serious privacy breaches when viewed by unauthorized users. Thus, there is a need for more efficient privacy control that requires automatic detection of users' private photos. However, the automatic detection of users' private photos is a challenging task, since different users may have different privacy concerns and a generalized one-size-fits-all approach for private photo detection would not be suitable for most users. User-specific detection of private photos should, therefore, be investigated. Furthermore, for effective privacy control, the exact sensitive regions in private photos need to be pinpointed, so that sensitive content can be protected via different privacy control methods. In this paper, we propose a novel system, AutoPri, to enable automatic and user-specific content-based photo privacy control in online social networks. We collect a large dataset of 31, 566 private and public photos from real-world users and present important observations on photo privacy concerns. Our system can automatically detect private photos in a user-specific manner using a detection model based on a multimodal variational autoencoder and pinpoint sensitive regions in private photos with an explainable deep learning-based approach. Our evaluations show that AutoPri can effectively determine user-specific private photos with high accuracy (94.32\%) and pinpoint exact sensitive regions in them to enable effective privacy control in user-centered online social networks.",2022,Proceedings of the Twelfth ACM Conference on Data and Application Security and Privacy,https://doi.org/10.1145/3508398.3511517,"{'series': ""CODASPY '22"", 'location': 'Baltimore, MD, USA', 'keywords': 'social media, privacy control, deep learning', 'numpages': '12', 'pages': '65–76', 'booktitle': 'Proceedings of the Twelfth ACM Conference on Data and Application Security and Privacy', 'abstract': ""A large number of photos shared online often contain private user information, which can cause serious privacy breaches when viewed by unauthorized users. Thus, there is a need for more efficient privacy control that requires automatic detection of users' private photos. However, the automatic detection of users' private photos is a challenging task, since different users may have different privacy concerns and a generalized one-size-fits-all approach for private photo detection would not be suitable for most users. User-specific detection of private photos should, therefore, be investigated. Furthermore, for effective privacy control, the exact sensitive regions in private photos need to be pinpointed, so that sensitive content can be protected via different privacy control methods. In this paper, we propose a novel system, AutoPri, to enable automatic and user-specific content-based photo privacy control in online social networks. We collect a large dataset of 31, 566 private and public photos from real-world users and present important observations on photo privacy concerns. Our system can automatically detect private photos in a user-specific manner using a detection model based on a multimodal variational autoencoder and pinpoint sensitive regions in private photos with an explainable deep learning-based approach. Our evaluations show that AutoPri can effectively determine user-specific private photos with high accuracy (94.32\\%) and pinpoint exact sensitive regions in them to enable effective privacy control in user-centered online social networks."", 'doi': '10.1145/3508398.3511517', 'url': 'https://doi.org/10.1145/3508398.3511517', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450392204', 'year': '2022', 'title': 'Towards Automated Content-based Photo Privacy Control in User-Centered Social Networks', 'author': 'Vishwamitra, Nishant and Li, Yifang and Hu, Hongxin and Caine, Kelly and Cheng, Long and Zhao, Ziming and Ahn, Gail-Joon', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3508398.3511517'}",ACM
"Nakajima, Kazuki and Shudo, Kazuyuki",Estimating Properties of Social Networks via Random Walk considering Private Nodes,"social networks, sampling, random walk, private nodes, estimation","Accurately analyzing graph properties of social networks is a challenging task because of access limitations to the graph data. To address this challenge, several algorithms to obtain unbiased estimates of properties from few samples via a random walk have been studied. However, existing algorithms do not consider private nodes who hide their neighbors in real social networks, leading to some practical problems. Here we design random walk-based algorithms to accurately estimate properties without any problems caused by private nodes. First, we design a random walk-based sampling algorithm that comprises the neighbor selection to obtain samples having the Markov property and the calculation of weights for each sample to correct the sampling bias. Further, for two graph property estimators, we propose the weighting methods to reduce not only the sampling bias but also estimation errors due to private nodes. The proposed algorithms improve the estimation accuracy of the existing algorithms by up to 92.6\% on real-world datasets.",2020,Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \&amp; Data Mining,https://doi.org/10.1145/3394486.3403116,"{'series': ""KDD '20"", 'location': 'Virtual Event, CA, USA', 'keywords': 'social networks, sampling, random walk, private nodes, estimation', 'numpages': '11', 'pages': '720–730', 'booktitle': 'Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \\&amp; Data Mining', 'abstract': 'Accurately analyzing graph properties of social networks is a challenging task because of access limitations to the graph data. To address this challenge, several algorithms to obtain unbiased estimates of properties from few samples via a random walk have been studied. However, existing algorithms do not consider private nodes who hide their neighbors in real social networks, leading to some practical problems. Here we design random walk-based algorithms to accurately estimate properties without any problems caused by private nodes. First, we design a random walk-based sampling algorithm that comprises the neighbor selection to obtain samples having the Markov property and the calculation of weights for each sample to correct the sampling bias. Further, for two graph property estimators, we propose the weighting methods to reduce not only the sampling bias but also estimation errors due to private nodes. The proposed algorithms improve the estimation accuracy of the existing algorithms by up to 92.6\\% on real-world datasets.', 'doi': '10.1145/3394486.3403116', 'url': 'https://doi.org/10.1145/3394486.3403116', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450379984', 'year': '2020', 'title': 'Estimating Properties of Social Networks via Random Walk considering Private Nodes', 'author': 'Nakajima, Kazuki and Shudo, Kazuyuki', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3394486.3403116'}",ACM
"Zhong, Haoti and Squicciarini, Anna and Miller, David",Toward Automated Multiparty Privacy Conflict Detection,"privacy, access control","In an effort to support users' decision making process in regards to shared and co-managed online images, in this paper we present a novel model to early detect images which may be subject to possible conflicting access control decisions. We present a group-based stochastic model able to identify potential privacy conflicts among multiple stakeholders of an image. We discuss experiments on a dataset of over 3000 online images, and compare our results with several baselines. Our approach outperforms all baselines, even the strong ones based on a Convolutional Neural Network architecture.",2018,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,https://doi.org/10.1145/3269206.3269329,"{'series': ""CIKM '18"", 'location': 'Torino, Italy', 'keywords': 'privacy, access control', 'numpages': '4', 'pages': '1811–1814', 'booktitle': 'Proceedings of the 27th ACM International Conference on Information and Knowledge Management', 'abstract': ""In an effort to support users' decision making process in regards to shared and co-managed online images, in this paper we present a novel model to early detect images which may be subject to possible conflicting access control decisions. We present a group-based stochastic model able to identify potential privacy conflicts among multiple stakeholders of an image. We discuss experiments on a dataset of over 3000 online images, and compare our results with several baselines. Our approach outperforms all baselines, even the strong ones based on a Convolutional Neural Network architecture."", 'doi': '10.1145/3269206.3269329', 'url': 'https://doi.org/10.1145/3269206.3269329', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450360142', 'year': '2018', 'title': 'Toward Automated Multiparty Privacy Conflict Detection', 'author': 'Zhong, Haoti and Squicciarini, Anna and Miller, David', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3269206.3269329'}",ACM
"Nakajima, Kazuki and Shudo, Kazuyuki",Random Walk Sampling in Social Networks Involving Private Nodes,"private nodes, random walk, sampling, estimation, Social networks","Analysis of social networks with limited data access is challenging for third parties. To address this challenge, a number of studies have developed algorithms that estimate properties of social networks via a simple random walk. However, most existing algorithms do not assume private nodes that do not publish their neighbors’ data when they are queried in empirical social networks. Here we propose a practical framework for estimating properties via random walk-based sampling in social networks involving private nodes. First, we develop a sampling algorithm by extending a simple random walk to the case of social networks involving private nodes. Then, we propose estimators with reduced biases induced by private nodes for the network size, average degree, and density of the node label. Our results show that the proposed estimators reduce biases induced by private nodes in the existing estimators by up to 92.6\% on social network datasets involving private nodes.",2023,ACM Trans. Knowl. Discov. Data,https://doi.org/10.1145/3561388,"{'keywords': 'private nodes, random walk, sampling, estimation, Social networks', 'numpages': '28', 'articleno': '51', 'month': 'feb', 'journal': 'ACM Trans. Knowl. Discov. Data', 'abstract': 'Analysis of social networks with limited data access is challenging for third parties. To address this challenge, a number of studies have developed algorithms that estimate properties of social networks via a simple random walk. However, most existing algorithms do not assume private nodes that do not publish their neighbors’ data when they are queried in empirical social networks. Here we propose a practical framework for estimating properties via random walk-based sampling in social networks involving private nodes. First, we develop a sampling algorithm by extending a simple random walk to the case of social networks involving private nodes. Then, we propose estimators with reduced biases induced by private nodes for the network size, average degree, and density of the node label. Our results show that the proposed estimators reduce biases induced by private nodes in the existing estimators by up to 92.6\\% on social network datasets involving private nodes.', 'doi': '10.1145/3561388', 'url': 'https://doi.org/10.1145/3561388', 'issn': '1556-4681', 'number': '4', 'volume': '17', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'issue_date': 'May 2023', 'year': '2023', 'title': 'Random Walk Sampling in Social Networks Involving Private Nodes', 'author': 'Nakajima, Kazuki and Shudo, Kazuyuki', 'ENTRYTYPE': 'article', 'ID': '10.1145/3561388'}",ACM
"Boukoros, Spyros and Katzenbeisser, Stefan",Measuring privacy in high dimensional microdata collections,"user empowerment, privacy metrics, privacy, microdata","Microdata is collected by companies in order to enhance their quality of service as well as the accuracy of their recommendation systems. These data often become publicly available after they have been sanitized. Recent reidentification attacks on publicly available, sanitized datasets illustrate the privacy risks involved in microdata collections. Currently, users have to trust the provider that their data will be safe in case data is published or if a privacy breach occurs. In this work, we empower users by developing a novel, user-centric tool for privacy measurement and a new lightweight privacy metric. The goal of our tool is to estimate users' privacy level prior to sharing their data with a provider. Hence, users can consciously decide whether to contribute their data. Our tool estimates an individuals' privacy level based on published popularity statistics regarding the items in the provider's database, and the users' microdata. In this work, we describe the architecture of our tool as well as a novel privacy metric, which is necessary for our setting where we do not have access to the provider's database. Our tool is user friendly, relying on smart visual results that raise privacy awareness. We evaluate our tool using three real world datasets, collected from major providers. We demonstrate strong correlations between the average anonymity set per user and the privacy score obtained by our metric. Our results illustrate that our tool which uses minimal information from the provider, estimates users' privacy levels comparably well, as if it had access to the actual database.",2017,"Proceedings of the 12th International Conference on Availability, Reliability and Security",https://doi.org/10.1145/3098954.3098977,"{'series': ""ARES '17"", 'location': 'Reggio Calabria, Italy', 'keywords': 'user empowerment, privacy metrics, privacy, microdata', 'numpages': '8', 'articleno': '15', 'booktitle': 'Proceedings of the 12th International Conference on Availability, Reliability and Security', 'abstract': ""Microdata is collected by companies in order to enhance their quality of service as well as the accuracy of their recommendation systems. These data often become publicly available after they have been sanitized. Recent reidentification attacks on publicly available, sanitized datasets illustrate the privacy risks involved in microdata collections. Currently, users have to trust the provider that their data will be safe in case data is published or if a privacy breach occurs. In this work, we empower users by developing a novel, user-centric tool for privacy measurement and a new lightweight privacy metric. The goal of our tool is to estimate users' privacy level prior to sharing their data with a provider. Hence, users can consciously decide whether to contribute their data. Our tool estimates an individuals' privacy level based on published popularity statistics regarding the items in the provider's database, and the users' microdata. In this work, we describe the architecture of our tool as well as a novel privacy metric, which is necessary for our setting where we do not have access to the provider's database. Our tool is user friendly, relying on smart visual results that raise privacy awareness. We evaluate our tool using three real world datasets, collected from major providers. We demonstrate strong correlations between the average anonymity set per user and the privacy score obtained by our metric. Our results illustrate that our tool which uses minimal information from the provider, estimates users' privacy levels comparably well, as if it had access to the actual database."", 'doi': '10.1145/3098954.3098977', 'url': 'https://doi.org/10.1145/3098954.3098977', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450352574', 'year': '2017', 'title': 'Measuring privacy in high dimensional microdata collections', 'author': 'Boukoros, Spyros and Katzenbeisser, Stefan', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3098954.3098977'}",ACM
"Ayci, G\""{o}n\""{u}l",Uncertainty-aware Personal Assistant and Explanation Method for Privacy Decisions,"explainability, online social networks, privacy, uncertainty","In many of today's software systems, most notably online social networks, users can share personal information. Behind the simple action of sharing is a more complicated thought process regarding privacy: which content to share, with whom to share, and why to share. For a user, it's time-consuming and error-prone to check individual personal content for privacy violations. Hence, it would be ideal if a personal assistant can learn its users' privacy preferences and subsequently help users' decision-making by signaling potentially private content. A personalized privacy assistant can help its user make privacy decisions taking into account the ambiguity and uncertainty of privacy predictions as well as its user's personal preferences. Moreover, an explanation of why an image is considered public or private can aid the user in understanding the assistant's decisions.",2023,Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems,,"{'series': ""AAMAS '23"", 'location': '<conf-loc>, <city>London</city>, <country>United Kingdom</country>, </conf-loc>', 'keywords': 'explainability, online social networks, privacy, uncertainty', 'numpages': '2', 'pages': '2991–2992', 'booktitle': 'Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems', 'abstract': ""In many of today's software systems, most notably online social networks, users can share personal information. Behind the simple action of sharing is a more complicated thought process regarding privacy: which content to share, with whom to share, and why to share. For a user, it's time-consuming and error-prone to check individual personal content for privacy violations. Hence, it would be ideal if a personal assistant can learn its users' privacy preferences and subsequently help users' decision-making by signaling potentially private content. A personalized privacy assistant can help its user make privacy decisions taking into account the ambiguity and uncertainty of privacy predictions as well as its user's personal preferences. Moreover, an explanation of why an image is considered public or private can aid the user in understanding the assistant's decisions."", 'address': 'Richland, SC', 'publisher': 'International Foundation for Autonomous Agents and Multiagent Systems', 'isbn': '9781450394321', 'year': '2023', 'title': 'Uncertainty-aware Personal Assistant and Explanation Method for Privacy Decisions', 'author': 'Ayci, G\\""{o}n\\""{u}l', 'ENTRYTYPE': 'inproceedings', 'ID': '10.5555/3545946.3599148'}",ACM
"Caven, Peter and Zhang, Zitao and Abbott, Jacob and Ma, Xinyao and Camp, L. Jean",Comparing the Use and Usefulness of Four IoT Security Labels,"IoT, icons, interaction, labels, privacy, security, trust","There are currently multiple proposed security label designs for consumer products, with each prioritizing different security and privacy factors. These differences risk making product comparisons more confusing than informative. Standardized labels could potentially resolve this by informing consumers of a product’s security features at the point of purchase. But which standard? This survey, of 500 participants, studied four label designs and measured comprehension, response time, acceptability, and cognitive load. We gauged understanding of participant perception and preferences using three smart devices: light bulbs, cameras, and thermostats. We identified preferences and behaviors before, during, and after label use for product selection. At first, participants believed more information-dense labels would better support their purchasing behavior; however, after they evaluated and compared products, participants gravitated towards less cognitively demanding designs. We identified how participants utilized and prioritized label elements to provide recommendations for US label design efforts.",2024,Proceedings of the CHI Conference on Human Factors in Computing Systems,https://doi.org/10.1145/3613904.3642951,"{'series': ""CHI '24"", 'location': '<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>', 'keywords': 'IoT, icons, interaction, labels, privacy, security, trust', 'numpages': '31', 'articleno': '827', 'booktitle': 'Proceedings of the CHI Conference on Human Factors in Computing Systems', 'abstract': 'There are currently multiple proposed security label designs for consumer products, with each prioritizing different security and privacy factors. These differences risk making product comparisons more confusing than informative. Standardized labels could potentially resolve this by informing consumers of a product’s security features at the point of purchase. But which standard? This survey, of 500 participants, studied four label designs and measured comprehension, response time, acceptability, and cognitive load. We gauged understanding of participant perception and preferences using three smart devices: light bulbs, cameras, and thermostats. We identified preferences and behaviors before, during, and after label use for product selection. At first, participants believed more information-dense labels would better support their purchasing behavior; however, after they evaluated and compared products, participants gravitated towards less cognitively demanding designs. We identified how participants utilized and prioritized label elements to provide recommendations for US label design efforts.', 'doi': '10.1145/3613904.3642951', 'url': 'https://doi.org/10.1145/3613904.3642951', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400703300', 'year': '2024', 'title': 'Comparing the Use and Usefulness of Four IoT Security Labels', 'author': 'Caven, Peter and Zhang, Zitao and Abbott, Jacob and Ma, Xinyao and Camp, L. Jean', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3613904.3642951'}",ACM
"Cappellari, Paolo and Chun, Soon Ae and Perelman, Mark",A Tool for Automatic Assessment and Awareness of Privacy Disclosure,"supervised learning, e-government, Twitter, Social media","With increasing frequency, the communication between citizens and institutions occurs via some type of e-mechanism, such as websites, emails, and social media. In particular, social media platforms are widely being adopted because of their simplicity of use, the large user base, and their high pervasiveness. One concern is that users may disclose sensitive information beyond the scope of the interaction with the institutions, not realizing that such data remains on these platforms. While awareness about basic data (e.g. address, date of birth) protection has risen in the past few years, many users still neglect or fail to realize the amount and significance of the personal information deliberately or involuntarily disclosed on these communication platforms. Determining private from non-private data is difficult. The goal of this work is to devise a method to detect messages carrying sensitive information from those that not. Specifically, we employ machine learning methods to build a privacy decision making tool. This work will contribute to develop a privacy protection framework where a client-side privacy awareness mechanism can alert users of the potential private information leakages in their communications.",2017,Proceedings of the 18th Annual International Conference on Digital Government Research,https://doi.org/10.1145/3085228.3085259,"{'series': ""dg.o '17"", 'location': 'Staten Island, NY, USA', 'keywords': 'supervised learning, e-government, Twitter, Social media', 'numpages': '2', 'pages': '586–587', 'booktitle': 'Proceedings of the 18th Annual International Conference on Digital Government Research', 'abstract': 'With increasing frequency, the communication between citizens and institutions occurs via some type of e-mechanism, such as websites, emails, and social media. In particular, social media platforms are widely being adopted because of their simplicity of use, the large user base, and their high pervasiveness. One concern is that users may disclose sensitive information beyond the scope of the interaction with the institutions, not realizing that such data remains on these platforms. While awareness about basic data (e.g. address, date of birth) protection has risen in the past few years, many users still neglect or fail to realize the amount and significance of the personal information deliberately or involuntarily disclosed on these communication platforms. Determining private from non-private data is difficult. The goal of this work is to devise a method to detect messages carrying sensitive information from those that not. Specifically, we employ machine learning methods to build a privacy decision making tool. This work will contribute to develop a privacy protection framework where a client-side privacy awareness mechanism can alert users of the potential private information leakages in their communications.', 'doi': '10.1145/3085228.3085259', 'url': 'https://doi.org/10.1145/3085228.3085259', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450353175', 'year': '2017', 'title': 'A Tool for Automatic Assessment and Awareness of Privacy Disclosure', 'author': 'Cappellari, Paolo and Chun, Soon Ae and Perelman, Mark', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3085228.3085259'}",ACM
"Liu, Sicong and Du, Junzhao and Shrivastava, Anshumali and Zhong, Lin",Privacy Adversarial Network: Representation Learning for Mobile Data Privacy,,"The remarkable success of machine learning has fostered a growing number of cloud-based intelligent services for mobile users. Such a service requires a user to send data, e.g. image, voice and video, to the provider, which presents a serious challenge to user privacy. To address this, prior works either obfuscate the data, e.g. add noise and remove identity information, or send representations extracted from the data, e.g. anonymized features. They struggle to balance between the service utility and data privacy because obfuscated data reduces utility and extracted representation may still reveal sensitive information.This work departs from prior works in methodology: we leverage adversarial learning to better balance between privacy and utility. We design a representation encoder that generates the feature representations to optimize against the privacy disclosure risk of sensitive information (a measure of privacy) by the privacy adversaries, and concurrently optimize with the task inference accuracy (a measure of utility) by the utility discriminator. The result is the privacy adversarial network (PAN), a novel deep model with the new training algorithm, that can automatically learn representations from the raw data. And the trained encoder can be deployed on the user side to generate representations that satisfy the task-defined utility requirements and the user-specified/agnostic privacy budgets.Intuitively, PAN adversarially forces the extracted representations to only convey information required by the target task. Surprisingly, this constitutes an implicit regularization that actually improves task accuracy. As a result, PAN achieves better utility and better privacy at the same time! We report extensive experiments on six popular datasets, and demonstrate the superiority of PAN compared with alternative methods reported in prior work.",2020,Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.,https://doi.org/10.1145/3369816,"{'numpages': '18', 'articleno': '144', 'month': 'sep', 'journal': 'Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.', 'abstract': 'The remarkable success of machine learning has fostered a growing number of cloud-based intelligent services for mobile users. Such a service requires a user to send data, e.g. image, voice and video, to the provider, which presents a serious challenge to user privacy. To address this, prior works either obfuscate the data, e.g. add noise and remove identity information, or send representations extracted from the data, e.g. anonymized features. They struggle to balance between the service utility and data privacy because obfuscated data reduces utility and extracted representation may still reveal sensitive information.This work departs from prior works in methodology: we leverage adversarial learning to better balance between privacy and utility. We design a representation encoder that generates the feature representations to optimize against the privacy disclosure risk of sensitive information (a measure of privacy) by the privacy adversaries, and concurrently optimize with the task inference accuracy (a measure of utility) by the utility discriminator. The result is the privacy adversarial network (PAN), a novel deep model with the new training algorithm, that can automatically learn representations from the raw data. And the trained encoder can be deployed on the user side to generate representations that satisfy the task-defined utility requirements and the user-specified/agnostic privacy budgets.Intuitively, PAN adversarially forces the extracted representations to only convey information required by the target task. Surprisingly, this constitutes an implicit regularization that actually improves task accuracy. As a result, PAN achieves better utility and better privacy at the same time! We report extensive experiments on six popular datasets, and demonstrate the superiority of PAN compared with alternative methods reported in prior work.', 'doi': '10.1145/3369816', 'url': 'https://doi.org/10.1145/3369816', 'number': '4', 'volume': '3', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'issue_date': 'December 2019', 'year': '2020', 'title': 'Privacy Adversarial Network: Representation Learning for Mobile Data Privacy', 'author': 'Liu, Sicong and Du, Junzhao and Shrivastava, Anshumali and Zhong, Lin', 'ENTRYTYPE': 'article', 'ID': '10.1145/3369816'}",ACM
"Warden, Pete and Stewart, Matthew and Plancher, Brian and Katti, Sachin and Reddi, Vijay Janapa",Machine Learning Sensors,,A design paradigm for the future of intelligent sensors.,2023,Commun. ACM,https://doi.org/10.1145/3586991,"{'numpages': '4', 'pages': '25–28', 'month': 'oct', 'journal': 'Commun. ACM', 'abstract': 'A design paradigm for the future of intelligent sensors.', 'doi': '10.1145/3586991', 'url': 'https://doi.org/10.1145/3586991', 'issn': '0001-0782', 'number': '11', 'volume': '66', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'issue_date': 'November 2023', 'year': '2023', 'title': 'Machine Learning Sensors', 'author': 'Warden, Pete and Stewart, Matthew and Plancher, Brian and Katti, Sachin and Reddi, Vijay Janapa', 'ENTRYTYPE': 'article', 'ID': '10.1145/3586991'}",ACM
"Kanchi, Shravya and Karlapalem, Kamalakar",A Multi Perspective Access Control in a Smart Home,"smart home, over-privilege, multi-user, internet of things","Existing methods to manage privileges in smart home systems have not considered allocating privileges to users based on (i) the relationship of the user with the device, (ii) the location and risk of the device and (iii) the current environment. In this work, we take a multi perspective view on the problem of sharing fine-grained privileges of IoT devices among multiple users in a smart home. We propose the concepts of user role (subset of privileges specific to each device), tasks and security levels (labels for each privilege) to allot right privileges to users. Thereby, limiting the exploitation of privileges assigned to legitimate insiders of the house. Thus, our work matches the aspirations of previous surveys on building a comprehensive access control system to manage privileges in a shared smart home.",2021,Proceedings of the Eleventh ACM Conference on Data and Application Security and Privacy,https://doi.org/10.1145/3422337.3450324,"{'series': ""CODASPY '21"", 'location': 'Virtual Event, USA', 'keywords': 'smart home, over-privilege, multi-user, internet of things', 'numpages': '3', 'pages': '321–323', 'booktitle': 'Proceedings of the Eleventh ACM Conference on Data and Application Security and Privacy', 'abstract': 'Existing methods to manage privileges in smart home systems have not considered allocating privileges to users based on (i) the relationship of the user with the device, (ii) the location and risk of the device and (iii) the current environment. In this work, we take a multi perspective view on the problem of sharing fine-grained privileges of IoT devices among multiple users in a smart home. We propose the concepts of user role (subset of privileges specific to each device), tasks and security levels (labels for each privilege) to allot right privileges to users. Thereby, limiting the exploitation of privileges assigned to legitimate insiders of the house. Thus, our work matches the aspirations of previous surveys on building a comprehensive access control system to manage privileges in a shared smart home.', 'doi': '10.1145/3422337.3450324', 'url': 'https://doi.org/10.1145/3422337.3450324', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450381437', 'year': '2021', 'title': 'A Multi Perspective Access Control in a Smart Home', 'author': 'Kanchi, Shravya and Karlapalem, Kamalakar', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3422337.3450324'}",ACM
,dg.o 2022: DG.O 2022: The 23rd Annual International Conference on Digital Government Research,,,2022,,,"{'location': 'Virtual Event, Republic of Korea', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450397490', 'year': '2022', 'title': 'dg.o 2022: DG.O 2022: The 23rd Annual International Conference on Digital Government Research', 'ENTRYTYPE': 'proceedings', 'ID': '10.1145/3543434'}",ACM
"Lee, Hao-Ping (Hank) and Yang, Yu-Ju and Von Davier, Thomas Serban and Forlizzi, Jodi and Das, Sauvik","Deepfakes, Phrenology, Surveillance, and More! A Taxonomy of AI Privacy Risks","AI incidents, Human-centered AI, Privacy, Privacy risks, Privacy taxonomy","Privacy is a key principle for developing ethical AI technologies, but how does including AI technologies in products and services change privacy risks? We constructed a taxonomy of AI privacy risks by analyzing 321 documented AI privacy incidents. We codified how the unique capabilities and requirements of AI technologies described in those incidents generated new privacy risks, exacerbated known ones, or otherwise did not meaningfully alter the risk. We present 12 high-level privacy risks that AI technologies either newly created (e.g., exposure risks from deepfake pornography) or exacerbated (e.g., surveillance risks from collecting training data). One upshot of our work is that incorporating AI technologies into a product can alter the privacy risks it entails. Yet, current approaches to privacy-preserving AI/ML (e.g., federated learning, differential privacy, checklists) only address a subset of the privacy risks arising from the capabilities and data requirements of AI.",2024,Proceedings of the CHI Conference on Human Factors in Computing Systems,https://doi.org/10.1145/3613904.3642116,"{'series': ""CHI '24"", 'location': '<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>', 'keywords': 'AI incidents, Human-centered AI, Privacy, Privacy risks, Privacy taxonomy', 'numpages': '19', 'articleno': '775', 'booktitle': 'Proceedings of the CHI Conference on Human Factors in Computing Systems', 'abstract': 'Privacy is a key principle for developing ethical AI technologies, but how does including AI technologies in products and services change privacy risks? We constructed a taxonomy of AI privacy risks by analyzing 321 documented AI privacy incidents. We codified how the unique capabilities and requirements of AI technologies described in those incidents generated new privacy risks, exacerbated known ones, or otherwise did not meaningfully alter the risk. We present 12 high-level privacy risks that AI technologies either newly created (e.g., exposure risks from deepfake pornography) or exacerbated (e.g., surveillance risks from collecting training data). One upshot of our work is that incorporating AI technologies into a product can alter the privacy risks it entails. Yet, current approaches to privacy-preserving AI/ML (e.g., federated learning, differential privacy, checklists) only address a subset of the privacy risks arising from the capabilities and data requirements of AI.', 'doi': '10.1145/3613904.3642116', 'url': 'https://doi.org/10.1145/3613904.3642116', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400703300', 'year': '2024', 'title': 'Deepfakes, Phrenology, Surveillance, and More! A Taxonomy of AI Privacy Risks', 'author': 'Lee, Hao-Ping (Hank) and Yang, Yu-Ju and Von Davier, Thomas Serban and Forlizzi, Jodi and Das, Sauvik', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3613904.3642116'}",ACM
"Yuan, Liang and Shen, Gang",A Training Scheme of Deep Neural Networks on Encrypted Data,"Privacy-preserving, Neural networks, Deep learning, Cryptography","Machine learning based on deep neural network has shown great potential in many application fields. Compared with traditional machine learning algorithms, training a reliable neural network model requires a huge amount of data. However, the data required to train a deep neural network model is often privacy sensitive. In order to preserve privacy data, users need to encrypt the data before uploading them to the cloud server. Since back-propagation algorithm works on plaintext, it is difficult to train a neural network model on ciphertext. To address this issue, we propose a new scheme to support training neural network over encrypted data. We use homomorphic cryptosystem to protect privacy feature data of users. We also improve the back-propagation algorithm in privacy-preserving environment to protect classification label of user. We implement the model based on LeNet-5 and present performance evaluation. The experimental results show that our scheme has similar accuracy to training the MNIST dataset in plaintext.",2021,Proceedings of the 2020 International Conference on Cyberspace Innovation of Advanced Technologies,https://doi.org/10.1145/3444370.3444618,"{'series': 'CIAT 2020', 'location': 'Guangzhou, China', 'keywords': 'Privacy-preserving, Neural networks, Deep learning, Cryptography', 'numpages': '6', 'pages': '490–495', 'booktitle': 'Proceedings of the 2020 International Conference on Cyberspace Innovation of Advanced Technologies', 'abstract': 'Machine learning based on deep neural network has shown great potential in many application fields. Compared with traditional machine learning algorithms, training a reliable neural network model requires a huge amount of data. However, the data required to train a deep neural network model is often privacy sensitive. In order to preserve privacy data, users need to encrypt the data before uploading them to the cloud server. Since back-propagation algorithm works on plaintext, it is difficult to train a neural network model on ciphertext. To address this issue, we propose a new scheme to support training neural network over encrypted data. We use homomorphic cryptosystem to protect privacy feature data of users. We also improve the back-propagation algorithm in privacy-preserving environment to protect classification label of user. We implement the model based on LeNet-5 and present performance evaluation. The experimental results show that our scheme has similar accuracy to training the MNIST dataset in plaintext.', 'doi': '10.1145/3444370.3444618', 'url': 'https://doi.org/10.1145/3444370.3444618', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450387828', 'year': '2021', 'title': 'A Training Scheme of Deep Neural Networks on Encrypted Data', 'author': 'Yuan, Liang and Shen, Gang', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3444370.3444618'}",ACM
"Volk, Vera and Prange, Sarah and Alt, Florian",PriCheck– An Online Privacy Assistant for Smart Device Purchases,"usable security, smart devices, privacy, browser extension","In this paper, we present PriCheck, a browser extension that provides privacy-relevant information about smart devices (e.g., in an online shop). This information is oftentimes hidden, difficult to access, and, thus, often neglected when buying a new device. With PriCheck, we enable users to make informed purchase decisions. We conducted an exploratory study using the browser extension in a simplified (mock) online shop for smart devices. Participants chose devices with and without using the extension. We found that participants (N = 11) appreciated the usability and available information of PriCheck, helping them with informed decisions for privacy-preserving products. We hope our work will stimulate further discussion on how to make privacy information for novel products available, understandable, and easy to access for users.",2022,Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems,https://doi.org/10.1145/3491101.3519827,"{'series': ""CHI EA '22"", 'location': 'New Orleans, LA, USA', 'keywords': 'usable security, smart devices, privacy, browser extension', 'numpages': '5', 'articleno': '275', 'booktitle': 'Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems', 'abstract': 'In this paper, we present PriCheck, a browser extension that provides privacy-relevant information about smart devices (e.g., in an online shop). This information is oftentimes hidden, difficult to access, and, thus, often neglected when buying a new device. With PriCheck, we enable users to make informed purchase decisions. We conducted an exploratory study using the browser extension in a simplified (mock) online shop for smart devices. Participants chose devices with and without using the extension. We found that participants (N = 11) appreciated the usability and available information of PriCheck, helping them with informed decisions for privacy-preserving products. We hope our work will stimulate further discussion on how to make privacy information for novel products available, understandable, and easy to access for users.', 'doi': '10.1145/3491101.3519827', 'url': 'https://doi.org/10.1145/3491101.3519827', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450391566', 'year': '2022', 'title': 'PriCheck– An Online Privacy Assistant for Smart Device Purchases', 'author': 'Volk, Vera and Prange, Sarah and Alt, Florian', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3491101.3519827'}",ACM
"Guo, Wentao and Rodolitz, Jay and Birrell, Eleanor",Poli-see: An Interactive Tool for Visualizing Privacy Policies,"visualization, usable privacy, privacy policies","Prior work has shown that current privacy policies fail to effectively implement informed consent. This work investigates how data use practices might be conveyed by a graphical representation. We present Poli-see, an interactive tool for visualizing privacy policies. We then describe the results of an in-person user study (n = 24) and an online study (n = 600) that evaluate how well Poli-see conveys information about data use practices. In our in-person study, we found that participants answered factual questions about privacy policies more accurately when shown a Poli-see representation than when shown an annotated text representation. In our online study, we found that participants who were shown a Poli-see representation reported higher levels of enjoyment and higher likelihood of looking at the policy than participants who were shown a conventional text representation or an annotated text representation. These results suggest that graphical representations might be useful for conveying data use practices to users, but that further research and refinement will be required before graphical representations can be effectively deployed in real-world systems. We conclude by identifying key advantages and challenges for graphical representations of privacy policies drawn from our experience.",2020,Proceedings of the 19th Workshop on Privacy in the Electronic Society,https://doi.org/10.1145/3411497.3420221,"{'series': ""WPES'20"", 'location': 'Virtual Event, USA', 'keywords': 'visualization, usable privacy, privacy policies', 'numpages': '15', 'pages': '57–71', 'booktitle': 'Proceedings of the 19th Workshop on Privacy in the Electronic Society', 'abstract': 'Prior work has shown that current privacy policies fail to effectively implement informed consent. This work investigates how data use practices might be conveyed by a graphical representation. We present Poli-see, an interactive tool for visualizing privacy policies. We then describe the results of an in-person user study (n = 24) and an online study (n = 600) that evaluate how well Poli-see conveys information about data use practices. In our in-person study, we found that participants answered factual questions about privacy policies more accurately when shown a Poli-see representation than when shown an annotated text representation. In our online study, we found that participants who were shown a Poli-see representation reported higher levels of enjoyment and higher likelihood of looking at the policy than participants who were shown a conventional text representation or an annotated text representation. These results suggest that graphical representations might be useful for conveying data use practices to users, but that further research and refinement will be required before graphical representations can be effectively deployed in real-world systems. We conclude by identifying key advantages and challenges for graphical representations of privacy policies drawn from our experience.', 'doi': '10.1145/3411497.3420221', 'url': 'https://doi.org/10.1145/3411497.3420221', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450380867', 'year': '2020', 'title': 'Poli-see: An Interactive Tool for Visualizing Privacy Policies', 'author': 'Guo, Wentao and Rodolitz, Jay and Birrell, Eleanor', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3411497.3420221'}",ACM
"Al Muhander, Bayan and Wiese, Jason and Rana, Omer and Perera, Charith",Interactive Privacy Management: Toward Enhancing Privacy Awareness and Control in the Internet of Things,"visualization, interaction, choice, privacy control, privacy management, notification methods, privacy awareness, sensors, Internet of Things","The balance between protecting user privacy while providing cost-effective devices that are functional and usable is a key challenge in the burgeoning Internet of Things (IoT). In traditional desktop and mobile contexts, the primary user interface is a screen; however, in IoT devices, screens are rare or very small, invalidating many existing approaches to protecting user privacy. Privacy visualizations are a common approach for assisting users in understanding the privacy implications of web and mobile services. To gain a thorough understanding of IoT privacy, we examine existing web, mobile, and IoT visualization approaches. Following that, we define five major privacy factors in the IoT context: type, usage, storage, retention period, and access. We then describe notification methods used in various contexts as reported in the literature. We aim to highlight key approaches that developers and researchers can use for creating effective IoT privacy notices that improve user privacy management (awareness and control). Using a toolkit, a use case scenario, and two examples from the literature, we demonstrate how privacy visualization approaches can be supported in practice.",2023,ACM Trans. Internet Things,https://doi.org/10.1145/3600096,"{'keywords': 'visualization, interaction, choice, privacy control, privacy management, notification methods, privacy awareness, sensors, Internet of Things', 'numpages': '34', 'articleno': '18', 'month': 'sep', 'journal': 'ACM Trans. Internet Things', 'abstract': 'The balance between protecting user privacy while providing cost-effective devices that are functional and usable is a key challenge in the burgeoning Internet of Things (IoT). In traditional desktop and mobile contexts, the primary user interface is a screen; however, in IoT devices, screens are rare or very small, invalidating many existing approaches to protecting user privacy. Privacy visualizations are a common approach for assisting users in understanding the privacy implications of web and mobile services. To gain a thorough understanding of IoT privacy, we examine existing web, mobile, and IoT visualization approaches. Following that, we define five major privacy factors in the IoT context: type, usage, storage, retention period, and access. We then describe notification methods used in various contexts as reported in the literature. We aim to highlight key approaches that developers and researchers can use for creating effective IoT privacy notices that improve user privacy management (awareness and control). Using a toolkit, a use case scenario, and two examples from the literature, we demonstrate how privacy visualization approaches can be supported in practice.', 'doi': '10.1145/3600096', 'url': 'https://doi.org/10.1145/3600096', 'number': '3', 'volume': '4', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'issue_date': 'August 2023', 'year': '2023', 'title': 'Interactive Privacy Management: Toward Enhancing Privacy Awareness and Control in the Internet of Things', 'author': 'Al Muhander, Bayan and Wiese, Jason and Rana, Omer and Perera, Charith', 'ENTRYTYPE': 'article', 'ID': '10.1145/3600096'}",ACM
"Zhao, Jun and Duron, Blanche and Wang, Ge",KOALA Hero: Inform Children of Privacy Risks of Mobile Apps,"parental controls, mobile apps, children online safety, Children online privacy","Children’s online activities are routinely tracked, aggregated, and exploited by online services, to manipulate children’s online behaviour or monetise. This contributes to the so-called datafied childhood. Unfortunately, such datafication remains largely invisible behind the services and is practically impossible to avoid. Existing approaches largely focus on direct online harms, and provide limited support to raise children’s awareness or understanding of how their data may be processed, transmitted across platforms, and used to affect their best interests. Through co-design workshops, we identified key barriers for children and families to cope with this type of data privacy risk. Our contribution is that instead of regarding children as passive users and needing protection, we draw on critical digital literacy theories and design a KOALA Hero app, which is aimed to enhance children’s cognitive, situated and critical thinking of datafication and online data privacy risks. KOALA Hero represents our first step towards facilitating children’s understanding of the invisible data privacy risks. We hope future empirical evaluations will further inform us regarding how our design approaches may affect the thinking process and behaviours of children and families.",2022,Proceedings of the 21st Annual ACM Interaction Design and Children Conference,https://doi.org/10.1145/3501712.3535278,"{'series': ""IDC '22"", 'location': 'Braga, Portugal', 'keywords': 'parental controls, mobile apps, children online safety, Children online privacy', 'numpages': '6', 'pages': '523–528', 'booktitle': 'Proceedings of the 21st Annual ACM Interaction Design and Children Conference', 'abstract': 'Children’s online activities are routinely tracked, aggregated, and exploited by online services, to manipulate children’s online behaviour or monetise. This contributes to the so-called datafied childhood. Unfortunately, such datafication remains largely invisible behind the services and is practically impossible to avoid. Existing approaches largely focus on direct online harms, and provide limited support to raise children’s awareness or understanding of how their data may be processed, transmitted across platforms, and used to affect their best interests. Through co-design workshops, we identified key barriers for children and families to cope with this type of data privacy risk. Our contribution is that instead of regarding children as passive users and needing protection, we draw on critical digital literacy theories and design a KOALA Hero app, which is aimed to enhance children’s cognitive, situated and critical thinking of datafication and online data privacy risks. KOALA Hero represents our first step towards facilitating children’s understanding of the invisible data privacy risks. We hope future empirical evaluations will further inform us regarding how our design approaches may affect the thinking process and behaviours of children and families.', 'doi': '10.1145/3501712.3535278', 'url': 'https://doi.org/10.1145/3501712.3535278', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450391979', 'year': '2022', 'title': 'KOALA Hero: Inform Children of Privacy Risks of Mobile Apps', 'author': 'Zhao, Jun and Duron, Blanche and Wang, Ge', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3501712.3535278'}",ACM
"Railean, Alexandr and Reinhardt, Delphine",Let there be LITE: design and evaluation of a label for IoT transparency enhancement,"usability, privacy, label, internet of things, IoT","We present a ""privacy facts"" label, which aims at helping non-experts understand how an Internet of Things (IoT) device collects and handles data. We describe our design methodology, and detail the results of our user study involving 31 participants, assessing the efficacy of the label. The results suggest that the label was perceived positively by the participants, and is a promising solution to help users in making informed decisions.",2018,Proceedings of the 20th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct,https://doi.org/10.1145/3236112.3236126,"{'series': ""MobileHCI '18"", 'location': 'Barcelona, Spain', 'keywords': 'usability, privacy, label, internet of things, IoT', 'numpages': '8', 'pages': '103–110', 'booktitle': 'Proceedings of the 20th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct', 'abstract': 'We present a ""privacy facts"" label, which aims at helping non-experts understand how an Internet of Things (IoT) device collects and handles data. We describe our design methodology, and detail the results of our user study involving 31 participants, assessing the efficacy of the label. The results suggest that the label was perceived positively by the participants, and is a promising solution to help users in making informed decisions.', 'doi': '10.1145/3236112.3236126', 'url': 'https://doi.org/10.1145/3236112.3236126', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450359412', 'year': '2018', 'title': 'Let there be LITE: design and evaluation of a label for IoT transparency enhancement', 'author': 'Railean, Alexandr and Reinhardt, Delphine', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3236112.3236126'}",ACM
"Reagle, Joseph and Cranor, Lorrie Faith",The platform for privacy preferences,,,1999,Commun. ACM,https://doi.org/10.1145/293411.293455,"{'numpages': '8', 'pages': '48–55', 'month': 'feb', 'journal': 'Commun. ACM', 'doi': '10.1145/293411.293455', 'url': 'https://doi.org/10.1145/293411.293455', 'issn': '0001-0782', 'number': '2', 'volume': '42', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'issue_date': 'Feb. 1999', 'year': '1999', 'title': 'The platform for privacy preferences', 'author': 'Reagle, Joseph and Cranor, Lorrie Faith', 'ENTRYTYPE': 'article', 'ID': '10.1145/293411.293455'}",ACM
"Tonge, Ashwini and Caragea, Cornelia",Privacy-aware Tag Recommendation for Accurate Image Privacy Prediction,"tag recommendation, privacy-aware tags, image privacy prediction, image analysis, deep learning, Social networks","Online images’ tags are very important for indexing, sharing, and searching of images, as well as surfacing images with private or sensitive content, which needs to be protected. Social media sites such as Flickr generate these metadata from user-contributed tags. However, as the tags are at the sole discretion of users, these tags tend to be noisy and incomplete. In this article, we present a privacy-aware approach to automatic image tagging, which aims at improving the quality of user annotations, while also preserving the images’ original privacy sharing patterns. Precisely, we recommend potential tags for each target image by mining privacy-aware tags from the most similar images of the target image, which are obtained from a large collection. Experimental results show that, although the user-input tags compose noise, our privacy-aware approach is able to predict accurate tags that can improve the performance of a downstream application on image privacy prediction and outperforms an existing privacy-oblivious approach to image tagging. The results also show that, even for images that do not have any user tags, our proposed approach can recommend accurate tags. Crowd-sourcing the predicted tags exhibits the quality of our privacy-aware recommended tags. Our code, features, and the dataset used in experiments are available at: https://github.com/ashwinitonge/privacy-aware-tag-rec.git.",2019,ACM Trans. Intell. Syst. Technol.,https://doi.org/10.1145/3335054,"{'keywords': 'tag recommendation, privacy-aware tags, image privacy prediction, image analysis, deep learning, Social networks', 'numpages': '28', 'articleno': '40', 'month': 'aug', 'journal': 'ACM Trans. Intell. Syst. Technol.', 'abstract': 'Online images’ tags are very important for indexing, sharing, and searching of images, as well as surfacing images with private or sensitive content, which needs to be protected. Social media sites such as Flickr generate these metadata from user-contributed tags. However, as the tags are at the sole discretion of users, these tags tend to be noisy and incomplete. In this article, we present a privacy-aware approach to automatic image tagging, which aims at improving the quality of user annotations, while also preserving the images’ original privacy sharing patterns. Precisely, we recommend potential tags for each target image by mining privacy-aware tags from the most similar images of the target image, which are obtained from a large collection. Experimental results show that, although the user-input tags compose noise, our privacy-aware approach is able to predict accurate tags that can improve the performance of a downstream application on image privacy prediction and outperforms an existing privacy-oblivious approach to image tagging. The results also show that, even for images that do not have any user tags, our proposed approach can recommend accurate tags. Crowd-sourcing the predicted tags exhibits the quality of our privacy-aware recommended tags. Our code, features, and the dataset used in experiments are available at: https://github.com/ashwinitonge/privacy-aware-tag-rec.git.', 'doi': '10.1145/3335054', 'url': 'https://doi.org/10.1145/3335054', 'issn': '2157-6904', 'number': '4', 'volume': '10', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'issue_date': 'July 2019', 'year': '2019', 'title': 'Privacy-aware Tag Recommendation for Accurate Image Privacy Prediction', 'author': 'Tonge, Ashwini and Caragea, Cornelia', 'ENTRYTYPE': 'article', 'ID': '10.1145/3335054'}",ACM
"Morel, Victor and Pardo, Ra\'{u}l",SoK: Three Facets of Privacy Policies,"usability, privacy policies, legal compliance, enforcement","Privacy policies are the main way to obtain information related to personal data collection and processing. Originally, privacy policies were presented as textual documents. However, the unsuitability of this format for the needs of today's society gave birth to other means of expression. In this paper, we systematically study the different means of expression of privacy policies. In doing so, we have explored the three main categories, which we call facets, i.e., natural language, graphical and machine-readable privacy policies. Each of these facets focuses on the particular needs of the communities they come from, ie, law experts, organizations and privacy advocates, and academics, respectively. We then analyze the benefits and limitations of each facet, and explain why solutions based on a single facet do not cover the needs of other communities. Finally, we set guidelines and discuss challenges of an approach to expressing privacy policies which brings together the benefits of each facet as an attempt to overcome their limitations.",2020,Proceedings of the 19th Workshop on Privacy in the Electronic Society,https://doi.org/10.1145/3411497.3420216,"{'series': ""WPES'20"", 'location': 'Virtual Event, USA', 'keywords': 'usability, privacy policies, legal compliance, enforcement', 'numpages': '16', 'pages': '41–56', 'booktitle': 'Proceedings of the 19th Workshop on Privacy in the Electronic Society', 'abstract': ""Privacy policies are the main way to obtain information related to personal data collection and processing. Originally, privacy policies were presented as textual documents. However, the unsuitability of this format for the needs of today's society gave birth to other means of expression. In this paper, we systematically study the different means of expression of privacy policies. In doing so, we have explored the three main categories, which we call facets, i.e., natural language, graphical and machine-readable privacy policies. Each of these facets focuses on the particular needs of the communities they come from, ie, law experts, organizations and privacy advocates, and academics, respectively. We then analyze the benefits and limitations of each facet, and explain why solutions based on a single facet do not cover the needs of other communities. Finally, we set guidelines and discuss challenges of an approach to expressing privacy policies which brings together the benefits of each facet as an attempt to overcome their limitations."", 'doi': '10.1145/3411497.3420216', 'url': 'https://doi.org/10.1145/3411497.3420216', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450380867', 'year': '2020', 'title': 'SoK: Three Facets of Privacy Policies', 'author': ""Morel, Victor and Pardo, Ra\\'{u}l"", 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3411497.3420216'}",ACM
"Wan, Xinwei and Sun, Jiankai and Wang, Shengjie and Chen, Lei and Zheng, Zhenzhe and Wu, Fan and Chen, Guihai",PSLF: Defending Against Label Leakage in Split Learning,"split learning, privacy preservation, label leakage","With increasing concern over data privacy, split learning has become a widely used distributed machine learning paradigm in practice, where two participants (namely the non-label party and the label party) own raw features and raw labels respectively, and jointly train a model. Although no raw data is communicated between the two parties during model training, several works have demonstrated that data privacy, especially label privacy, is still vulnerable in split learning, and have proposed several defense algorithms against label attacks. However, the theoretical guarantee on the privacy preservation of these algorithms is limited. In this work, we propose a novel Private Split Learning Framework (PSLF). In PSLF, the label party shares only the gradients computed by flipped labels with the non-label party, which improves privacy preservation on raw labels, and meanwhile, we further design an extra sub-model from true labels to improve prediction accuracy. We also design a Flipped Multi-Label Generation mechanism (FMLG) based on randomized response for the label party to generate flipped labels. FMLG is proven differentially private and the label party could make a trade-off between privacy and utility by setting the DP budget. In addition, we design an upsampling method to further protect the labels against some existing attacks. We have evaluated PSLF over real-world datasets to demonstrate its effectiveness in protecting label privacy and achieving promising prediction accuracy.",2023,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,https://doi.org/10.1145/3583780.3615019,"{'series': ""CIKM '23"", 'location': '<conf-loc>, <city>Birmingham</city>, <country>United Kingdom</country>, </conf-loc>', 'keywords': 'split learning, privacy preservation, label leakage', 'numpages': '10', 'pages': '2492–2501', 'booktitle': 'Proceedings of the 32nd ACM International Conference on Information and Knowledge Management', 'abstract': 'With increasing concern over data privacy, split learning has become a widely used distributed machine learning paradigm in practice, where two participants (namely the non-label party and the label party) own raw features and raw labels respectively, and jointly train a model. Although no raw data is communicated between the two parties during model training, several works have demonstrated that data privacy, especially label privacy, is still vulnerable in split learning, and have proposed several defense algorithms against label attacks. However, the theoretical guarantee on the privacy preservation of these algorithms is limited. In this work, we propose a novel Private Split Learning Framework (PSLF). In PSLF, the label party shares only the gradients computed by flipped labels with the non-label party, which improves privacy preservation on raw labels, and meanwhile, we further design an extra sub-model from true labels to improve prediction accuracy. We also design a Flipped Multi-Label Generation mechanism (FMLG) based on randomized response for the label party to generate flipped labels. FMLG is proven differentially private and the label party could make a trade-off between privacy and utility by setting the DP budget. In addition, we design an upsampling method to further protect the labels against some existing attacks. We have evaluated PSLF over real-world datasets to demonstrate its effectiveness in protecting label privacy and achieving promising prediction accuracy.', 'doi': '10.1145/3583780.3615019', 'url': 'https://doi.org/10.1145/3583780.3615019', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400701245', 'year': '2023', 'title': 'PSLF: Defending Against Label Leakage in Split Learning', 'author': 'Wan, Xinwei and Sun, Jiankai and Wang, Shengjie and Chen, Lei and Zheng, Zhenzhe and Wu, Fan and Chen, Guihai', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3583780.3615019'}",ACM
"Gleason, Jeffrey and Ghosh, Avijit and Robertson, Ronald E. and Wilson, Christo",Perceptions in Pixels: Analyzing Perceived Gender and Skin Tone in Real-world Image Search Results,"algorithm auditing, gender, image search, information retrieval, skin tone","The results returned by image search engines have the power to shape peoples' perceptions about social groups. Existing work on image search engines leverages hand-selected queries for occupations like ""doctor"" and ""engineer"" to quantify racial and gender bias in search results. We complement this work by analyzing peoples' real-world image search queries and measuring the distributions of perceived gender, skin tone, and age in their results. We collect 54,070 unique image search queries and analyze 1,481 open-ended people queries (i.e. not queries for named entities) from a representative sample of 643 US residents. For each query, we analyze the top 15 results returned on both Google and Bing Images.  Analysis of real-world image search queries produces multiple insights. First, less than 5\% of unique queries are open-ended people queries. Second, fashion queries are, by far, the most common category of open-ended people queries, accounting for over 30\% of the total. Third, the modal skin tone on the Monk Skin Tone scale is two out of ten (the second lightest) for images from both search engines. Finally, we observe a bias against older people: eleven of our top fifteen query categories have a median age that is lower than the median age in the US.",2024,Proceedings of the ACM on Web Conference 2024,https://doi.org/10.1145/3589334.3645666,"{'series': ""WWW '24"", 'location': '<conf-loc>, <city>Singapore</city>, <country>Singapore</country>, </conf-loc>', 'keywords': 'algorithm auditing, gender, image search, information retrieval, skin tone', 'numpages': '11', 'pages': '1249–1259', 'booktitle': 'Proceedings of the ACM on Web Conference 2024', 'abstract': 'The results returned by image search engines have the power to shape peoples\' perceptions about social groups. Existing work on image search engines leverages hand-selected queries for occupations like ""doctor"" and ""engineer"" to quantify racial and gender bias in search results. We complement this work by analyzing peoples\' real-world image search queries and measuring the distributions of perceived gender, skin tone, and age in their results. We collect 54,070 unique image search queries and analyze 1,481 open-ended people queries (i.e. not queries for named entities) from a representative sample of 643 US residents. For each query, we analyze the top 15 results returned on both Google and Bing Images.  Analysis of real-world image search queries produces multiple insights. First, less than 5\\% of unique queries are open-ended people queries. Second, fashion queries are, by far, the most common category of open-ended people queries, accounting for over 30\\% of the total. Third, the modal skin tone on the Monk Skin Tone scale is two out of ten (the second lightest) for images from both search engines. Finally, we observe a bias against older people: eleven of our top fifteen query categories have a median age that is lower than the median age in the US.', 'doi': '10.1145/3589334.3645666', 'url': 'https://doi.org/10.1145/3589334.3645666', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400701719', 'year': '2024', 'title': 'Perceptions in Pixels: Analyzing Perceived Gender and Skin Tone in Real-world Image Search Results', 'author': 'Gleason, Jeffrey and Ghosh, Avijit and Robertson, Ronald E. and Wilson, Christo', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3589334.3645666'}",ACM
"Wei, Penghui and Dou, Hongjian and Liu, Shaoguo and Tang, Rongjun and Liu, Li and Wang, Liang and Zheng, Bo",FedAds: A Benchmark for Privacy-Preserving CVR Estimation with Vertical Federated Learning,"ad ranking, deep generative model, vertical federated learning","Conversion rate (CVR) estimation aims to predict the probability of conversion event after a user has clicked an ad. Typically, online publisher has user browsing interests and click feedbacks, while demand-side advertising platform collects users' post-click behaviors such as dwell time and conversion decisions. To estimate CVR accurately and protect data privacy better, vertical federated learning (vFL) is a natural solution to combine two sides' advantages for training models, without exchanging raw data. Both CVR estimation and applied vFL algorithms have attracted increasing research attentions. However, standardized and systematical evaluations are missing: due to the lack of standardized datasets, existing studies adopt public datasets to simulate a vFL setting via hand-crafted feature partition, which brings challenges to fair comparison. We introduce FedAds, the first benchmark for CVR estimation with vFL, to facilitate standardized and systematical evaluations for vFL algorithms. It contains a large-scale real world dataset collected from Alibaba's advertising platform, as well as systematical evaluations for both effectiveness and privacy aspects of various vFL algorithms. Besides, we also explore to incorporate unaligned data in vFL to improve effectiveness, and develop perturbation operations to protect privacy well. We hope that future research work in vFL and CVR estimation benefits from the FedAds benchmark.",2023,Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval,https://doi.org/10.1145/3539618.3591909,"{'series': ""SIGIR '23"", 'location': '<conf-loc>, <city>Taipei</city>, <country>Taiwan</country>, </conf-loc>', 'keywords': 'ad ranking, deep generative model, vertical federated learning', 'numpages': '10', 'pages': '3037–3046', 'booktitle': 'Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval', 'abstract': ""Conversion rate (CVR) estimation aims to predict the probability of conversion event after a user has clicked an ad. Typically, online publisher has user browsing interests and click feedbacks, while demand-side advertising platform collects users' post-click behaviors such as dwell time and conversion decisions. To estimate CVR accurately and protect data privacy better, vertical federated learning (vFL) is a natural solution to combine two sides' advantages for training models, without exchanging raw data. Both CVR estimation and applied vFL algorithms have attracted increasing research attentions. However, standardized and systematical evaluations are missing: due to the lack of standardized datasets, existing studies adopt public datasets to simulate a vFL setting via hand-crafted feature partition, which brings challenges to fair comparison. We introduce FedAds, the first benchmark for CVR estimation with vFL, to facilitate standardized and systematical evaluations for vFL algorithms. It contains a large-scale real world dataset collected from Alibaba's advertising platform, as well as systematical evaluations for both effectiveness and privacy aspects of various vFL algorithms. Besides, we also explore to incorporate unaligned data in vFL to improve effectiveness, and develop perturbation operations to protect privacy well. We hope that future research work in vFL and CVR estimation benefits from the FedAds benchmark."", 'doi': '10.1145/3539618.3591909', 'url': 'https://doi.org/10.1145/3539618.3591909', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450394086', 'year': '2023', 'title': 'FedAds: A Benchmark for Privacy-Preserving CVR Estimation with Vertical Federated Learning', 'author': 'Wei, Penghui and Dou, Hongjian and Liu, Shaoguo and Tang, Rongjun and Liu, Li and Wang, Liang and Zheng, Bo', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3539618.3591909'}",ACM
"Zerr, Sergej and Siersdorfer, Stefan and Hare, Jonathon and Demidova, Elena",Privacy-aware image classification and search,"privacy, image analysis, diversification, classification","Modern content sharing environments such as Flickr or YouTube contain a large amount of private resources such as photos showing weddings, family holidays, and private parties. These resources can be of a highly sensitive nature, disclosing many details of the users' private sphere. In order to support users in making privacy decisions in the context of image sharing and to provide them with a better overview on privacy related visual content available on the Web, we propose techniques to automatically detect private images, and to enable privacy-oriented image search. To this end, we learn privacy classifiers trained on a large set of manually assessed Flickr photos, combining textual metadata of images with a variety of visual features. We employ the resulting classification models for specifically searching for private photos, and for diversifying query results to provide users with a better coverage of private and public content. Large-scale classification experiments reveal insights into the predictive performance of different visual and textual features, and a user evaluation of query result rankings demonstrates the viability of our approach.",2012,Proceedings of the 35th International ACM SIGIR Conference on Research and Development in Information Retrieval,https://doi.org/10.1145/2348283.2348292,"{'series': ""SIGIR '12"", 'location': 'Portland, Oregon, USA', 'keywords': 'privacy, image analysis, diversification, classification', 'numpages': '10', 'pages': '35–44', 'booktitle': 'Proceedings of the 35th International ACM SIGIR Conference on Research and Development in Information Retrieval', 'abstract': ""Modern content sharing environments such as Flickr or YouTube contain a large amount of private resources such as photos showing weddings, family holidays, and private parties. These resources can be of a highly sensitive nature, disclosing many details of the users' private sphere. In order to support users in making privacy decisions in the context of image sharing and to provide them with a better overview on privacy related visual content available on the Web, we propose techniques to automatically detect private images, and to enable privacy-oriented image search. To this end, we learn privacy classifiers trained on a large set of manually assessed Flickr photos, combining textual metadata of images with a variety of visual features. We employ the resulting classification models for specifically searching for private photos, and for diversifying query results to provide users with a better coverage of private and public content. Large-scale classification experiments reveal insights into the predictive performance of different visual and textual features, and a user evaluation of query result rankings demonstrates the viability of our approach."", 'doi': '10.1145/2348283.2348292', 'url': 'https://doi.org/10.1145/2348283.2348292', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450314725', 'year': '2012', 'title': 'Privacy-aware image classification and search', 'author': 'Zerr, Sergej and Siersdorfer, Stefan and Hare, Jonathon and Demidova, Elena', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/2348283.2348292'}",ACM
"Prange, Sarah and Rodriguez, Sarah Delgado and Mecke, Lukas and Alt, Florian",“I saw your partner naked”: Exploring Privacy Challenges During Video-based Online Meetings,"privacy mechanisms, privacy, online meetings, online meeting privacy, COVID-19","Video-based online meetings and, ultimately, the amount of private information that is shared – intentionally or accidentally – increased as a result of the COVID-19 pandemic. For example, online teaching might reveal lecturers’ private environment to students or business meetings might provide insights about employees’ family relationships. This raises the need to understand users’ perception towards privacy intrusion during online video conferences to inform concepts that better protect meeting participants’ privacy. We present the results of an online survey (N = 140) in which we investigate user stories of privacy-invasive situations in their homes during such meetings. Our results show that online meetings reveal private information that would not have become available during physical meetings. This often involves third parties (e.g., children, spouse, colleague), who might not even be aware of this. We discuss potential means to support users in protecting their and others’ privacy before, during, and after video-based online meetings.",2022,Proceedings of the 21st International Conference on Mobile and Ubiquitous Multimedia,https://doi.org/10.1145/3568444.3568468,"{'series': ""MUM '22"", 'location': '<conf-loc>, <city>Lisbon</city>, <country>Portugal</country>, </conf-loc>', 'keywords': 'privacy mechanisms, privacy, online meetings, online meeting privacy, COVID-19', 'numpages': '12', 'pages': '71–82', 'booktitle': 'Proceedings of the 21st International Conference on Mobile and Ubiquitous Multimedia', 'abstract': 'Video-based online meetings and, ultimately, the amount of private information that is shared – intentionally or accidentally – increased as a result of the COVID-19 pandemic. For example, online teaching might reveal lecturers’ private environment to students or business meetings might provide insights about employees’ family relationships. This raises the need to understand users’ perception towards privacy intrusion during online video conferences to inform concepts that better protect meeting participants’ privacy. We present the results of an online survey (N = 140) in which we investigate user stories of privacy-invasive situations in their homes during such meetings. Our results show that online meetings reveal private information that would not have become available during physical meetings. This often involves third parties (e.g., children, spouse, colleague), who might not even be aware of this. We discuss potential means to support users in protecting their and others’ privacy before, during, and after video-based online meetings.', 'doi': '10.1145/3568444.3568468', 'url': 'https://doi.org/10.1145/3568444.3568468', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450398206', 'year': '2022', 'title': '“I saw your partner naked”: Exploring Privacy Challenges During Video-based Online Meetings', 'author': 'Prange, Sarah and Rodriguez, Sarah Delgado and Mecke, Lukas and Alt, Florian', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3568444.3568468'}",ACM
"Appenzeller, Arno and Kadow, Thomas and Krempel, Erik and Beyerer, J\""{u}rgen",CPIQ - A Privacy Impact Quantification for Digital Medical Consent,"risk quantification, medical data, medical consent, formal consent model, e-health, digital consent, data sovereignty","Increasing digitization in healthcare promises easier exchange and more efficient use of medical information for patients, institutions and research. The number of sharing options for medical data increases, e.g., through personal health records, as well as the volume of data. To use this data in medical research patients’ consent is important. As more and more data access is regulated by consent forms and their complexity also increases. For the patient, it becomes less comprehensible which information could be gained from his or her disclosed data. This becomes more important when pressumably anonymized data has the risk of potential re-identification of an individual. In this paper we introduce a consent-privacy-impact-quantification (CPIQ) as a risk model of consent forms for the release of personal medical data for use within research projects. CPIQ evaluates how reasonable a consent decision is for the patient. It takes relevant factors such as the patient’s preferences into account, the circumstances and benefits of the research project, and the potential risk to the patient. The model can be parameterized so that different aspects such as the benefit of the research project, the risk of a data leak or the risk of a patient’s confidential data becoming known can be represented. We present the feasibility of this model by including it in an existing consent management system.",2021,Proceedings of the 14th PErvasive Technologies Related to Assistive Environments Conference,https://doi.org/10.1145/3453892.3461653,"{'series': ""PETRA '21"", 'location': 'Corfu, Greece', 'keywords': 'risk quantification, medical data, medical consent, formal consent model, e-health, digital consent, data sovereignty', 'numpages': '10', 'pages': '534–543', 'booktitle': 'Proceedings of the 14th PErvasive Technologies Related to Assistive Environments Conference', 'abstract': 'Increasing digitization in healthcare promises easier exchange and more efficient use of medical information for patients, institutions and research. The number of sharing options for medical data increases, e.g., through personal health records, as well as the volume of data. To use this data in medical research patients’ consent is important. As more and more data access is regulated by consent forms and their complexity also increases. For the patient, it becomes less comprehensible which information could be gained from his or her disclosed data. This becomes more important when pressumably anonymized data has the risk of potential re-identification of an individual. In this paper we introduce a consent-privacy-impact-quantification (CPIQ) as a risk model of consent forms for the release of personal medical data for use within research projects. CPIQ evaluates how reasonable a consent decision is for the patient. It takes relevant factors such as the patient’s preferences into account, the circumstances and benefits of the research project, and the potential risk to the patient. The model can be parameterized so that different aspects such as the benefit of the research project, the risk of a data leak or the risk of a patient’s confidential data becoming known can be represented. We present the feasibility of this model by including it in an existing consent management system.', 'doi': '10.1145/3453892.3461653', 'url': 'https://doi.org/10.1145/3453892.3461653', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450387927', 'year': '2021', 'title': 'CPIQ - A Privacy Impact Quantification for Digital Medical Consent', 'author': 'Appenzeller, Arno and Kadow, Thomas and Krempel, Erik and Beyerer, J\\""{u}rgen', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3453892.3461653'}",ACM
"Livraga, Giovanni and Motta, Alessandro and Viviani, Marco",Assessing User Privacy on Social Media: The Twitter Case Study,"Confidentiality, Privacy, Social Media, Vector Space Model","At the time of writing, nearly four billion people worldwide employ social media platforms such as Facebook, Instagram, WeChat, TikTok, etc. to share content of various kinds, which may also include personal data. In addition to this, users interact with members of the virtual community, leaving behind important behavioral traces. In most cases, people do not have a full understanding of who will be able to access and use such a body of information, and for what purposes. Although social platforms provide users with some tools to protect their privacy, the very nature of these technologies and the psychological characteristics of users often lead them to ignore such solutions. To address this issue, in this paper we aim to propose a model for assessing the privacy of users on social media by identifying the critical aspects associated with their content and interactions generated on such platforms. This model, in particular, considers distinct features, of different kinds, that capture the level of users’ exposure with respect to privacy. These features, dropped into a vector space, are used to derive a score that expresses, in a measurable way, the privacy risk of users compared to the information available on social media about them. The proposed model is instantiated and tested on data collected from the microblogging platform Twitter, on which the results of the experimental evaluation are analyzed. Specifically, the model is tested by considering both a binary scenario, i.e., where users’ privacy is evaluated as at risk or not, a multi-class scenario, i.e., where their privacy is evaluated against different risk ranges, and a ranking scenario, i.e., where the users are ranked according to their privacy assessment.",2022,Proceedings of the 2022 Workshop on Open Challenges in Online Social Networks,https://doi.org/10.1145/3524010.3539502,"{'series': ""OASIS '22"", 'location': 'Barcelona, Spain', 'keywords': 'Confidentiality, Privacy, Social Media, Vector Space Model', 'numpages': '9', 'pages': '1–9', 'booktitle': 'Proceedings of the 2022 Workshop on Open Challenges in Online Social Networks', 'abstract': 'At the time of writing, nearly four billion people worldwide employ social media platforms such as Facebook, Instagram, WeChat, TikTok, etc. to share content of various kinds, which may also include personal data. In addition to this, users interact with members of the virtual community, leaving behind important behavioral traces. In most cases, people do not have a full understanding of who will be able to access and use such a body of information, and for what purposes. Although social platforms provide users with some tools to protect their privacy, the very nature of these technologies and the psychological characteristics of users often lead them to ignore such solutions. To address this issue, in this paper we aim to propose a model for assessing the privacy of users on social media by identifying the critical aspects associated with their content and interactions generated on such platforms. This model, in particular, considers distinct features, of different kinds, that capture the level of users’ exposure with respect to privacy. These features, dropped into a vector space, are used to derive a score that expresses, in a measurable way, the privacy risk of users compared to the information available on social media about them. The proposed model is instantiated and tested on data collected from the microblogging platform Twitter, on which the results of the experimental evaluation are analyzed. Specifically, the model is tested by considering both a binary scenario, i.e., where users’ privacy is evaluated as at risk or not, a multi-class scenario, i.e., where their privacy is evaluated against different risk ranges, and a ranking scenario, i.e., where the users are ranked according to their privacy assessment.', 'doi': '10.1145/3524010.3539502', 'url': 'https://doi.org/10.1145/3524010.3539502', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450392792', 'year': '2022', 'title': 'Assessing User Privacy on Social Media: The Twitter Case Study', 'author': 'Livraga, Giovanni and Motta, Alessandro and Viviani, Marco', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3524010.3539502'}",ACM
"Zhang, Lei and Fu, Lele and Liu, Chen and Yang, Zhao and Yang, Jinghua and Zheng, Zibin and Chen, Chuan",Towards Few-Label Vertical Federated Learning,"Vertical Federated Learning, Semi-Supervised Learning, Contrastive Learning","Federated Learning (FL) provided a novel paradigm for privacy-preserving machine learning, enabling multiple clients to collaborate on model training without sharing private data. To handle multi-source heterogeneous data, vertical federated learning (VFL) has been extensively investigated. However, in the context of VFL, the label information tends to be kept in one authoritative client and is very limited. This poses two challenges for model training in the VFL scenario: On the one hand, a small number of labels cannot guarantee to train a well VFL model with informative network parameters, resulting in unclear boundaries for classification decisions; On the other hand, the large amount of unlabeled data is dominant and should not be discounted, and it’s worthwhile to focus on how to leverage them to improve representation modeling capabilities. In order to address the above two challenges, Firstly, we introduce supervised contrastive loss to enhance the intra-class aggregation and inter-class estrangement, which is to deeply explore label information and improve the effectiveness of downstream classification tasks. Secondly, for unlabeled data, we introduce a pseudo-label-guided consistency mechanism to induce the classification results coherent across clients, which allows the representations learned by local networks to absorb the knowledge from other clients, and alleviates the disagreement between different clients for classification tasks. We conduct sufficient experiments on four commonly used datasets, and the experimental results demonstrate that our method is superior to the state-of-the-art methods, especially in the low-label rate scenario, and the improvement becomes more significant.",2024,ACM Trans. Knowl. Discov. Data,https://doi.org/10.1145/3656344,"{'keywords': 'Vertical Federated Learning, Semi-Supervised Learning, Contrastive Learning', 'month': 'apr', 'journal': 'ACM Trans. Knowl. Discov. Data', 'note': 'Just Accepted', 'abstract': 'Federated Learning (FL) provided a novel paradigm for privacy-preserving machine learning, enabling multiple clients to collaborate on model training without sharing private data. To handle multi-source heterogeneous data, vertical federated learning (VFL) has been extensively investigated. However, in the context of VFL, the label information tends to be kept in one authoritative client and is very limited. This poses two challenges for model training in the VFL scenario: On the one hand, a small number of labels cannot guarantee to train a well VFL model with informative network parameters, resulting in unclear boundaries for classification decisions; On the other hand, the large amount of unlabeled data is dominant and should not be discounted, and it’s worthwhile to focus on how to leverage them to improve representation modeling capabilities. In order to address the above two challenges, Firstly, we introduce supervised contrastive loss to enhance the intra-class aggregation and inter-class estrangement, which is to deeply explore label information and improve the effectiveness of downstream classification tasks. Secondly, for unlabeled data, we introduce a pseudo-label-guided consistency mechanism to induce the classification results coherent across clients, which allows the representations learned by local networks to absorb the knowledge from other clients, and alleviates the disagreement between different clients for classification tasks. We conduct sufficient experiments on four commonly used datasets, and the experimental results demonstrate that our method is superior to the state-of-the-art methods, especially in the low-label rate scenario, and the improvement becomes more significant.', 'doi': '10.1145/3656344', 'url': 'https://doi.org/10.1145/3656344', 'issn': '1556-4681', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'year': '2024', 'title': 'Towards Few-Label Vertical Federated Learning', 'author': 'Zhang, Lei and Fu, Lele and Liu, Chen and Yang, Zhao and Yang, Jinghua and Zheng, Zibin and Chen, Chuan', 'ENTRYTYPE': 'article', 'ID': '10.1145/3656344'}",ACM
"Blanco-Justicia, Alberto and S\'{a}nchez, David and Domingo-Ferrer, Josep and Muralidhar, Krishnamurty",A Critical Review on the Use (and Misuse) of Differential Privacy in Machine Learning,"Differential privacy, machine learning, federated learning, data utility","We review the use of differential privacy (DP) for privacy protection in machine learning (ML). We show that, driven by the aim of preserving the accuracy of the learned models, DP-based ML implementations are so loose that they do not offer the ex ante privacy guarantees of DP. Instead, what they deliver is basically noise addition similar to the traditional (and often criticized) statistical disclosure control approach. Due to the lack of formal privacy guarantees, the actual level of privacy offered must be experimentally assessed ex post, which is done very seldom. In this respect, we present empirical results showing that standard anti-overfitting techniques in ML can achieve a better utility/privacy/efficiency tradeoff than DP.",2022,ACM Comput. Surv.,https://doi.org/10.1145/3547139,"{'keywords': 'Differential privacy, machine learning, federated learning, data utility', 'numpages': '16', 'articleno': '160', 'month': 'dec', 'journal': 'ACM Comput. Surv.', 'abstract': 'We review the use of differential privacy (DP) for privacy protection in machine learning (ML). We show that, driven by the aim of preserving the accuracy of the learned models, DP-based ML implementations are so loose that they do not offer the ex ante privacy guarantees of DP. Instead, what they deliver is basically noise addition similar to the traditional (and often criticized) statistical disclosure control approach. Due to the lack of formal privacy guarantees, the actual level of privacy offered must be experimentally assessed ex post, which is done very seldom. In this respect, we present empirical results showing that standard anti-overfitting techniques in ML can achieve a better utility/privacy/efficiency tradeoff than DP.', 'doi': '10.1145/3547139', 'url': 'https://doi.org/10.1145/3547139', 'issn': '0360-0300', 'number': '8', 'volume': '55', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'issue_date': 'August 2023', 'year': '2022', 'title': 'A Critical Review on the Use (and Misuse) of Differential Privacy in Machine Learning', 'author': ""Blanco-Justicia, Alberto and S\\'{a}nchez, David and Domingo-Ferrer, Josep and Muralidhar, Krishnamurty"", 'ENTRYTYPE': 'article', 'ID': '10.1145/3547139'}",ACM
"Lu, Xianghua and Phang, Chee Wei and Yu, Jie",Encouraging participation in virtual communities through usability and sociability development: an empirical investigation,"continuous participation, sociability, usability, virtual communities","Usability and sociability are two characteristics of a virtual community that are critical to its success. This study aims to explore how usability and sociability of virtual communities can be developed in order to encourage members' continuous participation in these communities. A theoretical model is proposed to explain the effects of factors related to usability and sociability on members' continuous participation through the motivational beliefs of perceived usefulness, perceived enjoyment and sense of belonging. Data was collected from members of five popular leisure-oriented virtual communities in China. The results show that both perceived enjoyment and sense of belonging impact members' continuous participation intention.Among the usability-and sociability-related factors, we find that information service quality is the most critical factor that encourages members to continuously participate in virtual communities, while interaction support quality, incentive policy, and event organization also have positive effects on members' continuous participation intention via perceived enjoyment and sense of belonging. Surprisingly, leaders' involvement has no impact on members' continuous participation. Implications of the study's findings for both research and practice are discussed.",2011,SIGMIS Database,https://doi.org/10.1145/2038056.2038062,"{'keywords': 'continuous participation, sociability, usability, virtual communities', 'numpages': '19', 'pages': '96–114', 'month': 'sep', 'journal': 'SIGMIS Database', 'abstract': ""Usability and sociability are two characteristics of a virtual community that are critical to its success. This study aims to explore how usability and sociability of virtual communities can be developed in order to encourage members' continuous participation in these communities. A theoretical model is proposed to explain the effects of factors related to usability and sociability on members' continuous participation through the motivational beliefs of perceived usefulness, perceived enjoyment and sense of belonging. Data was collected from members of five popular leisure-oriented virtual communities in China. The results show that both perceived enjoyment and sense of belonging impact members' continuous participation intention.Among the usability-and sociability-related factors, we find that information service quality is the most critical factor that encourages members to continuously participate in virtual communities, while interaction support quality, incentive policy, and event organization also have positive effects on members' continuous participation intention via perceived enjoyment and sense of belonging. Surprisingly, leaders' involvement has no impact on members' continuous participation. Implications of the study's findings for both research and practice are discussed."", 'doi': '10.1145/2038056.2038062', 'url': 'https://doi.org/10.1145/2038056.2038062', 'issn': '0095-0033', 'number': '3', 'volume': '42', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'issue_date': 'August 2011', 'year': '2011', 'title': 'Encouraging participation in virtual communities through usability and sociability development: an empirical investigation', 'author': 'Lu, Xianghua and Phang, Chee Wei and Yu, Jie', 'ENTRYTYPE': 'article', 'ID': '10.1145/2038056.2038062'}",ACM
"Yi, Xiao and Wu, Daoyuan and Jiang, Lingxiao and Fang, Yuzhou and Zhang, Kehuan and Zhang, Wei","An empirical study of blockchain system vulnerabilities: modules, types, and patterns","Blockchain Security, Data Mining, System Vulnerability","Blockchain, as a distributed ledger technology, becomes increasingly popular, especially for enabling valuable cryptocurrencies and smart contracts. However, the blockchain software systems inevitably have many bugs. Although bugs in smart contracts have been extensively investigated, security bugs of the underlying blockchain systems are much less explored. In this paper, we conduct an empirical study on blockchain’s system vulnerabilities from four representative blockchains, Bitcoin, Ethereum, Monero, and Stellar. Specifically, we first design a systematic filtering process to effectively identify 1,037 vulnerabilities and their 2,317 patches from 34,245 issues/PRs (pull requests) and 85,164 commits on GitHub. We thus build the first blockchain vulnerability dataset, which is available at https://github.com/VPRLab/BlkVulnDataset. We then perform unique analyses of this dataset at three levels, including (i) file-level vulnerable module categorization by identifying and correlating module paths across projects, (ii) text-level vulnerability type clustering by natural language processing and similarity-based sentence clustering, and (iii) code-level vulnerability pattern analysis by generating and clustering code change signatures that capture both syntactic and semantic information of patch code fragments.  


Our analyses reveal three key findings: (i) some blockchain modules are more susceptible than the others; notably, each of the modules related to consensus, wallet, and networking has over 200 issues; (ii) about 70\% of blockchain vulnerabilities are of traditional types, but we also identify four new types specific to blockchains; and (iii) we obtain 21 blockchain-specific vulnerability patterns that capture unique blockchain attributes and statuses, and demonstrate that they can be used to detect similar vulnerabilities in other popular blockchains, such as Dogecoin, Bitcoin SV, and Zcash.",2022,Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering,https://doi.org/10.1145/3540250.3549105,"{'series': 'ESEC/FSE 2022', 'location': '<conf-loc>, <city>Singapore</city>, <country>Singapore</country>, </conf-loc>', 'keywords': 'Blockchain Security, Data Mining, System Vulnerability', 'numpages': '13', 'pages': '709–721', 'booktitle': 'Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering', 'abstract': 'Blockchain, as a distributed ledger technology, becomes increasingly popular, especially for enabling valuable cryptocurrencies and smart contracts. However, the blockchain software systems inevitably have many bugs. Although bugs in smart contracts have been extensively investigated, security bugs of the underlying blockchain systems are much less explored. In this paper, we conduct an empirical study on blockchain’s system vulnerabilities from four representative blockchains, Bitcoin, Ethereum, Monero, and Stellar. Specifically, we first design a systematic filtering process to effectively identify 1,037 vulnerabilities and their 2,317 patches from 34,245 issues/PRs (pull requests) and 85,164 commits on GitHub. We thus build the first blockchain vulnerability dataset, which is available at https://github.com/VPRLab/BlkVulnDataset. We then perform unique analyses of this dataset at three levels, including (i) file-level vulnerable module categorization by identifying and correlating module paths across projects, (ii) text-level vulnerability type clustering by natural language processing and similarity-based sentence clustering, and (iii) code-level vulnerability pattern analysis by generating and clustering code change signatures that capture both syntactic and semantic information of patch code fragments.  \n\n\nOur analyses reveal three key findings: (i) some blockchain modules are more susceptible than the others; notably, each of the modules related to consensus, wallet, and networking has over 200 issues; (ii) about 70\\% of blockchain vulnerabilities are of traditional types, but we also identify four new types specific to blockchains; and (iii) we obtain 21 blockchain-specific vulnerability patterns that capture unique blockchain attributes and statuses, and demonstrate that they can be used to detect similar vulnerabilities in other popular blockchains, such as Dogecoin, Bitcoin SV, and Zcash.', 'doi': '10.1145/3540250.3549105', 'url': 'https://doi.org/10.1145/3540250.3549105', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450394130', 'year': '2022', 'title': 'An empirical study of blockchain system vulnerabilities: modules, types, and patterns', 'author': 'Yi, Xiao and Wu, Daoyuan and Jiang, Lingxiao and Fang, Yuzhou and Zhang, Kehuan and Zhang, Wei', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3540250.3549105'}",ACM
"Zhou, Haozhe and Goel, Mayank and Agarwal, Yuvraj",Bring Privacy To The Table: Interactive Negotiation for Privacy Settings of Shared Sensing Devices,"Internet of Things, Negotiation Agent, Preference Elicitation, Privacy Enhancing Technology, Privacy Profiles, Usable Privacy","To address privacy concerns with the Internet of Things (IoT) devices, researchers have proposed enhancements in data collection transparency and user control. However, managing privacy preferences for shared devices with multiple stakeholders remains challenging. We introduced ThingPoll, a system that helps users negotiate privacy configurations for IoT devices in shared settings. We designed ThingPoll by observing twelve participants verbally negotiating privacy preferences, from which we identified potentially successful and inefficient negotiation patterns. ThingPoll bootstraps a preference model from a custom crowdsourced privacy preferences dataset. During negotiations, ThingPoll strategically scaffolds the process by eliciting users’ privacy preferences, providing helpful contexts, and suggesting feasible configuration options. We evaluated ThingPoll with 30 participants negotiating the privacy settings of 4 devices. Using ThingPoll, participants reached an agreement in 97.5\% of scenarios within an average of 3.27 minutes. Participants reported high overall satisfaction of 83.3\% with ThingPoll as compared to baseline approaches.",2024,Proceedings of the CHI Conference on Human Factors in Computing Systems,https://doi.org/10.1145/3613904.3642897,"{'series': ""CHI '24"", 'location': '<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>', 'keywords': 'Internet of Things, Negotiation Agent, Preference Elicitation, Privacy Enhancing Technology, Privacy Profiles, Usable Privacy', 'numpages': '22', 'articleno': '770', 'booktitle': 'Proceedings of the CHI Conference on Human Factors in Computing Systems', 'abstract': 'To address privacy concerns with the Internet of Things (IoT) devices, researchers have proposed enhancements in data collection transparency and user control. However, managing privacy preferences for shared devices with multiple stakeholders remains challenging. We introduced ThingPoll, a system that helps users negotiate privacy configurations for IoT devices in shared settings. We designed ThingPoll by observing twelve participants verbally negotiating privacy preferences, from which we identified potentially successful and inefficient negotiation patterns. ThingPoll bootstraps a preference model from a custom crowdsourced privacy preferences dataset. During negotiations, ThingPoll strategically scaffolds the process by eliciting users’ privacy preferences, providing helpful contexts, and suggesting feasible configuration options. We evaluated ThingPoll with 30 participants negotiating the privacy settings of 4 devices. Using ThingPoll, participants reached an agreement in 97.5\\% of scenarios within an average of 3.27 minutes. Participants reported high overall satisfaction of 83.3\\% with ThingPoll as compared to baseline approaches.', 'doi': '10.1145/3613904.3642897', 'url': 'https://doi.org/10.1145/3613904.3642897', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400703300', 'year': '2024', 'title': 'Bring Privacy To The Table: Interactive Negotiation for Privacy Settings of Shared Sensing Devices', 'author': 'Zhou, Haozhe and Goel, Mayank and Agarwal, Yuvraj', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3613904.3642897'}",ACM
"Ramokapane, Kopo Marvin and Bird, Caroline and Rashid, Awais and Chitchyan, Ruzanna",Privacy Design Strategies for Home Energy Management Systems (HEMS),"User Perceptions, Smart Home Energy Management Systems, Smart Home, Security and Privacy protections, Energy Data","Home energy management systems (HEMS) offer control and the ability to manage energy, generating and collecting energy consumption data at the most detailed level. However, data at this level poses various privacy concerns, including, for instance, profiling consumer behaviors and large-scale surveillance. The question of how utility providers can get value from such data without infringing consumers’ privacy has remained under-investigated. We address this gap by exploring the pro-sharing attitudes and privacy perceptions of 30 HEMS users and non-users through an interview study. While participants are concerned about data misuse and stigmatization, our analysis also reveals that incentives, altruism, trust, security and privacy, transparency and accountability encourage data sharing. From this analysis, we derive privacy design strategies for HEMS that can both improve privacy and engender adoption.",2022,Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems,https://doi.org/10.1145/3491102.3517515,"{'series': ""CHI '22"", 'location': '<conf-loc>, <city>New Orleans</city>, <state>LA</state>, <country>USA</country>, </conf-loc>', 'keywords': 'User Perceptions, Smart Home Energy Management Systems, Smart Home, Security and Privacy protections, Energy Data', 'numpages': '15', 'articleno': '405', 'booktitle': 'Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems', 'abstract': 'Home energy management systems (HEMS) offer control and the ability to manage energy, generating and collecting energy consumption data at the most detailed level. However, data at this level poses various privacy concerns, including, for instance, profiling consumer behaviors and large-scale surveillance. The question of how utility providers can get value from such data without infringing consumers’ privacy has remained under-investigated. We address this gap by exploring the pro-sharing attitudes and privacy perceptions of 30 HEMS users and non-users through an interview study. While participants are concerned about data misuse and stigmatization, our analysis also reveals that incentives, altruism, trust, security and privacy, transparency and accountability encourage data sharing. From this analysis, we derive privacy design strategies for HEMS that can both improve privacy and engender adoption.', 'doi': '10.1145/3491102.3517515', 'url': 'https://doi.org/10.1145/3491102.3517515', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450391573', 'year': '2022', 'title': 'Privacy Design Strategies for Home Energy Management Systems (HEMS)', 'author': 'Ramokapane, Kopo Marvin and Bird, Caroline and Rashid, Awais and Chitchyan, Ruzanna', 'ENTRYTYPE': 'inproceedings', 'ID': '10.1145/3491102.3517515'}",ACM
"Xiao, Yunming and Varvello, Matteo and Warrior, Marc and Kuzmanovic, Aleksandar",Decoding the Kodi Ecosystem,"measurement, crowdsourcing, crawling, Kodi","Free and open-source media centers are experiencing a boom in popularity for the convenience they offer users seeking to remotely consume digital content. Kodi is today’s most popular home media center, with millions of users worldwide. Kodi’s popularity derives from its ability to centralize the sheer amount of media content available on the Web, both free and copyrighted. Researchers have been hinting at potential security concerns around Kodi, due to add-ons injecting unwanted content as well as user settings linked with security holes. Motivated by these observations, this article conducts the first comprehensive analysis of the Kodi ecosystem: 15,000 Kodi users from 104 countries, 11,000 unique add-ons, and data collected over 9 months.Our work makes three important contributions. Our first contribution is that we build “crawling” software (de-Kodi) which can automatically install a Kodi add-on, explore its menu, and locate (video) content. This is challenging for two main reasons. First, Kodi largely relies on visual information and user input which intrinsically complicates automation. Second, the potential sheer size of this ecosystem (i.e., the number of available add-ons) requires a highly scalable crawling solution. Our second contribution is that we develop a solution to discover Kodi add-ons. Our solution combines Web crawling of popular websites where Kodi add-ons are published (LazyKodi and GitHub) and SafeKodi, a Kodi add-on we have developed which leverages the help of Kodi users to learn which add-ons are used in the wild and, in return, offers information about how safe these add-ons are, e.g., do they track user activity or contact sketchy URLs/IP addresses. Our third contribution is a classifier to passively detect Kodi traffic and add-on usage in the wild.Our analysis of the Kodi ecosystem reveals the following findings. We find that most installed add-ons are unofficial but safe to use. Still, 78\% of the users have installed at least one unsafe add-on, and even worse, such add-ons are among the most popular. In response to the information offered by SafeKodi, one-third of the users reacted by disabling some of their add-ons. However, the majority of users ignored our warnings for several months attracted by the content such unsafe add-ons have to offer. Last but not least, we show that Kodi’s auto-update, a feature active for 97.6\% of SafeKodi users, makes Kodi users easily identifiable by their ISPs. While passively identifying which Kodi add-on is in use is, as expected, much harder, we also find that many unofficial add-ons do not use HTTPS yet, making their passive detection straightforward.1",2023,ACM Trans. Web,https://doi.org/10.1145/3563700,"{'keywords': 'measurement, crowdsourcing, crawling, Kodi', 'numpages': '36', 'articleno': '2', 'month': 'feb', 'journal': 'ACM Trans. Web', 'abstract': 'Free and open-source media centers are experiencing a boom in popularity for the convenience they offer users seeking to remotely consume digital content. Kodi is today’s most popular home media center, with millions of users worldwide. Kodi’s popularity derives from its ability to centralize the sheer amount of media content available on the Web, both free and copyrighted. Researchers have been hinting at potential security concerns around Kodi, due to add-ons injecting unwanted content as well as user settings linked with security holes. Motivated by these observations, this article conducts the first comprehensive analysis of the Kodi ecosystem: 15,000 Kodi users from 104 countries, 11,000 unique add-ons, and data collected over 9 months.Our work makes three important contributions. Our first contribution is that we build “crawling” software (de-Kodi) which can automatically install a Kodi add-on, explore its menu, and locate (video) content. This is challenging for two main reasons. First, Kodi largely relies on visual information and user input which intrinsically complicates automation. Second, the potential sheer size of this ecosystem (i.e., the number of available add-ons) requires a highly scalable crawling solution. Our second contribution is that we develop a solution to discover Kodi add-ons. Our solution combines Web crawling of popular websites where Kodi add-ons are published (LazyKodi and GitHub) and SafeKodi, a Kodi add-on we have developed which leverages the help of Kodi users to learn which add-ons are used in the wild and, in return, offers information about how safe these add-ons are, e.g., do they track user activity or contact sketchy URLs/IP addresses. Our third contribution is a classifier to passively detect Kodi traffic and add-on usage in the wild.Our analysis of the Kodi ecosystem reveals the following findings. We find that most installed add-ons are unofficial but safe to use. Still, 78\\% of the users have installed at least one unsafe add-on, and even worse, such add-ons are among the most popular. In response to the information offered by SafeKodi, one-third of the users reacted by disabling some of their add-ons. However, the majority of users ignored our warnings for several months attracted by the content such unsafe add-ons have to offer. Last but not least, we show that Kodi’s auto-update, a feature active for 97.6\\% of SafeKodi users, makes Kodi users easily identifiable by their ISPs. While passively identifying which Kodi add-on is in use is, as expected, much harder, we also find that many unofficial add-ons do not use HTTPS yet, making their passive detection straightforward.1', 'doi': '10.1145/3563700', 'url': 'https://doi.org/10.1145/3563700', 'issn': '1559-1131', 'number': '1', 'volume': '17', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'issue_date': 'February 2023', 'year': '2023', 'title': 'Decoding the Kodi Ecosystem', 'author': 'Xiao, Yunming and Varvello, Matteo and Warrior, Marc and Kuzmanovic, Aleksandar', 'ENTRYTYPE': 'article', 'ID': '10.1145/3563700'}",ACM
"Paci, Federica and Squicciarini, Anna and Zannone, Nicola",Survey on Access Control for Community-Centered Collaborative Systems,"usability, policy specification, literature study, data governance, Collaborative access control","The last decades have seen a growing interest and demand for community-centered collaborative systems and platforms. These systems and platforms aim to provide an environment in which users can collaboratively create, share, and manage resources. While offering attractive opportunities for online collaboration and information sharing, they also open several security and privacy issues. This has attracted several research efforts toward the design and implementation of novel access control solutions that can handle the complexity introduced by collaboration. Despite these efforts, transition to practice has been hindered by the lack of maturity of the proposed solutions. The access control mechanisms typically adopted by commercial collaborative systems like online social network websites and collaborative editing platforms, are still rather rudimentary and do not provide users with a sufficient control over their resources. This survey examines the growing literature on access control for collaborative systems centered on communities, and identifies the main challenges to be addressed in order to facilitate the adoption of collaborative access control solutions in real-life settings. Based on the literature study, we delineate a roadmap for future research in the area of access control for community-centered collaborative systems.",2018,ACM Comput. Surv.,https://doi.org/10.1145/3146025,"{'keywords': 'usability, policy specification, literature study, data governance, Collaborative access control', 'numpages': '38', 'articleno': '6', 'month': 'jan', 'journal': 'ACM Comput. Surv.', 'abstract': 'The last decades have seen a growing interest and demand for community-centered collaborative systems and platforms. These systems and platforms aim to provide an environment in which users can collaboratively create, share, and manage resources. While offering attractive opportunities for online collaboration and information sharing, they also open several security and privacy issues. This has attracted several research efforts toward the design and implementation of novel access control solutions that can handle the complexity introduced by collaboration. Despite these efforts, transition to practice has been hindered by the lack of maturity of the proposed solutions. The access control mechanisms typically adopted by commercial collaborative systems like online social network websites and collaborative editing platforms, are still rather rudimentary and do not provide users with a sufficient control over their resources. This survey examines the growing literature on access control for collaborative systems centered on communities, and identifies the main challenges to be addressed in order to facilitate the adoption of collaborative access control solutions in real-life settings. Based on the literature study, we delineate a roadmap for future research in the area of access control for community-centered collaborative systems.', 'doi': '10.1145/3146025', 'url': 'https://doi.org/10.1145/3146025', 'issn': '0360-0300', 'number': '1', 'volume': '51', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'issue_date': 'January 2019', 'year': '2018', 'title': 'Survey on Access Control for Community-Centered Collaborative Systems', 'author': 'Paci, Federica and Squicciarini, Anna and Zannone, Nicola', 'ENTRYTYPE': 'article', 'ID': '10.1145/3146025'}",ACM
"Austin, Thomas H. and Schmitz, Tommy and Flanagan, Cormac",Multiple Facets for Dynamic Information Flow with Exceptions,"Information flow control, JavaScript, dynamic analysis, web security","JavaScript is the source of many security problems, including cross-site scripting attacks and malicious advertising code. Central to these problems is the fact that code from untrusted sources runs with full privileges. Information flow controls help prevent violations of data confidentiality and integrity.This article explores faceted values, a mechanism for providing information flow security in a dynamic manner that avoids the stuck executions of some prior approaches, such as the no-sensitive-upgrade technique. Faceted values simultaneously simulate multiple executions for different security levels to guarantee termination-insensitive noninterference. We also explore the interaction of faceted values with exceptions, declassification, and clearance.",2017,ACM Trans. Program. Lang. Syst.,https://doi.org/10.1145/3024086,"{'keywords': 'Information flow control, JavaScript, dynamic analysis, web security', 'numpages': '56', 'articleno': '10', 'month': 'may', 'journal': 'ACM Trans. Program. Lang. Syst.', 'abstract': 'JavaScript is the source of many security problems, including cross-site scripting attacks and malicious advertising code. Central to these problems is the fact that code from untrusted sources runs with full privileges. Information flow controls help prevent violations of data confidentiality and integrity.This article explores faceted values, a mechanism for providing information flow security in a dynamic manner that avoids the stuck executions of some prior approaches, such as the no-sensitive-upgrade technique. Faceted values simultaneously simulate multiple executions for different security levels to guarantee termination-insensitive noninterference. We also explore the interaction of faceted values with exceptions, declassification, and clearance.', 'doi': '10.1145/3024086', 'url': 'https://doi.org/10.1145/3024086', 'issn': '0164-0925', 'number': '3', 'volume': '39', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'issue_date': 'September 2017', 'year': '2017', 'title': 'Multiple Facets for Dynamic Information Flow with Exceptions', 'author': 'Austin, Thomas H. and Schmitz, Tommy and Flanagan, Cormac', 'ENTRYTYPE': 'article', 'ID': '10.1145/3024086'}",ACM
,NSPW '23: Proceedings of the 2023 New Security Paradigms Workshop,,,2023,,,"{'location': '<conf-loc>, <city>Segovia</city>, <country>Spain</country>, </conf-loc>', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400716201', 'year': '2023', 'title': ""NSPW '23: Proceedings of the 2023 New Security Paradigms Workshop"", 'ENTRYTYPE': 'proceedings', 'ID': '10.1145/3633500'}",ACM
,MUM '22: Proceedings of the 21st International Conference on Mobile and Ubiquitous Multimedia,,,2022,,,"{'location': '<conf-loc>, <city>Lisbon</city>, <country>Portugal</country>, </conf-loc>', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450398206', 'year': '2022', 'title': ""MUM '22: Proceedings of the 21st International Conference on Mobile and Ubiquitous Multimedia"", 'ENTRYTYPE': 'proceedings', 'ID': '10.1145/3568444'}",ACM
,WWW '19: The World Wide Web Conference,,"It is our great pleasure to welcome you to The Web Conference 2019. The Web Conference is the premier venue focused on understanding the current state and the evolution of the Web through the lens of computer science, computational social science, economics, policy, and many other disciplines. The 2019 edition of the conference is a reflection point as we celebrate the 30th anniversary of the Web.",2019,,,"{'location': 'San Francisco, CA, USA', 'abstract': 'It is our great pleasure to welcome you to The Web Conference 2019. The Web Conference is the premier venue focused on understanding the current state and the evolution of the Web through the lens of computer science, computational social science, economics, policy, and many other disciplines. The 2019 edition of the conference is a reflection point as we celebrate the 30th anniversary of the Web.', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450366748', 'year': '2019', 'title': ""WWW '19: The World Wide Web Conference"", 'ENTRYTYPE': 'proceedings', 'ID': '10.1145/3308558'}",ACM
,MUM '23: Proceedings of the 22nd International Conference on Mobile and Ubiquitous Multimedia,,,2023,,,"{'location': '<conf-loc>, <city>Vienna</city>, <country>Austria</country>, </conf-loc>', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400709210', 'year': '2023', 'title': ""MUM '23: Proceedings of the 22nd International Conference on Mobile and Ubiquitous Multimedia"", 'ENTRYTYPE': 'proceedings', 'ID': '10.1145/3626705'}",ACM
,ACSAC '23: Proceedings of the 39th Annual Computer Security Applications Conference,,,2023,,,"{'location': '<conf-loc>, <city>Austin</city>, <state>TX</state>, <country>USA</country>, </conf-loc>', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400708862', 'year': '2023', 'title': ""ACSAC '23: Proceedings of the 39th Annual Computer Security Applications Conference"", 'ENTRYTYPE': 'proceedings', 'ID': '10.1145/3627106'}",ACM
,CHI '24: Proceedings of the CHI Conference on Human Factors in Computing Systems,,,2024,,,"{'location': '<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9798400703300', 'year': '2024', 'title': ""CHI '24: Proceedings of the CHI Conference on Human Factors in Computing Systems"", 'ENTRYTYPE': 'proceedings', 'ID': '10.1145/3613904'}",ACM
,ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,"On behalf of all members of the organizing committee, we are delighted to welcome everyone to the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE) 2022. The event continues the long, distinguished ESEC/FSE tradition of presenting the most innovative research, and facilitating interactions between scientists and engineers who are passionate about advancing the theory and practice of software engineering.",2022,,,"{'location': '<conf-loc>, <city>Singapore</city>, <country>Singapore</country>, </conf-loc>', 'abstract': 'On behalf of all members of the organizing committee, we are delighted to welcome everyone to the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE) 2022. The event continues the long, distinguished ESEC/FSE tradition of presenting the most innovative research, and facilitating interactions between scientists and engineers who are passionate about advancing the theory and practice of software engineering.', 'address': 'New York, NY, USA', 'publisher': 'Association for Computing Machinery', 'isbn': '9781450394130', 'year': '2022', 'title': 'ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering', 'ENTRYTYPE': 'proceedings', 'ID': '10.1145/3540250'}",ACM
"Puning Zhao, Rongfei Fan, Huiwen Wu, Qingming Li, Jiafei Wu, Zhe Liu",Enhancing Learning with Label Differential Privacy by Vector Approximation,,"Label differential privacy (DP) is a framework that protects the privacy of labels in training datasets, while the feature vectors are public. Existing approaches protect the privacy of labels by flipping them randomly, and then train a model to make the output approximate the privatized label. However, as the number of classes $K$ increases, stronger randomization is needed, thus the performances of these methods become significantly worse. In this paper, we propose a vector approximation approach, which is easy to implement and introduces little additional computational overhead. Instead of flipping each label into a single scalar, our method converts each label into a random vector with $K$ components, whose expectations reflect class conditional probabilities. Intuitively, vector approximation retains more information than scalar labels. A brief theoretical analysis shows that the performance of our method only decays slightly with $K$. Finally, we conduct experiments on both synthesized and real datasets, which validate our theoretical analysis as well as the practical performance of our method.",,,https://arxiv.org/abs/2405.15150,"@misc{zhao2024enhancing,
      title={Enhancing Learning with Label Differential Privacy by Vector Approximation}, 
      author={Puning Zhao and Rongfei Fan and Huiwen Wu and Qingming Li and Jiafei Wu and Zhe Liu},
      year={2024},
      eprint={2405.15150},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}",arxiv
"Wenjun Qiu, David Lie, Lisa Austin",Calpric: Inclusive and Fine-grain Labeling of Privacy Policies with Crowdsourcing and Active Learning,,"A significant challenge to training accurate deep learning models on privacy policies is the cost and difficulty of obtaining a large and comprehensive set of training data. To address these challenges, we present Calpric , which combines automatic text selection and segmentation, active learning and the use of crowdsourced annotators to generate a large, balanced training set for privacy policies at low cost. Automated text selection and segmentation simplifies the labeling task, enabling untrained annotators from crowdsourcing platforms, like Amazon's Mechanical Turk, to be competitive with trained annotators, such as law students, and also reduces inter-annotator agreement, which decreases labeling cost. Having reliable labels for training enables the use of active learning, which uses fewer training samples to efficiently cover the input space, further reducing cost and improving class and data category balance in the data set. The combination of these techniques allows Calpric to produce models that are accurate over a wider range of data categories, and provide more detailed, fine-grain labels than previous work. Our crowdsourcing process enables Calpric to attain reliable labeled data at a cost of roughly $0.92-$1.71 per labeled text segment. Calpric 's training process also generates a labeled data set of 16K privacy policy text segments across 9 Data categories with balanced positive and negative samples.",,,https://arxiv.org/abs/2401.08038,"@misc{qiu2024calpric,
      title={Calpric: Inclusive and Fine-grain Labeling of Privacy Policies with Crowdsourcing and Active Learning}, 
      author={Wenjun Qiu and David Lie and Lisa Austin},
      year={2024},
      eprint={2401.08038},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}",arxiv
"Zhongnian Li, Haotian Ren, Tongfeng Sun, Zhichen Li",Multi-label Learning from Privacy-Label,,"Multi-abel Learning (MLL) often involves the assignment of multiple relevant labels to each instance, which can lead to the leakage of sensitive information (such as smoking, diseases, etc.) about the instances. However, existing MLL suffer from failures in protection for sensitive information. In this paper, we propose a novel setting named Multi-Label Learning from Privacy-Label (MLLPL), which Concealing Labels via Privacy-Label Unit (CLPLU). Specifically, during the labeling phase, each privacy-label is randomly combined with a non-privacy label to form a Privacy-Label Unit (PLU). If any label within a PLU is positive, the unit is labeled as positive; otherwise, it is labeled negative, as shown in Figure 1. PLU ensures that only non-privacy labels are appear in the label set, while the privacy-labels remain concealed. Moreover, we further propose a Privacy-Label Unit Loss (PLUL) to learn the optimal classifier by minimizing the empirical risk of PLU. Experimental results on multiple benchmark datasets demonstrate the effectiveness and superiority of the proposed method.",,,https://arxiv.org/abs/2312.13312,"@misc{li2023multilabel,
      title={Multi-label Learning from Privacy-Label}, 
      author={Zhongnian Li and Haotian Ren and Tongfeng Sun and Zhichen Li},
      year={2023},
      eprint={2312.13312},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}",arxiv
"Ashwinkumar Badanidiyuru, Badih Ghazi, Pritish Kamath, Ravi Kumar, Ethan Leeman, Pasin Manurangsi, Avinash V Varadarajan, Chiyuan Zhang","Optimal Unbiased Randomizers for Regression with Label
                    Differential Privacy",,"We propose a new family of label randomizers for training regression models under the constraint of label differential privacy (DP). In particular, we leverage the trade-offs between bias and variance to construct better label randomizers depending on a privately estimated prior distribution over the labels. We demonstrate that these randomizers achieve state-of-the-art privacy-utility trade-offs on several datasets, highlighting the importance of reducing bias when training neural networks with label DP. We also provide theoretical results shedding light on the structural properties of the optimal unbiased randomizers.",,,https://arxiv.org/abs/2312.05659,"@misc{badanidiyuru2023optimal,
      title={Optimal Unbiased Randomizers for Regression with Label Differential Privacy}, 
      author={Ashwinkumar Badanidiyuru and Badih Ghazi and Pritish Kamath and Ravi Kumar and Ethan Leeman and Pasin Manurangsi and Avinash V Varadarajan and Chiyuan Zhang},
      year={2023},
      eprint={2312.05659},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}",arxiv
"Yanzi Lin, Jaideep Juneja, Eleanor Birrell, Lorrie Faith Cranor","Data Safety vs. App Privacy: Comparing the Usability of
                    Android and iOS Privacy Labels",,"Privacy labels -- standardized, compact representations of data collection and data use practices -- are often presented as a solution to the shortcomings of privacy policies. Apple introduced mandatory privacy labels for apps in its App Store in December 2020; Google introduced mandatory labels for Android apps in July 2022. iOS app privacy labels have been evaluated and critiqued in prior work. In this work, we evaluated Android Data Safety Labels and explored how differences between the two label designs impact user comprehension and label utility. We conducted a between-subjects, semi-structured interview study with 12 Android users and 12 iOS users. While some users found Android Data Safety Labels informative and helpful, other users found them too vague. Compared to iOS App Privacy Labels, Android users found the distinction between data collection groups more intuitive and found explicit inclusion of omitted data collection groups more salient. However, some users expressed skepticism regarding elided information about collected data type categories. Most users missed critical information due to not expanding the accordion interface, and they were surprised by collection practices excluded from Android's definitions. Our findings also revealed that Android users generally appreciated information about security practices included in the labels, and iOS users wanted that information added.",,,https://arxiv.org/abs/2312.03918,"@misc{lin2024data,
      title={Data Safety vs. App Privacy: Comparing the Usability of Android and iOS Privacy Labels}, 
      author={Yanzi Lin and Jaideep Juneja and Eleanor Birrell and Lorrie Faith Cranor},
      year={2024},
      eprint={2312.03918},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}",arxiv
"Tong Xia, Abhirup Ghosh, Cecilia Mascolo","FLea: Improving federated learning on scarce and label-skewed
                    data via privacy-preserving feature augmentation",,"Learning a global model by abstracting the knowledge, distributed across multiple clients, without aggregating the raw data is the primary goal of Federated Learning (FL). Typically, this works in rounds alternating between parallel local training at several clients, followed by model aggregation at a server. We found that existing FL methods under-perform when local datasets are small and present severe label skew as these lead to over-fitting and local model bias. This is a realistic setting in many real-world applications. To address the problem, we propose \textit{FLea}, a unified framework that tackles over-fitting and local bias by encouraging clients to exchange privacy-protected features to aid local training. The features refer to activations from an intermediate layer of the model, which are obfuscated before being shared with other clients to protect sensitive information in the data. \textit{FLea} leverages a novel way of combining local and shared features as augmentations to enhance local model learning. Our extensive experiments demonstrate that \textit{FLea} outperforms the start-of-the-art FL methods, sharing only model parameters, by up to $17.6\%$, and FL methods that share data augmentations by up to $6.3\%$, while reducing the privacy vulnerability associated with shared data augmentations.",,,https://arxiv.org/abs/2312.02327,"@misc{xia2023flea,
      title={FLea: Improving federated learning on scarce and label-skewed data via privacy-preserving feature augmentation}, 
      author={Tong Xia and Abhirup Ghosh and Cecilia Mascolo},
      year={2023},
      eprint={2312.02327},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}",arxiv
"Zhanbo Liang, Jie Guo, Weidong Qiu, Zheng Huang, Shujun Li",When Graph Convolution Meets Double Attention: Online Privacy Disclosure Detection with Multi-Label Text Classification,,"With the rise of Web 2.0 platforms such as online social media, people's private information, such as their location, occupation and even family information, is often inadvertently disclosed through online discussions. Therefore, it is important to detect such unwanted privacy disclosures to help alert people affected and the online platform. In this paper, privacy disclosure detection is modeled as a multi-label text classification (MLTC) problem, and a new privacy disclosure detection model is proposed to construct an MLTC classifier for detecting online privacy disclosures. This classifier takes an online post as the input and outputs multiple labels, each reflecting a possible privacy disclosure. The proposed presentation method combines three different sources of information, the input text itself, the label-to-text correlation and the label-to-label correlation. A double-attention mechanism is used to combine the first two sources of information, and a graph convolutional network (GCN) is employed to extract the third source of information that is then used to help fuse features extracted from the first two sources of information. Our extensive experimental results, obtained on a public dataset of privacy-disclosing posts on Twitter, demonstrated that our proposed privacy disclosure detection method significantly and consistently outperformed other state-of-the-art methods in terms of all key performance indicators.",,,https://arxiv.org/abs/2311.15917,"@misc{liang2023graph,
      title={When Graph Convolution Meets Double Attention: Online Privacy Disclosure Detection with Multi-Label Text Classification}, 
      author={Zhanbo Liang and Jie Guo and Weidong Qiu and Zheng Huang and Shujun Li},
      year={2023},
      eprint={2311.15917},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}",arxiv
"Anand Brahmbhatt, Rishi Saket, Shreyas Havaldar, Anshul Nasery, Aravindan Raghuveer",Label Differential Privacy via Aggregation,,"In many real-world applications, due to recent developments in the privacy landscape, training data may be aggregated to preserve the privacy of sensitive training labels. In the learning from label proportions (LLP) framework, the dataset is partitioned into bags of feature-vectors which are available only with the sum of the labels per bag. A further restriction, which we call learning from bag aggregates (LBA) is where instead of individual feature-vectors, only the (possibly weighted) sum of the feature-vectors per bag is available. We study whether such aggregation techniques can provide privacy guarantees under the notion of label differential privacy (label-DP) previously studied in for e.g. [Chaudhuri-Hsu'11, Ghazi et al.'21, Esfandiari et al.'22].
It is easily seen that naive LBA and LLP do not provide label-DP. Our main result however, shows that weighted LBA using iid Gaussian weights with $m$ randomly sampled disjoint $k$-sized bags is in fact $(\varepsilon, \delta)$-label-DP for any $\varepsilon > 0$ with $\delta \approx \exp(-\Omega(\sqrt{k}))$ assuming a lower bound on the linear-mse regression loss. Further, the $\ell_2^2$-regressor which minimizes the loss on the aggregated dataset has a loss within $\left(1 + o(1)\right)$-factor of the optimum on the original dataset w.p. $\approx 1 - exp(-\Omega(m))$. We emphasize that no additive label noise is required.
The analogous weighted-LLP does not however admit label-DP. Nevertheless, we show that if additive $N(0, 1)$ noise can be added to any constant fraction of the instance labels, then the noisy weighted-LLP admits similar label-DP guarantees without assumptions on the dataset, while preserving the utility of Lipschitz-bounded neural mse-regression tasks.
Our work is the first to demonstrate that label-DP can be achieved by randomly weighted aggregation for regression tasks, using no or little additive noise.",,,https://arxiv.org/abs/2310.10092,"@misc{brahmbhatt2023label,
      title={Label Differential Privacy via Aggregation}, 
      author={Anand Brahmbhatt and Rishi Saket and Shreyas Havaldar and Anshul Nasery and Aravindan Raghuveer},
      year={2023},
      eprint={2310.10092},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}",arxiv
"Lukas Struppek, Dominik Hintersdorf, Kristian Kersting","Be Careful What You Smooth For: Label Smoothing Can Be a
                    Privacy Shield but Also a Catalyst for Model Inversion
                    Attacks",,"Label smoothing -- using softened labels instead of hard ones -- is a widely adopted regularization method for deep learning, showing diverse benefits such as enhanced generalization and calibration. Its implications for preserving model privacy, however, have remained unexplored. To fill this gap, we investigate the impact of label smoothing on model inversion attacks (MIAs), which aim to generate class-representative samples by exploiting the knowledge encoded in a classifier, thereby inferring sensitive information about its training data. Through extensive analyses, we uncover that traditional label smoothing fosters MIAs, thereby increasing a model's privacy leakage. Even more, we reveal that smoothing with negative factors counters this trend, impeding the extraction of class-related information and leading to privacy preservation, beating state-of-the-art defenses. This establishes a practical and powerful novel way for enhancing model resilience against MIAs.",,,https://arxiv.org/abs/2310.06549,"@misc{struppek2024careful,
      title={Be Careful What You Smooth For: Label Smoothing Can Be a Privacy Shield but Also a Catalyst for Model Inversion Attacks}, 
      author={Lukas Struppek and Dominik Hintersdorf and Kristian Kersting},
      year={2024},
      eprint={2310.06549},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}",arxiv
"Amr Abourayya, Jens Kleesiek, Kanishka Rao, Erman Ayday, Bharat Rao, Geoff Webb, Michael Kamp",Little is Enough: Improving Privacy by Sharing Labels in Federated Semi-Supervised Learning,,"In many critical applications, sensitive data is inherently distributed and cannot be centralized due to privacy concerns. A wide range of federated learning approaches have been proposed in the literature to train models locally at each client without sharing their sensitive local data. Most of these approaches either share local model parameters, soft predictions on a public dataset, or a combination of both. This, however, still discloses private information and restricts local models to those that lend themselves to training via gradient-based methods. To reduce the amount of shared information, we propose to share only hard labels on a public unlabeled dataset, and use a consensus over the shared labels as a pseudo-labeling to be used by clients. The resulting federated co-training approach empirically improves privacy substantially, without compromising on model quality. At the same time, it allows us to use local models that do not lend themselves to the parameter aggregation used in federated learning, such as (gradient boosted) decision trees, rule ensembles, and random forests.",,,https://arxiv.org/abs/2310.05696,"@misc{abourayya2024little,
      title={Little is Enough: Improving Privacy by Sharing Labels in Federated Semi-Supervised Learning}, 
      author={Amr Abourayya and Jens Kleesiek and Kanishka Rao and Erman Ayday and Bharat Rao and Geoff Webb and Michael Kamp},
      year={2024},
      eprint={2310.05696},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}",arxiv
"Yixiang Yao, Weizhao Jin, Srivatsan Ravi",Labeling without Seeing? Blind Annotation for Privacy-Preserving Entity Resolution,,"The entity resolution problem requires finding pairs across datasets that belong to different owners but refer to the same entity in the real world. To train and evaluate solutions (either rule-based or machine-learning-based) to the entity resolution problem, generating a ground truth dataset with entity pairs or clusters is needed. However, such a data annotation process involves humans as domain oracles to review the plaintext data for all candidate record pairs from different parties, which inevitably infringes the privacy of data owners, especially in privacy-sensitive cases like medical records. To the best of our knowledge, there is no prior work on privacy-preserving ground truth dataset generation, especially in the domain of entity resolution. We propose a novel blind annotation protocol based on homomorphic encryption that allows domain oracles to collaboratively label ground truths without sharing data in plaintext with other parties. In addition, we design a domain-specific easy-to-use language that hides the sophisticated underlying homomorphic encryption layer. Rigorous proof of the privacy guarantee is provided and our empirical experiments via an annotation simulator indicate the feasibility of our privacy-preserving protocol (f-measure on average achieves more than 90\% compared with the real ground truths).",,,https://arxiv.org/abs/2308.03734,"@misc{yao2023labeling,
      title={Labeling without Seeing? Blind Annotation for Privacy-Preserving Entity Resolution}, 
      author={Yixiang Yao and Weizhao Jin and Srivatsan Ravi},
      year={2023},
      eprint={2308.03734},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}",arxiv
"Mir Masood Ali, David G. Balash, Chris Kanich, Adam J. Aviv","Honesty is the Best Policy: On the Accuracy of Apple Privacy
Labels Compared to Apps' Privacy Policies",,"Apple introduced \textit{privacy labels} in Dec. 2020 as a way for developers to report the privacy behaviors of their apps. While Apple does not validate labels, they do also require developers to provide a privacy policy, which offers an important comparison point. In this paper, we applied the NLP framework of Polisis to extract features of the privacy policy for 515,920 apps on the iOS App Store comparing the output to the privacy labels. We identify discrepancies between the policies and the labels, particularly as it relates to data collected that is linked to users. We find that 287$\pm196$K apps' privacy policies may indicate data collection that is linked to users than what is reported in the privacy labels. More alarming, a large number of (97$\pm30$\%) of the apps that have {\em Data Not Collected} privacy label have a privacy policy that indicates otherwise. We provide insights into potential sources for discrepancies, including the use of templates and confusion around Apple's definitions and requirements. These results suggest that there is still significant work to be done to help developers more accurately labeling their apps. Incorporating a Polisis-like system as a first-order check can help improve the current state and better inform developers when there are possible misapplication of privacy labels.",,,https://arxiv.org/abs/2306.17063,"@misc{ali2023honesty,
      title={Honesty is the Best Policy: On the Accuracy of Apple Privacy Labels Compared to Apps' Privacy Policies}, 
      author={Mir Masood Ali and David G. Balash and Chris Kanich and Adam J. Aviv},
      year={2023},
      eprint={2306.17063},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}",arxiv
"Shidong Pan, Thong Hoang, Dawen Zhang, Zhenchang Xing, Xiwei Xu, Qinghua Lu, Mark Staples","Toward the Cure of Privacy Policy Reading Phobia: Automated
                    Generation of Privacy Nutrition Labels From Privacy
                    Policies",,"Software applications have become an omnipresent part of modern society. The consequent privacy policies of these applications play a significant role in informing customers how their personal information is collected, stored, and used. However, customers rarely read and often fail to understand privacy policies because of the ``Privacy Policy Reading Phobia'' (PPRP). To tackle this emerging challenge, we propose the first framework that can automatically generate privacy nutrition labels from privacy policies. Based on our ground truth applications about the Data Safety Report from the Google Play app store, our framework achieves a 0.75 F1-score on generating first-party data collection practices and an average of 0.93 F1-score on general security practices. We also analyse the inconsistencies between ground truth and curated privacy nutrition labels on the market, and our framework can detect 90.1% under-claim issues. Our framework demonstrates decent generalizability across different privacy nutrition label formats, such as Google's Data Safety Report and Apple's App Privacy Details.",,,https://arxiv.org/abs/2306.10923,"@misc{pan2023cure,
      title={Toward the Cure of Privacy Policy Reading Phobia: Automated Generation of Privacy Nutrition Labels From Privacy Policies}, 
      author={Shidong Pan and Thong Hoang and Dawen Zhang and Zhenchang Xing and Xiwei Xu and Qinghua Lu and Mark Staples},
      year={2023},
      eprint={2306.10923},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}",arxiv
"Rishabh Khandelwal, Asmit Nayak, Paul Chung, Kassem Fawaz","Unpacking Privacy Labels: A Measurement and Developer Perspective on Google's
                    Data Safety Section",,"Google has mandated developers to use Data Safety Sections (DSS) to increase transparency in data collection and sharing practices. In this paper, we present a comprehensive analysis of Google's Data Safety Section (DSS) using both quantitative and qualitative methods. We conduct the first large-scale measurement study of DSS using apps from Android Play store (n=1.1M). We find that there are internal inconsistencies within the reported practices. We also find trends of both over and under-reporting practices in the DSSs.
Next, we conduct a longitudinal study of DSS to explore how the reported practices evolve over time, and find that the developers are still adjusting their practices. To contextualize these findings, we conduct a developer study, uncovering the process that app developers undergo when working with DSS. We highlight the challenges faced and strategies employed by developers for DSS submission, and the factors contributing to changes in the DSS. Our research contributes valuable insights into the complexities of implementing and maintaining privacy labels, underlining the need for better resources, tools, and guidelines to aid developers. This understanding is crucial as the accuracy and reliability of privacy labels directly impact their effectiveness.",,,https://arxiv.org/abs/2306.08111,"@misc{khandelwal2023unpacking,
      title={Unpacking Privacy Labels: A Measurement and Developer Perspective on Google's Data Safety Section}, 
      author={Rishabh Khandelwal and Asmit Nayak and Paul Chung and Kassem Fawaz},
      year={2023},
      eprint={2306.08111},
      archivePrefix={arXiv},
      primaryClass={cs.CY}
}",arxiv
"Tiantian Feng, Digbalay Bose, Xuan Shi, Shrikanth Narayanan","Unlocking Foundation Models for Privacy-Enhancing Speech
                    Understanding: An Early Study on Low Resource Speech Training Leveraging Label-guided Synthetic Speech Content",,"Automatic Speech Understanding (ASU) leverages the power of deep learning models for accurate interpretation of human speech, leading to a wide range of speech applications that enrich the human experience. However, training a robust ASU model requires the curation of a large number of speech samples, creating risks for privacy breaches. In this work, we investigate using foundation models to assist privacy-enhancing speech computing. Unlike conventional works focusing primarily on data perturbation or distributed algorithms, our work studies the possibilities of using pre-trained generative models to synthesize speech content as training data with just label guidance. We show that zero-shot learning with training label-guided synthetic speech content remains a challenging task. On the other hand, our results demonstrate that the model trained with synthetic speech samples provides an effective initialization point for low-resource ASU training. This result reveals the potential to enhance privacy by reducing user data collection but using label-guided synthetic speech content.",,,https://arxiv.org/abs/2306.07791,"@misc{feng2023unlocking,
      title={Unlocking Foundation Models for Privacy-Enhancing Speech Understanding: An Early Study on Low Resource Speech Training Leveraging Label-guided Synthetic Speech Content}, 
      author={Tiantian Feng and Digbalay Bose and Xuan Shi and Shrikanth Narayanan},
      year={2023},
      eprint={2306.07791},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}",arxiv
"Ziheng Wang, Conor Perreault, Xi Liu, Anthony Jarc","Automatic Detection of Out-of-body Frames in Surgical Videos for Privacy
                    Protection Using Self-supervised Learning and Minimal Labels",,"Endoscopic video recordings are widely used in minimally invasive robot-assisted surgery, but when the endoscope is outside the patient's body, it can capture irrelevant segments that may contain sensitive information. To address this, we propose a framework that accurately detects out-of-body frames in surgical videos by leveraging self-supervision with minimal data labels. We use a massive amount of unlabeled endoscopic images to learn meaningful representations in a self-supervised manner. Our approach, which involves pre-training on an auxiliary task and fine-tuning with limited supervision, outperforms previous methods for detecting out-of-body frames in surgical videos captured from da Vinci X and Xi surgical systems. The average F1 scores range from 96.00 to 98.02. Remarkably, using only 5% of the training labels, our approach still maintains an average F1 score performance above 97, outperforming fully-supervised methods with 95% fewer labels. These results demonstrate the potential of our framework to facilitate the safe handling of surgical video recordings and enhance data privacy protection in minimally invasive surgery.",,,https://arxiv.org/abs/2303.18106,"@misc{wang2023automatic,
      title={Automatic Detection of Out-of-body Frames in Surgical Videos for Privacy Protection Using Self-supervised Learning and Minimal Labels}, 
      author={Ziheng Wang and Conor Perreault and Xi Liu and Anthony Jarc},
      year={2023},
      eprint={2303.18106},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}",arxiv
"Manas Wadhwa, Gagan Raj Gupta, Ashutosh Sahu, Rahul Saini, Vidhi Mittal","PFSL: Personalized & Fair Split Learning with Data & Label Privacy for thin
                    clients",,"The traditional framework of federated learning (FL) requires each client to re-train their models in every iteration, making it infeasible for resource-constrained mobile devices to train deep-learning (DL) models. Split learning (SL) provides an alternative by using a centralized server to offload the computation of activations and gradients for a subset of the model but suffers from problems of slow convergence and lower accuracy. In this paper, we implement PFSL, a new framework of distributed split learning where a large number of thin clients perform transfer learning in parallel, starting with a pre-trained DL model without sharing their data or labels with a central server. We implement a lightweight step of personalization of client models to provide high performance for their respective data distributions. Furthermore, we evaluate performance fairness amongst clients under a work fairness constraint for various scenarios of non-i.i.d. data distributions and unequal sample sizes. Our accuracy far exceeds that of current SL algorithms and is very close to that of centralized learning on several real-life benchmarks. It has a very low computation cost compared to FL variants and promises to deliver the full benefits of DL to extremely thin, resource-constrained clients.",,,https://arxiv.org/abs/2303.10624,"@misc{wadhwa2023pfsl,
      title={PFSL: Personalized & Fair Split Learning with Data & Label Privacy for thin clients}, 
      author={Manas Wadhwa and Gagan Raj Gupta and Ashutosh Sahu and Rahul Saini and Vidhi Mittal},
      year={2023},
      eprint={2303.10624},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}",arxiv
"Rishabh Khandelwal, Asmit Nayak, Paul Chung, Kassem Fawaz","The Overview of Privacy Labels
                    and their Compatibility with Privacy Policies",,"Privacy nutrition labels provide a way to understand an app's key data practices without reading the long and hard-to-read privacy policies. Recently, the app distribution platforms for iOS(Apple) and Android(Google) have implemented mandates requiring app developers to fill privacy nutrition labels highlighting their privacy practices such as data collection, data sharing, and security practices. These privacy labels contain very fine-grained information about the apps' data practices such as the data types and purposes associated with each data type. This provides us with a unique vantage point from which we can understand apps' data practices at scale.",,,https://arxiv.org/abs/2303.08213,"@misc{khandelwal2023overview,
      title={The Overview of Privacy Labels and their Compatibility with Privacy Policies}, 
      author={Rishabh Khandelwal and Asmit Nayak and Paul Chung and Kassem Fawaz},
      year={2023},
      eprint={2303.08213},
      archivePrefix={arXiv},
      primaryClass={cs.CY}
}",arxiv
"Badih Ghazi, Pritish Kamath, Ravi Kumar, Ethan Leeman, Pasin Manurangsi, Avinash V Varadarajan, Chiyuan Zhang",Regression with Label Differential Privacy,,"We study the task of training regression models with the guarantee of label differential privacy (DP). Based on a global prior distribution on label values, which could be obtained privately, we derive a label DP randomization mechanism that is optimal under a given regression loss function. We prove that the optimal mechanism takes the form of a ""randomized response on bins"", and propose an efficient algorithm for finding the optimal bin values. We carry out a thorough experimental evaluation on several datasets demonstrating the efficacy of our algorithm.",,,https://arxiv.org/abs/2212.06074,"@misc{ghazi2023regression,
      title={Regression with Label Differential Privacy}, 
      author={Badih Ghazi and Pritish Kamath and Ravi Kumar and Ethan Leeman and Pasin Manurangsi and Avinash V Varadarajan and Chiyuan Zhang},
      year={2023},
      eprint={2212.06074},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}",arxiv
"Kaifa Zhao, Le Yu, Shiyao Zhou, Jing Li, Xiapu Luo, Yat Fei Aemon Chiu, Yutong Liu","A Fine-grained Chinese Software Privacy Policy Dataset for
                    Sequence Labeling and Regulation Compliant Identification",,"Privacy protection raises great attention on both legal levels and user awareness. To protect user privacy, countries enact laws and regulations requiring software privacy policies to regulate their behavior. However, privacy policies are written in natural languages with many legal terms and software jargon that prevent users from understanding and even reading them. It is desirable to use NLP techniques to analyze privacy policies for helping users understand them. Furthermore, existing datasets ignore law requirements and are limited to English. In this paper, we construct the first Chinese privacy policy dataset, namely CA4P-483, to facilitate the sequence labeling tasks and regulation compliance identification between privacy policies and software. Our dataset includes 483 Chinese Android application privacy policies, over 11K sentences, and 52K fine-grained annotations. We evaluate families of robust and representative baseline models on our dataset. Based on baseline performance, we provide findings and potential research directions on our dataset. Finally, we investigate the potential applications of CA4P-483 combing regulation requirements and program analysis.",,,https://arxiv.org/abs/2212.04357,"@misc{zhao2022finegrained,
      title={A Fine-grained Chinese Software Privacy Policy Dataset for Sequence Labeling and Regulation Compliant Identification}, 
      author={Kaifa Zhao and Le Yu and Shiyao Zhou and Jing Li and Xiapu Luo and Yat Fei Aemon Chiu and Yutong Liu},
      year={2022},
      eprint={2212.04357},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}",arxiv
"Yue Xiao, Zhengyi Li, Yue Qin, Xiaolong Bai, Jiale Guan, Xiaojing Liao, Luyi Xing","Lalaine: Measuring and Characterizing Non-Compliance of Apple Privacy
Labels at Scale",,"As a key supplement to privacy policies that are known to be lengthy and difficult to read, Apple has launched the app privacy labels, which purportedly help users more easily understand an app's privacy practices. However, false and misleading privacy labels can dupe privacy-conscious consumers into downloading data-intensive apps, ultimately eroding the credibility and integrity of the labels. Although Apple releases requirements and guidelines for app developers to create privacy labels, little is known about whether and to what extent the privacy labels in the wild are correct and compliant, reflecting the actual data practices of iOS apps. This paper presents the first systematic study, based on our new methodology named Lalaine, to evaluate data-flow to privacy-label (flow-to-label) consistency. Lalaine analyzed the privacy labels and binaries of 5,102 iOS apps, shedding light on the prevalence and seriousness of privacy-label non-compliance. We provide detailed case studies and analyze root causes for privacy label non-compliance that complements prior understandings. This has led to new insights for improving privacy-label design and compliance requirements, so app developers, platform stakeholders, and policy-makers can better achieve their privacy and accountability goals. Lalaine is thoroughly evaluated for its high effectiveness and efficiency. We are responsibly reporting the results to stakeholders.",,,https://arxiv.org/abs/2206.06274,"@misc{xiao2022lalaine,
      title={Lalaine: Measuring and Characterizing Non-Compliance of Apple Privacy Labels at Scale}, 
      author={Yue Xiao and Zhengyi Li and Yue Qin and Xiaolong Bai and Jiale Guan and Xiaojing Liao and Luyi Xing},
      year={2022},
      eprint={2206.06274},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}",arxiv
"David G. Balash, Mir Masood Ali, Xiaoyuan Wu, Chris Kanich, Adam J. Aviv",Longitudinal Analysis of Privacy Labels in the Apple App Store,,"In December of 2020, Apple started to require app developers to self-report privacy label annotations on their apps indicating what data is collected and how it is this http URL understand the adoption and shifts in privacy labels in the App Store, we collected nearly weekly snapshots of over 1.6 million apps for over a year (July 15, 2021 -- October 25, 2022) to understand the dynamics of privacy label ecosystem. Nearly two years after privacy labels launched, only 70.1% of apps have privacy labels, but we observed an increase of 28% during the measurement period. Privacy label adoption rates are mostly driven by new apps rather than older apps coming into compliance. Of apps with labels, 18.1% collect data used to track users, 38.1% collect data that is linked to a user identity, and 42.0% collect data that is not linked. A surprisingly large share (41.8%) of apps with labels indicate that they do not collect any data, and while we do not perform direct analysis of the apps to verify this claim, we observe that it is likely that many of these apps are choosing a Does Not Collect label due to being forced to select a label, rather than this being the true behavior of the app. Moreover, for apps that have assigned labels during the measurement period nearly all do not change their labels, and when they do, the new labels indicate more data collection than less. This suggests that privacy labels may be a ``set once'' mechanism for developers that may not actually provide users with the clarity needed to make informed privacy decisions.",,,https://arxiv.org/abs/2206.02658,"@misc{balash2023longitudinal,
      title={Longitudinal Analysis of Privacy Labels in the Apple App Store}, 
      author={David G. Balash and Mir Masood Ali and Xiaoyuan Wu and Chris Kanich and Adam J. Aviv},
      year={2023},
      eprint={2206.02658},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}",arxiv
"Teddy Cunningham, Konstantin Klemmer, Hongkai Wen, Hakan Ferhatosmanoglu","GeoPointGAN: Synthetic Spatial Data with Local Label
                    Differential Privacy",,"Synthetic data generation is a fundamental task for many data management and data science applications. Spatial data is of particular interest, and its sensitive nature often leads to privacy concerns. We introduce GeoPointGAN, a novel GAN-based solution for generating synthetic spatial point datasets with high utility and strong individual level privacy guarantees. GeoPointGAN's architecture includes a novel point transformation generator that learns to project randomly generated point co-ordinates into meaningful synthetic co-ordinates that capture both microscopic (e.g., junctions, squares) and macroscopic (e.g., parks, lakes) geographic features. We provide our privacy guarantees through label local differential privacy, which is more practical than traditional local differential privacy. We seamlessly integrate this level of privacy into GeoPointGAN by augmenting the discriminator to the point level and implementing a randomized response-based mechanism that flips the labels associated with the 'real' and 'fake' points used in training. Extensive experiments show that GeoPointGAN significantly outperforms recent solutions, improving by up to 10 times compared to the most competitive baseline. We also evaluate GeoPointGAN using range, hotspot, and facility location queries, which confirm the practical effectiveness of GeoPointGAN for privacy-preserving querying. The results illustrate that a strong level of privacy is achieved with little-to-no adverse utility cost, which we explain through the generalization and regularization effects that are realized by flipping the labels of the data during training.",,,https://arxiv.org/abs/2205.08886,"@misc{cunningham2022geopointgan,
      title={GeoPointGAN: Synthetic Spatial Data with Local Label Differential Privacy}, 
      author={Teddy Cunningham and Konstantin Klemmer and Hongkai Wen and Hakan Ferhatosmanoglu},
      year={2022},
      eprint={2205.08886},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}",arxiv
"Giannis Haralabopoulos, Ioannis Anagnostopoulos","Privacy-Aware Crowd Labelling
                    for Machine Learning Tasks",,"The extensive use of online social media has highlighted the importance of privacy in the digital space. As more scientists analyse the data created in these platforms, privacy concerns have extended to data usage within the academia. Although text analysis is a well documented topic in academic literature with a multitude of applications, ensuring privacy of user-generated content has been overlooked. Most sentiment analysis methods require emotion labels, which can be obtained through crowdsourcing, where non-expert individuals contribute to scientific tasks. The text itself has to be exposed to third parties in order to be labelled. In an effort to reduce the exposure of online users' information, we propose a privacy preserving text labelling method for varying applications, based in crowdsourcing. We transform text with different levels of privacy, and analyse the effectiveness of the transformation with regards to label correlation and consistency. Our results suggest that privacy can be implemented in labelling, retaining the annotational diversity and subjectivity of traditional labelling.",,,https://arxiv.org/abs/2203.01373,"@misc{haralabopoulos2022privacyaware,
      title={Privacy-Aware Crowd Labelling for Machine Learning Tasks}, 
      author={Giannis Haralabopoulos and Ioannis Anagnostopoulos},
      year={2022},
      eprint={2203.01373},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}",arxiv
"Hossein Esfandiari, Vahab Mirrokni, Umar Syed, Sergei Vassilvitskii",Label differential privacy via clustering,,"We present new mechanisms for \emph{label differential privacy}, a relaxation of differentially private machine learning that only protects the privacy of the labels in the training set. Our mechanisms cluster the examples in the training set using their (non-private) feature vectors, randomly re-sample each label from examples in the same cluster, and output a training set with noisy labels as well as a modified version of the true loss function. We prove that when the clusters are both large and high-quality, the model that minimizes the modified loss on the noisy training set converges to small excess risk at a rate that is comparable to the rate for non-private learning. We describe both a centralized mechanism in which the entire training set is stored by a trusted curator, and a distributed mechanism where each user stores a single labeled example and replaces her label with the label of a randomly selected user from the same cluster. We also describe a learning problem in which large clusters are necessary to achieve both strong privacy and either good precision or good recall. Our experiments show that randomizing the labels within each cluster significantly improves the privacy vs. accuracy trade-off compared to applying uniform randomized response to the labels, and also compared to learning a model via DP-SGD.",,,https://arxiv.org/abs/2110.02159,"@misc{esfandiari2021label,
      title={Label differential privacy via clustering}, 
      author={Hossein Esfandiari and Vahab Mirrokni and Umar Syed and Sergei Vassilvitskii},
      year={2021},
      eprint={2110.02159},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}",arxiv
"Hangyu Zhu, Rui Wang, Yaochu Jin, Kaitai Liang","PIVODL: Privacy-preserving vertical federated learning over
                    distributed labels",,"Federated learning (FL) is an emerging privacy preserving machine learning protocol that allows multiple devices to collaboratively train a shared global model without revealing their private local data. Non-parametric models like gradient boosting decision trees (GBDT) have been commonly used in FL for vertically partitioned data. However, all these studies assume that all the data labels are stored on only one client, which may be unrealistic for real-world applications. Therefore, in this work, we propose a secure vertical FL framework, named PIVODL, to train GBDT with data labels distributed on multiple devices. Both homomorphic encryption and differential privacy are adopted to prevent label information from being leaked through transmitted gradients and leaf values. Our experimental results show that both information leakage and model performance degradation of the proposed PIVODL are negligible.",,,https://arxiv.org/abs/2108.11444,"@misc{zhu2021pivodl,
      title={PIVODL: Privacy-preserving vertical federated learning over distributed labels}, 
      author={Hangyu Zhu and Rui Wang and Yaochu Jin and Kaitai Liang},
      year={2021},
      eprint={2108.11444},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}",arxiv
"Mani Malek, Ilya Mironov, Karthik Prasad, Igor Shilov, Florian Tramèr",Antipodes of Label Differential Privacy: PATE and ALIBI,,"We consider the privacy-preserving machine learning (ML) setting where the trained model must satisfy differential privacy (DP) with respect to the labels of the training examples. We propose two novel approaches based on, respectively, the Laplace mechanism and the PATE framework, and demonstrate their effectiveness on standard benchmarks.
While recent work by Ghazi et al. proposed Label DP schemes based on a randomized response mechanism, we argue that additive Laplace noise coupled with Bayesian inference (ALIBI) is a better fit for typical ML tasks. Moreover, we show how to achieve very strong privacy levels in some regimes, with our adaptation of the PATE framework that builds on recent advances in semi-supervised learning.
We complement theoretical analysis of our algorithms' privacy guarantees with empirical evaluation of their memorization properties. Our evaluation suggests that comparing different algorithms according to their provable DP guarantees can be misleading and favor a less private algorithm with a tighter analysis.
Code for implementation of algorithms and memorization attacks is available from this https URL.",,,https://arxiv.org/abs/2106.03408,"@misc{malek2021antipodes,
      title={Antipodes of Label Differential Privacy: PATE and ALIBI}, 
      author={Mani Malek and Ilya Mironov and Karthik Prasad and Igor Shilov and Florian Tramèr},
      year={2021},
      eprint={2106.03408},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}",arxiv
"Yuexin Xiang, Tiantian Li, Wei Ren, Tianqing Zhu, Kim-Kwang Raymond Choo","A Lightweight Privacy-Preserving Scheme Using Label-based Pixel Block Mixing for Image Classification in
                    Deep Learning",,"To ensure the privacy of sensitive data used in the training of deep learning models, a number of privacy-preserving methods have been designed by the research community. However, existing schemes are generally designed to work with textual data, or are not efficient when a large number of images is used for training. Hence, in this paper we propose a lightweight and efficient approach to preserve image privacy while maintaining the availability of the training set. Specifically, we design the pixel block mixing algorithm for image classification privacy preservation in deep learning. To evaluate its utility, we use the mixed training set to train the ResNet50, VGG16, InceptionV3 and DenseNet121 models on the WIKI dataset and the CNBC face dataset. Experimental findings on the testing set show that our scheme preserves image privacy while maintaining the availability of the training set in the deep learning models. Additionally, the experimental results demonstrate that we achieve good performance for the VGG16 model on the WIKI dataset and both ResNet50 and DenseNet121 on the CNBC dataset. The pixel block algorithm achieves fairly high efficiency in the mixing of the images, and it is computationally challenging for the attackers to restore the mixed training set to the original training set. Moreover, data augmentation can be applied to the mixed training set to improve the training's effectiveness.",,,https://arxiv.org/abs/2105.08876,"@misc{xiang2021lightweight,
      title={A Lightweight Privacy-Preserving Scheme Using Label-based Pixel Block Mixing for Image Classification in Deep Learning}, 
      author={Yuexin Xiang and Tiantian Li and Wei Ren and Tianqing Zhu and Kim-Kwang Raymond Choo},
      year={2021},
      eprint={2105.08876},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}",arxiv
"Badih Ghazi, Noah Golowich, Ravi Kumar, Pasin Manurangsi, Chiyuan Zhang",Deep Learning with Label Differential Privacy,,"The Randomized Response (RR) algorithm is a classical technique to improve robustness in survey aggregation, and has been widely adopted in applications with differential privacy guarantees. We propose a novel algorithm, Randomized Response with Prior (RRWithPrior), which can provide more accurate results while maintaining the same level of privacy guaranteed by RR. We then apply RRWithPrior to learn neural networks with label differential privacy (LabelDP), and show that when only the label needs to be protected, the model performance can be significantly improved over the previous state-of-the-art private baselines. Moreover, we study different ways to obtain priors, which when used with RRWithPrior can additionally improve the model performance, further reducing the accuracy gap between private and non-private models. We complement the empirical results with theoretical analysis showing that LabelDP is provably easier than protecting both the inputs and labels.",,,https://arxiv.org/abs/2102.06062,"@misc{ghazi2021deep,
      title={Deep Learning with Label Differential Privacy}, 
      author={Badih Ghazi and Noah Golowich and Ravi Kumar and Pasin Manurangsi and Chiyuan Zhang},
      year={2021},
      eprint={2102.06062},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}",arxiv
"Johanna Johansen, Tore Pedersen, Simone Fischer-Hübner, Christian Johansen, Gerardo Schneider, Arnold Roosendaal, Harald Zwingelberg, Anders Jakob Sivesind, Josef Noll",A Multidisciplinary Definition of Privacy Labels: The Story of Princess Privacy and the Seven Helpers,,"Privacy is currently in distress and in need of rescue, much like princesses in the all-familiar fairytales. We employ storytelling and metaphors from fairytales to make reader-friendly and streamline our arguments about how a complex concept of Privacy Labeling (the 'knight in shining armor') can be a solution to the current state of Privacy (the 'princess in distress'). We give a precise definition of Privacy Labeling (PL), painting a panoptic portrait from seven different perspectives (the 'seven helpers'): Business, Legal, Regulatory, Usability and Human Factors, Educative, Technological, and Multidisciplinary. We describe a common vision, proposing several important 'traits of character' of PL as well as identifying 'undeveloped potentialities', i.e., open problems on which the community can focus. More specifically, this position paper identifies the stakeholders of the PL and their needs with regard to privacy, describing how PL should be and look like in order to address these needs. Throughout the paper, we highlight goals, characteristics, open problems, and starting points for creating, what we consider to be, the ideal PL. In the end we present three approaches to establish and manage PL, through: self-evaluations, certifications, or community endeavors. Based on these, we sketch a roadmap for future developments.",,,https://arxiv.org/abs/2012.01813,"@misc{johansen2021multidisciplinary,
      title={A Multidisciplinary Definition of Privacy Labels: The Story of Princess Privacy and the Seven Helpers}, 
      author={Johanna Johansen and Tore Pedersen and Simone Fischer-Hübner and Christian Johansen and Gerardo Schneider and Arnold Roosendaal and Harald Zwingelberg and Anders Jakob Sivesind and Josef Noll},
      year={2021},
      eprint={2012.01813},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}",arxiv
"Yan Shvartzshnaider, Ananth Balashankar, Vikas Patidar, Thomas Wies, Lakshminarayanan Subramanian","Beyond The Text: Analysis of Privacy Statements through
                    Syntactic and Semantic Role Labeling",,"This paper formulates a new task of extracting privacy parameters from a privacy policy, through the lens of Contextual Integrity, an established social theory framework for reasoning about privacy norms. Privacy policies, written by lawyers, are lengthy and often comprise incomplete and vague statements. In this paper, we show that traditional NLP tasks, including the recently proposed Question-Answering based solutions, are insufficient to address the privacy parameter extraction problem and provide poor precision and recall. We describe 4 different types of conventional methods that can be partially adapted to address the parameter extraction task with varying degrees of success: Hidden Markov Models, BERT fine-tuned models, Dependency Type Parsing (DP) and Semantic Role Labeling (SRL). Based on a detailed evaluation across 36 real-world privacy policies of major enterprises, we demonstrate that a solution combining syntactic DP coupled with type-specific SRL tasks provides the highest accuracy for retrieving contextual privacy parameters from privacy statements. We also observe that incorporating domain-specific knowledge is critical to achieving high precision and recall, thus inspiring new NLP research to address this important problem in the privacy domain.",,,https://arxiv.org/abs/2010.00678,"@misc{shvartzshnaider2020text,
      title={Beyond The Text: Analysis of Privacy Statements through Syntactic and Semantic Role Labeling}, 
      author={Yan Shvartzshnaider and Ananth Balashankar and Vikas Patidar and Thomas Wies and Lakshminarayanan Subramanian},
      year={2020},
      eprint={2010.00678},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}",arxiv
"Sudhakar Kumawat, Hajime Nagahara",Privacy-Preserving Action Recognition via Motion Difference Quantization,,"The widespread use of smart computer vision systems in our personal spaces has led to an increased consciousness about the privacy and security risks that these systems pose. On the one hand, we want these systems to assist in our daily lives by understanding our surroundings, but on the other hand, we want them to do so without capturing any sensitive information. Towards this direction, this paper proposes a simple, yet robust privacy-preserving encoder called BDQ for the task of privacy-preserving human action recognition that is composed of three modules: 

, 

, and 

. First, the input scene is passed to the Blur module to smoothen the edges. This is followed by the Difference module to apply a pixel-wise intensity subtraction between consecutive frames to highlight motion features and suppress high-level privacy attributes. Finally, the Quantization module is applied to the motion difference frames to remove the low-level privacy attributes. The BDQ parameters are optimized in an end-to-end fashion via adversarial training such that it learns to allow action recognition attributes while inhibiting privacy attributes. Our experiments on three benchmark datasets show that the proposed encoder design can achieve state-of-the-art trade-off when compared with previous works. Furthermore, we show that the trade-off achieved is at par with the DVS sensor-based event cameras. Code available at: https://github.com/suakaw/BDQ_PrivacyAR",2022,Computer Vision – ECCV 2022,,"@InProceedings{10.1007/978-3-031-19778-9_30,
author=""Kumawat, Sudhakar
and Nagahara, Hajime"",
editor=""Avidan, Shai
and Brostow, Gabriel
and Ciss{\'e}, Moustapha
and Farinella, Giovanni Maria
and Hassner, Tal"",
title=""Privacy-Preserving Action Recognition via Motion Difference Quantization"",
booktitle=""Computer Vision -- ECCV 2022"",
year=""2022"",
publisher=""Springer Nature Switzerland"",
address=""Cham"",
pages=""518--534"",
abstract=""The widespread use of smart computer vision systems in our personal spaces has led to an increased consciousness about the privacy and security risks that these systems pose. On the one hand, we want these systems to assist in our daily lives by understanding our surroundings, but on the other hand, we want them to do so without capturing any sensitive information. Towards this direction, this paper proposes a simple, yet robust privacy-preserving encoder called BDQ for the task of privacy-preserving human action recognition that is composed of three modules: , , and . First, the input scene is passed to the Blur module to smoothen the edges. This is followed by the Difference module to apply a pixel-wise intensity subtraction between consecutive frames to highlight motion features and suppress high-level privacy attributes. Finally, the Quantization module is applied to the motion difference frames to remove the low-level privacy attributes. The BDQ parameters are optimized in an end-to-end fashion via adversarial training such that it learns to allow action recognition attributes while inhibiting privacy attributes. Our experiments on three benchmark datasets show that the proposed encoder design can achieve state-of-the-art trade-off when compared with previous works. Furthermore, we show that the trade-off achieved is at par with the DVS sensor-based event cameras. Code available at: https://github.com/suakaw/BDQ{\_}PrivacyAR"",
isbn=""978-3-031-19778-9""
}",Springer
"Chola Chhetri, Vivian Motti",Designing and Evaluating a Prototype for Data-Related Privacy Controls in a Smart Home,,"The privacy concerns of home Internet of Things (IoT) device users and experts have been widely studied, but the designs of privacy controls addressing those concerns are sparse. Literature shows a significant body of research uncovering design factors for privacy controls in smart home devices, but fewer studies have translated those design recommendations into design and evaluated the designs. To fill this gap, we designed a prototype user interface implementing the design recommendations of data-related privacy controls based on prior work and evaluated the prototype for user experience, usability, perceived information control, user satisfaction, and intention to use. The results of interviews (n = 10) critique the proposed design and the survey results (n = 105) show that the prototype design provides positive evaluation for perceived information control, user satisfaction and intention to use. Based on findings, we discuss design recommendations for further improvements. Thus, this paper contributes to the design of data-related privacy controls for user interfaces of home IoT devices and applications.",2022,Human Aspects of Information Security and Assurance,,"@InProceedings{10.1007/978-3-031-12172-2_19,
author=""Chhetri, Chola
and Motti, Vivian"",
editor=""Clarke, Nathan
and Furnell, Steven"",
title=""Designing and Evaluating a Prototype for Data-Related Privacy Controls in a Smart Home"",
booktitle=""Human Aspects of Information Security and Assurance"",
year=""2022"",
publisher=""Springer International Publishing"",
address=""Cham"",
pages=""240--250"",
abstract=""The privacy concerns of home Internet of Things (IoT) device users and experts have been widely studied, but the designs of privacy controls addressing those concerns are sparse. Literature shows a significant body of research uncovering design factors for privacy controls in smart home devices, but fewer studies have translated those design recommendations into design and evaluated the designs. To fill this gap, we designed a prototype user interface implementing the design recommendations of data-related privacy controls based on prior work and evaluated the prototype for user experience, usability, perceived information control, user satisfaction, and intention to use. The results of interviews (n = 10) critique the proposed design and the survey results (n = 105) show that the prototype design provides positive evaluation for perceived information control, user satisfaction and intention to use. Based on findings, we discuss design recommendations for further improvements. Thus, this paper contributes to the design of data-related privacy controls for user interfaces of home IoT devices and applications."",
isbn=""978-3-031-12172-2""
}",Springer
"Fenghua Li, Hui Li, Ben Niu",Privacy Computing Theory,,"Over the past 20 years, privacy preservation has received extensive attention. However, existing research has focused on scattered privacy-preserving methods for specific scenarios, and there is no systematic research on privacy preservation from the perspective of “computing”. To establish a computing framework for the preservation of privacy information throughout its life cycle, the authors of this book are the first to propose the concept and definition of privacy computing in 2015, formally described privacy computing, and analyzed its connotation and research scope. The formal definition has been proposed, the framework of privacy computing has been established, and the implementation details with initial results have been provided.",2024,Privacy Computing,,"@Inbook{Li2024,
author=""Li, Fenghua
and Li, Hui
and Niu, Ben"",
title=""Privacy Computing Theory"",
bookTitle=""Privacy Computing : Theory and Technology "",
year=""2024"",
publisher=""Springer Nature Singapore"",
address=""Singapore"",
pages=""43--88"",
abstract=""Over the past 20 years, privacy preservation has received extensive attention. However, existing research has focused on scattered privacy-preserving methods for specific scenarios, and there is no systematic research on privacy preservation from the perspective of ``computing''. To establish a computing framework for the preservation of privacy information throughout its life cycle, the authors of this book are the first to propose the concept and definition of privacy computing in 2015, formally described privacy computing, and analyzed its connotation and research scope. The formal definition has been proposed, the framework of privacy computing has been established, and the implementation details with initial results have been provided."",
isbn=""978-981-99-4943-4"",
doi=""10.1007/978-981-99-4943-4_3"",
url=""https://doi.org/10.1007/978-981-99-4943-4_3""
}",Springer
"Simone Fischer-Hübner, Farzaneh Karegar",Addressing Challenges: A Way Forward,,"This chapter provides an overview of solutions for achieving usable privacy. First, the need for combining human-centred and privacy by design approaches is highlighted. Moreover, it is discussed how important challenges for usable privacy can be approached by available solutions. These include example approaches for considering culturally dependent privacy personas, developing usable Privacy-Enhancing Technology (PET) configuration tools through interdisciplinary efforts, raising users’ attention to privacy as a secondary goal via engaging them with the policy content, designing usable multi-layered privacy notices and usable privacy management via semi-automation, and achieving usable transparency through usable explanations of PETs and different forms of visualisation of data disclosures. Finally, we discuss how fundamental legal privacy requirements map to Human-Computer Interaction (HCI) requirements and HCI solutions, focusing on the solutions discussed in this chapter.",2024,The Curious Case of Usable Privacy,,"@Inbook{Fischer-Hübner2024,
author=""Fischer-H{\""u}bner, Simone
and Karegar, Farzaneh"",
title=""Addressing Challenges: A Way Forward"",
bookTitle=""The Curious Case of Usable Privacy: Challenges, Solutions, and Prospects"",
year=""2024"",
publisher=""Springer International Publishing"",
address=""Cham"",
pages=""133--160"",
abstract=""This chapter provides an overview of solutions for achieving usable privacy. First, the need for combining human-centred and privacy by design approaches is highlighted. Moreover, it is discussed how important challenges for usable privacy can be approached by available solutions. These include example approaches for considering culturally dependent privacy personas, developing usable Privacy-Enhancing Technology (PET) configuration tools through interdisciplinary efforts, raising users' attention to privacy as a secondary goal via engaging them with the policy content, designing usable multi-layered privacy notices and usable privacy management via semi-automation, and achieving usable transparency through usable explanations of PETs and different forms of visualisation of data disclosures. Finally, we discuss how fundamental legal privacy requirements map to Human-Computer Interaction (HCI) requirements and HCI solutions, focusing on the solutions discussed in this chapter."",
isbn=""978-3-031-54158-2"",
doi=""10.1007/978-3-031-54158-2_5"",
url=""https://doi.org/10.1007/978-3-031-54158-2_5""
}",Springer
"Yangyou Ning, Jinyan Wang, ... Xianxian Li",GFedKRL: Graph Federated Knowledge Re-Learning for Effective Molecular Property Prediction via Privacy Protection,,"Graph Neural Networks (GNNs) are one of the primary methods for molecular property prediction due to their ability to learn state-of-the-art level representations from graph-structured molecular data. In addition, the Federated Learning (FL) paradigm, which allows multiple ends to collaborate on machine learning training without sharing local data, is being considered for introduction to improve the performance of multiple ends. However, in FL, the molecular graph data among clients are not only Non-Independent Identically Distribution (Non-IID) but also skewed in quantity distribution. In this paper, we propose the GFedKRL framework to perform knowledge distillation and re-learning during the interaction between clients and servers in each cluster after clustering the graph embeddings uploaded. We also analyze the risk of privacy leakage in the GFedKRL and propose personalized local differential privacy to protect privacy while better controlling the amount of noise input and improving model performance. In addition, to resist the impact of noise data on the clients’ model, graph representation learning is enhanced by knowledge contrast learning at the local clients. Finally, our approach achieves better results in three experimental datasets compared with four public benchmark methods.",2023,Artificial Neural Networks and Machine Learning – ICANN 2023,,"@InProceedings{10.1007/978-3-031-44213-1_36,
author=""Ning, Yangyou
and Wang, Jinyan
and Li, De
and Yan, Dongqi
and Li, Xianxian"",
editor=""Iliadis, Lazaros
and Papaleonidas, Antonios
and Angelov, Plamen
and Jayne, Chrisina"",
title=""GFedKRL: Graph Federated Knowledge Re-Learning for Effective Molecular Property Prediction via Privacy Protection"",
booktitle=""Artificial Neural Networks and Machine Learning -- ICANN 2023"",
year=""2023"",
publisher=""Springer Nature Switzerland"",
address=""Cham"",
pages=""426--438"",
abstract=""Graph Neural Networks (GNNs) are one of the primary methods for molecular property prediction due to their ability to learn state-of-the-art level representations from graph-structured molecular data. In addition, the Federated Learning (FL) paradigm, which allows multiple ends to collaborate on machine learning training without sharing local data, is being considered for introduction to improve the performance of multiple ends. However, in FL, the molecular graph data among clients are not only Non-Independent Identically Distribution (Non-IID) but also skewed in quantity distribution. In this paper, we propose the GFedKRL framework to perform knowledge distillation and re-learning during the interaction between clients and servers in each cluster after clustering the graph embeddings uploaded. We also analyze the risk of privacy leakage in the GFedKRL and propose personalized local differential privacy to protect privacy while better controlling the amount of noise input and improving model performance. In addition, to resist the impact of noise data on the clients' model, graph representation learning is enhanced by knowledge contrast learning at the local clients. Finally, our approach achieves better results in three experimental datasets compared with four public benchmark methods."",
isbn=""978-3-031-44213-1""
}",Springer
"Sarah Prange, Florian Alt",Increasing Users’ Privacy Awareness in the Internet of Things: Design Space and Sample Scenarios,,"An increasing number of devices and sensors in the environments we access daily are capable of collecting personal data about us. Surveillance cameras in public spaces, smart speakers in friends’ living rooms, or smartphones carried by individuals are just a few examples. At the same time, many users are unaware of sensors being in place, in particular, those deployed in unfamiliar environments. Hence, it becomes increasingly challenging for users to keep control over their personal data being tracked and/or processed. Crucially, for users to be able to make informed decisions and privacy choices, they first of all need to be aware of potential privacy intrusions in their surroundings. In this chapter, we address this by exploring means to increase users’ privacy awareness in the Internet of Things. In particular, we illustrate the design space for such privacy awareness mechanisms, including what information should be displayed, and how this information can be made accessible for various target groups such as (to-be) device owners or passers-by. We also introduce and compare three sample scenarios in which privacy awareness mechanisms can support users: (1) privacy-relevant information for purchase decisions, (2) on-demand privacy-relevant information for active device search, and (3) in situ privacy-relevant information and guidance. The chapter is complemented by a discussion on future approaches to raising privacy awareness.",2023,Human Factors in Privacy Research,,"@Inbook{Prange2023,
author=""Prange, Sarah
and Alt, Florian"",
editor=""Gerber, Nina
and St{\""o}ver, Alina
and Marky, Karola"",
title=""Increasing Users' Privacy Awareness in the Internet of Things: Design Space and Sample Scenarios"",
bookTitle=""Human Factors in Privacy Research"",
year=""2023"",
publisher=""Springer International Publishing"",
address=""Cham"",
pages=""321--336"",
abstract=""An increasing number of devices and sensors in the environments we access daily are capable of collecting personal data about us. Surveillance cameras in public spaces, smart speakers in friends' living rooms, or smartphones carried by individuals are just a few examples. At the same time, many users are unaware of sensors being in place, in particular, those deployed in unfamiliar environments. Hence, it becomes increasingly challenging for users to keep control over their personal data being tracked and/or processed. Crucially, for users to be able to make informed decisions and privacy choices, they first of all need to be aware of potential privacy intrusions in their surroundings. In this chapter, we address this by exploring means to increase users' privacy awareness in the Internet of Things. In particular, we illustrate the design space for such privacy awareness mechanisms, including what information should be displayed, and how this information can be made accessible for various target groups such as (to-be) device owners or passers-by. We also introduce and compare three sample scenarios in which privacy awareness mechanisms can support users: (1) privacy-relevant information for purchase decisions, (2) on-demand privacy-relevant information for active device search, and (3) in situ privacy-relevant information and guidance. The chapter is complemented by a discussion on future approaches to raising privacy awareness."",
isbn=""978-3-031-28643-8"",
doi=""10.1007/978-3-031-28643-8_16"",
url=""https://doi.org/10.1007/978-3-031-28643-8_16""
}",Springer
Grace Fox,Understanding and Enhancing Consumer Privacy Perceptions in the Cloud,,"The recent increase in highly publicised cloud breaches, coupled with issues surrounding transparency and control in the cloud, highlights the importance of understanding and addressing privacy in this context. The extant cloud privacy literature has a tendency to focus on technical solutions to address security and privacy together, but a small emerging body of literature acknowledges the importance of consumers’ privacy perceptions in the context of cloud computing. Given the breadth of cloud applications and the situational nature of privacy, it is imperative to unpack the role of privacy in this complex domain. This chapter leverages the broader privacy literature in the Information Systems field to identify potential measures to enhance consumer privacy in the cloud context and highlights a number of paths for research to further our knowledge of consumer privacy perceptions in the various cloud contexts.",2021,Data Privacy and Trust in Cloud Computing,,"@Inbook{Fox2021,
author=""Fox, Grace"",
editor=""Lynn, Theo
and Mooney, John G.
and van der Werff, Lisa
and Fox, Grace"",
title=""Understanding and Enhancing Consumer Privacy Perceptions in the Cloud"",
bookTitle=""Data Privacy and Trust in Cloud Computing: Building trust in the cloud through assurance and accountability"",
year=""2021"",
publisher=""Springer International Publishing"",
address=""Cham"",
pages=""59--78"",
abstract=""The recent increase in highly publicised cloud breaches, coupled with issues surrounding transparency and control in the cloud, highlights the importance of understanding and addressing privacy in this context. The extant cloud privacy literature has a tendency to focus on technical solutions to address security and privacy together, but a small emerging body of literature acknowledges the importance of consumers' privacy perceptions in the context of cloud computing. Given the breadth of cloud applications and the situational nature of privacy, it is imperative to unpack the role of privacy in this complex domain. This chapter leverages the broader privacy literature in the Information Systems field to identify potential measures to enhance consumer privacy in the cloud context and highlights a number of paths for research to further our knowledge of consumer privacy perceptions in the various cloud contexts."",
isbn=""978-3-030-54660-1"",
doi=""10.1007/978-3-030-54660-1_4"",
url=""https://doi.org/10.1007/978-3-030-54660-1_4""
}",Springer
Jessica Monteith,Who Is Benefiting from Your Fitness Data? A Privacy Analysis of Smartwatches (Transcript of Discussion),,"We’ve seen in the previous presentations that have touched on privacy data, a lot of them mentioned privacy data protection in flight from a technical point of view.",2023,Security Protocols XXVIII,,"@InProceedings{10.1007/978-3-031-43033-6_12,
author=""Monteith, Jessica"",
editor=""Stajano, Frank
and Maty{\'a}{\v{s}}, Vashek
and Christianson, Bruce
and Anderson, Jonathan"",
title=""Who Is Benefiting from Your Fitness Data? A Privacy Analysis of Smartwatches (Transcript of Discussion)"",
booktitle=""Security Protocols XXVIII"",
year=""2023"",
publisher=""Springer Nature Switzerland"",
address=""Cham"",
pages=""113--122"",
abstract=""We've seen in the previous presentations that have touched on privacy data, a lot of them mentioned privacy data protection in flight from a technical point of view."",
isbn=""978-3-031-43033-6""
}",Springer
"Arvid Butting, Niel Conradie, ... Sabine Theis",Souveräne digitalrechtliche Entscheidungsfindung hinsichtlich der Datenpreisgabe bei der Nutzung von Wearables,,"Wearables unterstützen ihre Nutzer:innen in unterschiedlichen Kontexten. Dabei erzeugen und nutzen sie eine Vielzahl von oft sehr persönlichen (Gesundheits-)Daten, ohne dass Nutzer:innen über die notwendigen Kenntnisse und Erfahrungen verfügen, um reflektierte Entscheidungen über die Nutzung dieser Daten treffen zu können. In der aktuellen Forschung fehlen Konzepte, die einen unreflektierten Datenaustausch vermeiden und reflektierte Entscheidungen unterstützen. In diesem Beitrag diskutieren wir gesellschaftliche Herausforderungen der digitalen Souveränität und zeigen mögliche Wege der Visualisierung persönlicher (Gesundheits-)Daten und der Interaktion mit einem System, das transparente Informationen über die Nutzung von Wearable-Daten liefert. Wir zeigen Möglichkeiten zur Visualisierung rechtlicher und datenschutzrechtlicher Informationen auf und diskutieren unsere Ideen für einen erlebbaren Datenschutz mit Gamifizierungskonzepten. Die Bereitstellung interaktiver und visueller Datenräume kann die Fähigkeit zur eigenständigen Selbstbestimmung für Datenpreisgaben stärken.",2022,"Selbstbestimmung, Privatheit und Datenschutz",,"@Inbook{Butting2022,
author=""Butting, Arvid
and Conradie, Niel
and Croll, Jutta
and Fehler, Manuel
and Gruber, Clemens
and Herrmann, Dominik
and Mertens, Alexander
and Michael, Judith
and Nitsch, Verena
and Nagel, Saskia
and P{\""u}tz, Sebastian
and Rumpe, Bernhard
and Schauermann, Elisabeth
and Sch{\""o}ning, Johannes
and Stellmacher, Carolin
and Theis, Sabine"",
editor=""Friedewald, Michael
and Kreutzer, Michael
and Hansen, Marit"",
title=""Souver{\""a}ne digitalrechtliche Entscheidungsfindung hinsichtlich der Datenpreisgabe bei der Nutzung von Wearables"",
bookTitle=""Selbstbestimmung, Privatheit und Datenschutz : Gestaltungsoptionen f{\""u}r einen europ{\""a}ischen Weg"",
year=""2022"",
publisher=""Springer Fachmedien Wiesbaden"",
address=""Wiesbaden"",
pages=""489--508"",
abstract=""Wearables unterst{\""u}tzen ihre Nutzer:innen in unterschiedlichen Kontexten. Dabei erzeugen und nutzen sie eine Vielzahl von oft sehr pers{\""o}nlichen (Gesundheits-)Daten, ohne dass Nutzer:innen {\""u}ber die notwendigen Kenntnisse und Erfahrungen verf{\""u}gen, um reflektierte Entscheidungen {\""u}ber die Nutzung dieser Daten treffen zu k{\""o}nnen. In der aktuellen Forschung fehlen Konzepte, die einen unreflektierten Datenaustausch vermeiden und reflektierte Entscheidungen unterst{\""u}tzen. In diesem Beitrag diskutieren wir gesellschaftliche Herausforderungen der digitalen Souver{\""a}nit{\""a}t und zeigen m{\""o}gliche Wege der Visualisierung pers{\""o}nlicher (Gesundheits-)Daten und der Interaktion mit einem System, das transparente Informationen {\""u}ber die Nutzung von Wearable-Daten liefert. Wir zeigen M{\""o}glichkeiten zur Visualisierung rechtlicher und datenschutzrechtlicher Informationen auf und diskutieren unsere Ideen f{\""u}r einen erlebbaren Datenschutz mit Gamifizierungskonzepten. Die Bereitstellung interaktiver und visueller Datenr{\""a}ume kann die F{\""a}higkeit zur eigenst{\""a}ndigen Selbstbestimmung f{\""u}r Datenpreisgaben st{\""a}rken."",
isbn=""978-3-658-33306-5"",
doi=""10.1007/978-3-658-33306-5_24"",
url=""https://doi.org/10.1007/978-3-658-33306-5_24""
}",Springer
Newton Lee,Consumer Privacy in the Age of Big Data,,"Privacy advocates scored a triumph in April 2021 with anti-tracking features in Apple’s privacy nutrition labels and, to a lesser extent, Google’s Federated Learning of Cohorts replacement for third-party cookies. However, data security remains elusive as cybercriminals posted online the stolen personal information of 533 million Facebook users from 106 countries.",2021,Facebook Nation,,"@Inbook{Lee2021,
author=""Lee, Newton"",
title=""Consumer Privacy in the Age of Big Data"",
bookTitle=""Facebook Nation: Total Information Awareness"",
year=""2021"",
publisher=""Springer New York"",
address=""New York, NY"",
pages=""157--171"",
abstract=""Privacy advocates scored a triumph in April 2021 with anti-tracking features in Apple's privacy nutrition labels and, to a lesser extent, Google's Federated Learning of Cohorts replacement for third-party cookies. However, data security remains elusive as cybercriminals posted online the stolen personal information of 533 million Facebook users from 106 countries."",
isbn=""978-1-0716-1867-7"",
doi=""10.1007/978-1-0716-1867-7_8"",
url=""https://doi.org/10.1007/978-1-0716-1867-7_8""
}",Springer
"Fuman Xie, Yanjun Zhang, ... Guangdong Bai",UQ-AAS21: A Comprehensive Dataset of Amazon Alexa Skills,,"Various virtual personal assistant (VPA) services have become popular, due to the convenient interaction manner of voice user interface (VUI) they offer. Centered around them, an ecosystem involving service providers, third-party developers and end users, has started being formulated. The developers are enabled to create applications and release them through application stores, from which the users can obtain them and then run them on smart devices. This emerging ecosystem is still in its early stage, and a great deal of research effort is desired to make it on the healthy track to facilitate its development. Nonetheless, there is still a lack of comprehensive datasets for our research community to conduct research on relevant issues, e.g., the bug-freeness and quality of the applications, and users’ security and privacy concerns on them. In this work, we aim to build such a dataset for research use. We target the Amazon VPA service, i.e., the Alexa, which is the most popular VPA service. We collect 65,195 Alexa applications (or skills), and extract comprehensive information about them, including invocation names, user reviews, among overall 16 attributes. We show the demographic details of the skills and their developers, and also conduct preliminary statistical analyses on the quality and privacy issues, to demonstrate the potential usage of our dataset. The dataset and analysis results are released online to facilitate future research: https://github.com/xie00059/Amazon-Alexa-UQ-AAS21-datasets.",2022,Advanced Data Mining and Applications,,"@InProceedings{10.1007/978-3-030-95405-5_12,
author=""Xie, Fuman
and Zhang, Yanjun
and Wei, Hanlin
and Bai, Guangdong"",
editor=""Li, Bohan
and Yue, Lin
and Jiang, Jing
and Chen, Weitong
and Li, Xue
and Long, Guodong
and Fang, Fei
and Yu, Han"",
title=""UQ-AAS21: A Comprehensive Dataset of Amazon Alexa Skills"",
booktitle=""Advanced Data Mining and Applications"",
year=""2022"",
publisher=""Springer International Publishing"",
address=""Cham"",
pages=""159--173"",
abstract=""Various virtual personal assistant (VPA) services have become popular, due to the convenient interaction manner of voice user interface (VUI) they offer. Centered around them, an ecosystem involving service providers, third-party developers and end users, has started being formulated. The developers are enabled to create applications and release them through application stores, from which the users can obtain them and then run them on smart devices. This emerging ecosystem is still in its early stage, and a great deal of research effort is desired to make it on the healthy track to facilitate its development. Nonetheless, there is still a lack of comprehensive datasets for our research community to conduct research on relevant issues, e.g., the bug-freeness and quality of the applications, and users' security and privacy concerns on them. In this work, we aim to build such a dataset for research use. We target the Amazon VPA service, i.e., the Alexa, which is the most popular VPA service. We collect 65,195 Alexa applications (or skills), and extract comprehensive information about them, including invocation names, user reviews, among overall 16 attributes. We show the demographic details of the skills and their developers, and also conduct preliminary statistical analyses on the quality and privacy issues, to demonstrate the potential usage of our dataset. The dataset and analysis results are released online to facilitate future research: https://github.com/xie00059/Amazon-Alexa-UQ-AAS21-datasets."",
isbn=""978-3-030-95405-5""
}",Springer
"Benjamin Ewerz, Peter Moertl","Evaluating Multiple Approaches to Impact Trust Formation: Labeling, Design, and Support Features",,"Creating trust in wireless solutions and increasing their social acceptance are major challenges to achieve the full potential of the Internet of Things (IoT).In the current study we investigate various methods to increase trust in wireless systems like user feedback, usability, and product labeling. This work is part of the European project SCOTT (Secure COnnected Trustable Things; https://scottproject.eu) with the goal to develop wireless solutions that are safe, trusted, and acceptable.Participants watched three videos of three use cases and then rated the expected impact of controllability, accountability, user feedback, usability, and product labeling on their trust in the technologies. Also, two labels were evaluated: a uni-dimensional label that reflected the privacy of user data as well as a multi-dimensional label that combined the dimensions privacy, product quality, manufacturing, usability, and cost.The results indicate that trustworthiness aspects of the system like controllability, accountability and usability have the strongest impact on positive trust formation among all the investigated methods. Furthermore, the results indicate that both the uni-dimensional and the multi-dimensional labeling conditions seemed to increase user trust at the maximum trust level and increased the participants indicated willingness to use the product. However, only the uni-dimensional label showed a positive influence on trust formation at the medium quality level.Results of this study highlight that service and product providers have various methods at hand to help increase trust among their customers. Consumers want control over their technologies, as well as accountability of technology vendors. Furthermore, in the long term, the results suggest that customers could benefit from digital competence education that may allow them to learn to use and rely on otherwise relatively complex multi-dimensional labeling systems. Next steps for this research are suggested.",2020,HCI International 2020 - Posters,,"@InProceedings{10.1007/978-3-030-50732-9_68,
author=""Ewerz, Benjamin
and Moertl, Peter"",
editor=""Stephanidis, Constantine
and Antona, Margherita"",
title=""Evaluating Multiple Approaches to Impact Trust Formation: Labeling, Design, and Support Features"",
booktitle=""HCI International 2020 - Posters"",
year=""2020"",
publisher=""Springer International Publishing"",
address=""Cham"",
pages=""526--533"",
abstract=""Creating trust in wireless solutions and increasing their social acceptance are major challenges to achieve the full potential of the Internet of Things (IoT)."",
isbn=""978-3-030-50732-9""
}",Springer
"Weijia Zhang, Tej Anand",Blockchain Components and Architecture,,"The four components of blockchain that working together create its enormous potential to alleviate economic inefficiencies in our current system are distributed ledgers, privacy preservation, algorithms for distributed systems consensus, and smart contracts.",2022,Blockchain and Ethereum Smart Contract Solution Development,,"@Inbook{Zhang2022,
author=""Zhang, Weijia
and Anand, Tej"",
title=""Blockchain Components and Architecture"",
bookTitle=""Blockchain and Ethereum Smart Contract Solution Development: Dapp Programming with Solidity"",
year=""2022"",
publisher=""Apress"",
address=""Berkeley, CA"",
pages=""81--111"",
abstract=""The four components of blockchain that working together create its enormous potential to alleviate economic inefficiencies in our current system are distributed ledgers, privacy preservation, algorithms for distributed systems consensus, and smart contracts."",
isbn=""978-1-4842-8164-2"",
doi=""10.1007/978-1-4842-8164-2_3"",
url=""https://doi.org/10.1007/978-1-4842-8164-2_3""
}",Springer
"Taewoo Roh, Young Soo Yang, ... Byung Il Park",What makes consumers trust and adopt fintech? An empirical investigation in China,,"Building upon the information systems success model (ISSM) and the theory of reasoned action (TRA), we suggest a set of hypotheses related to fintech services consumer adoption, and we use survey data from a sample of consumers in China’s fintech industries to test this framework. We demonstrate three main dimensions of quality in the context of fintech services—i.e., system, information, and service quality—and we find that both consumers’ perceived security and privacy are positively related to consumers’ trust in such services, which in turn encourages the formation of both positive attitudes toward those fintech services and intentions to use. This study sheds new light into fintech services by indicating that, to fully understand the relationships between improving the quality of fintech service, user security and privacy protection, and consumers’ behavioral attitudes and intentions, managers in fintech firms must actively assess the extent to which consumers trust their fintech services, and they must also be able to deal with the challenges posed by consumers’ behavioral uncertainty by implementing an effective trust-enhanced strategy. Through the integration of ISSM and TRA, our findings contribute to an emerging stream of fintech research and extend the literature on trust by providing novel evidence that building strong trust-based relationships with consumers can be particularly beneficial to fintech firms when they want to create positive attitudes in the minds of consumers and thus motivate them to adopt the services.",26 January 2022,Electronic Commerce Research,,,Springer
"Simone Fischer-Hübner, Farzaneh Karegar",Overview of Usable Privacy Research: Major Themes and Research Directions,,"A wide variety of literature exists on privacy across different communities and disciplines, including Human-Computer Interaction (HCI). Privacy literature is also scattered within HCI, considering that HCI has evolved from its origins to include a variety of disciplines. Therefore, this section is not intended to provide an exhaustive list of HCI privacy literature references. We explored the literature on usable privacy with a focus on the interaction and usability pillars of HCI, using the definition of usable privacy. Our search was narrowed to publications in reputed and high-quality journals and venues within and related to the privacy and security research field to categorise major themes and trends. Various themes are discussed in this section, including usable privacy research in the Internet of Things (IoT), inclusive privacy, usable privacy for developers, usable privacy for Privacy-Enhancing Technologies (PETs), visual privacy, and efforts to help people make better privacy decisions with usable privacy notices and choices. For each theme, we discuss pertinent literature and complete our discussion with existing problems, gaps, and future directions.",2024,The Curious Case of Usable Privacy,,"@Inbook{Fischer-Hübner2024,
author=""Fischer-H{\""u}bner, Simone
and Karegar, Farzaneh"",
title=""Overview of Usable Privacy Research: Major Themes and Research Directions"",
bookTitle=""The Curious Case of Usable Privacy: Challenges, Solutions, and Prospects"",
year=""2024"",
publisher=""Springer International Publishing"",
address=""Cham"",
pages=""43--102"",
abstract=""A wide variety of literature exists on privacy across different communities and disciplines, including Human-Computer Interaction (HCI). Privacy literature is also scattered within HCI, considering that HCI has evolved from its origins to include a variety of disciplines. Therefore, this section is not intended to provide an exhaustive list of HCI privacy literature references. We explored the literature on usable privacy with a focus on the interaction and usability pillars of HCI, using the definition of usable privacy. Our search was narrowed to publications in reputed and high-quality journals and venues within and related to the privacy and security research field to categorise major themes and trends. Various themes are discussed in this section, including usable privacy research in the Internet of Things (IoT), inclusive privacy, usable privacy for developers, usable privacy for Privacy-Enhancing Technologies (PETs), visual privacy, and efforts to help people make better privacy decisions with usable privacy notices and choices. For each theme, we discuss pertinent literature and complete our discussion with existing problems, gaps, and future directions."",
isbn=""978-3-031-54158-2"",
doi=""10.1007/978-3-031-54158-2_3"",
url=""https://doi.org/10.1007/978-3-031-54158-2_3""
}",Springer
"Johanna Johansen, Simone Fischer-Hübner",Making GDPR Usable: A Model to Support Usability Evaluations of Privacy,,"We introduce a new model for evaluating privacy that builds on the criteria proposed by the EuroPriSe certification scheme by adding usability criteria. Our model is visually represented through a cube, called Usable Privacy Cube (or UP Cube), where each of its three axes of variability captures, respectively: rights of the data subjects, privacy principles, and usable privacy criteria. We slightly reorganize the criteria of EuroPriSe to fit with the UP Cube model, i.e., we show how EuroPriSe can be viewed as a combination of only rights and principles, forming the two axes at the basis of our UP Cube. In this way we also want to bring out two perspectives on privacy: that of the data subjects and, respectively, that of the controllers/processors. We define usable privacy criteria based on usability goals that we have extracted from the whole text of the General Data Protection Regulation. The criteria are designed to produce measurements of the level of usability with which the goals are reached. Precisely, we measure effectiveness, efficiency, and satisfaction, considering both the objective and the perceived usability outcomes, producing measures of accuracy and completeness, of resource utilization (e.g., time, effort, financial), and measures resulting from satisfaction scales. In the long run, the UP Cube is meant to be the model behind a new certification methodology capable of evaluating the usability of privacy, to the benefit of common users. For industries, considering also the usability of privacy would allow for greater business differentiation, beyond GDPR compliance.",2020,Privacy and Identity Management. Data for Better Living: AI and Privacy,,"@Inbook{Johansen2020,
author=""Johansen, Johanna
and Fischer-H{\""u}bner, Simone"",
editor=""Friedewald, Michael
and {\""O}nen, Melek
and Lievens, Eva
and Krenn, Stephan
and Fricker, Samuel"",
title=""Making GDPR Usable: A Model to Support Usability Evaluations of Privacy"",
bookTitle=""Privacy and Identity Management. Data for Better Living: AI and Privacy: 14th IFIP WG 9.2, 9.6/11.7, 11.6/SIG 9.2.2 International Summer School, Windisch, Switzerland, August 19--23, 2019, Revised Selected Papers"",
year=""2020"",
publisher=""Springer International Publishing"",
address=""Cham"",
pages=""275--291"",
abstract=""We introduce a new model for evaluating privacy that builds on the criteria proposed by the EuroPriSe certification scheme by adding usability criteria. Our model is visually represented through a cube, called Usable Privacy Cube (or UP Cube), where each of its three axes of variability captures, respectively: rights of the data subjects, privacy principles, and usable privacy criteria. We slightly reorganize the criteria of EuroPriSe to fit with the UP Cube model, i.e., we show how EuroPriSe can be viewed as a combination of only rights and principles, forming the two axes at the basis of our UP Cube. In this way we also want to bring out two perspectives on privacy: that of the data subjects and, respectively, that of the controllers/processors. We define usable privacy criteria based on usability goals that we have extracted from the whole text of the General Data Protection Regulation. The criteria are designed to produce measurements of the level of usability with which the goals are reached. Precisely, we measure effectiveness, efficiency, and satisfaction, considering both the objective and the perceived usability outcomes, producing measures of accuracy and completeness, of resource utilization (e.g., time, effort, financial), and measures resulting from satisfaction scales. In the long run, the UP Cube is meant to be the model behind a new certification methodology capable of evaluating the usability of privacy, to the benefit of common users. For industries, considering also the usability of privacy would allow for greater business differentiation, beyond GDPR compliance."",
isbn=""978-3-030-42504-3"",
doi=""10.1007/978-3-030-42504-3_18"",
url=""https://doi.org/10.1007/978-3-030-42504-3_18""
}",Springer
"Anja Bechmann, Jiyoung Ydun Kim",Big Data,,"Big data research is an umbrella term that characterizes research in many fields. This chapter will focus specifically on big data research tied to the use of social media primarily with a focus on humanities and social science research. Social media as a data source provides opportunities to understand how people individually and collectively communicate, socialize, and critically scrutinize platform infrastructures, exposure, and interaction logic. However, the data and the subsequent processing are closely tied to important ethical issues especially concerning tensions between privacy on the one side and accountability/transparency on the other side. Through an illustrative big data case study of Facebook groups supplemented with existing literature, the chapter will explore ethical dilemmas that occur in connection with social media big data research. The chapter argues that we need to justify our research design balancing protection of the individuals and the aim of creating knowledge for the good of society.",2020,Handbook of Research Ethics and Scientific Integrity,,"@Inbook{Bechmann2020,
author=""Bechmann, Anja
and Kim, Jiyoung Ydun"",
editor=""Iphofen, Ron"",
title=""Big Data"",
bookTitle=""Handbook of Research Ethics and Scientific Integrity"",
year=""2020"",
publisher=""Springer International Publishing"",
address=""Cham"",
pages=""427--444"",
abstract=""Big data research is an umbrella term that characterizes research in many fields. This chapter will focus specifically on big data research tied to the use of social media primarily with a focus on humanities and social science research. Social media as a data source provides opportunities to understand how people individually and collectively communicate, socialize, and critically scrutinize platform infrastructures, exposure, and interaction logic. However, the data and the subsequent processing are closely tied to important ethical issues especially concerning tensions between privacy on the one side and accountability/transparency on the other side. Through an illustrative big data case study of Facebook groups supplemented with existing literature, the chapter will explore ethical dilemmas that occur in connection with social media big data research. The chapter argues that we need to justify our research design balancing protection of the individuals and the aim of creating knowledge for the good of society."",
isbn=""978-3-030-16759-2"",
doi=""10.1007/978-3-030-16759-2_18"",
url=""https://doi.org/10.1007/978-3-030-16759-2_18""
}",Springer
"Lisa van der Werff, Grace Fox, ... Theo Lynn",Building consumer trust in the cloud: an experimental analysis of the cloud trust label approach,,"The lack of transparency surrounding cloud service provision makes it difficult for consumers to make knowledge based purchasing decisions. As a result, consumer trust has become a major impediment to cloud computing adoption. Cloud Trust Labels represent a means of communicating relevant service and security information to potential customers on the cloud service provided, thereby facilitating informed decision making. This research investigates the potential of a Cloud Trust Label system to overcome the trust barrier. Specifically, it examines the impact of a Cloud Trust Label on consumer perceptions of a service and cloud service provider trustworthiness and trust in the cloud service and cloud service provider. An experimental study was carried out with a sample of 227 business decision makers with data collected before exposure to the label to examine initial perceptions and after exposure to the label to examine any change in perceptions and attitudes. As hypothesised, the results suggest that Cloud Trust Labels that contain positive information can have a positive impact on trust and trustworthiness while Cloud Trust Labels that contain negative information have a negative impact. The practical implications of this new method of communicating trustworthiness online are discussed and recommendations are made for future research.",24 April 2019,Journal of Cloud Computing,,,Springer
"Simson Garfinkel, Heather Richter Lipford",Major Themes in UPS Academic Research,,"Much of the UPS research of the past decade mirrors that of applied security work in general—tactical responses to specific problems of the day, rather than long-range strategic research. Tactical research is clearly important, as it addresses current needs and often results in immediate gains. However, literature reviews such as this are better suited to focusing on the longer-term strategic trends, as they represent the greatest opportunity for long-term payoff. Therefore we structure this section thematically, rather than chronologically, and some work that was only of tactical importance is left out. For the remainder we attempted to explain:


What was the UPS problem, and how did it arise?


Who was doing the research? In some cases themes were the result of intensive work by a single group that specialized in that area. In other cases, the theme was the result of a broad community effort. We believe that, in general, the most useful work has resulted from research performed at multiple institutions, although it is not clear whether multiple institutions attacked a problem because of its ripeness, or if a problem ripened as a result of multiple research efforts.


Was the problem resolved? If not, why not?",2014,Usable Security,,"@Inbook{Garfinkel2014,
author=""Garfinkel, Simson
and Lipford, Heather Richter"",
title=""Major Themes in UPS Academic Research"",
bookTitle=""Usable Security: History, Themes, and Challenges"",
year=""2014"",
publisher=""Springer International Publishing"",
address=""Cham"",
pages=""23--86"",
abstract=""Much of the UPS research of the past decade mirrors that of applied security work in general---tactical responses to specific problems of the day, rather than long-range strategic research. Tactical research is clearly important, as it addresses current needs and often results in immediate gains. However, literature reviews such as this are better suited to focusing on the longer-term strategic trends, as they represent the greatest opportunity for long-term payoff. Therefore we structure this section thematically, rather than chronologically, and some work that was only of tactical importance is left out. For the remainder we attempted to explain:What was the UPS problem, and how did it arise?Who was doing the research? In some cases themes were the result of intensive work by a single group that specialized in that area. In other cases, the theme was the result of a broad community effort. We believe that, in general, the most useful work has resulted from research performed at multiple institutions, although it is not clear whether multiple institutions attacked a problem because of its ripeness, or if a problem ripened as a result of multiple research efforts.Was the problem resolved? If not, why not?"",
isbn=""978-3-031-02343-9"",
doi=""10.1007/978-3-031-02343-9_3"",
url=""https://doi.org/10.1007/978-3-031-02343-9_3""
}",Springer
"Md. Sadim Mahmud, Sylvia L. Osborn",Tradeoff Analysis of Relational Database Storage of Privacy Preferences,,"When data providers are allowed to specify the privacy purposes for the data they enter into a database, this information must be stored in the database and dealt with by database operators. We introduce four storage designs incorporating sets of intended privacy purposes in a table in a relational database, and perform experiments to study their performance when executing select, insert, update and delete using the storage designs. A thorough discussion of the tradeoffs exposed is given.",2012,Secure Data Management,,"@InProceedings{10.1007/978-3-642-32873-2_1,
author=""Mahmud, Md. Sadim
and Osborn, Sylvia L."",
editor=""Jonker, Willem
and Petkovi{\'{c}}, Milan"",
title=""Tradeoff Analysis of Relational Database Storage of Privacy Preferences"",
booktitle=""Secure Data Management"",
year=""2012"",
publisher=""Springer Berlin Heidelberg"",
address=""Berlin, Heidelberg"",
pages=""1--13"",
abstract=""When data providers are allowed to specify the privacy purposes for the data they enter into a database, this information must be stored in the database and dealt with by database operators. We introduce four storage designs incorporating sets of intended privacy purposes in a table in a relational database, and perform experiments to study their performance when executing select, insert, update and delete using the storage designs. A thorough discussion of the tradeoffs exposed is given."",
isbn=""978-3-642-32873-2""
}",Springer
Els J. Kindt,A Legal Model for the Use of Biometric Data in the Private Sector,,"This last Chapter proposes various specific suggestions for a comprehensive regulation of biometric data processing operations in mainly the private sector. The author formulates seven general principles, based on the previous analysis, and makes detailed recommendations structured in nine domains for both the national and international legislator. One of the principles to be embedded in legislation is no hidden or secret collection of biometric data, while another is the availability of an alternative system if the biometric data processing relies on consent. The recommendations include distinct use by the private and public sector and enhanced rights for the data subjects. The recommendations are supported by the analysis of the law, decisions and the opinions of the data protection authorities made in the preceding Chapters, while including references to examples of other legal systems as well.",2013,Privacy and Data Protection Issues of Biometric Applications,,"@Inbook{Kindt2013,
author=""Kindt, Els J."",
title=""A Legal Model for the Use of Biometric Data in the Private Sector"",
bookTitle=""Privacy and Data Protection Issues of Biometric Applications: A Comparative Legal Analysis"",
year=""2013"",
publisher=""Springer Netherlands"",
address=""Dordrecht"",
pages=""831--907"",
abstract=""This last Chapter proposes various specific suggestions for a comprehensive regulation of biometric data processing operations in mainly the private sector. The author formulates seven general principles, based on the previous analysis, and makes detailed recommendations structured in nine domains for both the national and international legislator. One of the principles to be embedded in legislation is no hidden or secret collection of biometric data, while another is the availability of an alternative system if the biometric data processing relies on consent. The recommendations include distinct use by the private and public sector and enhanced rights for the data subjects. The recommendations are supported by the analysis of the law, decisions and the opinions of the data protection authorities made in the preceding Chapters, while including references to examples of other legal systems as well."",
isbn=""978-94-007-7522-0"",
doi=""10.1007/978-94-007-7522-0_9"",
url=""https://doi.org/10.1007/978-94-007-7522-0_9""
}",Springer
"Cornelia Graf, Peter Wolkerstorfer, ... Manfred Tscheligi",HCI for PrimeLife Prototypes,,"User-centered design (UCD) processes need to be further extended to the field of privacy enhancing technologies (PETs). The goal of the UCD process for PETs is to provide a means for users to empower them to manage their privacy on the Web. Taking care of privacy and being careful while surfing theWeb are still considered to be cumbersome and time-consuming activities. Hence, PrimeLife aspires to provide easy to use tools for users to manage their privacy. This chapter describes the challenges in UCD that arose during the development of the PrimeLife prototypes. As part of the HCI activities in the PrimeLife project, we have researched the users’ attitudes towards privacy and discovered the main challenges when developing userfriendly PETs. We use two example prototypes to explain how the challenges can be tackled in practice. In general, PETs should neither require much of the user’s attention and time, nor should they require particular technical knowledge. They should, in fact, present the complex methods of privacy enhancing technologies in an easy, understandable and usable way. We will conclude this chapter with a discussion of our findings and implications for further development of user-centered privacy enhancing technologies.",2011,Privacy and Identity Management for Life,,"@Inbook{Graf2011,
author=""Graf, Cornelia
and Wolkerstorfer, Peter
and Hochleitner, Christina
and W{\""a}stlund, Erik
and Tscheligi, Manfred"",
editor=""Camenisch, Jan
and Fischer-H{\""u}bner, Simone
and Rannenberg, Kai"",
title=""HCI for PrimeLife Prototypes"",
bookTitle=""Privacy and Identity Management for Life"",
year=""2011"",
publisher=""Springer Berlin Heidelberg"",
address=""Berlin, Heidelberg"",
pages=""221--232"",
abstract=""User-centered design (UCD) processes need to be further extended to the field of privacy enhancing technologies (PETs). The goal of the UCD process for PETs is to provide a means for users to empower them to manage their privacy on the Web. Taking care of privacy and being careful while surfing theWeb are still considered to be cumbersome and time-consuming activities. Hence, PrimeLife aspires to provide easy to use tools for users to manage their privacy. This chapter describes the challenges in UCD that arose during the development of the PrimeLife prototypes. As part of the HCI activities in the PrimeLife project, we have researched the users' attitudes towards privacy and discovered the main challenges when developing userfriendly PETs. We use two example prototypes to explain how the challenges can be tackled in practice. In general, PETs should neither require much of the user's attention and time, nor should they require particular technical knowledge. They should, in fact, present the complex methods of privacy enhancing technologies in an easy, understandable and usable way. We will conclude this chapter with a discussion of our findings and implications for further development of user-centered privacy enhancing technologies."",
isbn=""978-3-642-20317-6"",
doi=""10.1007/978-3-642-20317-6_11"",
url=""https://doi.org/10.1007/978-3-642-20317-6_11""
}",Springer
Walter Peissl,Information Privacy in Europe from a TA Perspective,,This chapter presents the results from a joint project of European Parliamentary Technology Assessment institutions on information and communication technologies (ICT) and privacy. It reflects the outcome of 28 projects from 7 countries. These TA projects were analysed under a common framework. The analysis rendered a set of challenges for European policy and finally several policy options on how to deal with these challenges.,2010,Data Protection in a Profiled World,,"@Inbook{Peissl2010,
author=""Peissl, Walter"",
editor=""Gutwirth, Serge
and Poullet, Yves
and De Hert, Paul"",
title=""Information Privacy in Europe from a TA Perspective"",
bookTitle=""Data Protection in a Profiled World"",
year=""2010"",
publisher=""Springer Netherlands"",
address=""Dordrecht"",
pages=""247--256"",
abstract=""This chapter presents the results from a joint project of European Parliamentary Technology Assessment institutions on information and communication technologies (ICT) and privacy. It reflects the outcome of 28 projects from 7 countries. These TA projects were analysed under a common framework. The analysis rendered a set of challenges for European policy and finally several policy options on how to deal with these challenges."",
isbn=""978-90-481-8865-9"",
doi=""10.1007/978-90-481-8865-9_14"",
url=""https://doi.org/10.1007/978-90-481-8865-9_14""
}",Springer
Nan Zhang,Towards Comprehensive Privacy Protection in Data Clustering,,"We address the protection of private information in data clustering. Previous work focuses on protecting the privacy of data being mined. We find that the cluster labels of individual data points can also be sensitive to data owners. Thus, we propose a privacy-preserving data clustering scheme that extracts accurate clustering rules from private data while protecting the privacy of both original data and individual cluster labels. We derive theoretical bounds on the performance of our scheme, and evaluate it experimentally with real-world data.",2007,Advances in Knowledge Discovery and Data Mining,,"@InProceedings{10.1007/978-3-540-71701-0_124,
author=""Zhang, Nan"",
editor=""Zhou, Zhi-Hua
and Li, Hang
and Yang, Qiang"",
title=""Towards Comprehensive Privacy Protection in Data Clustering"",
booktitle=""Advances in Knowledge Discovery and Data Mining"",
year=""2007"",
publisher=""Springer Berlin Heidelberg"",
address=""Berlin, Heidelberg"",
pages=""1096--1104"",
abstract=""We address the protection of private information in data clustering. Previous work focuses on protecting the privacy of data being mined. We find that the cluster labels of individual data points can also be sensitive to data owners. Thus, we propose a privacy-preserving data clustering scheme that extracts accurate clustering rules from private data while protecting the privacy of both original data and individual cluster labels. We derive theoretical bounds on the performance of our scheme, and evaluate it experimentally with real-world data."",
isbn=""978-3-540-71701-0""
}",Springer
"C. A. Ardagna, S. De Capitani di Vimercati, P. Samarati",Enhancing User Privacy Through Data Handling Policies,,"The protection of privacy is an increasing concern in today’s global infrastructure. One of the most important privacy protection principles states that personal information collected for one purpose may not be used for any other purpose without the specific informed consent of the person it concerns. Although users provide personal information for use in one specific context, they often have no idea on how such a personal information may be used subsequently.In this paper, we introduce a new type of privacy policy, called data handling policy, which defines how the personal information release will be (or should be) dealt with at the receiving party. A data handling policy allows users to define simple and appropriate levels of control over who sees what information about them and under which circumstances.",2006,Data and Applications Security XX,,"@InProceedings{10.1007/11805588_16,
author=""Ardagna, C. A.
and De Capitani di Vimercati, S.
and Samarati, P."",
editor=""Damiani, Ernesto
and Liu, Peng"",
title=""Enhancing User Privacy Through Data Handling Policies"",
booktitle=""Data and Applications Security XX"",
year=""2006"",
publisher=""Springer Berlin Heidelberg"",
address=""Berlin, Heidelberg"",
pages=""224--236"",
abstract=""The protection of privacy is an increasing concern in today's global infrastructure. One of the most important privacy protection principles states that personal information collected for one purpose may not be used for any other purpose without the specific informed consent of the person it concerns. Although users provide personal information for use in one specific context, they often have no idea on how such a personal information may be used subsequently."",
isbn=""978-3-540-36799-4""
}",Springer
"Marco Casassa Mont, Siani Pearson, Pete Bramhall",Towards Accountable Management of Privacy and Identity Information,,"Digital identities and profiles are valuable assets: they are more and more relevant to allow people to access services and information on the Internet. They need to be secured and protected. Unfortunately people have little control over the destiny of this information once it has been disclosed to third parties. People rely on enterprises and organizations for its management. In most cases this is a matter of trust. This paper describes an approach to make organizations more accountable, provide strong but not impregnable privacy enforcement mechanisms and allow users to be more involved in the management of the privacy of their confidential information. As part of our ongoing research, we introduce a technical solution based on ”sticky” privacy policies and tracing services that leverages Identifier-based Encryption (IBE) along with trusted platform technologies such as TCPA (TCG) and Tagged Operating Systems. Work is in progress to prototype this solution.",2003,Computer Security – ESORICS 2003,,"@InProceedings{10.1007/978-3-540-39650-5_9,
author=""Mont, Marco Casassa
and Pearson, Siani
and Bramhall, Pete"",
editor=""Snekkenes, Einar
and Gollmann, Dieter"",
title=""Towards Accountable Management of Privacy and Identity Information"",
booktitle=""Computer Security -- ESORICS 2003"",
year=""2003"",
publisher=""Springer Berlin Heidelberg"",
address=""Berlin, Heidelberg"",
pages=""146--161"",
abstract=""Digital identities and profiles are valuable assets: they are more and more relevant to allow people to access services and information on the Internet. They need to be secured and protected. Unfortunately people have little control over the destiny of this information once it has been disclosed to third parties. People rely on enterprises and organizations for its management. In most cases this is a matter of trust. This paper describes an approach to make organizations more accountable, provide strong but not impregnable privacy enforcement mechanisms and allow users to be more involved in the management of the privacy of their confidential information. As part of our ongoing research, we introduce a technical solution based on ''sticky'' privacy policies and tracing services that leverages Identifier-based Encryption (IBE) along with trusted platform technologies such as TCPA (TCG) and Tagged Operating Systems. Work is in progress to prototype this solution."",
isbn=""978-3-540-39650-5""
}",Springer
"Enrica Aureli, Barbara Baldazzi",Households and Territory. The Location of the Population of Rome in Relation to Housing Supply Characteristics,,"This study forms part of a general programme of research aimed at evaluating the quality of life in Rome. In particular, we have wished to analyse the way in which “housing quality”, measured with indicators of housing structure and utilization, intersects with the quality of urban “livability”, measured here only with indicators of social background, homogeneity and hardship referring to subjects living in the individual segments of the city. Groups of territorial areas, homogeneous by housing typology, were identified using multivariate data analysis and it was thus shown how particular typologies of household respond to this supply. From this emerged a particular model of development of the city in concentric bands, within which the originally differentiated households have tended over time to assume homogeneous characteristics.",01 May 1998,Social Indicators Research,,,Springer
"S Koch, M Wessels, B Altpeter",Keeping privacy labels honest,,"detect privacy-label violation via traffic analysis. Our experiments uncovered apps in which  a privacy label  After the privacy label analysis, we detail our traffic collection framework and",2022,… on Privacy Enhancing …,https://petsymposium.org/popets/2022/popets-2022-0119.php,"{'title': 'Keeping privacy labels honest', 'author': ['S Koch', 'M Wessels', 'B Altpeter'], 'pub_year': '2022', 'venue': '… on Privacy Enhancing …', 'abstract': 'detect privacy-label violation via traffic analysis. Our experiments uncovered apps in which  a privacy label  After the privacy label analysis, we detail our traffic collection framework and'}",Google Scholar
"P Emami-Naeini, Y Agarwal",Specification for CMU IoT security and privacy label,,& Privacy Label so we can use it? We are releasing our IoT Security & Privacy label design   waived all copyright and related or neighboring rights to our IoT Security and Privacy Label.,2021,…,https://www.iotsecurityprivacy.org/downloads/Privacy_and_Security_Specifications.pdf,"{'title': 'Specification for CMU IoT security and privacy label', 'author': ['P Emami-Naeini', 'Y Agarwal'], 'pub_year': '2021', 'venue': '…', 'abstract': '& Privacy Label so we can use it? We are releasing our IoT Security & Privacy label design   waived all copyright and related or neighboring rights to our IoT Security and Privacy Label.'}",Google Scholar
"H Yuan, N Xu, Y Shi, X Geng, Y Rui",Protective Label Enhancement for Label Privacy,,"Much sensitive data is gathered from the individual device for commercial value without  effective safeguards over the past decade, which would bring on serious privacy leakage. Here",2022,NA,https://openreview.net/forum?id=svP7EgyDcx,"{'title': 'Protective Label Enhancement for Label Privacy', 'author': ['H Yuan', 'N Xu', 'Y Shi', 'X Geng', 'Y Rui'], 'pub_year': '2022', 'venue': 'NA', 'abstract': 'Much sensitive data is gathered from the individual device for commercial value without  effective safeguards over the past decade, which would bring on serious privacy leakage. Here'}",Google Scholar
"S Zhang, N Sadeh",Do privacy labels answer users' privacy questions?,,TABLE II: Sample user questions and corresponding privacy label entry in the iOS and  Google Play Stores. N/A means that the question does not have a label addressing it.,2023,Workshop on Usable Security and Privacy,https://par.nsf.gov/biblio/10426770,"{'title': ""Do privacy labels answer users' privacy questions?"", 'author': ['S Zhang', 'N Sadeh'], 'pub_year': '2023', 'venue': 'Workshop on Usable Security and Privacy', 'abstract': 'TABLE II: Sample user questions and corresponding privacy label entry in the iOS and  Google Play Stores. N/A means that the question does not have a label addressing it.'}",Google Scholar
"C Zhao, J Mangat, S Koujalgi, A Squicciarini",Privacyalert: A dataset for image privacy prediction,,Image privacy issues have become an important challenge as millions of images are being  shared on social networking sites every day. Often due to users' lack of privacy awareness,2022,Proceedings of the …,https://ojs.aaai.org/index.php/ICWSM/article/view/19387,"{'title': 'Privacyalert: A dataset for image privacy prediction', 'author': ['C Zhao', 'J Mangat', 'S Koujalgi', 'A Squicciarini'], 'pub_year': '2022', 'venue': 'Proceedings of the …', 'abstract': ""Image privacy issues have become an important challenge as millions of images are being  shared on social networking sites every day. Often due to users' lack of privacy awareness""}",Google Scholar
"R Garg, R Telang",Impact of App Privacy Label Disclosure on Demand: An Empirical Analysis,,"While, on average, the effect of privacy label disclosure on app demand is small, we find that  when apps collect a large volume of user-specific data, they suffer from a significant decline",2022,Available at SSRN 4588747,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4588747,"{'title': 'Impact of App Privacy Label Disclosure on Demand: An Empirical Analysis', 'author': ['R Garg', 'R Telang'], 'pub_year': '2022', 'venue': 'Available at SSRN 4588747', 'abstract': 'While, on average, the effect of privacy label disclosure on app demand is small, we find that  when apps collect a large volume of user-specific data, they suffer from a significant decline'}",Google Scholar
"S Zhang, Y Feng, Y Yao, LF Cranor",How usable are ios app privacy labels?,,"However, since Apple uses the same privacy label system with identical terminology and  structures but slightly different layouts, many of our results could be reasonably extended to",2022,Proceedings on Privacy …,https://petsymposium.org/popets/2022/popets-2022-0106.php,"{'title': 'How usable are ios app privacy labels?', 'author': ['S Zhang', 'Y Feng', 'Y Yao', 'LF Cranor'], 'pub_year': '2022', 'venue': 'Proceedings on Privacy …', 'abstract': 'However, since Apple uses the same privacy label system with identical terminology and  structures but slightly different layouts, many of our results could be reasonably extended to'}",Google Scholar
"B Bian, X Ma, H Tang",The supply and demand for data privacy: Evidence from mobile apps,,"Exploiting the staggered release of privacy labels and using the nonexposed Android  version of each app to construct the control group, we find that after privacy label release, an",2021,Available at SSRN 3987541,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3987541,"{'title': 'The supply and demand for data privacy: Evidence from mobile apps', 'author': ['B Bian', 'X Ma', 'H Tang'], 'pub_year': '2021', 'venue': 'Available at SSRN 3987541', 'abstract': 'Exploiting the staggered release of privacy labels and using the nonexposed Android  version of each app to construct the control group, we find that after privacy label release, an'}",Google Scholar
PG Kelley,Conducting usable privacy & security studies with amazon's mechanical turk,,"In the privacy label work we wanted native english speakers. On the HIT acceptance  page we explicitly stated said “Only native english speakers are eligible.” However, to better",2010,Symposium on Usable Privacy and Security (SOUPS) …,https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=d41b0c0db98e96d26f73b8559a1c169aee20dce9,"{'title': ""Conducting usable privacy & security studies with amazon's mechanical turk"", 'author': ['PG Kelley'], 'pub_year': '2010', 'venue': 'Symposium on Usable Privacy and Security (SOUPS) …', 'abstract': 'In the privacy label work we wanted native english speakers. On the HIT acceptance  page we explicitly stated said “Only native english speakers are eligible.” However, to better'}",Google Scholar
"RI Busa-Fekete, U Syed, S Vassilvitskii",Population level privacy leakage in binary classification wtih label noise,,"We study the privacy limitations of label differential privacy. Label differential privacy has  emerged as an intermediate trust model between local and central differential privacy, where",2021,NeurIPS 2021 Workshop …,https://openreview.net/forum?id=Gf2EuAB9Xj,"{'title': 'Population level privacy leakage in binary classification wtih label noise', 'author': ['RI Busa-Fekete', 'U Syed', 'S Vassilvitskii'], 'pub_year': '2021', 'venue': 'NeurIPS 2021 Workshop …', 'abstract': 'We study the privacy limitations of label differential privacy. Label differential privacy has  emerged as an intermediate trust model between local and central differential privacy, where'}",Google Scholar
"A Filipowicz, T Chanyaswad, SY Kung",Desensitized RDCA Subspaces for Compressive Privacy in Machine Learning,,"privacy label. Based on five experiments, we show that desensitization by RDCA can effectively  protect privacy (ie low accuracy on the privacy label , we define a privacy label y(p) and a",2017,arXiv preprint arXiv:1707.07770,https://arxiv.org/abs/1707.07770,"{'title': 'Desensitized RDCA Subspaces for Compressive Privacy in Machine Learning', 'author': ['A Filipowicz', 'T Chanyaswad', 'SY Kung'], 'pub_year': '2017', 'venue': 'arXiv preprint arXiv:1707.07770', 'abstract': 'privacy label. Based on five experiments, we show that desensitization by RDCA can effectively  protect privacy (ie low accuracy on the privacy label , we define a privacy label y(p) and a'}",Google Scholar
"S Gürses, C Troncoso, C Diaz",Engineering privacy by design,,"This definition of privacy by design is therefore also susceptible to the interpretation to  collect any data as long as it is with a privacy label, while shrinking the scope of control, as we",2011,"Computers, Privacy & Data …",https://software.imdea.org/~carmela.troncoso/papers/Gurses-CPDP11.pdf,"{'title': 'Engineering privacy by design', 'author': ['S Gürses', 'C Troncoso', 'C Diaz'], 'pub_year': '2011', 'venue': 'Computers, Privacy & Data …', 'abstract': 'This definition of privacy by design is therefore also susceptible to the interpretation to  collect any data as long as it is with a privacy label, while shrinking the scope of control, as we'}",Google Scholar
"K Zhang, Z Tian, Z Cai, D Seo",Link-privacy preserving graph embedding data publication with adversarial learning,,"Because we want to exclude the private information in the graph embedding, a privacy label   each link, then how can we add a privacy label on each node to include the link information",2021,Tsinghua Science and …,https://ieeexplore.ieee.org/abstract/document/9552654/,"{'title': 'Link-privacy preserving graph embedding data publication with adversarial learning', 'author': ['K Zhang', 'Z Tian', 'Z Cai', 'D Seo'], 'pub_year': '2021', 'venue': 'Tsinghua Science and …', 'abstract': 'Because we want to exclude the private information in the graph embedding, a privacy label   each link, then how can we add a privacy label on each node to include the link information'}",Google Scholar
"XU Shirong, C Wang, WW Sun",Binary classification under local label differential privacy using randomized response mechanisms,,"Label differential privacy is a popular branch of $\epsilon$-differential privacy for protecting  labels in training datasets with non-private features. In this paper, we study the",2023,Transactions on Machine …,https://openreview.net/forum?id=uKCGOw9bGG,"{'title': 'Binary classification under local label differential privacy using randomized response mechanisms', 'author': ['XU Shirong', 'C Wang', 'WW Sun'], 'pub_year': '2023', 'venue': 'Transactions on Machine …', 'abstract': 'Label differential privacy is a popular branch of $\\epsilon$-differential privacy for protecting  labels in training datasets with non-private features. In this paper, we study the'}",Google Scholar
"H Han, W Zheng",A privacy data-oriented hierarchical MapReduce programming model,,"privacy label table both. So, TaskTracker reads the privacy data only according to the privacy  label  the public data only according to the privacy label table in public cloud clusters. Each",2013,TELKOMNIKA Indonesian Journal of …,http://journal.esperg.com/index.php/tijee/article/view/2524,"{'title': 'A privacy data-oriented hierarchical MapReduce programming model', 'author': ['H Han', 'W Zheng'], 'pub_year': '2013', 'venue': 'TELKOMNIKA Indonesian Journal of …', 'abstract': 'privacy label table both. So, TaskTracker reads the privacy data only according to the privacy  label  the public data only according to the privacy label table in public cloud clusters. Each'}",Google Scholar
"L Babun, ZB Celik, P McDaniel, AS Uluagac",Real-time analysis of privacy-(un) aware IoT applications,,"strings includes sensitive information and assign them a privacy label, we first implemented  a  related to more than one privacy label. We detail constructing the IoT corpus in Section 6.",2019,arXiv preprint arXiv …,https://arxiv.org/abs/1911.10461,"{'title': 'Real-time analysis of privacy-(un) aware IoT applications', 'author': ['L Babun', 'ZB Celik', 'P McDaniel', 'AS Uluagac'], 'pub_year': '2019', 'venue': 'arXiv preprint arXiv …', 'abstract': 'strings includes sensitive information and assign them a privacy label, we first implemented  a  related to more than one privacy label. We detail constructing the IoT corpus in Section 6.'}",Google Scholar
"J Gardner, Y Feng, A Jain, N Sadeh",Privacy Label Wiz: A Tool to Help iOS App Developers Create Accurate Privacy Labels,,"We introduce Privacy Label Wiz (PLW) [1], a software tool that helps iOS developers  generate accurate privacy labels. We present evaluation results from an initial usability test",2022,NA,https://www.usenix.org/system/files/soups2022-poster4_gardner_final.pdf,"{'title': 'Privacy Label Wiz: A Tool to Help iOS App Developers Create Accurate Privacy Labels', 'author': ['J Gardner', 'Y Feng', 'A Jain', 'N Sadeh'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': 'We introduce Privacy Label Wiz (PLW) [1], a software tool that helps iOS developers  generate accurate privacy labels. We present evaluation results from an initial usability test'}",Google Scholar
"Y Hu, T Cai, J Shan, S Tang, C Cai, E Song, B Li",Is vertical logistic regression privacy-preserving? a comprehensive privacy analysis and beyond,,We consider vertical logistic regression (VLR) trained with mini-batch gradient descent -- a  setting which has attracted growing interest among industries and proven to be useful in a,2022,arXiv preprint arXiv …,https://arxiv.org/abs/2207.09087,"{'title': 'Is vertical logistic regression privacy-preserving? a comprehensive privacy analysis and beyond', 'author': ['Y Hu', 'T Cai', 'J Shan', 'S Tang', 'C Cai', 'E Song', 'B Li'], 'pub_year': '2022', 'venue': 'arXiv preprint arXiv …', 'abstract': 'We consider vertical logistic regression (VLR) trained with mini-batch gradient descent -- a  setting which has attracted growing interest among industries and proven to be useful in a'}",Google Scholar
"SS Feger, M Windl, J Grootjen",Check for updates ConnectivityControl: Providing Smart Home Users with Real Privacy Configuration Options,,Connectivity Control features a privacy label that depicts how those modes impact device  features and privacy exposure. The label can be used to inform purchase decisions and to,2023,End-User Development …,https://books.google.com/books?hl=en&lr=&id=9KjBEAAAQBAJ&oi=fnd&pg=PA180&dq=%22privacy+label%22&ots=WF73n44rij&sig=4-ROkvpugOK3nry1_0hinI3DWec,"{'title': 'Check for updates ConnectivityControl: Providing Smart Home Users with Real Privacy Configuration Options', 'author': ['SS Feger', 'M Windl', 'J Grootjen'], 'pub_year': '2023', 'venue': 'End-User Development …', 'abstract': 'Connectivity Control features a privacy label that depicts how those modes impact device  features and privacy exposure. The label can be used to inform purchase decisions and to'}",Google Scholar
"P Emami-Naeini, J Dheenadhayalan, Y Agarwal",An Informative Security and Privacy 'Nutrition'Label for IoT Devices,,", we designed a usable and informative IoT security and privacy label.  www.iotsecurityprivacy.org/label  s Detailed Security & Privacy Label  for CMU IoT security and privacy label.”",NA,NA,https://ieeexplore.ieee.org/ielaam/8013/9740698/9664750-aam.pdf,"{'title': ""An Informative Security and Privacy 'Nutrition'Label for IoT Devices"", 'author': ['P Emami-Naeini', 'J Dheenadhayalan', 'Y Agarwal'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': ', we designed a usable and informative IoT security and privacy label.  www.iotsecurityprivacy.org/label  s Detailed Security & Privacy Label  for CMU IoT security and privacy label.”'}",Google Scholar
"I Adjerid, A Acquisti, G Loewenstein",Framing and the malleability of privacy choices,,"We hypothesized, in Section 3, that a privacy label would highlight privacy concerns for  participants, resulting in more self-protective (information concealing) behavior (H1a) and that",2014,… of the 13th Workshop on the …,https://www.econinfosec.org/archive/weis2014/papers/AdjeridAcquistiLoewenstein-WEIS2014.pdf,"{'title': 'Framing and the malleability of privacy choices', 'author': ['I Adjerid', 'A Acquisti', 'G Loewenstein'], 'pub_year': '2014', 'venue': '… of the 13th Workshop on the …', 'abstract': 'We hypothesized, in Section 3, that a privacy label would highlight privacy concerns for  participants, resulting in more self-protective (information concealing) behavior (H1a) and that'}",Google Scholar
"J Zhong, P Bertok, V Mirchandani, Z Tari",Privacy-Aware Granular Data Access Control For Cross-Domain Data Sharing,,"The Privacy Label Generator is a component of encapsulating privilege candidates to a  privacy label and after that, it sends the label to the Privilege Refinement module (See Figure 3).",2011,NA,https://aisel.aisnet.org/pacis2011/226/,"{'title': 'Privacy-Aware Granular Data Access Control For Cross-Domain Data Sharing', 'author': ['J Zhong', 'P Bertok', 'V Mirchandani', 'Z Tari'], 'pub_year': '2011', 'venue': 'NA', 'abstract': 'The Privacy Label Generator is a component of encapsulating privilege candidates to a  privacy label and after that, it sends the label to the Privilege Refinement module (See Figure 3).'}",Google Scholar
DG Balash,Usability of Privacy Control and Disclosure Mechanisms,,"Beginning in chapter 6 we present a measurement study on the Apple App Store privacy  label ecosystem. Next, we present the results of a privacy label user study to assess people’s",2023,NA,https://search.proquest.com/openview/4256e1cb2a3688feb704a223cfa2009a/1?pq-origsite=gscholar&cbl=18750&diss=y,"{'title': 'Usability of Privacy Control and Disclosure Mechanisms', 'author': ['DG Balash'], 'pub_year': '2023', 'venue': 'NA', 'abstract': 'Beginning in chapter 6 we present a measurement study on the Apple App Store privacy  label ecosystem. Next, we present the results of a privacy label user study to assess people’s'}",Google Scholar
"YD Ward, LJ Lester",Identity Attributes in Teaching Privacy,,"develop a model privacy label using their learnings  privacy label such as a smart tv, robot,  etc. You will focus on the GREEN APPLE identity attributes and design a model privacy label",2022,CYBERSECURITY PEDAGOGY & PRACTICE …,https://www.cppj.info/2022-1/n1/CPPJv1n1.pdf#page=66,"{'title': 'Identity Attributes in Teaching Privacy', 'author': ['YD Ward', 'LJ Lester'], 'pub_year': '2022', 'venue': 'CYBERSECURITY PEDAGOGY & PRACTICE …', 'abstract': 'develop a model privacy label using their learnings  privacy label such as a smart tv, robot,  etc. You will focus on the GREEN APPLE identity attributes and design a model privacy label'}",Google Scholar
A Hazim,Privacy Visualizations: Introducing an interactive visualization of privacy indicators based on Exodus Privacy to F-Droid,,While CLEVERFRANKE’s [21] “Privacy Label” takes a universal approach to streamlining  privacy  The privacy label proposed by CleverFranke is an example of such a format [21].,2023,NA,https://refubium.fu-berlin.de/handle/fub188/38148,"{'title': 'Privacy Visualizations: Introducing an interactive visualization of privacy indicators based on Exodus Privacy to F-Droid', 'author': ['A Hazim'], 'pub_year': '2023', 'venue': 'NA', 'abstract': 'While CLEVERFRANKE’s [21] “Privacy Label” takes a universal approach to streamlining  privacy  The privacy label proposed by CleverFranke is an example of such a format [21].'}",Google Scholar
"T Cadenhead, M Kantarcioglu","An Evaluation of Privacy, Risks and Utility with Provenance",,"The function ℓ maps a set of outputs to a privacy label, which is not limited to the ones we  presented here. This is useful in determining whether we can infer private data. This function is",2010,Secur. Knowl. Manag …,https://www.researchgate.net/profile/Tyrone-Cadenhead/publication/231175024_An_Evaluation_of_Privacy_Risks_and_Utility_with_Provenance/links/0fcfd506355d9f0ae4000000/An-Evaluation-of-Privacy-Risks-and-Utility-with-Provenance.pdf,"{'title': 'An Evaluation of Privacy, Risks and Utility with Provenance', 'author': ['T Cadenhead', 'M Kantarcioglu'], 'pub_year': '2010', 'venue': 'Secur. Knowl. Manag …', 'abstract': 'The function ℓ maps a set of outputs to a privacy label, which is not limited to the ones we  presented here. This is useful in determining whether we can infer private data. This function is'}",Google Scholar
"N Raval, A Machanavajjhala, J Pan",Olympus: Sensor privacy through utility aware obfuscation,,"Here, z is a privacy label of x and it takes a value from a set  ’s probability of predicting the  correct privacy label is 1/|Zs| for  (classifier) that predicts the privacy label z = xs given M(x) as",2019,Proceedings on Privacy …,https://petsymposium.org/popets/2019/popets-2019-0002.php,"{'title': 'Olympus: Sensor privacy through utility aware obfuscation', 'author': ['N Raval', 'A Machanavajjhala', 'J Pan'], 'pub_year': '2019', 'venue': 'Proceedings on Privacy …', 'abstract': 'Here, z is a privacy label of x and it takes a value from a set  ’s probability of predicting the  correct privacy label is 1/|Zs| for  (classifier) that predicts the privacy label z = xs given M(x) as'}",Google Scholar
"C Chen, H Ravishankar, D Shu, L Jain, Y Zeng",Ask the Consumers: What Should be on IoT Privacy & Security Labels?,,"Although expert opinion provided the basis for privacy label designs created by Emami-Naeini  et al. [1], insights gained from experts may differ from consumer opinion. They called for",2023,NA,https://www.usenix.org/system/files/soups2023-poster10_chen_claire_abstract_final.pdf,"{'title': 'Ask the Consumers: What Should be on IoT Privacy & Security Labels?', 'author': ['C Chen', 'H Ravishankar', 'D Shu', 'L Jain', 'Y Zeng'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': 'Although expert opinion provided the basis for privacy label designs created by Emami-Naeini  et al. [1], insights gained from experts may differ from consumer opinion. They called for'}",Google Scholar
J Greene,The so-called right to privacy,,"If doctrinal labels are nothing more, then the interment of the privacy label remains a point  worth making. Nonetheless, more can be said. Whether the Court is hospitable to certain",2009,UC Davis L. Rev.,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/davlr43&section=23,"{'title': 'The so-called right to privacy', 'author': ['J Greene'], 'pub_year': '2009', 'venue': 'UC Davis L. Rev.', 'abstract': 'If doctrinal labels are nothing more, then the interment of the privacy label remains a point  worth making. Nonetheless, more can be said. Whether the Court is hospitable to certain'}",Google Scholar
K Mansted,Mandatory Digital Privacy Labels: One Way to Protect Consumer Data,,"A privacy label can be thought of as a summary of the most salient, privacy-related information  about the relevant product or service—be it a website, app, or Internet-enabled device.",2017,Kennedy School Review,https://search.proquest.com/openview/79ba5ebcc7de00e3d2e8fbfe4d63ae2b/1?pq-origsite=gscholar&cbl=436382,"{'title': 'Mandatory Digital Privacy Labels: One Way to Protect Consumer Data', 'author': ['K Mansted'], 'pub_year': '2017', 'venue': 'Kennedy School Review', 'abstract': 'A privacy label can be thought of as a summary of the most salient, privacy-related information  about the relevant product or service—be it a website, app, or Internet-enabled device.'}",Google Scholar
"E Bello-Ogunu, M Shehab",Crowdsourcing for context: Regarding privacy in beacon encounters via contextual integrity,,"The last step required users to provide a privacy label for a beacon, which involved a few   These last few questions that pertained to the privacy label represented other levels of",2016,Proceedings on Privacy Enhancing …,https://petsymposium.org/popets/2016/popets-2016-0017.php,"{'title': 'Crowdsourcing for context: Regarding privacy in beacon encounters via contextual integrity', 'author': ['E Bello-Ogunu', 'M Shehab'], 'pub_year': '2016', 'venue': 'Proceedings on Privacy Enhancing …', 'abstract': 'The last step required users to provide a privacy label for a beacon, which involved a few   These last few questions that pertained to the privacy label represented other levels of'}",Google Scholar
"S Mahloujifar, C Guo, GE Suh",Machine Learning with Feature Differential Privacy,,Machine learning applications incorporating differential privacy frequently face significant  utility degradation. One prevalent solution involves enhancing utility through the use of publicly,2023,Federated Learning and …,https://openreview.net/forum?id=YFv8sy1m15,"{'title': 'Machine Learning with Feature Differential Privacy', 'author': ['S Mahloujifar', 'C Guo', 'GE Suh'], 'pub_year': '2023', 'venue': 'Federated Learning and …', 'abstract': 'Machine learning applications incorporating differential privacy frequently face significant  utility degradation. One prevalent solution involves enhancing utility through the use of publicly'}",Google Scholar
"C Suver, E Kuwana",mHealth wearables and smartphone health tracking apps: A changing privacy landscape,,"a “privacy label.” Like a food label on a grocery store item, Strava’s privacy label is easy  to read and understand - and is short [35]. Also noteworthy is Apple’s privacy label: as of",2021,Information Services & Use,https://content.iospress.com/articles/information-services-and-use/isu210114,"{'title': 'mHealth wearables and smartphone health tracking apps: A changing privacy landscape', 'author': ['C Suver', 'E Kuwana'], 'pub_year': '2021', 'venue': 'Information Services & Use', 'abstract': 'a “privacy label.” Like a food label on a grocery store item, Strava’s privacy label is easy  to read and understand - and is short [35]. Also noteworthy is Apple’s privacy label: as of'}",Google Scholar
"Y Dalat-Ward, LJ Lester",The Green Apple Approach to Teaching Privacy,,They worked individually as well as in group to select an Internet of Things device and  create a model privacy label. The privacy label was required to list the privacy attributes which,2021,Proceedings of the EDSIG Conference …,https://proc.iscap.info/2021/cases/5549.pdf,"{'title': 'The Green Apple Approach to Teaching Privacy', 'author': ['Y Dalat-Ward', 'LJ Lester'], 'pub_year': '2021', 'venue': 'Proceedings of the EDSIG Conference …', 'abstract': 'They worked individually as well as in group to select an Internet of Things device and  create a model privacy label. The privacy label was required to list the privacy attributes which'}",Google Scholar
"Y Zheng, Z Wu, Y Yuan, T Chen, Z Wang",Pcal: A privacy-preserving intelligent credit risk modeling framework based on adversarial learning,,"Here𝑌𝑃 is the privacy label in original data X𝑡 . 𝑓𝑃 is a privacy hacker model which tries  to infer 𝑌𝑃 from 𝑓𝐴(𝑋𝑡 ). 𝐿𝑃 is a loss function, which indicates the performance of privacy-",2020,arXiv preprint arXiv:2010.02529,https://arxiv.org/abs/2010.02529,"{'title': 'Pcal: A privacy-preserving intelligent credit risk modeling framework based on adversarial learning', 'author': ['Y Zheng', 'Z Wu', 'Y Yuan', 'T Chen', 'Z Wang'], 'pub_year': '2020', 'venue': 'arXiv preprint arXiv:2010.02529', 'abstract': 'Here𝑌𝑃 is the privacy label in original data X𝑡 . 𝑓𝑃 is a privacy hacker model which tries  to infer 𝑌𝑃 from 𝑓𝐴(𝑋𝑡 ). 𝐿𝑃 is a loss function, which indicates the performance of privacy-'}",Google Scholar
OK Lillebo,Next generation privacy policy,,"Through a laboratory study where the Nutrition Label was evaluated against a natural  language policy, the proposed privacy label allowed participants to find information more quickly",2011,NA,https://ntnuopen.ntnu.no/ntnu-xmlui/handle/11250/252506,"{'title': 'Next generation privacy policy', 'author': ['OK Lillebo'], 'pub_year': '2011', 'venue': 'NA', 'abstract': 'Through a laboratory study where the Nutrition Label was evaluated against a natural  language policy, the proposed privacy label allowed participants to find information more quickly'}",Google Scholar
"DRG Pontes, SD Zorzo, JSM Mello",Evaluation of the reliability of using the prototype PPMark-a tool to support the computer human interaction in readings the privacy policies-using the GQM and …,,"services, a prototype called PPMark was developed in order to read policy texts and show  what kind of data was being collected and to what end are were presented in a privacy label",2017,NA,https://core.ac.uk/download/pdf/301371891.pdf,"{'title': 'Evaluation of the reliability of using the prototype PPMark-a tool to support the computer human interaction in readings the privacy policies-using the GQM and …', 'author': ['DRG Pontes', 'SD Zorzo', 'JSM Mello'], 'pub_year': '2017', 'venue': 'NA', 'abstract': 'services, a prototype called PPMark was developed in order to read policy texts and show  what kind of data was being collected and to what end are were presented in a privacy label'}",Google Scholar
"J Angulo, S Fischer‐Hübner, E Wästlund",Towards usable privacy policy display and management,,"a “Nutrition Label” for P3P privacy policies based on the idea that people already understand  other nutrition, warning and energy labelling, and claim that their proposed privacy label",2012,… & Computer Security,https://www.emerald.com/insight/content/doi/10.1108/09685221211219155/full/html,"{'title': 'Towards usable privacy policy display and management', 'author': ['J Angulo', 'S Fischer‐Hübner', 'E Wästlund'], 'pub_year': '2012', 'venue': '… & Computer Security', 'abstract': 'a “Nutrition Label” for P3P privacy policies based on the idea that people already understand  other nutrition, warning and energy labelling, and claim that their proposed privacy label'}",Google Scholar
"D Kan, X Fang, Z Gong",Event Log Privacy Based on Differential Petri Nets,,"As an example, the event log in Table 1 is assumed to correspond to a Petri net model in  which the privacy label is AIDS detection, and this conclusion is obtained from a priori",2023,Applied Artificial Intelligence,https://www.tandfonline.com/doi/abs/10.1080/08839514.2023.2175109,"{'title': 'Event Log Privacy Based on Differential Petri Nets', 'author': ['D Kan', 'X Fang', 'Z Gong'], 'pub_year': '2023', 'venue': 'Applied Artificial Intelligence', 'abstract': 'As an example, the event log in Table 1 is assumed to correspond to a Petri net model in  which the privacy label is AIDS detection, and this conclusion is obtained from a priori'}",Google Scholar
LF Cranor,Necessary but not sufficient: Standardized mechanisms for privacy notice and choice,,"For several decades,"" notice and choice"" have been key principles of information privacy  protection.'Conceptions of privacy that involve the notion of individual control require a",2012,J. on Telecomm. & High Tech. L.,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/jtelhtel10&section=22,"{'title': 'Necessary but not sufficient: Standardized mechanisms for privacy notice and choice', 'author': ['LF Cranor'], 'pub_year': '2012', 'venue': 'J. on Telecomm. & High Tech. L.', 'abstract': 'For several decades,"" notice and choice"" have been key principles of information privacy  protection.\'Conceptions of privacy that involve the notion of individual control require a'}",Google Scholar
"J Zhong, P Bertok, Z Tari",Pair-wise privilege control for cross-domain private data sharing,,"), object/resource (O), privacy label (SPL) and session SYN (SYN Privacy label is a control  frame containing processing  is to be assigned only to Object Privacy Label. PSPC is a request-",2010,NA,https://aisel.aisnet.org/pacis2010/166/,"{'title': 'Pair-wise privilege control for cross-domain private data sharing', 'author': ['J Zhong', 'P Bertok', 'Z Tari'], 'pub_year': '2010', 'venue': 'NA', 'abstract': '), object/resource (O), privacy label (SPL) and session SYN (SYN Privacy label is a control  frame containing processing  is to be assigned only to Object Privacy Label. PSPC is a request-'}",Google Scholar
R Chandramouli,"Privacy & Authorization Policies-Validation & Assurance Techniques (Two Chapters for a book titled"" Identity and Security"" by FutureText)",,with each privacy label class are determined. The information types associated with a  privacy label (we use the terms privacy label class and privacy label interchangeably since in,NA,NA,https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=152171,"{'title': 'Privacy & Authorization Policies-Validation & Assurance Techniques (Two Chapters for a book titled"" Identity and Security"" by FutureText)', 'author': ['R Chandramouli'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': 'with each privacy label class are determined. The information types associated with a  privacy label (we use the terms privacy label class and privacy label interchangeably since in'}",Google Scholar
"J Dev, SR Gopavaram, E Gumusel, J Camp",A Consumer-focused Modular Approach to Labeling IoT Devices and Software,,Our modular privacy label approach provides an approach which empowers consumers to  take control of their privacy by selectively agreeing to only the sections of the privacy policy,NA,NA,https://www.nist.gov/document/cybersecurity-labeling-position-paper-indiana-university-submission-3,"{'title': 'A Consumer-focused Modular Approach to Labeling IoT Devices and Software', 'author': ['J Dev', 'SR Gopavaram', 'E Gumusel', 'J Camp'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': 'Our modular privacy label approach provides an approach which empowers consumers to  take control of their privacy by selectively agreeing to only the sections of the privacy policy'}",Google Scholar
"F Razmi, J Lou, L Xiong",Does Differential Privacy Prevent Backdoor Attacks in Practice?,,"Differential Privacy (DP) was originally developed to protect privacy. However, it has recently  been utilized to secure machine learning (ML) models from poisoning attacks, with DP-",2023,arXiv preprint arXiv:2311.06227,https://arxiv.org/abs/2311.06227,"{'title': 'Does Differential Privacy Prevent Backdoor Attacks in Practice?', 'author': ['F Razmi', 'J Lou', 'L Xiong'], 'pub_year': '2023', 'venue': 'arXiv preprint arXiv:2311.06227', 'abstract': 'Differential Privacy (DP) was originally developed to protect privacy. However, it has recently  been utilized to secure machine learning (ML) models from poisoning attacks, with DP-'}",Google Scholar
P Pathak,Creating accurate privacy nutrition labels through cross-platform code annotation,,create a CSV file that can be uploaded to the Google Play Console to create a privacy  label.  This can be uploaded to the Google Play Console to generate the privacy label. This,2023,NA,https://search.proquest.com/openview/adf01bdfd35c82fbf88cac0e1fd4d4fe/1?pq-origsite=gscholar&cbl=18750&diss=y,"{'title': 'Creating accurate privacy nutrition labels through cross-platform code annotation', 'author': ['P Pathak'], 'pub_year': '2023', 'venue': 'NA', 'abstract': 'create a CSV file that can be uploaded to the Google Play Console to create a privacy  label.  This can be uploaded to the Google Play Console to generate the privacy label. This'}",Google Scholar
"A Tonge, C Caragea",Dynamically identifying deep multimodal features for image privacy prediction,,"(3) Feature selection: Last, for a given target image, we first check the agreement on the  privacy label between the models trained on all the feature sets. If not all models agree, then we",2019,Proceedings of the AAAI Conference on Artificial …,https://ojs.aaai.org/index.php/AAAI/article/view/5165,"{'title': 'Dynamically identifying deep multimodal features for image privacy prediction', 'author': ['A Tonge', 'C Caragea'], 'pub_year': '2019', 'venue': 'Proceedings of the AAAI Conference on Artificial …', 'abstract': '(3) Feature selection: Last, for a given target image, we first check the agreement on the  privacy label between the models trained on all the feature sets. If not all models agree, then we'}",Google Scholar
BP Knijnenburg,Simplifying privacy decisions: Towards interactive and adaptive solutions.,,"For example, displaying a privacy label on an e-commerce website—a supposed vote of  confidence—may decrease instead of increase purchases [7].",2013,Decisions@ RecSys,https://www.researchgate.net/profile/Bart-Knijnenburg/publication/264898061_Simplifying_Privacy_Decisions_Towards_Interactive_and_Adaptive_Solutions/links/53f507f30cf2888a74914698/Simplifying-Privacy-Decisions-Towards-Interactive-and-Adaptive-Solutions.pdf,"{'title': 'Simplifying privacy decisions: Towards interactive and adaptive solutions.', 'author': ['BP Knijnenburg'], 'pub_year': '2013', 'venue': 'Decisions@ RecSys', 'abstract': 'For example, displaying a privacy label on an e-commerce website—a supposed vote of  confidence—may decrease instead of increase purchases [7].'}",Google Scholar
"L Duan, J Sun, Y Chen, M Gorlatova",PrivaScissors: Enhance the Privacy of Collaborative Inference through the Lens of Mutual Information,,"Edge-cloud collaborative inference empowers resource-limited IoT devices to support deep  learning applications without disclosing their raw data to the cloud server, thus preserving",2023,arXiv preprint arXiv:2306.07973,https://arxiv.org/abs/2306.07973,"{'title': 'PrivaScissors: Enhance the Privacy of Collaborative Inference through the Lens of Mutual Information', 'author': ['L Duan', 'J Sun', 'Y Chen', 'M Gorlatova'], 'pub_year': '2023', 'venue': 'arXiv preprint arXiv:2306.07973', 'abstract': 'Edge-cloud collaborative inference empowers resource-limited IoT devices to support deep  learning applications without disclosing their raw data to the cloud server, thus preserving'}",Google Scholar
SS as a Cyber-Physical,Theodore Gerard Lynn's Lab,,This paper presents the GDPR privacy label and uses two empirical studies to examine  the  Design/methodology/approach The paper tests the efficacy of two GDPR privacy label,2022,SAGE,https://www.researchgate.net/lab/Theodore-Gerard-Lynn-Lab-3,"{'title': ""Theodore Gerard Lynn's Lab"", 'author': ['SS as a Cyber-Physical'], 'pub_year': '2022', 'venue': 'SAGE', 'abstract': 'This paper presents the GDPR privacy label and uses two empirical studies to examine  the  Design/methodology/approach The paper tests the efficacy of two GDPR privacy label'}",Google Scholar
"I Adjerid, A Acquisti, G Loewenstein","Choice architecture, framing, and cascaded privacy choices",,"For example, choices to provide location information on mobile phones are sometimes  presented using a “Privacy” label and sometimes using a more descriptive “Location” label.",2019,Management science,https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2018.3028,"{'title': 'Choice architecture, framing, and cascaded privacy choices', 'author': ['I Adjerid', 'A Acquisti', 'G Loewenstein'], 'pub_year': '2019', 'venue': 'Management science', 'abstract': 'For example, choices to provide location information on mobile phones are sometimes  presented using a “Privacy” label and sometimes using a more descriptive “Location” label.'}",Google Scholar
LF Cranor,Privacy Notice and Choice in Practice,,Privacy label for Android,2013,NA,https://pdfs.semanticscholar.org/e4d3/033333fb6f42f22f4403e53dee6ae2a10fdc.pdf,"{'title': 'Privacy Notice and Choice in Practice', 'author': ['LF Cranor'], 'pub_year': '2013', 'venue': 'NA', 'abstract': 'Privacy label for Android'}",Google Scholar
A Abdelmoty,Towards modelling privacy risks in geo-social networks,,"Every edge e in the geo-folksonomy graph is given a privacy label vc = Green|Amber|Red,  that is a function of the pre-assigned weight on the edge. Thus, for example, vc(t, r) = f(w(t, r))",2018,NA,https://orca.cardiff.ac.uk/id/eprint/112127/1/geoprocessing_2018_6_20_30119.pdf,"{'title': 'Towards modelling privacy risks in geo-social networks', 'author': ['A Abdelmoty'], 'pub_year': '2018', 'venue': 'NA', 'abstract': 'Every edge e in the geo-folksonomy graph is given a privacy label vc = Green|Amber|Red,  that is a function of the pre-assigned weight on the edge. Thus, for example, vc(t, r) = f(w(t, r))'}",Google Scholar
"T Cory, W Rieder, TM Huynh",A Qualitative Analysis Framework for mHealth Privacy Practices,,"81% of apps that share nonstandard PHI, ie fitness information, do not publish a corresponding  privacy label. Although we only observe a small number of medical PHI transmissions to",2024,arXiv preprint arXiv:2405.17971,https://arxiv.org/abs/2405.17971,"{'title': 'A Qualitative Analysis Framework for mHealth Privacy Practices', 'author': ['T Cory', 'W Rieder', 'TM Huynh'], 'pub_year': '2024', 'venue': 'arXiv preprint arXiv:2405.17971', 'abstract': '81% of apps that share nonstandard PHI, ie fitness information, do not publish a corresponding  privacy label. Although we only observe a small number of medical PHI transmissions to'}",Google Scholar
"J Angulo, S Fischer-Hübner, T Pulls, E Wästlund",Towards Usable Privacy Policy Display & Management-The PrimeLife Approach.,,"a “Nutrition Label” for P3P privacy policies based on the idea that people already understand  other nutrition, warning and energy labelling, and claim that their proposed privacy label",2011,HAISA,https://books.google.com/books?hl=en&lr=&id=3apGAwAAQBAJ&oi=fnd&pg=PA108&dq=%22privacy+label%22&ots=81U4AyMn8y&sig=ejpvPuIvV3OOU6uChEBZu9HwiQI,"{'title': 'Towards Usable Privacy Policy Display & Management-The PrimeLife Approach.', 'author': ['J Angulo', 'S Fischer-Hübner', 'T Pulls', 'E Wästlund'], 'pub_year': '2011', 'venue': 'HAISA', 'abstract': 'a “Nutrition Label” for P3P privacy policies based on the idea that people already understand  other nutrition, warning and energy labelling, and claim that their proposed privacy label'}",Google Scholar
"Y Xiao, Y Jin, Y Bai, Y Wu, X Yang, X Luo, W Yu",Large language models can be good privacy protection learners,,"of words in the dictionary, and 2) a corresponding privacy label sequence p1:n ∈ {0, 1}n,   simultaneous prediction of the sequence and its privacy label in an auto-regressive manner.",2023,arXiv preprint arXiv …,https://arxiv.org/abs/2310.02469,"{'title': 'Large language models can be good privacy protection learners', 'author': ['Y Xiao', 'Y Jin', 'Y Bai', 'Y Wu', 'X Yang', 'X Luo', 'W Yu'], 'pub_year': '2023', 'venue': 'arXiv preprint arXiv …', 'abstract': 'of words in the dictionary, and 2) a corresponding privacy label sequence p1:n ∈ {0, 1}n,   simultaneous prediction of the sequence and its privacy label in an auto-regressive manner.'}",Google Scholar
J Bellin,Pure privacy,,"But descriptive bankruptcy isn't the only problem with the decisional privacy label. Since  decisional privacy is an expansive, ambiguous category with only coincidental overlap with",2021,Nw. UL Rev.,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/illlr116&section=16,"{'title': 'Pure privacy', 'author': ['J Bellin'], 'pub_year': '2021', 'venue': 'Nw. UL Rev.', 'abstract': ""But descriptive bankruptcy isn't the only problem with the decisional privacy label. Since  decisional privacy is an expansive, ambiguous category with only coincidental overlap with""}",Google Scholar
"X Tang, M Nasr, S Mahloujifar",Machine learning with differentially private labels: Mechanisms and frameworks,,Label differential privacy is a relaxation of differential privacy for machine learning scenarios  where the labels are the only sensitive information that needs to be protected in the training,2022,Proceedings on …,https://petsymposium.org/popets/2022/popets-2022-0112.php,"{'title': 'Machine learning with differentially private labels: Mechanisms and frameworks', 'author': ['X Tang', 'M Nasr', 'S Mahloujifar'], 'pub_year': '2022', 'venue': 'Proceedings on …', 'abstract': 'Label differential privacy is a relaxation of differential privacy for machine learning scenarios  where the labels are the only sensitive information that needs to be protected in the training'}",Google Scholar
H Li,Mediators Allowing Users to Control Information Given When Using Technologies,,"a benchmark for a privacy label that indicates the product  As a result, incentivized to  obtain the privacy label from NIST,  If we gradually extend this privacy label to more spaces,",2022,NA,https://deepblue.lib.umich.edu/handle/2027.42/176704,"{'title': 'Mediators Allowing Users to Control Information Given When Using Technologies', 'author': ['H Li'], 'pub_year': '2022', 'venue': 'NA', 'abstract': 'a benchmark for a privacy label that indicates the product  As a result, incentivized to  obtain the privacy label from NIST,  If we gradually extend this privacy label to more spaces,'}",Google Scholar
TW Jirout,Dynamic iOS Privacy Analysis: Verifying App Store Privacy Labels,,"Our results show that our platform could successfully verify a declared privacy label for the  Advertising Identifier in 70% of cases. Furthermore, we also discovered that among 50 apps",2021,NA,https://scholar.archive.org/work/5nalmn4diveu5asi53bbuzsw3a/access/wayback/https://repositum.tuwien.at/bitstream/20.500.12708/19197/1/Jirout%20Thomas%20-%202021%20-%20Dynamic%20iOS%20Privacy%20Analysis%20Verifying%20App%20Store%20Privacy...pdf,"{'title': 'Dynamic iOS Privacy Analysis: Verifying App Store Privacy Labels', 'author': ['TW Jirout'], 'pub_year': '2021', 'venue': 'NA', 'abstract': 'Our results show that our platform could successfully verify a declared privacy label for the  Advertising Identifier in 70% of cases. Furthermore, we also discovered that among 50 apps'}",Google Scholar
"J Gardner, A Jain",Helping Mobile App Developers Create Accurate Privacy Labels,,"data collection and use practices to generate a “privacy label” for their applications. The use  of  us to develop an enhanced software tool, Privacy Label Wiz, that more closely resembles",2022,NA,https://www.usenix.org/conference/pepr22/presentation/gardner,"{'title': 'Helping Mobile App Developers Create Accurate Privacy Labels', 'author': ['J Gardner', 'A Jain'], 'pub_year': '2022', 'venue': 'NA', 'abstract': 'data collection and use practices to generate a “privacy label” for their applications. The use  of  us to develop an enhanced software tool, Privacy Label Wiz, that more closely resembles'}",Google Scholar
"S Fischer-Hbner, S Berthold",Privacy-enhancing technologies,,"In our modern information age, recent technical developments and trends, such as mobile  and pervasive computing, big data, cloud computing, and Web 2.0 applications, increasingly",2017,Computer and information security …,https://www.sciencedirect.com/science/article/pii/B9780128038437000533,"{'title': 'Privacy-enhancing technologies', 'author': ['S Fischer-Hbner', 'S Berthold'], 'pub_year': '2017', 'venue': 'Computer and information security …', 'abstract': 'In our modern information age, recent technical developments and trends, such as mobile  and pervasive computing, big data, cloud computing, and Web 2.0 applications, increasingly'}",Google Scholar
O Kaplan,Privacy Pioneer: Creating an Automated Data-Privacy UI for Web Browsers,,"Perhaps most influential to the privacy label domain, Apple recently rolled out privacy labels  to over a billion users in the iOS App Store. Google plans to release similar “privacy tags” in",2022,NA,https://digitalcollections.wesleyan.edu/_flysystem/fedora/2023-03/24348-Original%20File.pdf,"{'title': 'Privacy Pioneer: Creating an Automated Data-Privacy UI for Web Browsers', 'author': ['O Kaplan'], 'pub_year': '2022', 'venue': 'NA', 'abstract': 'Perhaps most influential to the privacy label domain, Apple recently rolled out privacy labels  to over a billion users in the iOS App Store. Google plans to release similar “privacy tags” in'}",Google Scholar
T Li,Privacy Annotations: Designing Privacy Support for Developers,,"By identifying common errors and challenges that developers face when creating Apple  privacy labels, I aimed to uncover limitations in Apple’s privacy label design and offer timely",2023,NA,http://reports-archive.adm.cs.cmu.edu/anon/anon/usr/ftp/home/ftp/hcii/CMU-HCII-22-107.pdf,"{'title': 'Privacy Annotations: Designing Privacy Support for Developers', 'author': ['T Li'], 'pub_year': '2023', 'venue': 'NA', 'abstract': 'By identifying common errors and challenges that developers face when creating Apple  privacy labels, I aimed to uncover limitations in Apple’s privacy label design and offer timely'}",Google Scholar
"A Tonge, C Caragea",Privacy prediction of images shared on social media sites using deep features,,"Thus, similar type of tags will be used for describing images with a particular privacy label.  Figure 4 shows tag clouds for top 100 high frequency tags for private and public classes.",2015,arXiv preprint arXiv:1510.08583,https://arxiv.org/abs/1510.08583,"{'title': 'Privacy prediction of images shared on social media sites using deep features', 'author': ['A Tonge', 'C Caragea'], 'pub_year': '2015', 'venue': 'arXiv preprint arXiv:1510.08583', 'abstract': 'Thus, similar type of tags will be used for describing images with a particular privacy label.  Figure 4 shows tag clouds for top 100 high frequency tags for private and public classes.'}",Google Scholar
"J Mahler, B Hou, S Niyaz, FT Pokorny, R Chandra",Privacy-Preserving Grasp Planning,,"triangles of the masked mesh using primal triangular quadrisection [36] until the maximum  edge length of each triangle is less than some threshold ϵ, transferring the privacy label Z(ti)",NA,NA,https://www.brianhou.com/pubs/case16-privacy.pdf,"{'title': 'Privacy-Preserving Grasp Planning', 'author': ['J Mahler', 'B Hou', 'S Niyaz', 'FT Pokorny', 'R Chandra'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': 'triangles of the masked mesh using primal triangular quadrisection [36] until the maximum  edge length of each triangle is less than some threshold ϵ, transferring the privacy label Z(ti)'}",Google Scholar
"A Javanmard, V Mirrokni, J Pouget-Abadie",Causal Inference with Differentially Private (Clustered) Outcomes,,"Estimating causal effects from randomized experiments is only feasible if participants agree  to reveal their potentially sensitive responses. Of the many ways of ensuring privacy, label",2023,arXiv preprint arXiv …,https://arxiv.org/abs/2308.00957,"{'title': 'Causal Inference with Differentially Private (Clustered) Outcomes', 'author': ['A Javanmard', 'V Mirrokni', 'J Pouget-Abadie'], 'pub_year': '2023', 'venue': 'arXiv preprint arXiv …', 'abstract': 'Estimating causal effects from randomized experiments is only feasible if participants agree  to reveal their potentially sensitive responses. Of the many ways of ensuring privacy, label'}",Google Scholar
RT Thompson III,Image as personal property: how privacy law has influenced the right of publicity,,"To make the distinction between privacy and publicity simpler, many courts began to give  the right of publicity a property label, and the right of privacy was given a privacy label. This",2009,UCLA Ent. L. Rev.,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/uclaetrlr16&section=10,"{'title': 'Image as personal property: how privacy law has influenced the right of publicity', 'author': ['RT Thompson III'], 'pub_year': '2009', 'venue': 'UCLA Ent. L. Rev.', 'abstract': 'To make the distinction between privacy and publicity simpler, many courts began to give  the right of publicity a property label, and the right of privacy was given a privacy label. This'}",Google Scholar
T Chanyaswad,Privacy-Preserving Machine Learning via Data Compression & Differential Privacy,,"The technical di erences from Chapter 3 are that, rst, DCA is trained by the privacy label,  as opposed to the utility label, and, second, the data are projected on the privacy noise",2018,NA,https://search.proquest.com/openview/ae46b39fcac22c9b34718a7d4be74a1a/1?pq-origsite=gscholar&cbl=18750&diss=y,"{'title': 'Privacy-Preserving Machine Learning via Data Compression & Differential Privacy', 'author': ['T Chanyaswad'], 'pub_year': '2018', 'venue': 'NA', 'abstract': 'The technical di erences from Chapter 3 are that, rst, DCA is trained by the privacy label,  as opposed to the utility label, and, second, the data are projected on the privacy noise'}",Google Scholar
MI Evones,Privacy in Online Social Networking Sites,,There are more than 192 active social networking websites. Bringing every kind of social  group together in one place and letting them interact is really a big thing indeed. Huge amount,2014,Compusoft,https://www.academia.edu/download/42046535/COMPUSOFT__35__777-779.pdf,"{'title': 'Privacy in Online Social Networking Sites', 'author': ['MI Evones'], 'pub_year': '2014', 'venue': 'Compusoft', 'abstract': 'There are more than 192 active social networking websites. Bringing every kind of social  group together in one place and letting them interact is really a big thing indeed. Huge amount'}",Google Scholar
J Johansen,Towards Making Privacy Usable,,"A Privacy Label is a legally binding label containing information about the privacy that a  product or service provides. The labels may be physical or digital. They are defined, and are",2022,NA,https://www.duo.uio.no/handle/10852/94329,"{'title': 'Towards Making Privacy Usable', 'author': ['J Johansen'], 'pub_year': '2022', 'venue': 'NA', 'abstract': 'A Privacy Label is a legally binding label containing information about the privacy that a  product or service provides. The labels may be physical or digital. They are defined, and are'}",Google Scholar
"P Lannerö, G Bernstein",Poster: CommonTerms-Magnifying the Fine Print,,"Standardize but embrace change The Privacy Label project has showed [10] that a  standardized selection, ordering and presentation of privacy terms can significantly enhance",NA,NA,https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=03ec1ad09a2667c1e2664bf77959bd0ed4b2cf38,"{'title': 'Poster: CommonTerms-Magnifying the Fine Print', 'author': ['P Lannerö', 'G Bernstein'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': 'Standardize but embrace change The Privacy Label project has showed [10] that a  standardized selection, ordering and presentation of privacy terms can significantly enhance'}",Google Scholar
"J Dev, L Kisselburgh",Privacy and Respectful Discourse in {AI} Chatbots,,"data collection and use practices to generate a “privacy label” for their applications. The use  of  us to develop an enhanced software tool, Privacy Label Wiz, that more closely resembles",2022,NA,https://www.usenix.org/conference/pepr22/conference-program,"{'title': 'Privacy and Respectful Discourse in {AI} Chatbots', 'author': ['J Dev', 'L Kisselburgh'], 'pub_year': '2022', 'venue': 'NA', 'abstract': 'data collection and use practices to generate a “privacy label” for their applications. The use  of  us to develop an enhanced software tool, Privacy Label Wiz, that more closely resembles'}",Google Scholar
LA Bygrave,Hardwiring privacy,,the different manifestations of privacy by design in policy documents leave open the  option of interpreting it as the collection and processing of any data – but with a privacy label.,2017,The Oxford Handbook of the Law and Regulation of …,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2901405,"{'title': 'Hardwiring privacy', 'author': ['LA Bygrave'], 'pub_year': '2017', 'venue': 'The Oxford Handbook of the Law and Regulation of …', 'abstract': 'the different manifestations of privacy by design in policy documents leave open the  option of interpreting it as the collection and processing of any data – but with a privacy label.'}",Google Scholar
J Zhong,Enforcing privacy via access control and data perturbation.,,"This section explained how the subject privacy label and object privacy label help to  calculate the subject’s final proper permissions over the requested object, and the solution for",2013,NA,https://researchrepository.rmit.edu.au/esploro/outputs/9921861599201341?institution=61RMIT_INST&skipUsageReporting=true&recordUsage=false,"{'title': 'Enforcing privacy via access control and data perturbation.', 'author': ['J Zhong'], 'pub_year': '2013', 'venue': 'NA', 'abstract': 'This section explained how the subject privacy label and object privacy label help to  calculate the subject’s final proper permissions over the requested object, and the solution for'}",Google Scholar
"L Edwards, W Abel",The use of privacy icons and standard contract terms for generating consumer trust and confidence in digital services,,"1 EXECUTIVE SUMMARY In the wake of the Snowden revelations about covert state access  to consumer data stored in the cloud, consumer confidence about the handling of their",2014,CREATe Working Paper Series,https://core.ac.uk/download/pdf/30441688.pdf,"{'title': 'The use of privacy icons and standard contract terms for generating consumer trust and confidence in digital services', 'author': ['L Edwards', 'W Abel'], 'pub_year': '2014', 'venue': 'CREATe Working Paper Series', 'abstract': '1 EXECUTIVE SUMMARY In the wake of the Snowden revelations about covert state access  to consumer data stored in the cloud, consumer confidence about the handling of their'}",Google Scholar
"J Mahler, B Hou, S Niyaz, FT Pokorny, R Chandra",Privacy-Preserving Cloud-Based Grasp Planning,,"triangles of the masked mesh using primal triangular quadrisection [32] until the maximum  edge length of each triangle is less than some threshold ∈, transferring the privacy label Z(ti)",NA,NA,https://goldberg.berkeley.edu/pubs/case2016-privacy-preserving-grasp-planning-submitted.pdf,"{'title': 'Privacy-Preserving Cloud-Based Grasp Planning', 'author': ['J Mahler', 'B Hou', 'S Niyaz', 'FT Pokorny', 'R Chandra'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': 'triangles of the masked mesh using primal triangular quadrisection [32] until the maximum  edge length of each triangle is less than some threshold ∈, transferring the privacy label Z(ti)'}",Google Scholar
CR Thambirajah,Assessment of Measurable Privacy for IoT Consumer Products,,the continuing development of a Privacy Label to present to  order to create a presentable  Privacy Label for consumers [26] project in order to be able to present such a Privacy Label.,2019,NA,https://www.duo.uio.no/handle/10852/69042,"{'title': 'Assessment of Measurable Privacy for IoT Consumer Products', 'author': ['CR Thambirajah'], 'pub_year': '2019', 'venue': 'NA', 'abstract': 'the continuing development of a Privacy Label to present to  order to create a presentable  Privacy Label for consumers [26] project in order to be able to present such a Privacy Label.'}",Google Scholar
M Saginatham,A Framework of Comparing Privacy Policies for Smart Home Devices,,"In the future, we plan to conduct al the surveys and use the survey results as a basis to create  a privacy label visualization that addresses users' concerns as well as limitations of current",2020,NA,https://ir.library.oregonstate.edu/concern/graduate_thesis_or_dissertations/cn69mb541,"{'title': 'A Framework of Comparing Privacy Policies for Smart Home Devices', 'author': ['M Saginatham'], 'pub_year': '2020', 'venue': 'NA', 'abstract': ""In the future, we plan to conduct al the surveys and use the survey results as a basis to create  a privacy label visualization that addresses users' concerns as well as limitations of current""}",Google Scholar
"SI Sherwani, BR Bates","Role of wearable technology and fitness apps in obesity and diabetes: privacy, ownership, and portability of data",,"On the Privacy Label, Strava clearly indicates that it shares and sells aggregate information  and that it retains personal data as long as necessary unless the consumer requests for",2021,… Personal Information Sharing on Health and …,https://www.igi-global.com/chapter/role-of-wearable-technology-and-fitness-apps-in-obesity-and-diabetes/261904,"{'title': 'Role of wearable technology and fitness apps in obesity and diabetes: privacy, ownership, and portability of data', 'author': ['SI Sherwani', 'BR Bates'], 'pub_year': '2021', 'venue': '… Personal Information Sharing on Health and …', 'abstract': 'On the Privacy Label, Strava clearly indicates that it shares and sells aggregate information  and that it retains personal data as long as necessary unless the consumer requests for'}",Google Scholar
"M Taherisadr, S Elmalaki",HILT: Personalized and Adaptive Privacy-Aware Early-Exit for Reinforcement Learning in Human-in-the-Loop Systems,,The intuition is that we want to give each EE branch two labels: a utility label and a  privacy label. Each label can take a value of “1” or “0” to indicate if a particular EE satisfies a,2024,arXiv preprint arXiv:2403.05864,https://arxiv.org/abs/2403.05864,"{'title': 'HILT: Personalized and Adaptive Privacy-Aware Early-Exit for Reinforcement Learning in Human-in-the-Loop Systems', 'author': ['M Taherisadr', 'S Elmalaki'], 'pub_year': '2024', 'venue': 'arXiv preprint arXiv:2403.05864', 'abstract': 'The intuition is that we want to give each EE branch two labels: a utility label and a  privacy label. Each label can take a value of “1” or “0” to indicate if a particular EE satisfies a'}",Google Scholar
K Zhang,Towards Data Privacy and Utility in the Applications of Graph Neural Networks,,"Because we want to exclude the private information in the graph embedding, a privacy label  that represents that information explicitly should be provided to the decoder. However, each",2023,NA,https://scholarworks.gsu.edu/cs_diss/208/,"{'title': 'Towards Data Privacy and Utility in the Applications of Graph Neural Networks', 'author': ['K Zhang'], 'pub_year': '2023', 'venue': 'NA', 'abstract': 'Because we want to exclude the private information in the graph embedding, a privacy label  that represents that information explicitly should be provided to the decoder. However, each'}",Google Scholar
R Kesler,The Impact of Apple's App Tracking Transparency on App Monetization,,"We include the alternative payment option and the presence of a privacy label (for Apple-only  samples) as explanatory variables and employ app fixed effects. Additionally, we include",2022,Available at SSRN 4090786,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4090786,"{'title': ""The Impact of Apple's App Tracking Transparency on App Monetization"", 'author': ['R Kesler'], 'pub_year': '2022', 'venue': 'Available at SSRN 4090786', 'abstract': 'We include the alternative payment option and the presence of a privacy label (for Apple-only  samples) as explanatory variables and employ app fixed effects. Additionally, we include'}",Google Scholar
"R Zhao, Y Zhang, T Wang, W Wen, Y Xiang",Visual content privacy protection: A survey,,"Meanwhile, the scheme based on privacy label training are difficult to generalize since  privacy may still be implied in other information. Dave et al. [124] proposed a self-supervised",2023,arXiv preprint arXiv …,https://arxiv.org/abs/2303.16552,"{'title': 'Visual content privacy protection: A survey', 'author': ['R Zhao', 'Y Zhang', 'T Wang', 'W Wen', 'Y Xiang'], 'pub_year': '2023', 'venue': 'arXiv preprint arXiv …', 'abstract': 'Meanwhile, the scheme based on privacy label training are difficult to generalize since  privacy may still be implied in other information. Dave et al. [124] proposed a self-supervised'}",Google Scholar
"M Srinath, P Venkit, M Badillo, F Schaub",Automated Detection and Analysis of Data Practices Using A Real-World Corpus,,• We design a privacy label to provide users with information regarding their data privacy at   Figure 2: Privacy label with varying information levels. Detailed information access by the,2024,arXiv preprint arXiv …,https://arxiv.org/abs/2402.11006,"{'title': 'Automated Detection and Analysis of Data Practices Using A Real-World Corpus', 'author': ['M Srinath', 'P Venkit', 'M Badillo', 'F Schaub'], 'pub_year': '2024', 'venue': 'arXiv preprint arXiv …', 'abstract': '• We design a privacy label to provide users with information regarding their data privacy at   Figure 2: Privacy label with varying information levels. Detailed information access by the'}",Google Scholar
C Renner,Privacy in online social networks,,Similar to the nutrition facts label this privacy label shows the user how an Internet site treats  the user’s data. In contrast to the privacy policies used today such as P3P [20] such a label,2010,"Swiss Federal Institute of Tech., Zurich",https://pub.tik.ee.ethz.ch/students/2009-HS/MA-2009-11.pdf,"{'title': 'Privacy in online social networks', 'author': ['C Renner'], 'pub_year': '2010', 'venue': 'Swiss Federal Institute of Tech., Zurich', 'abstract': 'Similar to the nutrition facts label this privacy label shows the user how an Internet site treats  the user’s data. In contrast to the privacy policies used today such as P3P [20] such a label'}",Google Scholar
EA Brown,The Fitbit fault line: two proposals to protect health and fitness data at work,,"If the FDA can adapt labeling requirements to help consumers make more informed  choices, it stands to reason that the FTC can develop privacy label requirements for health-related",2016,Yale J. Health Pol'y L. & Ethics,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/yjhple16&section=5,"{'title': 'The Fitbit fault line: two proposals to protect health and fitness data at work', 'author': ['EA Brown'], 'pub_year': '2016', 'venue': ""Yale J. Health Pol'y L. & Ethics"", 'abstract': 'If the FDA can adapt labeling requirements to help consumers make more informed  choices, it stands to reason that the FTC can develop privacy label requirements for health-related'}",Google Scholar
"RMK van Dijk, D Gawehns",Wearda: Recording wearable sensor data for human activity monitoring,,", the sensor values are enriched with a privacy label indicating that the watch was inside the   preservation data can not be collected and the privacy label is ‘?’. After data collection, the",2023,Journal of …,https://scholarlypublications.universiteitleiden.nl/access/item%3A3656626/download,"{'title': 'Wearda: Recording wearable sensor data for human activity monitoring', 'author': ['RMK van Dijk', 'D Gawehns'], 'pub_year': '2023', 'venue': 'Journal of …', 'abstract': ', the sensor values are enriched with a privacy label indicating that the watch was inside the   preservation data can not be collected and the privacy label is ‘?’. After data collection, the'}",Google Scholar
"SR Chowdhury, X Zhou",Differentially private reward estimation with preference feedback,,Learning from preference-based feedback has recently gained considerable traction as a  promising approach to align generative models with human interests. Instead of relying on,2024,… Conference on Artificial …,https://proceedings.mlr.press/v238/ray-chowdhury24a.html,"{'title': 'Differentially private reward estimation with preference feedback', 'author': ['SR Chowdhury', 'X Zhou'], 'pub_year': '2024', 'venue': '… Conference on Artificial …', 'abstract': 'Learning from preference-based feedback has recently gained considerable traction as a  promising approach to align generative models with human interests. Instead of relying on'}",Google Scholar
"S Pan, Z Tao, T Hoang, D Zhang, Z Xing, X Xu",\textsc {SeePrivacy}: Automated Contextual Privacy Policy Generation for Mobile Applications,,"Privacy policies have become the most critical approach to safeguarding individuals' privacy  and digital security. To enhance their presentation and readability, researchers propose the",2023,arXiv preprint arXiv …,https://arxiv.org/abs/2307.01691,"{'title': '\\textsc {SeePrivacy}: Automated Contextual Privacy Policy Generation for Mobile Applications', 'author': ['S Pan', 'Z Tao', 'T Hoang', 'D Zhang', 'Z Xing', 'X Xu'], 'pub_year': '2023', 'venue': 'arXiv preprint arXiv …', 'abstract': ""Privacy policies have become the most critical approach to safeguarding individuals' privacy  and digital security. To enhance their presentation and readability, researchers propose the""}",Google Scholar
"Q Zhang, F He, J Gu, B Gu, C Deng, H Huang, D Tao",BAMBI: Vertical Federated Bilevel Optimization with Privacy-Preserving and Computation Efficiency,,"Vertical federated learning (VFL) has shown promising in meeting the vast demands of multi-party  privacy-preserving learning. However, existing VFL methods are not applicable to",2022,NA,https://openreview.net/forum?id=pO7KggcbMiP,"{'title': 'BAMBI: Vertical Federated Bilevel Optimization with Privacy-Preserving and Computation Efficiency', 'author': ['Q Zhang', 'F He', 'J Gu', 'B Gu', 'C Deng', 'H Huang', 'D Tao'], 'pub_year': '2022', 'venue': 'NA', 'abstract': 'Vertical federated learning (VFL) has shown promising in meeting the vast demands of multi-party  privacy-preserving learning. However, existing VFL methods are not applicable to'}",Google Scholar
"D Liu, Y Xiao, C Zhang, K Xie, X Bai, S Zhang, L Xing",iHunter: Hunting Privacy Violations at Scale in the Software Supply Chain on iOS,,"privacy label, we check whether the data is in the app’s privacy label, if it is, we regard the  app’s privacy label  We observed that 469 apps omit 593 data in their privacy label disclosure,",NA,NA,https://www.usenix.org/system/files/sec24fall-prepub-85-liu-dexin.pdf,"@inproceedings {298110,
	author = {Dexin Liu and Yue Xiao and Chaoqi Zhang and Kaitao Xie and Xiaolong Bai and Shikun Zhang and Luyi Xing},
	title = {{iHunter}: Hunting Privacy Violations at Scale in the Software Supply Chain on {iOS}},
	booktitle = {33rd USENIX Security Symposium (USENIX Security 24)},
	year = {2024},
	isbn = {978-1-939133-44-1},
	address = {Philadelphia, PA},
	pages = {5663--5680},
	url = {https://www.usenix.org/conference/usenixsecurity24/presentation/liu-dexin},
	publisher = {USENIX Association},
	month = aug
}
",Google Scholar
"AM McDonald, T Lowenthal",Nano-notice: Privacy disclosure at a mobile scale,,"How can meaningful privacy policies best be provided to users of mobile devices with small  screens? “Natural language” policies are far too long, according to the authors, so many app",2013,Journal of …,https://scholarlypublishingcollective.org/psup/information-policy/article-abstract/3/1/331/314353,"{'title': 'Nano-notice: Privacy disclosure at a mobile scale', 'author': ['AM McDonald', 'T Lowenthal'], 'pub_year': '2013', 'venue': 'Journal of …', 'abstract': 'How can meaningful privacy policies best be provided to users of mobile devices with small  screens? “Natural language” policies are far too long, according to the authors, so many app'}",Google Scholar
"JM Chang, D Zhuang, G Samaraweera",Privacy-preserving Machine Learning,,For datasets that have samples with two labels—a utility label and a privacy label—Kung [15]  proposes a dimensionality reduction method that enables the data owner to project their,2023,NA,https://books.google.com/books?hl=en&lr=&id=ioK3EAAAQBAJ&oi=fnd&pg=PA1&dq=%22privacy+label%22&ots=AySunU5igg&sig=Slq9hXeMUjOq15jH-Jdz-Y3rW9w,"{'title': 'Privacy-preserving Machine Learning', 'author': ['JM Chang', 'D Zhuang', 'G Samaraweera'], 'pub_year': '2023', 'venue': 'NA', 'abstract': 'For datasets that have samples with two labels—a utility label and a privacy label—Kung [15]  proposes a dimensionality reduction method that enables the data owner to project their'}",Google Scholar
"V Morel, R Pardo",Three dimensions of privacy policies,,"[65] conducted a user study, to refine their privacy label. They compared the accuracy of  information retrieval between their proposition and natural language privacy policies in natural",2019,arXiv preprint arXiv:1908.06814,https://www.researchgate.net/profile/Raul-Pardo/publication/335257756_SoK_Three_Facets_of_Privacy_Policies/links/5ddbc70b92851c1fedafc762/SoK-Three-Facets-of-Privacy-Policies.pdf,"{'title': 'Three dimensions of privacy policies', 'author': ['V Morel', 'R Pardo'], 'pub_year': '2019', 'venue': 'arXiv preprint arXiv:1908.06814', 'abstract': '[65] conducted a user study, to refine their privacy label. They compared the accuracy of  information retrieval between their proposition and natural language privacy policies in natural'}",Google Scholar
"S Kariyappa, MK Qureshi",Exploit: Extracting private labels in split learning,,"Split learning is a popular technique used to perform vertical federated learning, where the  goal is to jointly train a model on the private input and label data held by two parties. To",2023,2023 IEEE conference on secure …,https://ieeexplore.ieee.org/abstract/document/10136175/,"{'title': 'Exploit: Extracting private labels in split learning', 'author': ['S Kariyappa', 'MK Qureshi'], 'pub_year': '2023', 'venue': '2023 IEEE conference on secure …', 'abstract': 'Split learning is a popular technique used to perform vertical federated learning, where the  goal is to jointly train a model on the private input and label data held by two parties. To'}",Google Scholar
EA Bello-Ogunu,A framework for user-centric privacy management in smartphones regarding bluetooth low energy beacons,,"The last step required users to provide a privacy label for a beacon, which involved a few  questions, as shown in 12e, regarding the “sensitivity” based on the selected category. In this",2016,NA,https://search.proquest.com/openview/c518ffb9a2ec90af8a851c75184adf44/1?pq-origsite=gscholar&cbl=18750,"{'title': 'A framework for user-centric privacy management in smartphones regarding bluetooth low energy beacons', 'author': ['EA Bello-Ogunu'], 'pub_year': '2016', 'venue': 'NA', 'abstract': 'The last step required users to provide a privacy label for a beacon, which involved a few  questions, as shown in 12e, regarding the “sensitivity” based on the selected category. In this'}",Google Scholar
SA Hartman,"Privacy, Personhood, and the Courts: FOIA Exemption 7 (C) in Context",,"The first basis for critique-that the ""privacy"" label fails to describe accurately how the court  assesses the coverage of the Fourth Amendmentarises from the observation that a significant",2010,Yale LJ,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/ylr120&section=13,"{'title': 'Privacy, Personhood, and the Courts: FOIA Exemption 7 (C) in Context', 'author': ['SA Hartman'], 'pub_year': '2010', 'venue': 'Yale LJ', 'abstract': 'The first basis for critique-that the ""privacy"" label fails to describe accurately how the court  assesses the coverage of the Fourth Amendmentarises from the observation that a significant'}",Google Scholar
M Al,Scalable building blocks for privacy enhancing machine learning,,"sN ] are reserved for the utility and privacy label matrices, respectively, where {yi}N  If the  utility and privacy labels are scalars, we denote the utility and privacy label vectors as y and s,",2020,NA,https://search.proquest.com/openview/cec2098967079a803ed3719ae57b1dd8/1?pq-origsite=gscholar&cbl=44156,"{'title': 'Scalable building blocks for privacy enhancing machine learning', 'author': ['M Al'], 'pub_year': '2020', 'venue': 'NA', 'abstract': 'sN ] are reserved for the utility and privacy label matrices, respectively, where {yi}N  If the  utility and privacy labels are scalars, we denote the utility and privacy label vectors as y and s,'}",Google Scholar
"N Iacob, F Simonelli",Towards a European health data ecosystem,,"To increase transparency and address potential concerns around data privacy and security,  introducing a “privacy label” for health apps should be considered. Such a label could",2020,European Journal of Risk Regulation,https://www.cambridge.org/core/journals/european-journal-of-risk-regulation/article/towards-a-european-health-data-ecosystem/9738719CD715D14FF71F621E9E00EA78,"{'title': 'Towards a European health data ecosystem', 'author': ['N Iacob', 'F Simonelli'], 'pub_year': '2020', 'venue': 'European Journal of Risk Regulation', 'abstract': 'To increase transparency and address potential concerns around data privacy and security,  introducing a “privacy label” for health apps should be considered. Such a label could'}",Google Scholar
MS Mahmud,TRADE-OFF ANALYSIS OF RELATIONAL DATABASE STORAGE FOR PRIVACY PURPOSES,,"In our study, we will focus on the privacy label for RBAC and the efficient storage scheme  for extended RBAC with Privacy labels. Here, we will focus on attributebased labelling. In MAC",2011,NA,https://ir.lib.uwo.ca/digitizedtheses/3595/,"{'title': 'TRADE-OFF ANALYSIS OF RELATIONAL DATABASE STORAGE FOR PRIVACY PURPOSES', 'author': ['MS Mahmud'], 'pub_year': '2011', 'venue': 'NA', 'abstract': 'In our study, we will focus on the privacy label for RBAC and the efficient storage scheme  for extended RBAC with Privacy labels. Here, we will focus on attributebased labelling. In MAC'}",Google Scholar
"P Ruotsalainen, P Pharow, F Petersen",Privacy Management and Networked PPD Systems-Challenges Solutions.,,Privacy label approach is a simplified policy solution where data elements are tagged  with privacy labels and the labels is linked to corresponding policy rules stored at the level of,2015,pHealth,https://books.google.com/books?hl=en&lr=&id=IzgxCgAAQBAJ&oi=fnd&pg=PA271&dq=%22privacy+label%22&ots=odtm3a9Li3&sig=4zKNp1oj8w3okaD28PmXVNYDpZk,"{'title': 'Privacy Management and Networked PPD Systems-Challenges Solutions.', 'author': ['P Ruotsalainen', 'P Pharow', 'F Petersen'], 'pub_year': '2015', 'venue': 'pHealth', 'abstract': 'Privacy label approach is a simplified policy solution where data elements are tagged  with privacy labels and the labels is linked to corresponding policy rules stored at the level of'}",Google Scholar
"U Salama, L Yao, H Paik",An internet of things based multi-level privacy-preserving access control for smart living,,The presence of the Internet of Things (IoT) in healthcare through the use of mobile medical  applications and wearable devices allows patients to capture their healthcare data and,2018,Informatics,https://www.mdpi.com/2227-9709/5/2/23,"{'title': 'An internet of things based multi-level privacy-preserving access control for smart living', 'author': ['U Salama', 'L Yao', 'H Paik'], 'pub_year': '2018', 'venue': 'Informatics', 'abstract': 'The presence of the Internet of Things (IoT) in healthcare through the use of mobile medical  applications and wearable devices allows patients to capture their healthcare data and'}",Google Scholar
"MM Lotan, NN Patil",Issues and Challenges Faced by Mobile Application Users and Developers,,"unexplored, Researcher use the policy of privacy label disclosure to assess the impact of   strategies, and that the revelation of a privacy label to do so decreases app demands. When an",2023,Journal of Mobile Computing …,https://www.researchgate.net/profile/Makarand-Mali/publication/374476366_Issues_and_Challenges_Faced_by_Mobile_Application_Users_and_Developers/links/651f8362d717ef1293cf2b24/Issues-and-Challenges-Faced-by-Mobile-Application-Users-and-Developers.pdf,"{'title': 'Issues and Challenges Faced by Mobile Application Users and Developers', 'author': ['MM Lotan', 'NN Patil'], 'pub_year': '2023', 'venue': 'Journal of Mobile Computing …', 'abstract': 'unexplored, Researcher use the policy of privacy label disclosure to assess the impact of   strategies, and that the revelation of a privacy label to do so decreases app demands. When an'}",Google Scholar
"S Zerr, S Siersdorfer, J Hare, E Demidova",I Know What You Did Last Summer!: Privacy-Aware Image Classification and Search,,"the privacy label assignments, each photo was shown to at least two different users. In case  of a disagreement, the photo was queued to be shown to additional users. Users gathered",NA,Proceedings of the 35th …,https://www.researchgate.net/profile/Jonathon-Hare/publication/266227104_I_Know_What_You_Did_Last_SummerPrivacy-Aware_Image_Classification_and_Search/links/54e506b30cf276cec172f4d0/I-Know-What-You-Did-Last-SummerPrivacy-Aware-Image-Classification-and-Search.pdf,"{'title': 'I Know What You Did Last Summer!: Privacy-Aware Image Classification and Search', 'author': ['S Zerr', 'S Siersdorfer', 'J Hare', 'E Demidova'], 'pub_year': 'NA', 'venue': 'Proceedings of the 35th …', 'abstract': 'the privacy label assignments, each photo was shown to at least two different users. In case  of a disagreement, the photo was queued to be shown to additional users. Users gathered'}",Google Scholar
DJ Solove,Against Privacy Essentialism,,"In this essay, Daniel Solove responds to Maria Angel and Ryan Calo’s critique of his theory  of privacy. In their article, Distinguishing Privacy Law: A Critique of Privacy as Social",2024,GWU Legal Studies Research Paper Forthcoming,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4826385,"{'title': 'Against Privacy Essentialism', 'author': ['DJ Solove'], 'pub_year': '2024', 'venue': 'GWU Legal Studies Research Paper Forthcoming', 'abstract': 'In this essay, Daniel Solove responds to Maria Angel and Ryan Calo’s critique of his theory  of privacy. In their article, Distinguishing Privacy Law: A Critique of Privacy as Social'}",Google Scholar
"S Barth, T Ngo, MDT De Jong",Toward an understanding of online privacy perceptions: Using the Q-sort method to identify different user perspectives,,"Second, the privacy label should particularly focus on the types of data collected (what) and  the way this personal information is processed (how). The parties involved in the handling of",2021,AND EVEN MORE …,https://research.utwente.nl/files/283738090/PhD_Thesis_Susanne_Barth.pdf#page=120,"{'title': 'Toward an understanding of online privacy perceptions: Using the Q-sort method to identify different user perspectives', 'author': ['S Barth', 'T Ngo', 'MDT De Jong'], 'pub_year': '2021', 'venue': 'AND EVEN MORE …', 'abstract': 'Second, the privacy label should particularly focus on the types of data collected (what) and  the way this personal information is processed (how). The parties involved in the handling of'}",Google Scholar
"AR Khan, HU Manzoor, F Ayaz, MA Imran, A Zoha",A privacy and energy-aware federated framework for human activity recognition,,"Human activity recognition (HAR) using wearable sensors enables continuous monitoring  for healthcare applications. However, the conventional centralised training of deep learning",2023,Sensors,https://www.mdpi.com/1424-8220/23/23/9339,"{'title': 'A privacy and energy-aware federated framework for human activity recognition', 'author': ['AR Khan', 'HU Manzoor', 'F Ayaz', 'MA Imran', 'A Zoha'], 'pub_year': '2023', 'venue': 'Sensors', 'abstract': 'Human activity recognition (HAR) using wearable sensors enables continuous monitoring  for healthcare applications. However, the conventional centralised training of deep learning'}",Google Scholar
"B Ando, C Valente",Balancing AI and Privacy: Cross-Border Perspectives,,This author singled out under the privacy's label four causes of action aimed at safeguarding  different personal interests:9 intrusion upon seclusion; disclosure of private facts; false light,2023,Collection Papers from Conf. Org. on Occasion Day …,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/cnopsfmt2023&section=64,"{'title': 'Balancing AI and Privacy: Cross-Border Perspectives', 'author': ['B Ando', 'C Valente'], 'pub_year': '2023', 'venue': 'Collection Papers from Conf. Org. on Occasion Day …', 'abstract': ""This author singled out under the privacy's label four causes of action aimed at safeguarding  different personal interests:9 intrusion upon seclusion; disclosure of private facts; false light""}",Google Scholar
"A Kochhar, A Khanna",Privacy and Security Issues in Cloud Computing,,"The cloud privacy label (CPL) is added to identity management to protect cloud users. Here  every user has been allotted several attributes for authentication of their identity, which are",2020,Applications of Cloud Computing,https://www.taylorfrancis.com/chapters/edit/10.1201/9781003025696-7/privacy-security-issues-cloud-computing-akanksha-kochhar-anubha-khanna,"{'title': 'Privacy and Security Issues in Cloud Computing', 'author': ['A Kochhar', 'A Khanna'], 'pub_year': '2020', 'venue': 'Applications of Cloud Computing', 'abstract': 'The cloud privacy label (CPL) is added to identity management to protect cloud users. Here  every user has been allotted several attributes for authentication of their identity, which are'}",Google Scholar
"M Stewart, P Warden, Y Omri, S Prakash",Datasheets for Machine Learning Sensors,,"The IoT security and privacy label is aimed at enhancing consumer awareness and  For  our ML sensor, the IoT security and privacy label is shows that there is only a camera on the",2023,arXiv preprint arXiv …,https://arxiv.org/abs/2306.08848,"{'title': 'Datasheets for Machine Learning Sensors', 'author': ['M Stewart', 'P Warden', 'Y Omri', 'S Prakash'], 'pub_year': '2023', 'venue': 'arXiv preprint arXiv …', 'abstract': 'The IoT security and privacy label is aimed at enhancing consumer awareness and  For  our ML sensor, the IoT security and privacy label is shows that there is only a camera on the'}",Google Scholar
M Watney,Mobile Phone Surveillance: An Overview of Privacy and Security Legal Risks,,"Any new or updated app must include a privacy label, otherwise it will not be available  on the App Store. This requirement applies not just to third-party apps but to Apple's own",2021,European Conference on Cyber Warfare and …,https://books.google.com/books?hl=en&lr=&id=wCo4EAAAQBAJ&oi=fnd&pg=PA462&dq=%22privacy+label%22&ots=_XTdvkgGZM&sig=tvIH-xt91-hxRcz3SRDnlLuQ0fg,"{'title': 'Mobile Phone Surveillance: An Overview of Privacy and Security Legal Risks', 'author': ['M Watney'], 'pub_year': '2021', 'venue': 'European Conference on Cyber Warfare and …', 'abstract': ""Any new or updated app must include a privacy label, otherwise it will not be available  on the App Store. This requirement applies not just to third-party apps but to Apple's own""}",Google Scholar
"R Das Chaudhury, C Choe",Digital privacy: GDPR and its lessons for Australia,,"Somewhat related, Apple's release of privacy label requirements in 2020 is shown to have  resulted in a decrease in iOS app downloads and app developers' revenue, but smaller firms",2023,Australian Economic Review,https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-8462.12506,"{'title': 'Digital privacy: GDPR and its lessons for Australia', 'author': ['R Das Chaudhury', 'C Choe'], 'pub_year': '2023', 'venue': 'Australian Economic Review', 'abstract': ""Somewhat related, Apple's release of privacy label requirements in 2020 is shown to have  resulted in a decrease in iOS app downloads and app developers' revenue, but smaller firms""}",Google Scholar
S Treiber,Smart home privacy leaks,,"Customers did not only understand it more accurately than a privacy policy, they also were  more confident in understanding this standardized privacy label, further they were faster",2021,NA,https://appsec.at/publication/treiber-2021-smart/treiber-2021-smart.pdf,"{'title': 'Smart home privacy leaks', 'author': ['S Treiber'], 'pub_year': '2021', 'venue': 'NA', 'abstract': 'Customers did not only understand it more accurately than a privacy policy, they also were  more confident in understanding this standardized privacy label, further they were faster'}",Google Scholar
"G Liu, X Sun, Y Li, H Li, S Zhao, Z Guo",An Automatic Privacy-Aware Framework for Text Data in Online Social Network Based on a Multi-Deep Learning Model,,"With the increasing severity of user privacy leaks in online social networks (OSNs), existing  privacy protection technologies have difficulty meeting the diverse privacy protection needs",2023,International Journal of …,https://www.hindawi.com/journals/ijis/2023/1727285/,"{'title': 'An Automatic Privacy-Aware Framework for Text Data in Online Social Network Based on a Multi-Deep Learning Model', 'author': ['G Liu', 'X Sun', 'Y Li', 'H Li', 'S Zhao', 'Z Guo'], 'pub_year': '2023', 'venue': 'International Journal of …', 'abstract': 'With the increasing severity of user privacy leaks in online social networks (OSNs), existing  privacy protection technologies have difficulty meeting the diverse privacy protection needs'}",Google Scholar
SC Robinson,Self-disclosure and managing privacy: Implications for interpersonal and online communication for consumers and marketers,,"Since privacy policies and software license agreements may be skimmed over by users,  it has been advised that creation of a privacy label may act similar to nutrition labels, where",2017,Journal of Internet Commerce,https://www.tandfonline.com/doi/abs/10.1080/15332861.2017.1402637,"{'title': 'Self-disclosure and managing privacy: Implications for interpersonal and online communication for consumers and marketers', 'author': ['SC Robinson'], 'pub_year': '2017', 'venue': 'Journal of Internet Commerce', 'abstract': 'Since privacy policies and software license agreements may be skimmed over by users,  it has been advised that creation of a privacy label may act similar to nutrition labels, where'}",Google Scholar
"SE Carter, M d'Aquin, D Spagnuelo, I Tiddi",The Privacy-Value-App Relationship and the Value-Centered Privacy Assistant,,"To measure values, we utilized a modified version of the Short Schwartz Value Survey (SSVS)  and the Apple Privacy Label ontology to measure privacy preferences. These results were",2023,arXiv preprint arXiv …,https://arxiv.org/abs/2308.05700,"{'title': 'The Privacy-Value-App Relationship and the Value-Centered Privacy Assistant', 'author': ['SE Carter', ""M d'Aquin"", 'D Spagnuelo', 'I Tiddi'], 'pub_year': '2023', 'venue': 'arXiv preprint arXiv …', 'abstract': 'To measure values, we utilized a modified version of the Short Schwartz Value Survey (SSVS)  and the Apple Privacy Label ontology to measure privacy preferences. These results were'}",Google Scholar
"Y Xu, MJ Lee",Shopping as a Social Activity: Understanding People's Categorical Item Sharing Preferences on Social Networks.,,"For example, we removed the “privacy” label item during the first iteration of factor reduction  analysis, as the communality was 0.29 (<0.4). We then performed the second iteration with",2018,IUI Workshops,https://www.gidgetlab.com/publications/Xu2018_SocialShoppingActivity.pdf,"{'title': ""Shopping as a Social Activity: Understanding People's Categorical Item Sharing Preferences on Social Networks."", 'author': ['Y Xu', 'MJ Lee'], 'pub_year': '2018', 'venue': 'IUI Workshops', 'abstract': 'For example, we removed the “privacy” label item during the first iteration of factor reduction  analysis, as the communality was 0.29 (<0.4). We then performed the second iteration with'}",Google Scholar
"PJ Caven, S Gopavaram, J Dev",SoK: Anatomy of Effective Cybersecurity Label Development,,"corporate America, and various NGOs about what should be presented on a security and  privacy label [38]. Based on this survey and other studies, they proposed an example of an IoT",2023,Available at SSRN …,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4591786,"{'title': 'SoK: Anatomy of Effective Cybersecurity Label Development', 'author': ['PJ Caven', 'S Gopavaram', 'J Dev'], 'pub_year': '2023', 'venue': 'Available at SSRN …', 'abstract': 'corporate America, and various NGOs about what should be presented on a security and  privacy label [38]. Based on this survey and other studies, they proposed an example of an IoT'}",Google Scholar
"L Berry, L Van der Werff, T Lynn",Rebuilding and Engendering Trust in the Retail Banking Environment: The Role of a Trust Label,,The concept has been adapted to a standardised banking privacy label (Kleimann 2006)  and standardised online privacy label (Kelley et al 2009). More recent research by Lynn at al. (,2015,Conference Paper. September,https://www.researchgate.net/profile/Theodore-Lynn/publication/281785309_Rebuilding_and_Engendering_Trust_in_the_Retail_Banking_Environment_The_Role_of_a_Trust_Label/links/55f88e8c08aec948c4811199/Rebuilding-and-Engendering-Trust-in-the-Retail-Banking-Environment-The-Role-of-a-Trust-Label.pdf,"{'title': 'Rebuilding and Engendering Trust in the Retail Banking Environment: The Role of a Trust Label', 'author': ['L Berry', 'L Van der Werff', 'T Lynn'], 'pub_year': '2015', 'venue': 'Conference Paper. September', 'abstract': 'The concept has been adapted to a standardised banking privacy label (Kleimann 2006)  and standardised online privacy label (Kelley et al 2009). More recent research by Lynn at al. ('}",Google Scholar
B Kaplan,Device discovery and identification with multipurpose privacy tags,,"This website may resemble a privacy label, be as simple as its Amazon sales page, or a  custom page that includes detailed specifications about the attached thing. The identification",2022,NA,https://www.ideals.illinois.edu/items/125012,"{'title': 'Device discovery and identification with multipurpose privacy tags', 'author': ['B Kaplan'], 'pub_year': '2022', 'venue': 'NA', 'abstract': 'This website may resemble a privacy label, be as simple as its Amazon sales page, or a  custom page that includes detailed specifications about the attached thing. The identification'}",Google Scholar
"Y Long, X Luo, Y Zhu, KP Lee",Data Transparency Design in Internet of Things: A Systematic Review,,"Several privacy label design patterns have been proposed in Perera et al. (Citation2020)   This information could be presented on a privacy label, as done in Das et al. (Citation2018),",2023,International Journal of …,https://www.tandfonline.com/doi/abs/10.1080/10447318.2023.2228997,"{'title': 'Data Transparency Design in Internet of Things: A Systematic Review', 'author': ['Y Long', 'X Luo', 'Y Zhu', 'KP Lee'], 'pub_year': '2023', 'venue': 'International Journal of …', 'abstract': 'Several privacy label design patterns have been proposed in Perera et al. (Citation2020)   This information could be presented on a privacy label, as done in Das et al. (Citation2018),'}",Google Scholar
N Wang,The Illusion of Privacy Control: The Case of Third-party Apps on Facebook,,"Little research examines the privacy threats associated with the use of third-party apps on  Facebook. To address this gap in the literature, we systematically study third-party apps'",2011,NA,https://etda.libraries.psu.edu/catalog/12372,"{'title': 'The Illusion of Privacy Control: The Case of Third-party Apps on Facebook', 'author': ['N Wang'], 'pub_year': '2011', 'venue': 'NA', 'abstract': ""Little research examines the privacy threats associated with the use of third-party apps on  Facebook. To address this gap in the literature, we systematically study third-party apps'""}",Google Scholar
C Chhetri,Designing for Privacy in Smart Home Devices,,One-sixth of the 20 billion Internet of Things (IoT) devices connecting to the Internet are  smart home devices (SHD) that provide home automation. These SHDs present privacy and,2022,NA,https://search.proquest.com/openview/e8566a4439c3b0a70b54bebd65a6be7a/1?pq-origsite=gscholar&cbl=18750&diss=y,"{'title': 'Designing for Privacy in Smart Home Devices', 'author': ['C Chhetri'], 'pub_year': '2022', 'venue': 'NA', 'abstract': 'One-sixth of the 20 billion Internet of Things (IoT) devices connecting to the Internet are  smart home devices (SHD) that provide home automation. These SHDs present privacy and'}",Google Scholar
FE Meymand,Domain Specific Analysis of Privacy Practices and Concerns in the Mobile Application Market,,"Based on our analysis, we suggest several design strategies to help app stores preserve  the credibility and utility of their privacy label systems.",2023,NA,https://search.proquest.com/openview/620459619d7b223440f51403e875c5b1/1?pq-origsite=gscholar&cbl=18750&diss=y,"{'title': 'Domain Specific Analysis of Privacy Practices and Concerns in the Mobile Application Market', 'author': ['FE Meymand'], 'pub_year': '2023', 'venue': 'NA', 'abstract': 'Based on our analysis, we suggest several design strategies to help app stores preserve  the credibility and utility of their privacy label systems.'}",Google Scholar
R Wu,Toward Trustworthy AI: Exploring Privacy and Robustness in Machine Learning Models,,"Machine learning has recently achieved significant milestones, resulting in potent  real-world applications such as chatbots, autonomous driving, and protein structure discovery",2023,NA,https://search.proquest.com/openview/ac08a72f6f9037210927258e63c990a4/1?pq-origsite=gscholar&cbl=18750&diss=y,"{'title': 'Toward Trustworthy AI: Exploring Privacy and Robustness in Machine Learning Models', 'author': ['R Wu'], 'pub_year': '2023', 'venue': 'NA', 'abstract': 'Machine learning has recently achieved significant milestones, resulting in potent  real-world applications such as chatbots, autonomous driving, and protein structure discovery'}",Google Scholar
"N Van Dijk, A Tanas, K Rommetveit",Right engineering? The redesign of privacy and personal data protection,,not acknowledge the level of specificity required by engineering’ where many decisions have  to be made all the time that ‘pass under the radar’ but ‘we still have to stick a “privacy label:,2018,International review of …,https://www.tandfonline.com/doi/abs/10.1080/13600869.2018.1457002,"{'title': 'Right engineering? The redesign of privacy and personal data protection', 'author': ['N Van Dijk', 'A Tanas', 'K Rommetveit'], 'pub_year': '2018', 'venue': 'International review of …', 'abstract': 'not acknowledge the level of specificity required by engineering’ where many decisions have  to be made all the time that ‘pass under the radar’ but ‘we still have to stick a “privacy label:'}",Google Scholar
RA Estrada,The Internet of Things (IoT): Privacy and Security Challenges and Discovering IoT Risks through Exploratory Research,,The purpose of this research was to examine Internet of Things (IoT) security challenges  and discovering IoT risks through exploratory research. This research focused on security,2022,NA,https://search.proquest.com/openview/fe6374afe13c2ee43a0646aa2daf0c0b/1?pq-origsite=gscholar&cbl=18750&diss=y,"{'title': 'The Internet of Things (IoT): Privacy and Security Challenges and Discovering IoT Risks through Exploratory Research', 'author': ['RA Estrada'], 'pub_year': '2022', 'venue': 'NA', 'abstract': 'The purpose of this research was to examine Internet of Things (IoT) security challenges  and discovering IoT risks through exploratory research. This research focused on security'}",Google Scholar
"J Zhang, J Hua, Y Chen, N Niu, C Liu",Mining User Privacy Concern Topics from App Reviews,,"Context: As mobile applications (Apps) widely spread over our society and life, various  personal information is constantly demanded by Apps in exchange for more intelligent and",2022,arXiv preprint arXiv:2212.09289,https://arxiv.org/abs/2212.09289,"{'title': 'Mining User Privacy Concern Topics from App Reviews', 'author': ['J Zhang', 'J Hua', 'Y Chen', 'N Niu', 'C Liu'], 'pub_year': '2022', 'venue': 'arXiv preprint arXiv:2212.09289', 'abstract': 'Context: As mobile applications (Apps) widely spread over our society and life, various  personal information is constantly demanded by Apps in exchange for more intelligent and'}",Google Scholar
"N Catano, V Kostakos, I Oakley",Poporo: A formal framework for social networking,,"This classification can be used to automatically assign a simple “Privacy” label (eg Green,  Yellow, Red) to 3rd party software or plug-ins that will be used by our formal specification",2009,Preliminary Proceedings of the …,https://www.academia.edu/download/42077346/Poporo_A_Formal_Framework_for_Social_Net20160204-22236-1fl1x5f.pdf#page=87,"{'title': 'Poporo: A formal framework for social networking', 'author': ['N Catano', 'V Kostakos', 'I Oakley'], 'pub_year': '2009', 'venue': 'Preliminary Proceedings of the …', 'abstract': 'This classification can be used to automatically assign a simple “Privacy” label (eg Green,  Yellow, Red) to 3rd party software or plug-ins that will be used by our formal specification'}",Google Scholar
"A Javanmard, M Fahrbach, V Mirrokni",PriorBoost: An Adaptive Algorithm for Learning from Aggregate Responses,,This work studies algorithms for learning from aggregate responses. We focus on the  construction of aggregation sets (called bags in the literature) for event-level loss functions. We,2024,arXiv preprint arXiv:2402.04987,https://arxiv.org/abs/2402.04987,"{'title': 'PriorBoost: An Adaptive Algorithm for Learning from Aggregate Responses', 'author': ['A Javanmard', 'M Fahrbach', 'V Mirrokni'], 'pub_year': '2024', 'venue': 'arXiv preprint arXiv:2402.04987', 'abstract': 'This work studies algorithms for learning from aggregate responses. We focus on the  construction of aggregation sets (called bags in the literature) for event-level loss functions. We'}",Google Scholar
"J Fu, Y Hong, X Ling, L Wang, X Ran, Z Sun",Differentially private federated learning: A systematic review,,"In recent years, privacy and security concerns in machine learning have promoted trusted  federated learning to the forefront of research. Differential privacy has emerged as the de facto",2024,arXiv preprint arXiv …,https://arxiv.org/abs/2405.08299,"{'title': 'Differentially private federated learning: A systematic review', 'author': ['J Fu', 'Y Hong', 'X Ling', 'L Wang', 'X Ran', 'Z Sun'], 'pub_year': '2024', 'venue': 'arXiv preprint arXiv …', 'abstract': 'In recent years, privacy and security concerns in machine learning have promoted trusted  federated learning to the forefront of research. Differential privacy has emerged as the de facto'}",Google Scholar
"S Pan, Z Tao, T Hoang, D Zhang, T Li, Z Xing",{A New Hope}: Contextual Privacy Policies for Mobile Applications and An Approach Toward Automated Generation,,"Privacy policies have emerged as the predominant approach to conveying privacy notices to  mobile application users. In an effort to enhance both readability and user engagement, the",2024,arXiv preprint arXiv …,https://arxiv.org/abs/2402.14544,"{'title': '{A New Hope}: Contextual Privacy Policies for Mobile Applications and An Approach Toward Automated Generation', 'author': ['S Pan', 'Z Tao', 'T Hoang', 'D Zhang', 'T Li', 'Z Xing'], 'pub_year': '2024', 'venue': 'arXiv preprint arXiv …', 'abstract': 'Privacy policies have emerged as the predominant approach to conveying privacy notices to  mobile application users. In an effort to enhance both readability and user engagement, the'}",Google Scholar
"A Bechmann, JY Kim",Big data: A focus on social media research dilemmas,,Big data research is an umbrella term that characterizes research in many fields. This chapter  will focus specifically on big data research tied to the use of social media primarily with a,2020,Handbook of research ethics and scientific integrity,https://link.springer.com/content/pdf/10.1007/978-3-030-16759-2_18.pdf,"{'title': 'Big data: A focus on social media research dilemmas', 'author': ['A Bechmann', 'JY Kim'], 'pub_year': '2020', 'venue': 'Handbook of research ethics and scientific integrity', 'abstract': 'Big data research is an umbrella term that characterizes research in many fields. This chapter  will focus specifically on big data research tied to the use of social media primarily with a'}",Google Scholar
"J Bi, V Suppakitpaisarn",Performances of Symmetric Loss for Private Data from Exponential Mechanism,,"This study explores the robustness of learning by symmetric loss on private data. Specifically,  we leverage exponential mechanism (EM) on private labels. First, we theoretically re-",2022,2022 Tenth International Symposium …,https://ieeexplore.ieee.org/abstract/document/10062786/,"{'title': 'Performances of Symmetric Loss for Private Data from Exponential Mechanism', 'author': ['J Bi', 'V Suppakitpaisarn'], 'pub_year': '2022', 'venue': '2022 Tenth International Symposium …', 'abstract': 'This study explores the robustness of learning by symmetric loss on private data. Specifically,  we leverage exponential mechanism (EM) on private labels. First, we theoretically re-'}",Google Scholar
"H Inayoshi, S Kakei, S Saito",Detection of Inconsistencies between Guidance Pages and Actual Data Collection of Third-party SDKs in Android Apps,,"The concept of privacy label was proposed by Kelley et al. in 2009 [18], and recently, major   The privacy label section on each product page on the app stores informs users of data",2024,NA,https://www.researchgate.net/profile/Hiroki-Inayoshi/publication/380430079_Detection_of_Inconsistencies_between_Guidance_Pages_and_Actual_Data_Collection_of_Third-party_SDKs_in_Android_Apps/links/663c4ac77091b94e930cd893/Detection-of-Inconsistencies-between-Guidance-Pages-and-Actual-Data-Collection-of-Third-party-SDKs-in-Android-Apps.pdf,"{'title': 'Detection of Inconsistencies between Guidance Pages and Actual Data Collection of Third-party SDKs in Android Apps', 'author': ['H Inayoshi', 'S Kakei', 'S Saito'], 'pub_year': '2024', 'venue': 'NA', 'abstract': 'The concept of privacy label was proposed by Kelley et al. in 2009 [18], and recently, major   The privacy label section on each product page on the app stores informs users of data'}",Google Scholar
"R Balebako, R Shay, LF Cranor",Is your inseam a biometric? a case study on the role of usability studies in developing public policy,,Academic researchers have also proposed privacy label standards. Kelley et al. developed  and tested a “privacy nutrition label” for websites. They also found that a tabular format was,2014,Proc. USEC,https://lorrie.cranor.org/pubs/usec14-inseam.pdf,"{'title': 'Is your inseam a biometric? a case study on the role of usability studies in developing public policy', 'author': ['R Balebako', 'R Shay', 'LF Cranor'], 'pub_year': '2014', 'venue': 'Proc. USEC', 'abstract': 'Academic researchers have also proposed privacy label standards. Kelley et al. developed  and tested a “privacy nutrition label” for websites. They also found that a tabular format was'}",Google Scholar
"J Gunaratne, O Nov",Using interactive “Nutrition labels” for financial products to assist decision making under uncertainty,,"We applied these clustering techniques to our financial label and used a similar format  inspired by the privacy label, with summary information listed at the top of the label, secondary",2017,Journal of the Association for Information …,https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/asi.23844,"{'title': 'Using interactive “Nutrition labels” for financial products to assist decision making under uncertainty', 'author': ['J Gunaratne', 'O Nov'], 'pub_year': '2017', 'venue': 'Journal of the Association for Information …', 'abstract': 'We applied these clustering techniques to our financial label and used a similar format  inspired by the privacy label, with summary information listed at the top of the label, secondary'}",Google Scholar
PG Kelley,Designing Privacy Notices: Supporting User Understanding and Control,,"Figure 3.2: Our Simplified Label, an early attempt at a privacy label.  Thistype of view  allows someone using an online privacy label to not justend up learning that a company collects",2013,NA,https://search.proquest.com/openview/7287770e320cad6771b3220ca1f9759f/1?pq-origsite=gscholar&cbl=18750,"{'title': 'Designing Privacy Notices: Supporting User Understanding and Control', 'author': ['PG Kelley'], 'pub_year': '2013', 'venue': 'NA', 'abstract': 'Figure 3.2: Our Simplified Label, an early attempt at a privacy label.  Thistype of view  allows someone using an online privacy label to not justend up learning that a company collects'}",Google Scholar
"H Qin, J Kong, W Ding, R Ahluwalia, CE Morr",Towards Trustworthy Artificial Intelligence for Equitable Global Health,,"Artificial intelligence (AI) can potentially transform global health, but algorithmic bias can  exacerbate social inequities and disparity. Trustworthy AI entails the intentional design to",2023,arXiv preprint arXiv …,https://arxiv.org/abs/2309.05088,"{'title': 'Towards Trustworthy Artificial Intelligence for Equitable Global Health', 'author': ['H Qin', 'J Kong', 'W Ding', 'R Ahluwalia', 'CE Morr'], 'pub_year': '2023', 'venue': 'arXiv preprint arXiv …', 'abstract': 'Artificial intelligence (AI) can potentially transform global health, but algorithmic bias can  exacerbate social inequities and disparity. Trustworthy AI entails the intentional design to'}",Google Scholar
"J Jung, A Sheth, S Consolvo, B Greenstein, A LaMarca",Taking the Mystery Out of Sensing Devices in the Home,,"• Label structure: A privacy label describes the source of sensor data (eg, camera, microphone)  and the sensor location (eg, living room, front door) and the sensitivity level. Unlike [10],",2010,NA,http://www.appanalysis.org/jjung/jaeyeon-pub/HomeDashboard-HotSecsubmission.pdf,"{'title': 'Taking the Mystery Out of Sensing Devices in the Home', 'author': ['J Jung', 'A Sheth', 'S Consolvo', 'B Greenstein', 'A LaMarca'], 'pub_year': '2010', 'venue': 'NA', 'abstract': '• Label structure: A privacy label describes the source of sensor data (eg, camera, microphone)  and the sensor location (eg, living room, front door) and the sensitivity level. Unlike [10],'}",Google Scholar
"B Bian, M Pagel, H Tang",Consumer surveillance and financial fraud,,"Below, we also introduce two other disclosure policies, Apple’s Privacy Label and Google’s  Data Safety form, that allow us to extract information about firms’ data collection and security",2023,NA,https://www.nber.org/papers/w31692,"{'title': 'Consumer surveillance and financial fraud', 'author': ['B Bian', 'M Pagel', 'H Tang'], 'pub_year': '2023', 'venue': 'NA', 'abstract': 'Below, we also introduce two other disclosure policies, Apple’s Privacy Label and Google’s  Data Safety form, that allow us to extract information about firms’ data collection and security'}",Google Scholar
"JP Dubé, D Bergemann, M Demirer",The Intended and Unintended Consequences of Privacy Regulation for Consumer Marketing: A Marketing Science Institute Report,,"In an era where firms are innovating and using more data than ever before for marketing  purposes, there is a perceived need for enhanced regulation to protect consumers' privacy. We",2024,Available at SSRN …,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4847653,"{'title': 'The Intended and Unintended Consequences of Privacy Regulation for Consumer Marketing: A Marketing Science Institute Report', 'author': ['JP Dubé', 'D Bergemann', 'M Demirer'], 'pub_year': '2024', 'venue': 'Available at SSRN …', 'abstract': ""In an era where firms are innovating and using more data than ever before for marketing  purposes, there is a perceived need for enhanced regulation to protect consumers' privacy. We""}",Google Scholar
"C Labadie, C Legner",Understanding data protection regulations from a data management perspective: a capability-based approach to EU-GDPR,,The European General Data Protection Regulation (EU-GDPR) has entered into force in  May 2018. Its emphasis on individual control and organizational accountability constitutes a,2019,… of the 14th International Conference on …,https://serval.unil.ch/resource/serval:BIB_65AAB323C49C.P001/REF.pdf,"{'title': 'Understanding data protection regulations from a data management perspective: a capability-based approach to EU-GDPR', 'author': ['C Labadie', 'C Legner'], 'pub_year': '2019', 'venue': '… of the 14th International Conference on …', 'abstract': 'The European General Data Protection Regulation (EU-GDPR) has entered into force in  May 2018. Its emphasis on individual control and organizational accountability constitutes a'}",Google Scholar
"A Srivastava, G Geethakumari",Privacy landscape in online social networks,,"The users were asked to assign the privacy label, ie, (allow, deny) for a profile item with  respect to the friend. If for a friend f and profile item i the preference, ie, pref (i, f) = allow, then that",2015,International Journal of …,https://www.inderscienceonline.com/doi/abs/10.1504/IJTMCC.2015.072461,"{'title': 'Privacy landscape in online social networks', 'author': ['A Srivastava', 'G Geethakumari'], 'pub_year': '2015', 'venue': 'International Journal of …', 'abstract': 'The users were asked to assign the privacy label, ie, (allow, deny) for a profile item with  respect to the friend. If for a friend f and profile item i the preference, ie, pref (i, f) = allow, then that'}",Google Scholar
"J Sun, Z Du, A Dai, S Baghersalimi, A Amirshahi",Robust and ip-protecting vertical federated learning against unexpected quitting of parties,,"Vertical federated learning (VFL) enables a service provider (ie, active party) who owns  labeled features to collaborate with passive parties who possess auxiliary features to improve",2023,arXiv preprint arXiv …,https://arxiv.org/abs/2303.18178,"{'title': 'Robust and ip-protecting vertical federated learning against unexpected quitting of parties', 'author': ['J Sun', 'Z Du', 'A Dai', 'S Baghersalimi', 'A Amirshahi'], 'pub_year': '2023', 'venue': 'arXiv preprint arXiv …', 'abstract': 'Vertical federated learning (VFL) enables a service provider (ie, active party) who owns  labeled features to collaborate with passive parties who possess auxiliary features to improve'}",Google Scholar
EA Brown,The Femtech Paradox: How workplace monitoring threatens women's equity,,"As biometric monitoring becomes increasingly common in workplace wellness programs,  there are three reasons to believe that women will suffer disproportionately from the data",2020,Jurimetrics,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/juraba61&section=19,"{'title': ""The Femtech Paradox: How workplace monitoring threatens women's equity"", 'author': ['EA Brown'], 'pub_year': '2020', 'venue': 'Jurimetrics', 'abstract': 'As biometric monitoring becomes increasingly common in workplace wellness programs,  there are three reasons to believe that women will suffer disproportionately from the data'}",Google Scholar
"X Gong, Q Wang, Y Chen, W Yang",Model extraction attacks and defenses on cloud-based machine learning models,,"Machine learning models have achieved state-of-the-art performance in various fields, from  image classification to speech recognition. However, such models are trained with a large",2020,IEEE Communications …,https://ieeexplore.ieee.org/abstract/document/9311938/,"{'title': 'Model extraction attacks and defenses on cloud-based machine learning models', 'author': ['X Gong', 'Q Wang', 'Y Chen', 'W Yang'], 'pub_year': '2020', 'venue': 'IEEE Communications …', 'abstract': 'Machine learning models have achieved state-of-the-art performance in various fields, from  image classification to speech recognition. However, such models are trained with a large'}",Google Scholar
E Sumii,A Co-Inductive Proof Method for Contextual Properties in Untyped λ-Calculus with References and Deallocation6,,"We develop a general method of proving properties of programs under arbitrary contexts—including  (but not limited to) observational equivalence, space improvement, and memory",NA,NA,https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=afdc19492f852242cd9fdd670fd0abd8f8eb29ea,"{'title': 'A Co-Inductive Proof Method for Contextual Properties in Untyped λ-Calculus with References and Deallocation6', 'author': ['E Sumii'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': 'We develop a general method of proving properties of programs under arbitrary contexts—including  (but not limited to) observational equivalence, space improvement, and memory'}",Google Scholar
S Wang,"Tackling Bias, Privacy, and Scarcity Challenges in Health Data Analytics",,"Health data analysis has emerged as a critical domain with immense potential to  revolutionize healthcare delivery, disease management, and medical research. However, it is",2023,NA,https://search.proquest.com/openview/f695d2021e7fca3110e24373e1f98328/1?pq-origsite=gscholar&cbl=18750&diss=y,"{'title': 'Tackling Bias, Privacy, and Scarcity Challenges in Health Data Analytics', 'author': ['S Wang'], 'pub_year': '2023', 'venue': 'NA', 'abstract': 'Health data analysis has emerged as a critical domain with immense potential to  revolutionize healthcare delivery, disease management, and medical research. However, it is'}",Google Scholar
MS Daniels,Ontology-Guided Pre-Release Inference Disruption,,"In our approach, we use patterns as the basis for privacy label assignment. A pattern may   Regardless of the number of patterns matched, the privacy label used for the data item must",2018,NA,https://search.proquest.com/openview/e3b583d8db5c0ab030dfab6ef133d754/1?pq-origsite=gscholar&cbl=18750,"{'title': 'Ontology-Guided Pre-Release Inference Disruption', 'author': ['MS Daniels'], 'pub_year': '2018', 'venue': 'NA', 'abstract': 'In our approach, we use patterns as the basis for privacy label assignment. A pattern may   Regardless of the number of patterns matched, the privacy label used for the data item must'}",Google Scholar
"M Tabassum, H Lipford",Exploring privacy implications of awareness and control mechanisms in smart home devices,,Emami-Naeini et al. proposed an IoT Security and Privacy Label [20] to be placed on the  package of any IoT device that contains all the key information regarding the device’s data,2023,Proceedings on Privacy Enhancing …,https://petsymposium.org/popets/2023/popets-2023-0033.php,"{'title': 'Exploring privacy implications of awareness and control mechanisms in smart home devices', 'author': ['M Tabassum', 'H Lipford'], 'pub_year': '2023', 'venue': 'Proceedings on Privacy Enhancing …', 'abstract': 'Emami-Naeini et al. proposed an IoT Security and Privacy Label [20] to be placed on the  package of any IoT device that contains all the key information regarding the device’s data'}",Google Scholar
JRY Miranda,Beyond the commodification of privacy: Personal data management as a strategy for accountability in a digital world,,The definition of privacy by design is therefore also “susceptible to the interpretation to  collect any data as long as it is with a privacy label while shrinking the scope of control from the,NA,NA,https://www.researchgate.net/profile/Jaseff-Yauri-Miranda/publication/331592252_Beyond_the_commodification_of_privacy_Personal_data_management_as_a_strategy_for_accountability_in_a_digital_world/links/5c826f99299bf1268d453caa/Beyond-the-commodification-of-privacy-Personal-data-management-as-a-strategy-for-accountability-in-a-digital-world.pdf,"{'title': 'Beyond the commodification of privacy: Personal data management as a strategy for accountability in a digital world', 'author': ['JRY Miranda'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': 'The definition of privacy by design is therefore also “susceptible to the interpretation to  collect any data as long as it is with a privacy label while shrinking the scope of control from the'}",Google Scholar
"X Ding, H Huang",For Whom is Privacy Policy Written? A New Understanding of Data Privacy Law's Notice-and-Consent Framework,,"The readership of privacy policies has been underestimated. It extends beyond data subjects  to encompass corporate personnel, organizations, courts, regulators, and non-users. The",2023,A New Understanding of Data Privacy Law's …,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4560201,"{'title': ""For Whom is Privacy Policy Written? A New Understanding of Data Privacy Law's Notice-and-Consent Framework"", 'author': ['X Ding', 'H Huang'], 'pub_year': '2023', 'venue': ""A New Understanding of Data Privacy Law's …"", 'abstract': 'The readership of privacy policies has been underestimated. It extends beyond data subjects  to encompass corporate personnel, organizations, courts, regulators, and non-users. The'}",Google Scholar
JE Harris,Taking disability public,,"For example, feminist legal theorists have well documented the ways in which attaching a  privacy label has ""operated to make violence against women legally and politically invisible.""",2020,U. Pa. l. Rev.,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/pnlr169&section=40,"{'title': 'Taking disability public', 'author': ['JE Harris'], 'pub_year': '2020', 'venue': 'U. Pa. l. Rev.', 'abstract': 'For example, feminist legal theorists have well documented the ways in which attaching a  privacy label has ""operated to make violence against women legally and politically invisible.""'}",Google Scholar
BG Zayniddinovna,Distinctive features of pleonasms in political speech,,"“October Coup: originally a mourning“... one can also find the phenomenon of pleonasm in  an article entitled: “over the past decades, archives have been opened, the privacy label has",2023,Intellectual Education Technological Solutions …,https://interonconf.org/index.php/neth/article/view/1865,"{'title': 'Distinctive features of pleonasms in political speech', 'author': ['BG Zayniddinovna'], 'pub_year': '2023', 'venue': 'Intellectual Education Technological Solutions …', 'abstract': '“October Coup: originally a mourning“... one can also find the phenomenon of pleonasm in  an article entitled: “over the past decades, archives have been opened, the privacy label has'}",Google Scholar
"J Turow, Y Lelkes, NA Draper, AE Waldman",Americans Cannot Consent to Companies' Use of Their Data,,"An extension of this individual literacy approach for adults is the notion of a “privacy label.”  In 2009, researchers from Carnegie Mellon University created “a clear, uniform, single-page",2023,NA,https://escholarship.org/uc/item/8z16x3h7,"{'title': ""Americans Cannot Consent to Companies' Use of Their Data"", 'author': ['J Turow', 'Y Lelkes', 'NA Draper', 'AE Waldman'], 'pub_year': '2023', 'venue': 'NA', 'abstract': 'An extension of this individual literacy approach for adults is the notion of a “privacy label.”  In 2009, researchers from Carnegie Mellon University created “a clear, uniform, single-page'}",Google Scholar
H Wang,Montag: Cloud Native Data Tainting and Policy Enforcement,,"to maintain this logic, each service must be aware of the current architecture being used to  enforce data regulations because the service must determine the appropriate privacy label. In",2020,Ph. D. dissertation,https://www2.eecs.berkeley.edu/Pubs/TechRpts/2020/EECS-2020-105.pdf,"{'title': 'Montag: Cloud Native Data Tainting and Policy Enforcement', 'author': ['H Wang'], 'pub_year': '2020', 'venue': 'Ph. D. dissertation', 'abstract': 'to maintain this logic, each service must be aware of the current architecture being used to  enforce data regulations because the service must determine the appropriate privacy label. In'}",Google Scholar
MR Llorens,"9th International Conference on Internet, Law and Politics (IDP 2013) Big Data: Challenges and Opportunities Report",,using copyrighted material relies in the idea of selfdevelopment and freedom of thought  expressed through personal creations something worth to be protected under the privacy label.,2013,SCRIPTed,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/scripted10&section=22,"{'title': '9th International Conference on Internet, Law and Politics (IDP 2013) Big Data: Challenges and Opportunities Report', 'author': ['MR Llorens'], 'pub_year': '2013', 'venue': 'SCRIPTed', 'abstract': 'using copyrighted material relies in the idea of selfdevelopment and freedom of thought  expressed through personal creations something worth to be protected under the privacy label.'}",Google Scholar
D Johnson,A multiphase mixed-methods analysis of UK e-commerce privacy policies,,"Database technology and advanced statistical processes have rendered it possible to process  unprecedented volumes of personal data. However, tension exists between the rights of",2019,NA,https://core.ac.uk/download/pdf/288352746.pdf,"{'title': 'A multiphase mixed-methods analysis of UK e-commerce privacy policies', 'author': ['D Johnson'], 'pub_year': '2019', 'venue': 'NA', 'abstract': 'Database technology and advanced statistical processes have rendered it possible to process  unprecedented volumes of personal data. However, tension exists between the rights of'}",Google Scholar
M Al-Rubaie,Towards privacy-aware mobile-based continuous authentication systems,,"For datasets that have samples with two labels: a utility label and a privacy label, Kung [26]  proposes a DR method to enable the data owner to project her data in a way that enables",2018,NA,https://search.proquest.com/openview/64b00628034b9769fef56b892f4e28d6/1?pq-origsite=gscholar&cbl=18750,"{'title': 'Towards privacy-aware mobile-based continuous authentication systems', 'author': ['M Al-Rubaie'], 'pub_year': '2018', 'venue': 'NA', 'abstract': 'For datasets that have samples with two labels: a utility label and a privacy label, Kung [26]  proposes a DR method to enable the data owner to project her data in a way that enables'}",Google Scholar
"L Zhang-Kennedy, S Chiasson",The role of instructional design in persuasion: A comics approach for improving cybersecurity,,"The authors designed a privacy label using design elements and principles from nutrition,   on the proposed privacy label compared to existing natural language privacy policies.",2016,International Journal of …,https://www.tandfonline.com/doi/abs/10.1080/10447318.2016.1136177,"{'title': 'The role of instructional design in persuasion: A comics approach for improving cybersecurity', 'author': ['L Zhang-Kennedy', 'S Chiasson'], 'pub_year': '2016', 'venue': 'International Journal of …', 'abstract': 'The authors designed a privacy label using design elements and principles from nutrition,   on the proposed privacy label compared to existing natural language privacy policies.'}",Google Scholar
"GJ Ahn, P Sekar",Ontology-based risk evaluation in user-centric identity management,,Recent trends in the area of identity management have evolved from a traditional identification  solution to a distributed user-centric identity management mechanism. The major goal of,2011,2011 IEEE International Conference on …,https://ieeexplore.ieee.org/abstract/document/5962948/,"{'title': 'Ontology-based risk evaluation in user-centric identity management', 'author': ['GJ Ahn', 'P Sekar'], 'pub_year': '2011', 'venue': '2011 IEEE International Conference on …', 'abstract': 'Recent trends in the area of identity management have evolved from a traditional identification  solution to a distributed user-centric identity management mechanism. The major goal of'}",Google Scholar
"R Li, W Wang",HyShield: Enforcing Service Level Data Access Control with Data Tainting,,"to maintain this logic, each service must be aware of the current architecture being used to  enforce data regulations because the service must determine the appropriate privacy label. In",NA,NA,https://people.eecs.berkeley.edu/~kubitron/courses/cs262a-F19/projects/reports/project1_report.pdf,"{'title': 'HyShield: Enforcing Service Level Data Access Control with Data Tainting', 'author': ['R Li', 'W Wang'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': 'to maintain this logic, each service must be aware of the current architecture being used to  enforce data regulations because the service must determine the appropriate privacy label. In'}",Google Scholar
"J Turow, Y Lelkes, N Draper","Americans Can't Consent to Companies' Use of Their Data: They Admit They Don't Understand It, Say They're Helpless to Control It, and Believe They're Harmed …",,"An extension of this individual literacy approach for adults is the notion of a “privacy label.”  In 2009, researchers from Carnegie Mellon University created “a clear, uniform, single-page",2023,Say They're Helpless to …,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4391134,"{'title': ""Americans Can't Consent to Companies' Use of Their Data: They Admit They Don't Understand It, Say They're Helpless to Control It, and Believe They're Harmed …"", 'author': ['J Turow', 'Y Lelkes', 'N Draper'], 'pub_year': '2023', 'venue': ""Say They're Helpless to …"", 'abstract': 'An extension of this individual literacy approach for adults is the notion of a “privacy label.”  In 2009, researchers from Carnegie Mellon University created “a clear, uniform, single-page'}",Google Scholar
"BA Muhander, J Wiese, O Rana, C Perera",Privacy-aware internet of things notices in shared spaces: A survey,,"The authors in [118] presented a privacy label prototype, and they found that individuals  purchase behaviour tends to change when they know the privacy implication of the IoT device.",2020,arXiv preprint arXiv …,https://arxiv.org/abs/2006.13633,"{'title': 'Privacy-aware internet of things notices in shared spaces: A survey', 'author': ['BA Muhander', 'J Wiese', 'O Rana', 'C Perera'], 'pub_year': '2020', 'venue': 'arXiv preprint arXiv …', 'abstract': 'The authors in [118] presented a privacy label prototype, and they found that individuals  purchase behaviour tends to change when they know the privacy implication of the IoT device.'}",Google Scholar
BST Larsen,Setting the watch: privacy and the ethics of CCTV surveillance,,"Sceptics, such as JJ Thomson, argue that the discussion about privacy should be ‘reduced’  to a discussion of other rights, because the interests subsumed under the privacy label are",2011,NA,https://books.google.com/books?hl=en&lr=&id=vhXcBAAAQBAJ&oi=fnd&pg=PR1&dq=%22privacy+label%22&ots=smq_dYA6Ib&sig=R5GBgbfmk2teG7lCw3lJS2-uM5s,"{'title': 'Setting the watch: privacy and the ethics of CCTV surveillance', 'author': ['BST Larsen'], 'pub_year': '2011', 'venue': 'NA', 'abstract': 'Sceptics, such as JJ Thomson, argue that the discussion about privacy should be ‘reduced’  to a discussion of other rights, because the interests subsumed under the privacy label are'}",Google Scholar
"V Ziegler, P Schneider, H Viswanathan, M Montag",Security and Trust in the 6G Era,,"In addition, a comprehensive theoretical foundation of data privacy models is needed  that allows verified model transformations and privacy labeling of data like ‘‘free of privacy",2021,Ieee …,https://ieeexplore.ieee.org/abstract/document/9570274/,"{'title': 'Security and Trust in the 6G Era', 'author': ['V Ziegler', 'P Schneider', 'H Viswanathan', 'M Montag'], 'pub_year': '2021', 'venue': 'Ieee …', 'abstract': 'In addition, a comprehensive theoretical foundation of data privacy models is needed  that allows verified model transformations and privacy labeling of data like ‘‘free of privacy'}",Google Scholar
L Zhang-Kennedy,Improving mental models of computer security through information graphics,,The authors designed an easy to read privacy label drawing from design elements and   quickly and accurately on the proposed privacy label compared to existing natural language,2013,NA,https://repository.library.carleton.ca/concern/etds/2f75r8587,"{'title': 'Improving mental models of computer security through information graphics', 'author': ['L Zhang-Kennedy'], 'pub_year': '2013', 'venue': 'NA', 'abstract': 'The authors designed an easy to read privacy label drawing from design elements and   quickly and accurately on the proposed privacy label compared to existing natural language'}",Google Scholar
"L Garrison, M Hastak, JM Hogarth",Designing Evidence‐Based Disclosures: A Case Study of Financial Privacy Notices,,"Disclosure is a key component of consumer protection policy. By informing consumers about  a product or service, disclosures can help consumers understand product features and",2012,Journal of Consumer …,https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1745-6606.2012.01226.x,"{'title': 'Designing Evidence‐Based Disclosures: A Case Study of Financial Privacy Notices', 'author': ['L Garrison', 'M Hastak', 'JM Hogarth'], 'pub_year': '2012', 'venue': 'Journal of Consumer …', 'abstract': 'Disclosure is a key component of consumer protection policy. By informing consumers about  a product or service, disclosures can help consumers understand product features and'}",Google Scholar
"K Bajpai, K Weber",Privacy in public: Translating the category of privacy to the digital age,,"However, the cohering of a distinct set of notions under the informational privacy label  begins in earnest only at this point. The early discursive convergence can be seen in the",2017,From categories to categorization: Studies in …,https://www.emerald.com/insight/content/doi/10.1108/S0733-558X20170000051006/full/html,"{'title': 'Privacy in public: Translating the category of privacy to the digital age', 'author': ['K Bajpai', 'K Weber'], 'pub_year': '2017', 'venue': 'From categories to categorization: Studies in …', 'abstract': 'However, the cohering of a distinct set of notions under the informational privacy label  begins in earnest only at this point. The early discursive convergence can be seen in the'}",Google Scholar
T Solvers,ELSEWHERE IN THE CS,,The authors of this article from the March/April 2022 issue of IEEE Security & Privacy  designed a usable and informative IoT security and privacy label.,NA,NA,https://ieeexplore.ieee.org/abstract/document/9869600/,"{'title': 'ELSEWHERE IN THE CS', 'author': ['T Solvers'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': 'The authors of this article from the March/April 2022 issue of IEEE Security & Privacy  designed a usable and informative IoT security and privacy label.'}",Google Scholar
I Annex,Final framework for building trusted systems,,Imagine that the privacy label/product trustworthiness label is awarded by the company   Imagine that the privacy label/product trustworthiness label is awarded by an independent,2020,NA,https://scottproject.eu/wp-content/uploads/2020/10/SCOTT_D_28.6.pdf,"{'title': 'Final framework for building trusted systems', 'author': ['I Annex'], 'pub_year': '2020', 'venue': 'NA', 'abstract': 'Imagine that the privacy label/product trustworthiness label is awarded by the company   Imagine that the privacy label/product trustworthiness label is awarded by an independent'}",Google Scholar
"Y LELKES, NA DRAPER, ARIE WALDMAN",AMERICANS CAN'T CONSENT TO COMPANIES'USE OF THEIR DATA,,"An extension of this individual literacy approach for adults is the notion of a “privacy label.”  In 2009, researchers from Carnegie Mellon University created “a clear, uniform, single-page",NA,NA,https://www.asc.upenn.edu/sites/default/files/2023-02/Americans_Cant_Consent.pdf,"{'title': ""AMERICANS CAN'T CONSENT TO COMPANIES'USE OF THEIR DATA"", 'author': ['Y LELKES', 'NA DRAPER', 'ARIE WALDMAN'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': 'An extension of this individual literacy approach for adults is the notion of a “privacy label.”  In 2009, researchers from Carnegie Mellon University created “a clear, uniform, single-page'}",Google Scholar
"J Jordon, L Szpruch, F Houssiau, M Bottarelli","Synthetic Data--what, why and how?",,"This explainer document aims to provide an overview of the current state of the rapidly  expanding work on synthetic data technologies, with a particular focus on privacy. The article is",2022,arXiv preprint arXiv …,https://arxiv.org/abs/2205.03257,"{'title': 'Synthetic Data--what, why and how?', 'author': ['J Jordon', 'L Szpruch', 'F Houssiau', 'M Bottarelli'], 'pub_year': '2022', 'venue': 'arXiv preprint arXiv …', 'abstract': 'This explainer document aims to provide an overview of the current state of the rapidly  expanding work on synthetic data technologies, with a particular focus on privacy. The article is'}",Google Scholar
SE Carter,A Value-Centered Approach to Data Privacy Decisions,,"There are a host of data privacy decisions we must make every day–and it is exceedingly  difficult, if not impossible, for us to make meaningful decisions about all of them. In this thesis, I",2023,NA,https://aran.library.nuigalway.ie/bitstream/handle/10379/18048/2023CarterPhD.pdf?sequence=1,"{'title': 'A Value-Centered Approach to Data Privacy Decisions', 'author': ['SE Carter'], 'pub_year': '2023', 'venue': 'NA', 'abstract': 'There are a host of data privacy decisions we must make every day–and it is exceedingly  difficult, if not impossible, for us to make meaningful decisions about all of them. In this thesis, I'}",Google Scholar
"ID Raji, G Fried",About face: A survey of facial recognition evaluation,,"We survey over 100 face datasets constructed between 1976 to 2019 of 145 million images  of over 17 million subjects from a range of sources, demographics and conditions. Our",2021,arXiv preprint arXiv:2102.00813,https://arxiv.org/abs/2102.00813,"{'title': 'About face: A survey of facial recognition evaluation', 'author': ['ID Raji', 'G Fried'], 'pub_year': '2021', 'venue': 'arXiv preprint arXiv:2102.00813', 'abstract': 'We survey over 100 face datasets constructed between 1976 to 2019 of 145 million images  of over 17 million subjects from a range of sources, demographics and conditions. Our'}",Google Scholar
"J Sun, Z Du, A Dai, S Baghersalimi, A Amirshahi",PlugVFL: Robust and IP-Protecting Vertical Federated Learning against Unexpected Quitting of Parties,,"In federated learning systems, the unexpected quitting of participants is inevitable. Such  quittings generally do not incur serious consequences in horizontal federated learning (HFL),",2023,NA,https://openreview.net/forum?id=TzcuXQq0aR,"{'title': 'PlugVFL: Robust and IP-Protecting Vertical Federated Learning against Unexpected Quitting of Parties', 'author': ['J Sun', 'Z Du', 'A Dai', 'S Baghersalimi', 'A Amirshahi'], 'pub_year': '2023', 'venue': 'NA', 'abstract': 'In federated learning systems, the unexpected quitting of participants is inevitable. Such  quittings generally do not incur serious consequences in horizontal federated learning (HFL),'}",Google Scholar
S Zhang,"Understanding People's Diverse Privacy Attitudes: Notification, Control, and Regulatory Implications",,103 6.2 Sample user questions and corresponding privacy label entry in the iOS and  Google  Another study found that a prototype Android app privacy label was more likely to be,2023,NA,https://kilthub.cmu.edu/ndownloader/files/43231983,"{'title': ""Understanding People's Diverse Privacy Attitudes: Notification, Control, and Regulatory Implications"", 'author': ['S Zhang'], 'pub_year': '2023', 'venue': 'NA', 'abstract': '103 6.2 Sample user questions and corresponding privacy label entry in the iOS and  Google  Another study found that a prototype Android app privacy label was more likely to be'}",Google Scholar
"AE Youssef, M Alageel",A framework for secure cloud computing,,"In this method the author added the Cloud Privacy Label (CPL) to the user centric identity  management [57] to get a mechanism to protect the cloud users’ privacy, 4) user control",2012,International Journal of Computer …,https://www.researchgate.net/profile/Ahmed-Youssef/publication/299558786_A_Framework_for_Secure_Cloud_Computing/links/56feb5df08aea6b77468cfff/A-Framework-for-Secure-Cloud-Computing.pdf,"{'title': 'A framework for secure cloud computing', 'author': ['AE Youssef', 'M Alageel'], 'pub_year': '2012', 'venue': 'International Journal of Computer …', 'abstract': 'In this method the author added the Cloud Privacy Label (CPL) to the user centric identity  management [57] to get a mechanism to protect the cloud users’ privacy, 4) user control'}",Google Scholar
"J Kraemer, R Feasey","Device Neutrality: Openness, non-discrimination and transparency on mobile devices for general internet access",,"Since the ‘net neutrality’debate began in the early 2000s, the internet ecosystem has evolved  and European policymakers now face a different type of gatekeeper. This CERRE Tech,",2021,NA,https://books.google.com/books?hl=en&lr=&id=xrc-EAAAQBAJ&oi=fnd&pg=PT3&dq=%22privacy+label%22&ots=EQvBm-S_qF&sig=zQfEoq4XSRLe2rjEUWrmuhT5U1w,"{'title': 'Device Neutrality: Openness, non-discrimination and transparency on mobile devices for general internet access', 'author': ['J Kraemer', 'R Feasey'], 'pub_year': '2021', 'venue': 'NA', 'abstract': 'Since the ‘net neutrality’debate began in the early 2000s, the internet ecosystem has evolved  and European policymakers now face a different type of gatekeeper. This CERRE Tech,'}",Google Scholar
MO Soeder,Privacy challenges and approaches to the consent dilemma,,"The ‘privacy label’ as a standard could show which data is collected, how it is used and  with whom it is shared.In the above mentioned study, Kelley et al. find that ‘privacy labels’",2019,Available at SSRN 3442612,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3442612,"{'title': 'Privacy challenges and approaches to the consent dilemma', 'author': ['MO Soeder'], 'pub_year': '2019', 'venue': 'Available at SSRN 3442612', 'abstract': 'The ‘privacy label’ as a standard could show which data is collected, how it is used and  with whom it is shared.In the above mentioned study, Kelley et al. find that ‘privacy labels’'}",Google Scholar
C Miller,Surveillance Capitalism,,"In fact, Google recently published its privacy label for the Gmail app, which reports on all  of the types of data Google will collect, including location, purchase history, contacts, user",2024,Writing for Digital Media,https://pressbooks.palni.org/writingfordigitalmedia/chapter/surveillance-capitalism/,"{'title': 'Surveillance Capitalism', 'author': ['C Miller'], 'pub_year': '2024', 'venue': 'Writing for Digital Media', 'abstract': 'In fact, Google recently published its privacy label for the Gmail app, which reports on all  of the types of data Google will collect, including location, purchase history, contacts, user'}",Google Scholar
V Pandey,Ethical Issues Surrounding AI Applications,,"Just like nutrition label on a food packet, privacy label is meant to clearly list out key aspects  of any application in a clear and easy language. Apple has recently adopted this feature for",2021,Artificial Intelligence and Machine Learning in …,https://www.taylorfrancis.com/chapters/edit/10.1201/9781003125129-14/ethical-issues-surrounding-ai-applications-vidushi-pandey,"{'title': 'Ethical Issues Surrounding AI Applications', 'author': ['V Pandey'], 'pub_year': '2021', 'venue': 'Artificial Intelligence and Machine Learning in …', 'abstract': 'Just like nutrition label on a food packet, privacy label is meant to clearly list out key aspects  of any application in a clear and easy language. Apple has recently adopted this feature for'}",Google Scholar
E Grünewald,Cloud Native Privacy Engineering for Transparency and Accountability,,"Advancing transparency and accountability is one of the key challenges for the next generation  of Cloud Native software systems. First, transparency is an indispensable precondition",2024,NA,https://depositonce.tu-berlin.de/bitstreams/8394547f-5b36-4f3c-b381-3d5d4a68fcd3/download,"{'title': 'Cloud Native Privacy Engineering for Transparency and Accountability', 'author': ['E Grünewald'], 'pub_year': '2024', 'venue': 'NA', 'abstract': 'Advancing transparency and accountability is one of the key challenges for the next generation  of Cloud Native software systems. First, transparency is an indispensable precondition'}",Google Scholar
"R SOBTI, A BAGGA, G GEETHA",Security of online social networks,,Similar to the nutrition facts label this privacy label shows the user how an internet site  treats the user’s data. In contrast to the privacy policies used today such as Platform for Privacy,2012,International Conference on …,https://www.researchgate.net/profile/Rajeev-Sobti/publication/281494176_SECURITY_OF_ONLINE_SOCIAL_NETWORKS/links/55eb438d08ae65b6389dea31/SECURITY-OF-ONLINE-SOCIAL-NETWORKS.pdf,"{'title': 'Security of online social networks', 'author': ['R SOBTI', 'A BAGGA', 'G GEETHA'], 'pub_year': '2012', 'venue': 'International Conference on …', 'abstract': 'Similar to the nutrition facts label this privacy label shows the user how an internet site  treats the user’s data. In contrast to the privacy policies used today such as Platform for Privacy'}",Google Scholar
"CA Ardagna, M Cremonini, E Damiani",Privacy in the electronic society: Emerging problems and solutions,,"PREP allows users to specify, for each attribute, a privacy label that is characterized by a  purpose, type of access, recipient, data retention, remedies, and disputes. The Platform for",2009,Algorithms …,https://www.worldscientific.com/doi/abs/10.1142/9789812836243_0011,"{'title': 'Privacy in the electronic society: Emerging problems and solutions', 'author': ['CA Ardagna', 'M Cremonini', 'E Damiani'], 'pub_year': '2009', 'venue': 'Algorithms …', 'abstract': 'PREP allows users to specify, for each attribute, a privacy label that is characterized by a  purpose, type of access, recipient, data retention, remedies, and disputes. The Platform for'}",Google Scholar
"SS Lai, V Andelsman, S Flensburg",Datafied school life: The hidden commodification of digital learning,,Apple’s recent launch of its ‘privacy label’ in the Appstore provides a much-needed tool for  examining the otherwise black boxed relations between what data is collected and how it is,2023,"Learning, Media and …",https://www.tandfonline.com/doi/abs/10.1080/17439884.2023.2219063,"{'title': 'Datafied school life: The hidden commodification of digital learning', 'author': ['SS Lai', 'V Andelsman', 'S Flensburg'], 'pub_year': '2023', 'venue': 'Learning, Media and …', 'abstract': 'Apple’s recent launch of its ‘privacy label’ in the Appstore provides a much-needed tool for  examining the otherwise black boxed relations between what data is collected and how it is'}",Google Scholar
V Morel,CHIST-ERA 2015,,"[33] conducted a user study, to refine their privacy label. They compared the accuracy of  information retrieval between their proposition and natural language privacy policies in natural",NA,NA,https://uprise-iot.supsi.ch/deliverables/D4.1.Report_on_methods%20thatp_rovides_data_transparency_to_the_users.pdf,"{'title': 'CHIST-ERA 2015', 'author': ['V Morel'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': '[33] conducted a user study, to refine their privacy label. They compared the accuracy of  information retrieval between their proposition and natural language privacy policies in natural'}",Google Scholar
"MV Luzón, N Rodríguez-Barroso","A tutorial on federated learning from theory to practice: Foundations, software frameworks, exemplary use cases, and selected trends",,"When data privacy is imposed as a necessity, Federated learning (FL) emerges as a relevant  artificial intelligence field for developing machine learning (ML) models in a distributed and",2024,IEEE/CAA Journal of …,https://ieeexplore.ieee.org/abstract/document/10475194/,"{'title': 'A tutorial on federated learning from theory to practice: Foundations, software frameworks, exemplary use cases, and selected trends', 'author': ['MV Luzón', 'N Rodríguez-Barroso'], 'pub_year': '2024', 'venue': 'IEEE/CAA Journal of …', 'abstract': 'When data privacy is imposed as a necessity, Federated learning (FL) emerges as a relevant  artificial intelligence field for developing machine learning (ML) models in a distributed and'}",Google Scholar
E Brown,Supercharged sexism: The triple threat of workplace monitoring for women,,One way to accomplish this would be through a universal standard privacy label. Scholars  have been proposing various forms of at-a-glance privacy labels for years.Lorrie Cranor has,2020,Available at SSRN 3680861,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3680861,"{'title': 'Supercharged sexism: The triple threat of workplace monitoring for women', 'author': ['E Brown'], 'pub_year': '2020', 'venue': 'Available at SSRN 3680861', 'abstract': 'One way to accomplish this would be through a universal standard privacy label. Scholars  have been proposing various forms of at-a-glance privacy labels for years.Lorrie Cranor has'}",Google Scholar
L Zhang-Kennedy,Multimedia Approaches for Improving Children's Privacy and Security Knowledge and Persuading Behaviour Change,,"The privacy label uses design elements and principles from nutrition, warnings, energy  labelling, and banking notifications to make privacy policies quicker to read and easier",2017,NA,https://repository.library.carleton.ca/concern/etds/jm214p98b,"{'title': ""Multimedia Approaches for Improving Children's Privacy and Security Knowledge and Persuading Behaviour Change"", 'author': ['L Zhang-Kennedy'], 'pub_year': '2017', 'venue': 'NA', 'abstract': 'The privacy label uses design elements and principles from nutrition, warnings, energy  labelling, and banking notifications to make privacy policies quicker to read and easier'}",Google Scholar
"S Garfinkel, HR Lipford","Usable security: History, themes, and challenges",,"There has been roughly 15 years of research into approaches for aligning research in Human  Computer Interaction with computer Security, more colloquially known as``usable security.''",2014,NA,https://books.google.com/books?hl=en&lr=&id=HPS9BAAAQBAJ&oi=fnd&pg=PR11&dq=%22privacy+label%22&ots=rjDsovKWSJ&sig=Gx5Dk0DyENE_btSXIE1DEUYeMHI,"{'title': 'Usable security: History, themes, and challenges', 'author': ['S Garfinkel', 'HR Lipford'], 'pub_year': '2014', 'venue': 'NA', 'abstract': ""There has been roughly 15 years of research into approaches for aligning research in Human  Computer Interaction with computer Security, more colloquially known as``usable security.''""}",Google Scholar
"S Khare, V Verma",Designing a Security Framework for Mitigating Flaws in Cloud Based Web Hosting for Privacy and Confidentiality Services,,User-centric identity management was given the Cloud Privacy Label (CPL) by the author  [25]. The Third-Party Auditor (TPA) [26] was created by the author to ensure that cloud service,2023,International Journal of Intelligent Systems and …,https://www.ijisae.org/index.php/IJISAE/article/view/3455,"{'title': 'Designing a Security Framework for Mitigating Flaws in Cloud Based Web Hosting for Privacy and Confidentiality Services', 'author': ['S Khare', 'V Verma'], 'pub_year': '2023', 'venue': 'International Journal of Intelligent Systems and …', 'abstract': 'User-centric identity management was given the Cloud Privacy Label (CPL) by the author  [25]. The Third-Party Auditor (TPA) [26] was created by the author to ensure that cloud service'}",Google Scholar
"S Heer, S Alghamdi, S Furnell",Are we smart enough for smart technology?,,"For example, work such as the IoT Security and Privacy label from researchers at Carnegie  Mellon University and the University of Washington would offer a means of enabling",2023,Computer Fraud & Security,https://www.magonlinelibrary.com/doi/abs/10.12968/S1361-3723%2823%2970021-3,"{'title': 'Are we smart enough for smart technology?', 'author': ['S Heer', 'S Alghamdi', 'S Furnell'], 'pub_year': '2023', 'venue': 'Computer Fraud & Security', 'abstract': 'For example, work such as the IoT Security and Privacy label from researchers at Carnegie  Mellon University and the University of Washington would offer a means of enabling'}",Google Scholar
M Tabassum,"Understanding End-Users' Privacy Perceptions, Concerns, Behaviors, and Needs in the Smart Home",,Emami-Naeini et al. have proposed an IoT Security and Privacy Label [32] to be placed  on the package of any IoT device that contains all the key information regarding the device’s,2022,NA,https://search.proquest.com/openview/d5c7a873aa5f04d6b577fa477612b39d/1?pq-origsite=gscholar&cbl=18750&diss=y,"{'title': ""Understanding End-Users' Privacy Perceptions, Concerns, Behaviors, and Needs in the Smart Home"", 'author': ['M Tabassum'], 'pub_year': '2022', 'venue': 'NA', 'abstract': 'Emami-Naeini et al. have proposed an IoT Security and Privacy Label [32] to be placed  on the package of any IoT device that contains all the key information regarding the device’s'}",Google Scholar
N Raval,Enabling Fine-Grained Permissions in Smartphones,,The increasing popularity of smart devices that continuously monitor various aspects of users'  life and the prevalence of third-party services that utilize these data feeds have resulted in,2019,NA,https://search.proquest.com/openview/e823ff7802fbd70e84ce5c4ab79f2b4a/1?pq-origsite=gscholar&cbl=18750&diss=y,"{'title': 'Enabling Fine-Grained Permissions in Smartphones', 'author': ['N Raval'], 'pub_year': '2019', 'venue': 'NA', 'abstract': ""The increasing popularity of smart devices that continuously monitor various aspects of users'  life and the prevalence of third-party services that utilize these data feeds have resulted in""}",Google Scholar
"V Zhora, O Synetskyi",Use of the PVS formal logic system in the method of formal proof of security in the construction of information security systems,,"L : ∪ → that for each object of the system define the corresponding privacy label and the  Request: SOR ∪ ∪ → { , }01 function, which will show whether the subject is allowed or denied",2021,Technology audit and production reserves,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3848589,"{'title': 'Use of the PVS formal logic system in the method of formal proof of security in the construction of information security systems', 'author': ['V Zhora', 'O Synetskyi'], 'pub_year': '2021', 'venue': 'Technology audit and production reserves', 'abstract': 'L : ∪ → that for each object of the system define the corresponding privacy label and the  Request: SOR ∪ ∪ → { , }01 function, which will show whether the subject is allowed or denied'}",Google Scholar
A Alqhatani,Understanding and Designing for Sharing and Privacy in Wearable Fitness Platforms,,"The results suggest that the privacy label can help users in making informed privacy  decisions. In another study, Gluck et al. [24] addresses poor usability of privacy notices in mobile",2021,NA,https://search.proquest.com/openview/b297bcd8a349c8c67b33af3d1d8c6144/1?pq-origsite=gscholar&cbl=18750&diss=y,"{'title': 'Understanding and Designing for Sharing and Privacy in Wearable Fitness Platforms', 'author': ['A Alqhatani'], 'pub_year': '2021', 'venue': 'NA', 'abstract': 'The results suggest that the privacy label can help users in making informed privacy  decisions. In another study, Gluck et al. [24] addresses poor usability of privacy notices in mobile'}",Google Scholar
"K Munir, S Palaniappan",Framework for secure cloud computing,,"In this method the author added the Cloud Privacy Label (CPL) to the user centric identity  management [10] to get a mechanism to protect the cloud users’ privacy, 4) user control",2013,International Journal on Cloud …,https://www.researchgate.net/profile/Kashif-Munir-3/publication/269672042_Framework_for_Secure_Cloud_Computing/links/57a03b9608ae94f454e7c821/Framework-for-Secure-Cloud-Computing.pdf,"{'title': 'Framework for secure cloud computing', 'author': ['K Munir', 'S Palaniappan'], 'pub_year': '2013', 'venue': 'International Journal on Cloud …', 'abstract': 'In this method the author added the Cloud Privacy Label (CPL) to the user centric identity  management [10] to get a mechanism to protect the cloud users’ privacy, 4) user control'}",Google Scholar
"R Rizk, S Gürses, O Guenther",SNS and 3rd party applications privacy policies and their construction of privacy concerns,,Designing a privacy label: assisting consumer understanding of online privacy practices.  In Proceedings of the International Conference Extended Abstracts on Human Factors in,2010,NA,https://aisel.aisnet.org/ecis2010/143/,"{'title': 'SNS and 3rd party applications privacy policies and their construction of privacy concerns', 'author': ['R Rizk', 'S Gürses', 'O Guenther'], 'pub_year': '2010', 'venue': 'NA', 'abstract': 'Designing a privacy label: assisting consumer understanding of online privacy practices.  In Proceedings of the International Conference Extended Abstracts on Human Factors in'}",Google Scholar
L Griebeler da Motta,User Behavior and Market Developments Towards Data Protection,,"Contrary to most articles that have been recently written about data protection and dominant  technology firms, this paper suggests that no direct government intervention is needed.",2021,Available at SSRN 3851441,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3851441,"{'title': 'User Behavior and Market Developments Towards Data Protection', 'author': ['L Griebeler da Motta'], 'pub_year': '2021', 'venue': 'Available at SSRN 3851441', 'abstract': 'Contrary to most articles that have been recently written about data protection and dominant  technology firms, this paper suggests that no direct government intervention is needed.'}",Google Scholar
"H Le, J Hayes, S Elmalaki, M Nasr",{AutoFR}: Automated Filter Rule Generation for Adblocking,,The full Proceedings published by USENIX for the symposium are available for download  below. Individual papers can also be downloaded from their respective presentation pages.,2023,32nd USENIX Security …,https://www.usenix.org/conference/usenixsecurity23/technical-sessions,"{'title': '{AutoFR}: Automated Filter Rule Generation for Adblocking', 'author': ['H Le', 'J Hayes', 'S Elmalaki', 'M Nasr'], 'pub_year': '2023', 'venue': '32nd USENIX Security …', 'abstract': 'The full Proceedings published by USENIX for the symposium are available for download  below. Individual papers can also be downloaded from their respective presentation pages.'}",Google Scholar
"I Arkalakis, M Diamantaris, S Moustakas, S Ioannidis","Abandon All Hope Ye Who Enter Here: A Dynamic, Longitudinal Investigation of Android's Data Safety Section",,"Users’ growing concerns about online privacy have led to increased platform support for  transparency and consent in the web and mobile ecosystems. To that end, Android recently",NA,NA,https://www.usenix.org/system/files/sec24fall-prepub-399-arkalakis.pdf,"@inproceedings {298166,
	author = {Ioannis Arkalakis and Michalis Diamantaris and Serafeim Moustakas and Sotiris Ioannidis and Jason Polakis and Panagiotis Ilia},
	title = {Abandon All Hope Ye Who Enter Here: A Dynamic, Longitudinal Investigation of Android{\textquoteright}s Data Safety Section},
	booktitle = {33rd USENIX Security Symposium (USENIX Security 24)},
	year = {2024},
	isbn = {978-1-939133-44-1},
	address = {Philadelphia, PA},
	pages = {5645--5662},
	url = {https://www.usenix.org/conference/usenixsecurity24/presentation/arkalakis},
	publisher = {USENIX Association},
	month = aug
}
",Google Scholar
EU DENK,An Important Cheese in Turkish Cuisine: A Research on PGI-Registered Erzurum String Cheese,,"However, after the manufacturer's responses, the privacy label was shown to them, and  they asked if they knew. Four manufacturers (30.7%) said they needed help knowing where to",2023,NA,https://www.researchsquare.com/article/rs-3085584/latest,"{'title': 'An Important Cheese in Turkish Cuisine: A Research on PGI-Registered Erzurum String Cheese', 'author': ['EU DENK'], 'pub_year': '2023', 'venue': 'NA', 'abstract': ""However, after the manufacturer's responses, the privacy label was shown to them, and  they asked if they knew. Four manufacturers (30.7%) said they needed help knowing where to""}",Google Scholar
TT Nguyen,Understanding and measuring privacy violations in Android apps,,"or privacy labels to identify potential GDPR violations, ie, determining whether an actual  app’s behavior is consistent with what is declared in the app privacy policy or privacy label [4,",2023,NA,https://publikationen.sulb.uni-saarland.de/handle/20.500.11880/36342,"{'title': 'Understanding and measuring privacy violations in Android apps', 'author': ['TT Nguyen'], 'pub_year': '2023', 'venue': 'NA', 'abstract': 'or privacy labels to identify potential GDPR violations, ie, determining whether an actual  app’s behavior is consistent with what is declared in the app privacy policy or privacy label [4,'}",Google Scholar
LR Fowler,Health App Lemons,,"Below that, there is a section for ""What's New,"" including recent app updates, user interface  previews, the developer's name, ratings and reviews, and, below that, the privacy label (",2022,Ala. L. Rev.,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/bamalr74&section=6,"{'title': 'Health App Lemons', 'author': ['LR Fowler'], 'pub_year': '2022', 'venue': 'Ala. L. Rev.', 'abstract': 'Below that, there is a section for ""What\'s New,"" including recent app updates, user interface  previews, the developer\'s name, ratings and reviews, and, below that, the privacy label ('}",Google Scholar
"EM El-Mhamdi, S Farhadkhani, R Guerraoui",On the impossible safety of large AI models,,"Large AI Models (LAIMs), of which large language models are the most prominent recent  example, showcase some impressive performance. However they have been empirically found",2022,arXiv preprint arXiv …,https://arxiv.org/abs/2209.15259,"{'title': 'On the impossible safety of large AI models', 'author': ['EM El-Mhamdi', 'S Farhadkhani', 'R Guerraoui'], 'pub_year': '2022', 'venue': 'arXiv preprint arXiv …', 'abstract': 'Large AI Models (LAIMs), of which large language models are the most prominent recent  example, showcase some impressive performance. However they have been empirically found'}",Google Scholar
"O Drozd, S Kirrane",A Conceptual Consent Request Framework for Mobile Devices,,"[10] developed a privacy label in the style of a “nutrition label” that helps users find the  information more quickly. Reeder et al. [11] visualized security policies, concerning permissions in",2023,Information,https://www.mdpi.com/2078-2489/14/9/515,"{'title': 'A Conceptual Consent Request Framework for Mobile Devices', 'author': ['O Drozd', 'S Kirrane'], 'pub_year': '2023', 'venue': 'Information', 'abstract': '[10] developed a privacy label in the style of a “nutrition label” that helps users find the  information more quickly. Reeder et al. [11] visualized security policies, concerning permissions in'}",Google Scholar
"C Landers, B Wies, M Ienca",Ethical considerations of digital therapeutics for mental health,,"The NHS app library, for example, uses a privacy label system to highlight that not all apps  it recommends fulfill the same level of privacy. The library also makes it clear that it does not",2023,Digital Therapeutics for Mental Health and …,https://www.sciencedirect.com/science/article/pii/B9780323900454000071,"{'title': 'Ethical considerations of digital therapeutics for mental health', 'author': ['C Landers', 'B Wies', 'M Ienca'], 'pub_year': '2023', 'venue': 'Digital Therapeutics for Mental Health and …', 'abstract': 'The NHS app library, for example, uses a privacy label system to highlight that not all apps  it recommends fulfill the same level of privacy. The library also makes it clear that it does not'}",Google Scholar
IM Rautenbach,"Die kweek, besit en gebruik van dagga: die verhouding tussen die reg op privaatheid en ander handvesregte",,1 Inleiding In Minister of Justice and Constitutional Development v Prince; National Director  of Public Prosecutions v Rubin; National Director of Public Prosecutions v Acton het die,2019,Journal of South African Law/Tydskrif vir die Suid …,https://journals.co.za/doi/abs/10.10520/EJC-137674b4ce,"{'title': 'Die kweek, besit en gebruik van dagga: die verhouding tussen die reg op privaatheid en ander handvesregte', 'author': ['IM Rautenbach'], 'pub_year': '2019', 'venue': 'Journal of South African Law/Tydskrif vir die Suid …', 'abstract': '1 Inleiding In Minister of Justice and Constitutional Development v Prince; National Director  of Public Prosecutions v Rubin; National Director of Public Prosecutions v Acton het die'}",Google Scholar
F Stajano,"Jessica Monteith ID University of Cambridge, Cambridge, UK psjm3@ cl. cam. ac. uk We've seen in the previous presentations that have touched on privacy data, a lot …",,So where the studies have made an effort to design this short one page sort of privacy label  that will help users in making informed choices when it comes to purchasing these kind of,2023,"… International Workshop, Cambridge, UK, March 27 …",https://books.google.com/books?hl=en&lr=&id=qHveEAAAQBAJ&oi=fnd&pg=PA113&dq=%22privacy+label%22&ots=B7FA0xFJ7i&sig=41YUrnm2xuTwHOuT8ZFkwAswl1o,"{'title': ""Jessica Monteith ID University of Cambridge, Cambridge, UK psjm3@ cl. cam. ac. uk We've seen in the previous presentations that have touched on privacy data, a lot …"", 'author': ['F Stajano'], 'pub_year': '2023', 'venue': '… International Workshop, Cambridge, UK, March 27 …', 'abstract': 'So where the studies have made an effort to design this short one page sort of privacy label  that will help users in making informed choices when it comes to purchasing these kind of'}",Google Scholar
D Langone,Data disclosure and tracking in digital markets: two essays,,"So under the hypothesis of non-simultaneity in the Privacy Label’s choice, the typical reverse  causality problem would be attenuated. In fact, the characterization of different data uses in",2023,NA,https://iris.unipv.it/bitstream/11571/1483338/2/Final_Langone_PHD_XXXV-1.pdf,"{'title': 'Data disclosure and tracking in digital markets: two essays', 'author': ['D Langone'], 'pub_year': '2023', 'venue': 'NA', 'abstract': 'So under the hypothesis of non-simultaneity in the Privacy Label’s choice, the typical reverse  causality problem would be attenuated. In fact, the characterization of different data uses in'}",Google Scholar
"P Azzoni, F Rogo, C Coveri, M Steger",Applying SHIELD in New Domains,,", providing the end customer with a privacy label (A+, A, B, , F) for services and devices.  The envisaged implementation of the privacy label will use the SHIELD multimetrics approach",2017,Measurable and …,https://api.taylorfrancis.com/content/chapters/edit/download?identifierName=doi&identifierValue=10.1201/9781138042858-21&type=chapterpdf,"{'title': 'Applying SHIELD in New Domains', 'author': ['P Azzoni', 'F Rogo', 'C Coveri', 'M Steger'], 'pub_year': '2017', 'venue': 'Measurable and …', 'abstract': ', providing the end customer with a privacy label (A+, A, B, , F) for services and devices.  The envisaged implementation of the privacy label will use the SHIELD multimetrics approach'}",Google Scholar
"V Rupp, M von Grafenstein",Clarifying “personal data” and the role of anonymisation in data protection law including and excluding data from the scope of the GDPR (more clearly) …,,"In a data-driven society, the collection and processing of data is essential to the operation of  existing technologies and the development of new ones. Data protection law protects",2024,Computer Law & Security Review,https://www.sciencedirect.com/science/article/pii/S0267364923001425,"{'title': 'Clarifying “personal data” and the role of anonymisation in data protection law including and excluding data from the scope of the GDPR (more clearly) …', 'author': ['V Rupp', 'M von Grafenstein'], 'pub_year': '2024', 'venue': 'Computer Law & Security Review', 'abstract': 'In a data-driven society, the collection and processing of data is essential to the operation of  existing technologies and the development of new ones. Data protection law protects'}",Google Scholar
N Girvan,An Investigation into the Privacy and Security Risks of Smart Toys in New Zealand,,"Smart toys are a growing portion of the children’s toy market. They offer a unique and  personalised play experience via the use of onboard sensors, internet connectivity, and innovative",2020,NA,https://openrepository.aut.ac.nz/handle/10292/13372,"{'title': 'An Investigation into the Privacy and Security Risks of Smart Toys in New Zealand', 'author': ['N Girvan'], 'pub_year': '2020', 'venue': 'NA', 'abstract': 'Smart toys are a growing portion of the children’s toy market. They offer a unique and  personalised play experience via the use of onboard sensors, internet connectivity, and innovative'}",Google Scholar
MA Birkett,The Trier Social Stress Test protocol for inducing psychological stress,,This article demonstrates a psychological stress protocol for use in a laboratory setting.  Protocols that allow researchers to study the biological pathways of the stress response in health,2011,JoVE (Journal of Visualized Experiments),https://www.jove.com/t/3238/the-trier-social-stress-test-protocol-for-inducing-psychological,"{'title': 'The Trier Social Stress Test protocol for inducing psychological stress', 'author': ['MA Birkett'], 'pub_year': '2011', 'venue': 'JoVE (Journal of Visualized Experiments)', 'abstract': 'This article demonstrates a psychological stress protocol for use in a laboratory setting.  Protocols that allow researchers to study the biological pathways of the stress response in health'}",Google Scholar
BP Knijnenburg,Privacy Support for the Total Learning Architecture Volume 1: Operational Characteristics,,The purpose of this document is to inform ADL and other Training and Learning Architecture  (TLA) producers and consumers about the Operational Characteristics that impact users,2017,NA,https://apps.dtic.mil/sti/citations/trecms/AD1064704,"{'title': 'Privacy Support for the Total Learning Architecture Volume 1: Operational Characteristics', 'author': ['BP Knijnenburg'], 'pub_year': '2017', 'venue': 'NA', 'abstract': 'The purpose of this document is to inform ADL and other Training and Learning Architecture  (TLA) producers and consumers about the Operational Characteristics that impact users'}",Google Scholar
"X Shen, H Brown, J Tao, M Strobel, Y Tong",Towards Regulatable AI Systems: Technical Gaps and Policy Opportunities,,"There is increasing attention being given to how to regulate AI systems. As governing bodies  grapple with what values to encapsulate into regulation, we consider the technical half of",2023,arXiv preprint arXiv …,https://arxiv.org/abs/2306.12609,"{'title': 'Towards Regulatable AI Systems: Technical Gaps and Policy Opportunities', 'author': ['X Shen', 'H Brown', 'J Tao', 'M Strobel', 'Y Tong'], 'pub_year': '2023', 'venue': 'arXiv preprint arXiv …', 'abstract': 'There is increasing attention being given to how to regulate AI systems. As governing bodies  grapple with what values to encapsulate into regulation, we consider the technical half of'}",Google Scholar
"M Raciti, G Bella, K Kalogiannis, A Henriksson",EuroSPW 2023,,"(De Montfort University, United Kingdom), Isabel Wagner (University of Basel, Switzerland),  and Eerke Albert Boiten (De Montfort University, United Kingdom)Comparing Privacy Label",NA,NA,https://www.computer.org/csdl/proceedings-article/euros&pw/2023/272000z005/1PehUSszmCc,"{'title': 'EuroSPW 2023', 'author': ['M Raciti', 'G Bella', 'K Kalogiannis', 'A Henriksson'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': '(De Montfort University, United Kingdom), Isabel Wagner (University of Basel, Switzerland),  and Eerke Albert Boiten (De Montfort University, United Kingdom)Comparing Privacy Label'}",Google Scholar
"C Nabila, FA Alfonso, K Kahlila, MH Pua",The Development of Personal Data Protection: 21st Century Businesses' Reality in Adopting the Law and Gen Z's Perspective as Subsequent Target Market,,"Besides, with the new iOS 14, Apple also developed a new feature known as privacy label.  The redesign Apple App Store added a new column that shows the app's privacy labels to",2021,Asian J. Legal Stud.,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/alsacdmj7&section=7,"{'title': ""The Development of Personal Data Protection: 21st Century Businesses' Reality in Adopting the Law and Gen Z's Perspective as Subsequent Target Market"", 'author': ['C Nabila', 'FA Alfonso', 'K Kahlila', 'MH Pua'], 'pub_year': '2021', 'venue': 'Asian J. Legal Stud.', 'abstract': ""Besides, with the new iOS 14, Apple also developed a new feature known as privacy label.  The redesign Apple App Store added a new column that shows the app's privacy labels to""}",Google Scholar
V Morel,Enhancing transparency and consent in the internet of things,,"They determined that security and privacy were among the most important factors of purchase,  and consequently developed an Internet of Things privacy label to improve information",2020,NA,https://inria.hal.science/tel-02973666/document,"{'title': 'Enhancing transparency and consent in the internet of things', 'author': ['V Morel'], 'pub_year': '2020', 'venue': 'NA', 'abstract': 'They determined that security and privacy were among the most important factors of purchase,  and consequently developed an Internet of Things privacy label to improve information'}",Google Scholar
"KM Choi, N Moletta",Virtually connecting across geographical boundaries through Facebook,,"This article reviews using closed group Facebook pages as a social network to create a  pedagogical space where counseling students communicate, share resources, and develop",2013,Journal for International Counselor …,https://digitalscholarship.unlv.edu/jice/vol5/iss1/4/,"{'title': 'Virtually connecting across geographical boundaries through Facebook', 'author': ['KM Choi', 'N Moletta'], 'pub_year': '2013', 'venue': 'Journal for International Counselor …', 'abstract': 'This article reviews using closed group Facebook pages as a social network to create a  pedagogical space where counseling students communicate, share resources, and develop'}",Google Scholar
"L Duan, J Sun, J Jia, Y Chen, M Gorlatova",InfoScissors: Defense against Data Leakage in Collaborative Inference through the Lens of Mutual Information,,"Edge-cloud collaborative inference empowers resource-limited IoT devices to support deep  learning applications without disclosing their raw data to the cloud server, thus protecting",NA,NA,https://openreview.net/forum?id=IwDE4zULBk,"{'title': 'InfoScissors: Defense against Data Leakage in Collaborative Inference through the Lens of Mutual Information', 'author': ['L Duan', 'J Sun', 'J Jia', 'Y Chen', 'M Gorlatova'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': 'Edge-cloud collaborative inference empowers resource-limited IoT devices to support deep  learning applications without disclosing their raw data to the cloud server, thus protecting'}",Google Scholar
R Balebako,Mitigating the Risks of Smartphone Data Sharing: Identifying Opportunities and Evaluating Notice,,"As smartphones become more ubiquitous, increasing amounts of information about  smartphone users are created, collected, and shared. This information may pose privacy and",2014,NA,https://kilthub.cmu.edu/articles/thesis/Mitigating_the_Risks_of_Smartphone_Data_Sharing_Identifying_Opportunities_and_Evaluating_Notice/6720635,"{'title': 'Mitigating the Risks of Smartphone Data Sharing: Identifying Opportunities and Evaluating Notice', 'author': ['R Balebako'], 'pub_year': '2014', 'venue': 'NA', 'abstract': 'As smartphones become more ubiquitous, increasing amounts of information about  smartphone users are created, collected, and shared. This information may pose privacy and'}",Google Scholar
"BP Knijnenburg, D Cherry, Y He, RG Anaraky",Privacy Support for the Total Learning Architecture Volume 2: Modeling Factors,,"For example, marketers [1,46,105] have discovered that displaying a privacy label on an  e-commerce website—a supposed vote of confidence in the site’s privacy practices—may",2018,NA,https://apps.dtic.mil/sti/citations/AD1064608,"{'title': 'Privacy Support for the Total Learning Architecture Volume 2: Modeling Factors', 'author': ['BP Knijnenburg', 'D Cherry', 'Y He', 'RG Anaraky'], 'pub_year': '2018', 'venue': 'NA', 'abstract': 'For example, marketers [1,46,105] have discovered that displaying a privacy label on an  e-commerce website—a supposed vote of confidence in the site’s privacy practices—may'}",Google Scholar
JT Weiss,"Gender autonomy, transgender identity and substantive due process: Finding a rational basis for Lawrence v. Texas",,"My description of the right to privacy was based on the formulation championed by Laurence  Tribe in 1978: ""the single core common to all of what passes under the privacy label [is]",2010,JRGE,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/jlorcgd5&section=6,"{'title': 'Gender autonomy, transgender identity and substantive due process: Finding a rational basis for Lawrence v. Texas', 'author': ['JT Weiss'], 'pub_year': '2010', 'venue': 'JRGE', 'abstract': 'My description of the right to privacy was based on the formulation championed by Laurence  Tribe in 1978: ""the single core common to all of what passes under the privacy label [is]'}",Google Scholar
II Policy,Institutional Handbook of Operating Procedures Policy 09.13. 29,,ensure the patient information tag from the component is removed and placed in the blue  recycle bin for patient protected information or covered with an identity-concealing privacy label,NA,Policy,"http://www.utmb.edu/policies_and_procedures/IHOP/Clinical/General_Clinical_Procedures_and_Care/IHOP%20-%2009.13.29%20-%20Transfusion%20of%20Blood%20Components,%20Adults%20and%20Pediatrics.pdf","{'title': 'Institutional Handbook of Operating Procedures Policy 09.13. 29', 'author': ['II Policy'], 'pub_year': 'NA', 'venue': 'Policy', 'abstract': 'ensure the patient information tag from the component is removed and placed in the blue  recycle bin for patient protected information or covered with an identity-concealing privacy label'}",Google Scholar
"LR Fowler, JL Roberts",Mind the App,,"155 Including an evidence label alongside other pertinent information, like Apple's Privacy  Label 15 6 in the Apple App Store, can help improve app selection. A succinct label in an",2022,Annals Health L.,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/anohl31&section=14,"{'title': 'Mind the App', 'author': ['LR Fowler', 'JL Roberts'], 'pub_year': '2022', 'venue': 'Annals Health L.', 'abstract': ""155 Including an evidence label alongside other pertinent information, like Apple's Privacy  Label 15 6 in the Apple App Store, can help improve app selection. A succinct label in an""}",Google Scholar
"V Urovi, R Celebi, C Sun, L Rieswijk, M Erard",TAPS Responsibility Matrix: A tool for responsible data science by design,,"For example, “accountability” was first called “governance,” and “confidentiality” was later  added to the “privacy” label. Once we agreed on four categories, we conducted targeted",2023,arXiv preprint arXiv …,https://arxiv.org/abs/2302.01041,"{'title': 'TAPS Responsibility Matrix: A tool for responsible data science by design', 'author': ['V Urovi', 'R Celebi', 'C Sun', 'L Rieswijk', 'M Erard'], 'pub_year': '2023', 'venue': 'arXiv preprint arXiv …', 'abstract': 'For example, “accountability” was first called “governance,” and “confidentiality” was later  added to the “privacy” label. Once we agreed on four categories, we conducted targeted'}",Google Scholar
H Zhong,User protection in social networks using machine learning techniques,,"Further, we extend the problem of determining a single privacy label for a given image to  jointly inferring a privacy label and detecting the specific areas of sensitive content within a",2019,NA,https://search.proquest.com/openview/0adb7e962466264066c89cc79bb7ee10/1?pq-origsite=gscholar&cbl=18750&diss=y,"{'title': 'User protection in social networks using machine learning techniques', 'author': ['H Zhong'], 'pub_year': '2019', 'venue': 'NA', 'abstract': 'Further, we extend the problem of determining a single privacy label for a given image to  jointly inferring a privacy label and detecting the specific areas of sensitive content within a'}",Google Scholar
JR Yauri Miranda,"Personal data management and accountability: European regulation, market principles and civic agency strategies",,The definition of privacy by design is therefore also ‘susceptible to the interpretation to  collect any data as long as it is with a privacy label while shrinking the scope of control from the,2019,European Politics and Society,https://www.tandfonline.com/doi/abs/10.1080/23745118.2018.1542771,"{'title': 'Personal data management and accountability: European regulation, market principles and civic agency strategies', 'author': ['JR Yauri Miranda'], 'pub_year': '2019', 'venue': 'European Politics and Society', 'abstract': 'The definition of privacy by design is therefore also ‘susceptible to the interpretation to  collect any data as long as it is with a privacy label while shrinking the scope of control from the'}",Google Scholar
"M Von Grafenstein, T Jakobi, G Stevens",Effective data protection by design through interdisciplinary research methods: The example of effective purpose specification by applying user-Centred UX …,,"211 and 212; this is not to say that the debate that primarily in the USA has already started  in the 60ies and continues to be conducted under the privacy label, has not led to similar",2022,Computer Law & Security Review,https://www.sciencedirect.com/science/article/pii/S026736492200067X,"{'title': 'Effective data protection by design through interdisciplinary research methods: The example of effective purpose specification by applying user-Centred UX …', 'author': ['M Von Grafenstein', 'T Jakobi', 'G Stevens'], 'pub_year': '2022', 'venue': 'Computer Law & Security Review', 'abstract': '211 and 212; this is not to say that the debate that primarily in the USA has already started  in the 60ies and continues to be conducted under the privacy label, has not led to similar'}",Google Scholar
B Altpeter,Informed Consent? A Study of “Consent Dialogs” on Android and iOS,,"For each privacy label data type, we determine whether it was correctly declared, correctly  not declared, wrongly declared as anonymous, wrongly undeclared, unnecessarily declared,",2022,NA,https://benjamin-altpeter.de/doc/thesis-consent-dialogs.pdf,"{'title': 'Informed Consent? A Study of “Consent Dialogs” on Android and iOS', 'author': ['B Altpeter'], 'pub_year': '2022', 'venue': 'NA', 'abstract': 'For each privacy label data type, we determine whether it was correctly declared, correctly  not declared, wrongly declared as anonymous, wrongly undeclared, unnecessarily declared,'}",Google Scholar
C Perera,Sensing as a service for internet of things: A roadmap,,The Sensing as a Service model envisions to extract more value out of Internet of Things  paradigm. This book aims to lay down a roadmap towards building the sensing as a Service,2017,NA,https://books.google.com/books?hl=en&lr=&id=sP38DQAAQBAJ&oi=fnd&pg=PA2&dq=%22privacy+label%22&ots=tATRChC85l&sig=b6S4BmLJoR2hueaIMO-iga9v61Q,"{'title': 'Sensing as a service for internet of things: A roadmap', 'author': ['C Perera'], 'pub_year': '2017', 'venue': 'NA', 'abstract': 'The Sensing as a Service model envisions to extract more value out of Internet of Things  paradigm. This book aims to lay down a roadmap towards building the sensing as a Service'}",Google Scholar
AM Rathore,A Formal Model for a General-Purpose Compiler for Secure Multiparty Computations,,"we extend their permission model by including a privacy label. Each memory block has a list   the byte that it corresponds to, and the privacy label a and permission perm for that byte of",2022,NA,https://search.proquest.com/openview/6d069ce76524547fa738c2f21d72e2ea/1?pq-origsite=gscholar&cbl=18750&diss=y,"{'title': 'A Formal Model for a General-Purpose Compiler for Secure Multiparty Computations', 'author': ['AM Rathore'], 'pub_year': '2022', 'venue': 'NA', 'abstract': 'we extend their permission model by including a privacy label. Each memory block has a list   the byte that it corresponds to, and the privacy label a and permission perm for that byte of'}",Google Scholar
J Lake,"Hey, you stole my avatar!: virtual reality and its risks to identity protection",,"The ""privacy"" label, in the sense of a right to be ""left alone,"" seemed to run counter to the  fact that famous people, who have voluntarily sacrificed their right of privacy in exchange for",2019,Emory LJ,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/emlj69&section=27,"{'title': 'Hey, you stole my avatar!: virtual reality and its risks to identity protection', 'author': ['J Lake'], 'pub_year': '2019', 'venue': 'Emory LJ', 'abstract': 'The ""privacy"" label, in the sense of a right to be ""left alone,"" seemed to run counter to the  fact that famous people, who have voluntarily sacrificed their right of privacy in exchange for'}",Google Scholar
SQ Raza,Selecting online vendors by privacy risks,,"Many people have growing concerns about privacy issues, especially the treatment of personal  information. Other researchers have demonstrated that consumers do not effectively use",2012,NA,https://search.proquest.com/openview/b3dd0e9ad97c3433c4367c3f3463fb5b/1?pq-origsite=gscholar&cbl=18750,"{'title': 'Selecting online vendors by privacy risks', 'author': ['SQ Raza'], 'pub_year': '2012', 'venue': 'NA', 'abstract': 'Many people have growing concerns about privacy issues, especially the treatment of personal  information. Other researchers have demonstrated that consumers do not effectively use'}",Google Scholar
E Milne,Materialities of law: Celebrity production and the public domain,,"that they wanted no one to commercialise their identity, but rather that they wanted the right  to control when, where and how their identity was so used ...mesmerized by the 'privacy' label",2009,Fibreculture,https://researchbank.swinburne.edu.au/file/3c98245e-5142-4000-b1be-c23a9e2430f1/1/PDF%20(Published%20version).pdf,"{'title': 'Materialities of law: Celebrity production and the public domain', 'author': ['E Milne'], 'pub_year': '2009', 'venue': 'Fibreculture', 'abstract': ""that they wanted no one to commercialise their identity, but rather that they wanted the right  to control when, where and how their identity was so used ...mesmerized by the 'privacy' label""}",Google Scholar
V Zimmer,Winter is Here: The Impossibility of Schrems II for US-Based Direct-to-Consumer Companies,,"In this paper, Vanessa Zimmer exposes the precarious position of Direct-to-Consumer (DTC)  companies that are physically located in the United States but still subject to the European",2021,Nw. J. Int'l L. & Bus.,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/nwjilb42&section=5,"{'title': 'Winter is Here: The Impossibility of Schrems II for US-Based Direct-to-Consumer Companies', 'author': ['V Zimmer'], 'pub_year': '2021', 'venue': ""Nw. J. Int'l L. & Bus."", 'abstract': 'In this paper, Vanessa Zimmer exposes the precarious position of Direct-to-Consumer (DTC)  companies that are physically located in the United States but still subject to the European'}",Google Scholar
P Kosseim,IPC Comments on the Ontario Government's White Paper on Modernizing Privacy in Ontario,,"The Office of the Information and Privacy Commissioner of Ontario (IPC) is pleased to offer  its views in response to the government’s white paper, Modernizing Privacy in Ontario. 1 The",2021,NA,https://www.ipc.on.ca/wp-content/uploads/2021/09/2021-09-03-ipc-comments-on-gov-white-paper_modernizing-privacy-in-ontario.pdf,"{'title': ""IPC Comments on the Ontario Government's White Paper on Modernizing Privacy in Ontario"", 'author': ['P Kosseim'], 'pub_year': '2021', 'venue': 'NA', 'abstract': 'The Office of the Information and Privacy Commissioner of Ontario (IPC) is pleased to offer  its views in response to the government’s white paper, Modernizing Privacy in Ontario. 1 The'}",Google Scholar
"M Fenwick, P Jurcys",From Cyborgs to Quantified Selves,,"The privacy label contains a set of icons as well as the key buzzwords describing the  categories of data accessed. Gradually, such data privacy app icons are becoming the norm: in",2022,… Information Technology and E-Commerce Law,https://www.academia.edu/download/89188542/fenwick_pdf_2.pdf,"{'title': 'From Cyborgs to Quantified Selves', 'author': ['M Fenwick', 'P Jurcys'], 'pub_year': '2022', 'venue': '… Information Technology and E-Commerce Law', 'abstract': 'The privacy label contains a set of icons as well as the key buzzwords describing the  categories of data accessed. Gradually, such data privacy app icons are becoming the norm: in'}",Google Scholar
AM Paul,"The cult of personality testing: How personality tests are leading us to miseducate our children, mismanage our companies, and misunderstand ourselves",,Award-winning psychology writer Annie Paul delivers a scathing exposé on the history and  effects of personality tests. Millions of people worldwide take personality tests each year to,2010,NA,https://books.google.com/books?hl=en&lr=&id=Njh9KgwSjs0C&oi=fnd&pg=PR11&dq=%22privacy+label%22&ots=bdy9-8lVIs&sig=HMDbxqXBTi4l5jVf6jCPAfr6cKI,"{'title': 'The cult of personality testing: How personality tests are leading us to miseducate our children, mismanage our companies, and misunderstand ourselves', 'author': ['AM Paul'], 'pub_year': '2010', 'venue': 'NA', 'abstract': 'Award-winning psychology writer Annie Paul delivers a scathing exposé on the history and  effects of personality tests. Millions of people worldwide take personality tests each year to'}",Google Scholar
"M Steinböck, J Bleier, M Rainer, T Urban, C Utz","Comparing Apples to Androids: Discovery, Retrieval, and Matching of iOS and Android Apps for Cross-Platform Analyses",,"For years, researchers have been analyzing mobile Android apps to investigate diverse  properties such as software engineering practices, business models, security, privacy, or",2024,NA,https://themoep.at/research/2024-comparing-apples-to-androids.pdf,"{'title': 'Comparing Apples to Androids: Discovery, Retrieval, and Matching of iOS and Android Apps for Cross-Platform Analyses', 'author': ['M Steinböck', 'J Bleier', 'M Rainer', 'T Urban', 'C Utz'], 'pub_year': '2024', 'venue': 'NA', 'abstract': 'For years, researchers have been analyzing mobile Android apps to investigate diverse  properties such as software engineering practices, business models, security, privacy, or'}",Google Scholar
NB Said,Information Flow Security in Component-Based Models: From Verification to Implementation,,"The security of information systems are paramount in today’s life, especially with the growth  of complex and highly interconnected computer systems. For instance, bank systems have",2016,NA,https://theses.hal.science/tel-01679945/,"{'title': 'Information Flow Security in Component-Based Models: From Verification to Implementation', 'author': ['NB Said'], 'pub_year': '2016', 'venue': 'NA', 'abstract': 'The security of information systems are paramount in today’s life, especially with the growth  of complex and highly interconnected computer systems. For instance, bank systems have'}",Google Scholar
"DM Payne, K Watson",AN ETHICAL ANALYSIS OF MEDICAL DATA MINING: AN ARGUMENT FOR BUSINESS RESTRAINT IN THE FACE OF AGGRESSIVE DATA MINING …,,A Federal mandate requiring healthcare providers to adopt and demonstrate “meaningful  use” of electronic healthcare records creates the specter of a comprehensive national medical,2021,… of Business & …,https://sjbe.s3.us-east-2.amazonaws.com/SJBE_Volume_13_2021.pdf#page=10,"{'title': 'AN ETHICAL ANALYSIS OF MEDICAL DATA MINING: AN ARGUMENT FOR BUSINESS RESTRAINT IN THE FACE OF AGGRESSIVE DATA MINING …', 'author': ['DM Payne', 'K Watson'], 'pub_year': '2021', 'venue': '… of Business & …', 'abstract': 'A Federal mandate requiring healthcare providers to adopt and demonstrate “meaningful  use” of electronic healthcare records creates the specter of a comprehensive national medical'}",Google Scholar
I Annex,Second Evaluation of Technical Progress & Assessment of Project Objectives,,1 EXECUTIVE SUMMARY This deliverable is the second of three deliverables within SCOTT  that performs an assessment of progress and achievement of objectives. This particular,2019,NA,https://scottproject.eu/wp-content/uploads/2021/03/SCOTT_D_1.5.pdf,"{'title': 'Second Evaluation of Technical Progress & Assessment of Project Objectives', 'author': ['I Annex'], 'pub_year': '2019', 'venue': 'NA', 'abstract': '1 EXECUTIVE SUMMARY This deliverable is the second of three deliverables within SCOTT  that performs an assessment of progress and achievement of objectives. This particular'}",Google Scholar
"DEA Moses Namara, R Davis, R Anaraky, M Namara",Operational Characteristics,,14. ABSTRACT The purpose of this document is to inform ADL and other Training and Learning  Architecture (TLA) producers and consumers about the Operational Characteristics that,NA,NA,https://apps.dtic.mil/sti/pdfs/AD1064704.pdf,"{'title': 'Operational Characteristics', 'author': ['DEA Moses Namara', 'R Davis', 'R Anaraky', 'M Namara'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': '14. ABSTRACT The purpose of this document is to inform ADL and other Training and Learning  Architecture (TLA) producers and consumers about the Operational Characteristics that'}",Google Scholar
P Traung,The proposed new EU general data protection regulation,,"Among other things, the proposed General Data Protection Regulation aims at substantially  reducing fragmentation, administrative burden and cost and to provide clear rules,",2012,Computer law review international,https://www.degruyter.com/document/doi/10.9785/ovs-cri-2012-33/html,"{'title': 'The proposed new EU general data protection regulation', 'author': ['P Traung'], 'pub_year': '2012', 'venue': 'Computer law review international', 'abstract': 'Among other things, the proposed General Data Protection Regulation aims at substantially  reducing fragmentation, administrative burden and cost and to provide clear rules,'}",Google Scholar
"JD Smith, JE Williams, MT Jones","AMERICANS DON'T UNDERSTAND HOW THEIR DATA IS USED, CAN'T CONTROL IT",,"An extension of this individual literacy approach for adults is the notion of a “privacy label.”  In 2009, researchers from Carnegie Mellon University created “a clear, uniform, single-page",2022,American Journal of Arts and …,http://topjournals.org/index.php/AJAC/article/view/219,"{'title': ""AMERICANS DON'T UNDERSTAND HOW THEIR DATA IS USED, CAN'T CONTROL IT"", 'author': ['JD Smith', 'JE Williams', 'MT Jones'], 'pub_year': '2022', 'venue': 'American Journal of Arts and …', 'abstract': 'An extension of this individual literacy approach for adults is the notion of a “privacy label.”  In 2009, researchers from Carnegie Mellon University created “a clear, uniform, single-page'}",Google Scholar
W McGeveran,"Disclosure, endorsement, and identity in social marketing",,"Courts and treatise writers may file disclosure and identity control concerns together under  the ""privacy"" label because of their ""family resemblance.""'' But identity control differs from",2009,U. Ill. L. Rev.,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/unilllr2009&section=33,"{'title': 'Disclosure, endorsement, and identity in social marketing', 'author': ['W McGeveran'], 'pub_year': '2009', 'venue': 'U. Ill. L. Rev.', 'abstract': 'Courts and treatise writers may file disclosure and identity control concerns together under  the ""privacy"" label because of their ""family resemblance.""\'\' But identity control differs from'}",Google Scholar
C Perera,Sensing as a Service,,"Few years back, I wrote about the Sensing as a Service (S2aaS) in two scholarly publications  [198][140]. Since then, these publications have been well cited and discussed by different",2017,arXiv,https://www.academia.edu/download/51461601/main.pdf,"{'title': 'Sensing as a Service', 'author': ['C Perera'], 'pub_year': '2017', 'venue': 'arXiv', 'abstract': 'Few years back, I wrote about the Sensing as a Service (S2aaS) in two scholarly publications  [198][140]. Since then, these publications have been well cited and discussed by different'}",Google Scholar
"M Holler, B van Giffen, S Benzell",The general data protection regulation in financial services industries: how do companies approach the implementation of the gdpr and what can we learn from …,,This research study sets out to explore the General Data Protection Regulation in financial  services industries grounded on the pivotal question:“How do companies approach to,2020,Proceedings of the 82th …,https://www.researchgate.net/profile/Manuel-Holler/publication/340003405_The_General_Data_Protection_Regulation_in_Financial_Services_Industries_How_Do_Companies_Approach_the_Implementation_of_the_GDPR_and_What_Can_We_Learn_From_Their_Approaches/links/5ff5c99c45851553a023340b/The-General-Data-Protection-Regulation-in-Financial-Services-Industries-How-Do-Companies-Approach-the-Implementation-of-the-GDPR-and-What-Can-We-Learn-From-Their-Approaches.pdf,"{'title': 'The general data protection regulation in financial services industries: how do companies approach the implementation of the gdpr and what can we learn from …', 'author': ['M Holler', 'B van Giffen', 'S Benzell'], 'pub_year': '2020', 'venue': 'Proceedings of the 82th …', 'abstract': 'This research study sets out to explore the General Data Protection Regulation in financial  services industries grounded on the pivotal question:“How do companies approach to'}",Google Scholar
L Groth,A Vulnerability Management Solution for constrained IoT devices with a Trusted Execution Environment using a Hardware Root of Trust,,The popularity and prevalence of Internet of Things (IoT) devices has been ever increasing.  They have found their way into our everyday lives and increasingly transform our living,2023,NA,https://refubium.fu-berlin.de/handle/fub188/37741,"{'title': 'A Vulnerability Management Solution for constrained IoT devices with a Trusted Execution Environment using a Hardware Root of Trust', 'author': ['L Groth'], 'pub_year': '2023', 'venue': 'NA', 'abstract': 'The popularity and prevalence of Internet of Things (IoT) devices has been ever increasing.  They have found their way into our everyday lives and increasingly transform our living'}",Google Scholar
"GRB Neller, SMRL Green, M Fayloga",Commandant of the Marine Corps,,Next to the activity privacy label choose the drop down list and select the level of privacy  you want. The most restrictive default level is “Friends except acquaintances” the least is “public,2017,Message to the Force …,https://www.marines.mil/Portals/1/Docs/Social-Media-Handbook20170308.pdf,"{'title': 'Commandant of the Marine Corps', 'author': ['GRB Neller', 'SMRL Green', 'M Fayloga'], 'pub_year': '2017', 'venue': 'Message to the Force …', 'abstract': 'Next to the activity privacy label choose the drop down list and select the level of privacy  you want. The most restrictive default level is “Friends except acquaintances” the least is “public'}",Google Scholar
B VAN HOOF,Protecting Personal Data in the Age of the Internet of Toys,,"In 2017 security researcher Troy Hunt wrote an article about an event that would not have  been possible in the not too distant past. It spoke of toy teddy bears, called CloudPets, that",NA,NA,http://arno.uvt.nl/show.cgi?fid=150358,"{'title': 'Protecting Personal Data in the Age of the Internet of Toys', 'author': ['B VAN HOOF'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': 'In 2017 security researcher Troy Hunt wrote an article about an event that would not have  been possible in the not too distant past. It spoke of toy teddy bears, called CloudPets, that'}",Google Scholar
FR Marani,Defensive Machine Learning Techniques for Countering Adversarial Attacks,,The increasing reliance on machine learning algorithms has made them a target for exploiting  vulnerabilities in these systems and launching adversarial attacks. The attacker in these,2023,NA,https://search.proquest.com/openview/7db3924c6bb3da57e8c3c76094d5e21c/1?pq-origsite=gscholar&cbl=18750&diss=y,"{'title': 'Defensive Machine Learning Techniques for Countering Adversarial Attacks', 'author': ['FR Marani'], 'pub_year': '2023', 'venue': 'NA', 'abstract': 'The increasing reliance on machine learning algorithms has made them a target for exploiting  vulnerabilities in these systems and launching adversarial attacks. The attacker in these'}",Google Scholar
JS Hoffman,"Your data, their billions: Unraveling and simplifying big tech",,THE GUIDE TO USING EVERYDAY TECH—FROM GOOGLE SEARCHES AND AMAZON  TO GPS AND FACEBOOK—WITH EYES WIDE OPEN. What if somebody knew everything,2022,NA,https://books.google.com/books?hl=en&lr=&id=zMBgEAAAQBAJ&oi=fnd&pg=PT6&dq=%22privacy+label%22&ots=kRd_jc5yPH&sig=jkfLNFjvUTWSs2ZOVwLAxaJ_0qM,"{'title': 'Your data, their billions: Unraveling and simplifying big tech', 'author': ['JS Hoffman'], 'pub_year': '2022', 'venue': 'NA', 'abstract': 'THE GUIDE TO USING EVERYDAY TECH—FROM GOOGLE SEARCHES AND AMAZON  TO GPS AND FACEBOOK—WITH EYES WIDE OPEN. What if somebody knew everything'}",Google Scholar
"V Benson, S Furnell, D Masi, T Muller","Regulation, Policy and Cybersecurity: Hardware Security",,"The digital society has a significant reliance upon the secure operation of systems and  machinery, including the hardware present in personal and industrial devices. The volume of",2021,NA,https://publications.aston.ac.uk/id/eprint/43500/,"{'title': 'Regulation, Policy and Cybersecurity: Hardware Security', 'author': ['V Benson', 'S Furnell', 'D Masi', 'T Muller'], 'pub_year': '2021', 'venue': 'NA', 'abstract': 'The digital society has a significant reliance upon the secure operation of systems and  machinery, including the hardware present in personal and industrial devices. The volume of'}",Google Scholar
"G Petkos, S Papadopoulos, AP CEA, M Hildebrandt",Version Changes,,"Actions: WP6 has worked in close collaboration with WP5 in various ways, the most prominent  being the collaboration for the image privacy module that assigns a privacy label to the",NA,NA,https://www.usemp.eu/wp-content/uploads/2017/05/usemp_deliverable_d6.5.pdf,"{'title': 'Version Changes', 'author': ['G Petkos', 'S Papadopoulos', 'AP CEA', 'M Hildebrandt'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': 'Actions: WP6 has worked in close collaboration with WP5 in various ways, the most prominent  being the collaboration for the image privacy module that assigns a privacy label to the'}",Google Scholar
L Fang,Mechanisms of controlled sharing for social networking users,,"In the most general sense, the classifier uses a feature vector representation of a friend to  predict the friend’s privacy label. Formally, for a particular data item i ∈ I, the classifier can be",2013,NA,https://search.proquest.com/openview/f85376f993e4bc2fb955ecba0771495f/1?pq-origsite=gscholar&cbl=18750,"{'title': 'Mechanisms of controlled sharing for social networking users', 'author': ['L Fang'], 'pub_year': '2013', 'venue': 'NA', 'abstract': 'In the most general sense, the classifier uses a feature vector representation of a friend to  predict the friend’s privacy label. Formally, for a particular data item i ∈ I, the classifier can be'}",Google Scholar
"MP Rogers, W Siever",The Great Objective-C Swift Migration of 2015,,"Since December 2020, the Apple App Store has required all developers to create a  privacy label when submitting new apps or app updates. However, there has not been a",2015,Proceedings of the 46th ACM Technical …,https://dl.acm.org/doi/abs/10.1145/2676723.2691849,"{'title': 'The Great Objective-C Swift Migration of 2015', 'author': ['MP Rogers', 'W Siever'], 'pub_year': '2015', 'venue': 'Proceedings of the 46th ACM Technical …', 'abstract': 'Since December 2020, the Apple App Store has required all developers to create a  privacy label when submitting new apps or app updates. However, there has not been a'}",Google Scholar
"M Colon, J Madison",How can iowans effectively prevent the commercial misappropriation of their identities? why iowa needs a right of publicity statute,,"(""Judges appeared confused as to how to fit the 'privacy' label to a plaintiff whose identity  already enjoyed widespread recognition. Some seemed to feel that there could be no privacy'",2020,Iowa L. Rev.,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/ilr106&section=11,"{'title': 'How can iowans effectively prevent the commercial misappropriation of their identities? why iowa needs a right of publicity statute', 'author': ['M Colon', 'J Madison'], 'pub_year': '2020', 'venue': 'Iowa L. Rev.', 'abstract': '(""Judges appeared confused as to how to fit the \'privacy\' label to a plaintiff whose identity  already enjoyed widespread recognition. Some seemed to feel that there could be no privacy\''}",Google Scholar
MB Vleju,Client-centric identity and access management in cloud computing/eingereicht von: Mircea Boris Vleju,,"While cloud computing boasts other advantages it should be noted that the adoption of  cloud-based services comes with disadvantages, such as: loss of governance, provider lock-in,",2015,NA,https://epub.jku.at/urn:nbn:at:at-ubl:1-3457,"{'title': 'Client-centric identity and access management in cloud computing/eingereicht von: Mircea Boris Vleju', 'author': ['MB Vleju'], 'pub_year': '2015', 'venue': 'NA', 'abstract': 'While cloud computing boasts other advantages it should be noted that the adoption of  cloud-based services comes with disadvantages, such as: loss of governance, provider lock-in,'}",Google Scholar
"V Benson, S Furnell, D Masi, T Muller","Regulation, Policy and Cybersecurity",,"The digital society has a significant reliance upon the secure operation of systems and  machinery, including the hardware present in personal and industrial devices. The volume of",2021,NA,https://www.discribehub.org/s/Discribe-report-submission-version_fin_for_release-with-cover-page.pdf,"{'title': 'Regulation, Policy and Cybersecurity', 'author': ['V Benson', 'S Furnell', 'D Masi', 'T Muller'], 'pub_year': '2021', 'venue': 'NA', 'abstract': 'The digital society has a significant reliance upon the secure operation of systems and  machinery, including the hardware present in personal and industrial devices. The volume of'}",Google Scholar
"A Rathore, M Blanton, M Gaboardi, L Ziarek",A Formal Model for Secure Multiparty Computation,,"we extend their permission model by including a privacy label. Each memory block has a list   the byte that it corresponds to, and the privacy label a and permission p for that byte of data.",2023,arXiv preprint arXiv …,https://arxiv.org/abs/2306.00308,"{'title': 'A Formal Model for Secure Multiparty Computation', 'author': ['A Rathore', 'M Blanton', 'M Gaboardi', 'L Ziarek'], 'pub_year': '2023', 'venue': 'arXiv preprint arXiv …', 'abstract': 'we extend their permission model by including a privacy label. Each memory block has a list   the byte that it corresponds to, and the privacy label a and permission p for that byte of data.'}",Google Scholar
"GJF Amos, SMM Barrett",marines. dodlive. mil/social-media,,Next to the activity privacy label choose the drop down list and select the level of privacy  you want. The most restrictive default level is “Friends except acquaintances” the least is “public,NA,NA,https://www.mcasyuma.marines.mil/Portals/152/Social%20Media%20Smart%20Cards/Marines-Social-Media-Handbook.pdf,"{'title': 'marines. dodlive. mil/social-media', 'author': ['GJF Amos', 'SMM Barrett'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': 'Next to the activity privacy label choose the drop down list and select the level of privacy  you want. The most restrictive default level is “Friends except acquaintances” the least is “public'}",Google Scholar
C Grimaldi,Resolving the Circuit Split Over Consent Based Searches in Shared Living Spaces,,"The court should find that when there is ambiguity as to whether a person has the authority  to authorize the search of property under common authority, or property subjected to mutual",2017,"Int'l Comp., Policy & Ethics L. Rev.",https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/icpelr1&section=17,"{'title': 'Resolving the Circuit Split Over Consent Based Searches in Shared Living Spaces', 'author': ['C Grimaldi'], 'pub_year': '2017', 'venue': ""Int'l Comp., Policy & Ethics L. Rev."", 'abstract': 'The court should find that when there is ambiguity as to whether a person has the authority  to authorize the search of property under common authority, or property subjected to mutual'}",Google Scholar
C Batchelder,Busted mugs and bad lighting: Balancing First Amendment interests against claims for control of one's identity,,"for uses of their image, courts began to struggle with the privacy label originally attached to   A stark privacy label on claims by celebrities seemed disingenuous to courts, since these",2014,NA,https://conservancy.umn.edu/handle/11299/165422,"{'title': ""Busted mugs and bad lighting: Balancing First Amendment interests against claims for control of one's identity"", 'author': ['C Batchelder'], 'pub_year': '2014', 'venue': 'NA', 'abstract': 'for uses of their image, courts began to struggle with the privacy label originally attached to   A stark privacy label on claims by celebrities seemed disingenuous to courts, since these'}",Google Scholar
B Bruni,The Right of Publicity as Market Regulator in the Age of Social Media,,"The right of publicity is defined as a property right in one's name and likeness, I and stems  from the idea that each of us should be able to wield control over how representations of",2019,Cardozo L. Rev.,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/cdozo41&section=55,"{'title': 'The Right of Publicity as Market Regulator in the Age of Social Media', 'author': ['B Bruni'], 'pub_year': '2019', 'venue': 'Cardozo L. Rev.', 'abstract': ""The right of publicity is defined as a property right in one's name and likeness, I and stems  from the idea that each of us should be able to wield control over how representations of""}",Google Scholar
U Salama,"An Integrative Analytical Framework for Internet of Things Security, Forensics and Intelligence",,The Internet of things (IoT) has recently become an important research topic because it  revolutionises our everyday life through integrating various sensors and objects to communicate,2022,NA,https://unsworks.unsw.edu.au/entities/publication/246dde80-1bf3-4153-9e99-4c6ce8432da1/full,"{'title': 'An Integrative Analytical Framework for Internet of Things Security, Forensics and Intelligence', 'author': ['U Salama'], 'pub_year': '2022', 'venue': 'NA', 'abstract': 'The Internet of things (IoT) has recently become an important research topic because it  revolutionises our everyday life through integrating various sensors and objects to communicate'}",Google Scholar
DJ Anthony,Caught in the middle: Transsexual marriage and the disconnect between sex and legal sex,,"Professor Laurence Tribe has argued that ""autonomy with respect to the most personal of  life choices"" is ""the single core common to all of what passes under the privacy label."" Gender",2011,Tex. J. Women & L.,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/tjwl21&section=10,"{'title': 'Caught in the middle: Transsexual marriage and the disconnect between sex and legal sex', 'author': ['DJ Anthony'], 'pub_year': '2011', 'venue': 'Tex. J. Women & L.', 'abstract': 'Professor Laurence Tribe has argued that ""autonomy with respect to the most personal of  life choices"" is ""the single core common to all of what passes under the privacy label."" Gender'}",Google Scholar
"R Schuster, JP Zhou, T Eisenhofer, P Grubbs",Learned Systems Security,,"A learned system uses machine learning (ML) internally to improve performance. We can  expect such systems to be vulnerable to some adversarial-ML attacks. Often, the learned",2022,arXiv preprint arXiv …,https://arxiv.org/abs/2212.10318,"{'title': 'Learned Systems Security', 'author': ['R Schuster', 'JP Zhou', 'T Eisenhofer', 'P Grubbs'], 'pub_year': '2022', 'venue': 'arXiv preprint arXiv …', 'abstract': 'A learned system uses machine learning (ML) internally to improve performance. We can  expect such systems to be vulnerable to some adversarial-ML attacks. Often, the learned'}",Google Scholar
T Cadenhead,Secured data provenance using semantic web technologies,,"Provenance is the lineage of a resource (or data item) and is essential for various domains,  including healthcare, intelligence, E-science, legal and industry. The ongoing mutual",2011,NA,https://search.proquest.com/openview/021c6e00992f9324a86fa19fde367fa1/1?pq-origsite=gscholar&cbl=18750,"{'title': 'Secured data provenance using semantic web technologies', 'author': ['T Cadenhead'], 'pub_year': '2011', 'venue': 'NA', 'abstract': 'Provenance is the lineage of a resource (or data item) and is essential for various domains,  including healthcare, intelligence, E-science, legal and industry. The ongoing mutual'}",Google Scholar
YS Tseng,Protecting the First Amendment Rights of Video Games from Lanham Act and Right of Publicity Claims,,But applying the privacy label to these cases became a stumbling block in cases where  celebrities sued for the unauthorized use of their name or likeness.,2021,Pepp. L. Rev.,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/pepplr48&section=22,"{'title': 'Protecting the First Amendment Rights of Video Games from Lanham Act and Right of Publicity Claims', 'author': ['YS Tseng'], 'pub_year': '2021', 'venue': 'Pepp. L. Rev.', 'abstract': 'But applying the privacy label to these cases became a stumbling block in cases where  celebrities sued for the unauthorized use of their name or likeness.'}",Google Scholar
"J Kraemer, R Feasey",Device Neutrality: Policy Recommendations for a Regulation of Mobile Devices for General Internet Access,,"So, for example, if an app in the app store would have to provide a ‘privacy label’ in order  to show which personal data it collects, then the same would have to hold true for pre-installed",2021,Available at SSRN 4090581,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4090581,"{'title': 'Device Neutrality: Policy Recommendations for a Regulation of Mobile Devices for General Internet Access', 'author': ['J Kraemer', 'R Feasey'], 'pub_year': '2021', 'venue': 'Available at SSRN 4090581', 'abstract': 'So, for example, if an app in the app store would have to provide a ‘privacy label’ in order  to show which personal data it collects, then the same would have to hold true for pre-installed'}",Google Scholar
"PS Akash, J Huang, KCC Chang, Y Li, L Popa",Domain Representative Keywords Selection: A Probabilistic Approach,,"We propose a probabilistic approach to select a subset of a \textit{target domain representative  keywords} from a candidate set, contrasting with a context domain. Such a task is crucial",2022,arXiv preprint arXiv …,https://arxiv.org/abs/2203.10365,"{'title': 'Domain Representative Keywords Selection: A Probabilistic Approach', 'author': ['PS Akash', 'J Huang', 'KCC Chang', 'Y Li', 'L Popa'], 'pub_year': '2022', 'venue': 'arXiv preprint arXiv …', 'abstract': 'We propose a probabilistic approach to select a subset of a \\textit{target domain representative  keywords} from a candidate set, contrasting with a context domain. Such a task is crucial'}",Google Scholar
OR Goodenough,Governance for Cloud Computing: The Role of Public and Private Rulemaking in Promoting the Growth of a New Industry,,"grouped with them under the “privacy” label. Still, it is sometimes useful to distinguish it from  its companions. In some instances there are things about ourselves or about our companies",2013,Vermont Law School Research Paper,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2342594,"{'title': 'Governance for Cloud Computing: The Role of Public and Private Rulemaking in Promoting the Growth of a New Industry', 'author': ['OR Goodenough'], 'pub_year': '2013', 'venue': 'Vermont Law School Research Paper', 'abstract': 'grouped with them under the “privacy” label. Still, it is sometimes useful to distinguish it from  its companions. In some instances there are things about ourselves or about our companies'}",Google Scholar
"L Gastaldi, FP Appio, M Corso",Managing the exploration-exploitation paradox in healthcare: Three complementary paths to leverage on the digital transformation,,Purpose The purpose of this paper is to understand how digital technologies can help healthcare  organisations and improve the exploration-exploitation paradox over time. The authors,2018,Business Process …,https://www.emerald.com/insight/content/doi/10.1108/BPMJ-04-2017-0092/full/html,"{'title': 'Managing the exploration-exploitation paradox in healthcare: Three complementary paths to leverage on the digital transformation', 'author': ['L Gastaldi', 'FP Appio', 'M Corso'], 'pub_year': '2018', 'venue': 'Business Process …', 'abstract': 'Purpose The purpose of this paper is to understand how digital technologies can help healthcare  organisations and improve the exploration-exploitation paradox over time. The authors'}",Google Scholar
L Leiter,Exploring perceptions of disaster and preparedness: A participatory photo-documentation study in Kachina Village households,,I believe that allowing the privacy label to stick unquestioned also conforms too neatly to the  prerogative of the neoliberal state to dump the responsibilities of reproduction on the highly-,2016,NA,https://search.proquest.com/openview/9aabb9aaa5506fcb34255a8af4e595c7/1?pq-origsite=gscholar&cbl=18750,"{'title': 'Exploring perceptions of disaster and preparedness: A participatory photo-documentation study in Kachina Village households', 'author': ['L Leiter'], 'pub_year': '2016', 'venue': 'NA', 'abstract': 'I believe that allowing the privacy label to stick unquestioned also conforms too neatly to the  prerogative of the neoliberal state to dump the responsibilities of reproduction on the highly-'}",Google Scholar
A Lindeberg,Hacking Into Someone's Home using Radio Waves: Ethical Hacking of Securitas' Alarm System,,"In their master thesis, author Diermen examines the design of an IoT privacy label, to help  consumers recognize the security risks of the products they bring into their home [16]. The",2021,NA,https://www.diva-portal.org/smash/record.jsf?pid=diva2:1600180,"{'title': ""Hacking Into Someone's Home using Radio Waves: Ethical Hacking of Securitas' Alarm System"", 'author': ['A Lindeberg'], 'pub_year': '2021', 'venue': 'NA', 'abstract': 'In their master thesis, author Diermen examines the design of an IoT privacy label, to help  consumers recognize the security risks of the products they bring into their home [16]. The'}",Google Scholar
J Gunaratne,Influencing Financial Decision-Making through Human-Computer Interaction Design Interventions,,Society is increasingly dependent on the use of technology to facilitate transactions and guide  individual decision-making. The ubiquity of computing technology and its great availability,2017,NA,https://search.proquest.com/openview/64bafcba34c961c4222f3c46193ffc96/1?pq-origsite=gscholar&cbl=18750,"{'title': 'Influencing Financial Decision-Making through Human-Computer Interaction Design Interventions', 'author': ['J Gunaratne'], 'pub_year': '2017', 'venue': 'NA', 'abstract': 'Society is increasingly dependent on the use of technology to facilitate transactions and guide  individual decision-making. The ubiquity of computing technology and its great availability'}",Google Scholar
AJ Sivesind,Community Coordinated Artificial Intelligence: Towards a unified framework for the democratisation of AI,,"Contributing to an emerging AI-paradigm shift, this thesis presents a unified socio-technical  framework called Community Coordinated Artificial Intelligence (CoCoAI), which expands",2021,NA,https://www.duo.uio.no/handle/10852/87204,"{'title': 'Community Coordinated Artificial Intelligence: Towards a unified framework for the democratisation of AI', 'author': ['AJ Sivesind'], 'pub_year': '2021', 'venue': 'NA', 'abstract': 'Contributing to an emerging AI-paradigm shift, this thesis presents a unified socio-technical  framework called Community Coordinated Artificial Intelligence (CoCoAI), which expands'}",Google Scholar
"B Rosskamp, P Delvenne",Change Records,,"This paper is written as part of the PACITA project, and discusses the past, present and  future Cross-European work going on in the field of Parliamentary Technology Assessment.",NA,NA,https://epub.oeaw.ac.at/buecher/eOnlyEditions/Institut%20f%C3%BCr%20Technologiefolgenabsch%C3%A4tzung/projektberichte/PACITA%20D%202%204_Cross%20European%20TA_FINAL_incl%20annex.pdf?ts=1544258549243,"{'title': 'Change Records', 'author': ['B Rosskamp', 'P Delvenne'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': 'This paper is written as part of the PACITA project, and discusses the past, present and  future Cross-European work going on in the field of Parliamentary Technology Assessment.'}",Google Scholar
MK Ryan,An investigation of IoT device vulnerabilities and how to prevent them in the future,,The Internet of Things (IoT) is an increasingly widespread phenomenon involving computing  devices that interact with the real world and also network with other computers. These types,2023,NA,https://search.proquest.com/openview/6b3ce2df641fc9563857980f5ff55121/1?pq-origsite=gscholar&cbl=18750&diss=y,"{'title': 'An investigation of IoT device vulnerabilities and how to prevent them in the future', 'author': ['MK Ryan'], 'pub_year': '2023', 'venue': 'NA', 'abstract': 'The Internet of Things (IoT) is an increasingly widespread phenomenon involving computing  devices that interact with the real world and also network with other computers. These types'}",Google Scholar
"TC Lin, Y Liu, F Lu",Happy App Happy Tip: The Return Predictability from Amusement Apps Downloads Around the World,,"As individual investors increasingly rely on smartphones for their daily lives, we construct a  measure of real-time investor sentiment based on global amusement app downloads. We",2024,Available at SSRN 4744745,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4744745,"{'title': 'Happy App Happy Tip: The Return Predictability from Amusement Apps Downloads Around the World', 'author': ['TC Lin', 'Y Liu', 'F Lu'], 'pub_year': '2024', 'venue': 'Available at SSRN 4744745', 'abstract': 'As individual investors increasingly rely on smartphones for their daily lives, we construct a  measure of real-time investor sentiment based on global amusement app downloads. We'}",Google Scholar
"JF DeFranco, M Kassab",What Every Engineer Should Know about the Internet of Things,,"Internet of Things (IoT) products and cyber-physical systems (CPS) are being utilized in  almost every discipline and there continues to be significant increases in spending on design,",2021,NA,https://www.taylorfrancis.com/books/mono/10.1201/9781003027799/every-engineer-know-internet-things-joanna-defranco-mohamad-kassab,"{'title': 'What Every Engineer Should Know about the Internet of Things', 'author': ['JF DeFranco', 'M Kassab'], 'pub_year': '2021', 'venue': 'NA', 'abstract': 'Internet of Things (IoT) products and cyber-physical systems (CPS) are being utilized in  almost every discipline and there continues to be significant increases in spending on design,'}",Google Scholar
SR Moore,Cybersecurity for Android Applications,,"Drawing from nutrition food labels, the team constructed a privacy label so information could  be found more easily in a familiar format. Another approach to permissions in Agarwal and",2017,NA,https://search.proquest.com/openview/181354f5827dde0221b4be17af45dd37/1?pq-origsite=gscholar&cbl=18750,"{'title': 'Cybersecurity for Android Applications', 'author': ['SR Moore'], 'pub_year': '2017', 'venue': 'NA', 'abstract': 'Drawing from nutrition food labels, the team constructed a privacy label so information could  be found more easily in a familiar format. Another approach to permissions in Agarwal and'}",Google Scholar
SS Rupra,A CLOUD COMPUTING SECURITY ASSESSMENT FRAMEWORK FOR SMALL AND MEDIUM ENTERPRISES IN KENYA,,Cloud computing plays a very important role in the development of business and competitive  edge for many organisations including SMEs. Cloud computing is considered to be a very,2020,NA,http://library.kabarak.ac.ke/handle/123456789/650,"{'title': 'A CLOUD COMPUTING SECURITY ASSESSMENT FRAMEWORK FOR SMALL AND MEDIUM ENTERPRISES IN KENYA', 'author': ['SS Rupra'], 'pub_year': '2020', 'venue': 'NA', 'abstract': 'Cloud computing plays a very important role in the development of business and competitive  edge for many organisations including SMEs. Cloud computing is considered to be a very'}",Google Scholar
"G Gupta, S Joseph",Challenges in corporate governance in the implementation of GDPR for it start-up companies in india,,"compliance: Developing a GDPR privacy label. Americas Conference on Information Systems  2018: Digital Disruption, AMCIS 2018, 1–5 GDPR and Corporate Governance The Role of",2020,PalArch's Journal of Archaeology of Egypt …,https://archives.palarch.nl/index.php/jae/article/download/3999/3938,"{'title': 'Challenges in corporate governance in the implementation of GDPR for it start-up companies in india', 'author': ['G Gupta', 'S Joseph'], 'pub_year': '2020', 'venue': ""PalArch's Journal of Archaeology of Egypt …"", 'abstract': 'compliance: Developing a GDPR privacy label. Americas Conference on Information Systems  2018: Digital Disruption, AMCIS 2018, 1–5 GDPR and Corporate Governance The Role of'}",Google Scholar
I Elevant,Consent as a basis of processing personal data in the Internet of Things,,Consent as a basis of processing personal data in the Internet of Things Page 1 1 Consent  as a basis of processing personal data in the Internet of Things Master’s thesis University of,2021,Communications,https://helda.helsinki.fi/bitstream/10138/337503/3/Elevant_Ina_thesis_2021.pdf,"{'title': 'Consent as a basis of processing personal data in the Internet of Things', 'author': ['I Elevant'], 'pub_year': '2021', 'venue': 'Communications', 'abstract': 'Consent as a basis of processing personal data in the Internet of Things Page 1 1 Consent  as a basis of processing personal data in the Internet of Things Master’s thesis University of'}",Google Scholar
Y Xu,Supporting User Interaction and Social Relationship Formation in a Collaborative Online Shopping Context,,"The combination of online shopping and social media allow people with similar shopping  interests and experiences to share, comment, and discuss about shopping from anywhere and",2020,NA,https://search.proquest.com/openview/2c4a2c35cbf91f525e4799fc1cdaf406/1?pq-origsite=gscholar&cbl=18750&diss=y,"{'title': 'Supporting User Interaction and Social Relationship Formation in a Collaborative Online Shopping Context', 'author': ['Y Xu'], 'pub_year': '2020', 'venue': 'NA', 'abstract': 'The combination of online shopping and social media allow people with similar shopping  interests and experiences to share, comment, and discuss about shopping from anywhere and'}",Google Scholar
"J Marchessault, K Sawchuk","Wild science: reading feminism, medicine and the media",,"Wild Science investigates the world-wide boom in 'health culture'. While self-help health  books and medical dramas are popular around the globe, we are bombarded with daily media",2013,NA,https://api.taylorfrancis.com/content/books/mono/download?identifierName=doi&identifierValue=10.4324/9781315008851&type=googlepdf,"{'title': 'Wild science: reading feminism, medicine and the media', 'author': ['J Marchessault', 'K Sawchuk'], 'pub_year': '2013', 'venue': 'NA', 'abstract': ""Wild Science investigates the world-wide boom in 'health culture'. While self-help health  books and medical dramas are popular around the globe, we are bombarded with daily media""}",Google Scholar
J Dearing,China farming boom has left ecosystems in danger of total collapse,,"< div class="" fit-vids-style"">┬¡< style>. fluid-width-video-wrapper { width: 100%; position:  relative; padding: 0;}. fluid-width-video-wrapper iframe,. fluid-width-video-wrapper object,. fluid-",2015,The Conversation,https://eprints.soton.ac.uk/377020/2/china-farming-boom-has-left-ecosystems-in-danger-of-total-collapse-38058,"{'title': 'China farming boom has left ecosystems in danger of total collapse', 'author': ['J Dearing'], 'pub_year': '2015', 'venue': 'The Conversation', 'abstract': '< div class="" fit-vids-style"">┬¡< style>. fluid-width-video-wrapper { width: 100%; position:  relative; padding: 0;}. fluid-width-video-wrapper iframe,. fluid-width-video-wrapper object,. fluid-'}",Google Scholar
"N Hasan, C Watson, J Basu",Get ahead! Specialties: OSCEs and Data Interpretation,,"Get ahead! SPECIALTIES OSCEs and Data Interpretation is an invaluable revision tool for  all medical students preparing for final exams. Detailed scenarios covering obstetrics,",2015,NA,https://books.google.com/books?hl=en&lr=&id=dmEDCwAAQBAJ&oi=fnd&pg=PP1&dq=%22privacy+label%22&ots=loYY0eKKgu&sig=52ro2QG77tQEcMuzjOlQ-3yNrjA,"{'title': 'Get ahead! Specialties: OSCEs and Data Interpretation', 'author': ['N Hasan', 'C Watson', 'J Basu'], 'pub_year': '2015', 'venue': 'NA', 'abstract': 'Get ahead! SPECIALTIES OSCEs and Data Interpretation is an invaluable revision tool for  all medical students preparing for final exams. Detailed scenarios covering obstetrics,'}",Google Scholar
NL Bingham,En (Gendering) Policy: Gender Policies in Former Soviet Republics,,"This dissertation examines gender policies in former Soviet republics. Gender policies are  depicted as traditional policies (including such policies as child support, spousal support, and",2012,NA,https://search.proquest.com/openview/1a392cbb9eebc92c0c026608c92d4c0b/1?pq-origsite=gscholar&cbl=18750&diss=y,"{'title': 'En (Gendering) Policy: Gender Policies in Former Soviet Republics', 'author': ['NL Bingham'], 'pub_year': '2012', 'venue': 'NA', 'abstract': 'This dissertation examines gender policies in former Soviet republics. Gender policies are  depicted as traditional policies (including such policies as child support, spousal support, and'}",Google Scholar
Α Ζάννη,Ζητήματα λόγω της εκμετάλλευσης προσωπικών δεδομένων,,Η πληθώρα ευρωπαϊκών νομοθετημάτων για την προστασία των προσωπικών δεδομένων  των Ευρωπαίων πολιτών που προηγήθηκαν χρονικά του Γενικού Κανονισμού Ε. Ε 2016/679,2019,NA,https://search.proquest.com/openview/5cc0265e72c493337148b0a9f2975d2c/1?pq-origsite=gscholar&cbl=2026366&diss=y,"{'title': 'Ζητήματα λόγω της εκμετάλλευσης προσωπικών δεδομένων', 'author': ['Α Ζάννη'], 'pub_year': '2019', 'venue': 'NA', 'abstract': 'Η πληθώρα ευρωπαϊκών νομοθετημάτων για την προστασία των προσωπικών δεδομένων  των Ευρωπαίων πολιτών που προηγήθηκαν χρονικά του Γενικού Κανονισμού Ε. Ε 2016/679'}",Google Scholar
MMB Azambuja,Internet das coisas e as rela?? es de consumo: a necessidade de ressignifica?? oe efetividade do direito? privacidade,,"The evolution of technology has left Law operators more and more attentive to the new  configurations of legal relations that have been changing year after year. For that, it is necessary",2021,NA,https://bdtd.ibict.br/vufind/Record/P_RS_9066815ff55c2a25ab39ae0ec7d45a28,"{'title': 'Internet das coisas e as rela?? es de consumo: a necessidade de ressignifica?? oe efetividade do direito? privacidade', 'author': ['MMB Azambuja'], 'pub_year': '2021', 'venue': 'NA', 'abstract': 'The evolution of technology has left Law operators more and more attentive to the new  configurations of legal relations that have been changing year after year. For that, it is necessary'}",Google Scholar
S Boukoros,Multidimensional Privacy Quantification for User Empowerment,,"As we are living in an interconnected world, serious privacy concerns have been raised due  to the ever increasing data collection. As a result, many privacy-preserving methodologies",2019,NA,https://tuprints.ulb.tu-darmstadt.de/8716/7/Spyros_Boukoros_PhD.pdf,"{'title': 'Multidimensional Privacy Quantification for User Empowerment', 'author': ['S Boukoros'], 'pub_year': '2019', 'venue': 'NA', 'abstract': 'As we are living in an interconnected world, serious privacy concerns have been raised due  to the ever increasing data collection. As a result, many privacy-preserving methodologies'}",Google Scholar
"M Danilescu, V Beshliu",Trust-based modeling mac-type access control through access and actions control policies,,"An object in a domain to which a MAC policy applies, in addition to the privacy label, the  domain to which it belongs, is attached for each action it can support, a trust value that a user",2021,Journal of Engineering Sciences,https://ibn.idsi.md/vizualizare_articol/132771,"{'title': 'Trust-based modeling mac-type access control through access and actions control policies', 'author': ['M Danilescu', 'V Beshliu'], 'pub_year': '2021', 'venue': 'Journal of Engineering Sciences', 'abstract': 'An object in a domain to which a MAC policy applies, in addition to the privacy label, the  domain to which it belongs, is attached for each action it can support, a trust value that a user'}",Google Scholar
DRG Pontes,Geração de rótulo de privacidade por palavras-chaves e casamento de padrões,,"To generate the Privacy Label, a study was made in a set of  by cells in the Privacy Label.  Using word comparison  For each category we find, we show it in the Privacy Label. To",2016,NA,https://repositorio.ufscar.br/handle/ufscar/8730,"{'title': 'Geração de rótulo de privacidade por palavras-chaves e casamento de padrões', 'author': ['DRG Pontes'], 'pub_year': '2016', 'venue': 'NA', 'abstract': 'To generate the Privacy Label, a study was made in a set of  by cells in the Privacy Label.  Using word comparison  For each category we find, we show it in the Privacy Label. To'}",Google Scholar
"ВА Альшаев, АЮ Цветков",Разработка модуля разграничения сетевого трафика для повышения уровня защиты в платформе виртуализации vmware vsphere,,"В данной статье был рассмотрен вопрос, касающийся повышения защиты информации  в виртуальной инфраструктуре. В виду быстрого развития виртуализации, этот",2020,… в науке и образовании (АПИНО 2020),https://elibrary.ru/item.asp?id=44603962,"{'title': 'Разработка модуля разграничения сетевого трафика для повышения уровня защиты в платформе виртуализации vmware vsphere', 'author': ['ВА Альшаев', 'АЮ Цветков'], 'pub_year': '2020', 'venue': '… в науке и образовании (АПИНО 2020)', 'abstract': 'В данной статье был рассмотрен вопрос, касающийся повышения защиты информации  в виртуальной инфраструктуре. В виду быстрого развития виртуализации, этот'}",Google Scholar
C Kühnl,Persönlichkeitsschutz 2.0: Profilbildung und-nutzung durch Soziale Netzwerke am Beispiel von Facebook im Rechtsvergleich zwischen Deutschland und den …,,"Web 2.0-Dienste, allen voran Soziale Netzwerke, verfügen über reichhaltige Nutzerdaten.  Durch Datenanalysen können Profile mit neuen, weitreichenden Erkenntnissen über den",2016,NA,https://books.google.com/books?hl=en&lr=&id=Ju0sDQAAQBAJ&oi=fnd&pg=PR5&dq=%22privacy+label%22&ots=CUETyAfE6r&sig=RFw8rcw0YCcTwSQqcf1vBa4_pcs,"{'title': 'Persönlichkeitsschutz 2.0: Profilbildung und-nutzung durch Soziale Netzwerke am Beispiel von Facebook im Rechtsvergleich zwischen Deutschland und den …', 'author': ['C Kühnl'], 'pub_year': '2016', 'venue': 'NA', 'abstract': 'Web 2.0-Dienste, allen voran Soziale Netzwerke, verfügen über reichhaltige Nutzerdaten.  Durch Datenanalysen können Profile mit neuen, weitreichenden Erkenntnissen über den'}",Google Scholar
MNV Blacutt,Análisis de caso para formular el Modelo de prevención de fuga de información para dispositivos IoT en redes domésticas,,El Internet de las cosas convierte el mundo físico en un entorno de información donde  dispositivos IoT recolectan y envían datos generados por un usuario y su entorno. Por la,2020,INF-FCPN-PGI Revista PGI,https://ojs.umsa.bo/ojs/index.php/inf_fcpn_pgi/article/view/111,"{'title': 'Análisis de caso para formular el Modelo de prevención de fuga de información para dispositivos IoT en redes domésticas', 'author': ['MNV Blacutt'], 'pub_year': '2020', 'venue': 'INF-FCPN-PGI Revista PGI', 'abstract': 'El Internet de las cosas convierte el mundo físico en un entorno de información donde  dispositivos IoT recolectan y envían datos generados por un usuario y su entorno. Por la'}",Google Scholar
"DA Wydler, G Pataro",Seguridad y privacidad para el consumidor de IoT,,"La seguridad y privacidad de la información generan numerosos desafíos para IoT, pero  mientras que a nivel corporativo e industrial los expertos en seguridad informática pueden",NA,NA,http://bibliotecadigital.econ.uba.ar/download/tpos/1502-1996_WydlerDA.pdf,"{'title': 'Seguridad y privacidad para el consumidor de IoT', 'author': ['DA Wydler', 'G Pataro'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': 'La seguridad y privacidad de la información generan numerosos desafíos para IoT, pero  mientras que a nivel corporativo e industrial los expertos en seguridad informática pueden'}",Google Scholar
HH Kielman,"Kielman, HH",,"Ter verkrijging van de graad van Doctor aan de Universiteit Leiden, op gezag van de Rector  Magnificus prof. mr. PF van der Heijden, hoogleraar in de faculteit der Rechtsgeleerdheid,",NA,NA,https://scholarlypublications.universiteitleiden.nl/access/item%3A2862386/download,"{'title': 'Kielman, HH', 'author': ['HH Kielman'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': 'Ter verkrijging van de graad van Doctor aan de Universiteit Leiden, op gezag van de Rector  Magnificus prof. mr. PF van der Heijden, hoogleraar in de faculteit der Rechtsgeleerdheid,'}",Google Scholar
J Pierre,Le cadre privatif: des données aux contextes: approche interdimensionnelle des enjeux de médiation de la vie privée,,Nous construisons une analyse des dispositifs identitaires contemporains (dont les réseaux  socionumériques) sur plusieurs niveaux : au niveau informatique (modèle conceptuel,2013,NA,https://theses.hal.science/tel-01334055/,"{'title': 'Le cadre privatif: des données aux contextes: approche interdimensionnelle des enjeux de médiation de la vie privée', 'author': ['J Pierre'], 'pub_year': '2013', 'venue': 'NA', 'abstract': 'Nous construisons une analyse des dispositifs identitaires contemporains (dont les réseaux  socionumériques) sur plusieurs niveaux : au niveau informatique (modèle conceptuel'}",Google Scholar
"MF MARTIN-JUCHAT, MB MIÈGE, MD BOULLIER",Le cadre privatif: des données aux contextes,,Nous construisons une analyse des dispositifs identitaires contemporains (dont les réseaux  socionumériques) sur plusieurs niveaux: au niveau informatique (modèle conceptuel,NA,NA,https://theses.hal.science/docs/00/96/87/82/PDF/28055_PIERRE_2013_archivage.pdf,"{'title': 'Le cadre privatif: des données aux contextes', 'author': ['MF MARTIN-JUCHAT', 'MB MIÈGE', 'MD BOULLIER'], 'venue': 'NA', 'pub_year': 'NA', 'abstract': 'Nous construisons une analyse des dispositifs identitaires contemporains (dont les réseaux  socionumériques) sur plusieurs niveaux: au niveau informatique (modèle conceptuel'}",Google Scholar
